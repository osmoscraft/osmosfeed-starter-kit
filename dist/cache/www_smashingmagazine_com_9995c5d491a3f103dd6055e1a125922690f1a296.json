{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Articles on Smashing Magazine — For Web Designers And Developers",
  "feed_url": "https://www.smashingmagazine.com/feed/",
  "items": [
    {
      "id": "https://smashingmagazine.com/2022/06/voice-control-usability-considerations-partially-visually-hidden-link-names/",
      "url": "https://smashingmagazine.com/2022/06/voice-control-usability-considerations-partially-visually-hidden-link-names/",
      "title": "Voice Control Usability Considerations For Partially Visually Hidden Link Names",
      "summary": "Partially visually hidden link names may be good for people who use screen readers, but they can be problematic for those who rely on voice control software. Here’s a suggestion on how to solve this.",
      "content_html": "<p>Digital accessibility tends to be taught through the lens of how your experience works (or fails to work) with a screen reader. It makes sense to think that, if <a href=\"https://alistapart.com/article/semantics-to-screen-readers/\">it works for a screen reader</a>, it will also work for a lot of other kinds of assistive technology.</p>\n<p>However, this approach also indirectly reinforces the narrative that blindness is the majority experience. Within this narrative, there is also some subtlety in the fact that <a href=\"https://adrianroselli.com/2017/02/not-all-screen-reader-users-are-blind.html\">not everyone who uses a screen reader is blind</a>. </p>\n<p><a href=\"https://www.who.int/news-room/fact-sheets/detail/depression\">The majority disability experience is actually depression</a>, which is a complicated disability with highly variable symptoms. One of the most notable symptoms of depression is that it negatively impacts your cognition, which affects your ability to understand things.</p>\n<p>The other salient bit is that the majority experience is not default. The point I’m getting at is that overcorrecting for one form of disability may unintentionally negatively impact the experience for other forms of disability — voice control software being one example.</p>\nUnique Link Names\n<p>Making each link’s accessible name unique is an important thing to do. It helps clarify where each link goes to someone who is navigating via a specialized screen reader browsing mode. For example, all major screen readers have the ability to list all the links on the current page or view, with the links being removed from their surrounding text content and context.</p>\n<p>Eleven links called “learn more” don’t make a lot of sense when separated from their surrounding context. It’s far better to tell the reader what they’ll be learning about:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4601bced-d2e3-463d-8f4a-f01e1179e692/1-voice-control-usability-considerations-partially-visually-hidden-link-names.png\" /></p>\nVisually Hidden Text\n<p>If you use CSS libraries such as <a href=\"https://getbootstrap.com/docs/4.1/getting-started/accessibility/#visually-hidden-content\">Bootstrap</a> or <a href=\"https://tailwindcss.com/docs/screen-readers\">Tailwind</a>, you may be familiar with a specialized class that a screen reader can read, but is not displayed visually. These classes help provide additional context, such as supplying <a href=\"https://webaim.org/projects/screenreadersurvey9/#heading\">additional heading elements to help with way-finding</a>.</p>\n<pre><code>&lt;h2 class=\"sr-only\"&gt;\n  Footer\n&lt;/h2&gt;\n</code></pre>\n\nPartially Visually Hidden Text\n<p>Another thing visually hidden classes are commonly used for is to hide the portion of an interactive control that makes its name unique. A common pattern for this is a call-to-action (CTA) link in a card component:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/10715f4a-3f5d-41d5-81e9-0102f7bd8314/2-v2-voice-control-usability-considerations-partially-visually-hidden-link-names.jpg\" /></p>\n<h3>Who Uses It?</h3>\n<p>There are more people who use voice control than you’d think. If you’ve ever asked Siri to set a timer, congratulations! You’re a voice control user!</p>\n<p>That being said, software like Voice Control, Dragon, and Talon are designed for more long-form, specialized use. <a href=\"https://tetralogical.com/blog/2021/11/15/browsing-with-speech-recognition/\">People who use these applications</a> may temporarily or permanently, and circumstantially or biologically be:</p>\n<ul>\n<li>Fully or partially paralyzed;</li>\n<li>Unable to use their hands;</li>\n<li>Unable to make fine motor movements;</li>\n<li>Unable to make repetitive movements over a long duration;</li>\n<li>Operating with lowered cognition.</li>\n</ul>\n<p>Disability is also not a binary state, so it is entirely possible (and relatively common) that multiple disability conditions may be present at any given time.  </p>\nWorkarounds\n<p>Some voice control software has the functionality to work around this issue, the same way screen readers do. Dragon, for example, uses heuristics to identify links that contain the term “learn more.” It then lists a number for each link with that term, which you can then say “choose number” to activate.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5f6b1202-b73a-45b5-b3ec-c8c28f4829c2/3-voice-control-usability-considerations-partially-visually-hidden-link-names.jpg\" /></p>\n<p>If you need to update your existing work to accommodate these kinds of real-world considerations, you’ll probably have to collaborate with content writers, developers, and project managers. <a href=\"https://uxdesign.cc/design-is-about-facilitation-not-creation-c268e76ce1fd\">Design thrives in this kind of collaborative environment</a>, where you can identify and work with the limits of the systems you work inside of.</p>\n<p>Sometimes you’ll be able to tweak what you already have. Sometimes you’ll have to create net-new content. Sometimes you’ll even have to throw it all out and go back to the drawing board. These efforts all speak to the value of a <a href=\"https://applitools.com/blog/shifting-accessibility-testing-to-the-left/\">Shift Left methodology</a>, where these kinds of considerations are named and dealt with early in the conception phase.</p>\nHow Do We Make Sure Our Experiences Are Easy To Use By Voice Control Software?\n<p>For interactive controls such as links and buttons, you’ll want to:</p>\n<ul>\n<li>Show the full text of the control’s name,</li>\n<li>Use a unique, accessible name for each control on the current page or view, </li>\n<li>Avoid overriding accessible names with <code>aria-label</code>, and</li>\n<li>Avoid using just a cryptic or abstract icon — especially if the control’s functionality is exotic.</li>\n</ul>\n<p>These steps will go a long way towards making using voice control software easier and more pleasant.  </p>\nIt’s Not Really About Voice Control Software\n<p>The three overarching themes that I hope you’re picking up on:</p>\n<ol>\n<li>Testing with a range of assistive technology is important to understanding actual support,</li>\n<li>Agency can be granted by letting go of control, and </li>\n<li>Design decisions carry a tremendous amount of power.</li>\n</ol>\n<p>Your designs need to be flexible and adaptable, as well as be able to accommodate the many different ways people can interact with them. This includes voice control, as well as numerous other forms of assistive technology.</p>\n<h3>Further Reading On Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/02/voice-user-interfaces-guide/\">Everything You Want To Know About Creating Voice User Interfaces</a>,” Nick Babich &amp; Gleb Kuznetsov </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/05/equivalent-experiences-part1/\">Equivalent Experiences: What Are They?</a>,” Eric Bailey</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/07/strong-case-for-accessibility/\">Making A Strong Case For Accessibility</a>,” Todd Libby</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/06/guide-windows-high-contrast-mode/\">The Guide To Windows High Contrast Mode</a>,” Cristian Díaz</li>\n</ul>",
      "content_text": "Digital accessibility tends to be taught through the lens of how your experience works (or fails to work) with a screen reader. It makes sense to think that, if it works for a screen reader, it will also work for a lot of other kinds of assistive technology.\nHowever, this approach also indirectly reinforces the narrative that blindness is the majority experience. Within this narrative, there is also some subtlety in the fact that not everyone who uses a screen reader is blind. \nThe majority disability experience is actually depression, which is a complicated disability with highly variable symptoms. One of the most notable symptoms of depression is that it negatively impacts your cognition, which affects your ability to understand things.\nThe other salient bit is that the majority experience is not default. The point I’m getting at is that overcorrecting for one form of disability may unintentionally negatively impact the experience for other forms of disability — voice control software being one example.\nUnique Link Names\nMaking each link’s accessible name unique is an important thing to do. It helps clarify where each link goes to someone who is navigating via a specialized screen reader browsing mode. For example, all major screen readers have the ability to list all the links on the current page or view, with the links being removed from their surrounding text content and context.\nEleven links called “learn more” don’t make a lot of sense when separated from their surrounding context. It’s far better to tell the reader what they’ll be learning about:\n\nVisually Hidden Text\nIf you use CSS libraries such as Bootstrap or Tailwind, you may be familiar with a specialized class that a screen reader can read, but is not displayed visually. These classes help provide additional context, such as supplying additional heading elements to help with way-finding.\n<h2 class=\"sr-only\">\n  Footer\n</h2>\n\n\nPartially Visually Hidden Text\nAnother thing visually hidden classes are commonly used for is to hide the portion of an interactive control that makes its name unique. A common pattern for this is a call-to-action (CTA) link in a card component:\n\nWho Uses It?\nThere are more people who use voice control than you’d think. If you’ve ever asked Siri to set a timer, congratulations! You’re a voice control user!\nThat being said, software like Voice Control, Dragon, and Talon are designed for more long-form, specialized use. People who use these applications may temporarily or permanently, and circumstantially or biologically be:\n\nFully or partially paralyzed;\nUnable to use their hands;\nUnable to make fine motor movements;\nUnable to make repetitive movements over a long duration;\nOperating with lowered cognition.\n\nDisability is also not a binary state, so it is entirely possible (and relatively common) that multiple disability conditions may be present at any given time.  \nWorkarounds\nSome voice control software has the functionality to work around this issue, the same way screen readers do. Dragon, for example, uses heuristics to identify links that contain the term “learn more.” It then lists a number for each link with that term, which you can then say “choose number” to activate.\n\nIf you need to update your existing work to accommodate these kinds of real-world considerations, you’ll probably have to collaborate with content writers, developers, and project managers. Design thrives in this kind of collaborative environment, where you can identify and work with the limits of the systems you work inside of.\nSometimes you’ll be able to tweak what you already have. Sometimes you’ll have to create net-new content. Sometimes you’ll even have to throw it all out and go back to the drawing board. These efforts all speak to the value of a Shift Left methodology, where these kinds of considerations are named and dealt with early in the conception phase.\nHow Do We Make Sure Our Experiences Are Easy To Use By Voice Control Software?\nFor interactive controls such as links and buttons, you’ll want to:\n\nShow the full text of the control’s name,\nUse a unique, accessible name for each control on the current page or view, \nAvoid overriding accessible names with aria-label, and\nAvoid using just a cryptic or abstract icon — especially if the control’s functionality is exotic.\n\nThese steps will go a long way towards making using voice control software easier and more pleasant.  \nIt’s Not Really About Voice Control Software\nThe three overarching themes that I hope you’re picking up on:\n\nTesting with a range of assistive technology is important to understanding actual support,\nAgency can be granted by letting go of control, and \nDesign decisions carry a tremendous amount of power.\n\nYour designs need to be flexible and adaptable, as well as be able to accommodate the many different ways people can interact with them. This includes voice control, as well as numerous other forms of assistive technology.\nFurther Reading On Smashing Magazine\n\n“Everything You Want To Know About Creating Voice User Interfaces,” Nick Babich & Gleb Kuznetsov \n“Equivalent Experiences: What Are They?,” Eric Bailey\n“Making A Strong Case For Accessibility,” Todd Libby\n“The Guide To Windows High Contrast Mode,” Cristian Díaz\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/54545ed9-3238-4807-b56c-3c2b18e576c7/voice-control-usability-considerations-partially-visually-hidden-link-names-sharing-card.jpg",
      "date_published": "2022-06-24T09:00:00.000Z",
      "date_modified": "2022-06-24T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/vanilla-javascript-gantt-chart-part-2/",
      "url": "https://smashingmagazine.com/2022/06/vanilla-javascript-gantt-chart-part-2/",
      "title": "How To Create A Vanilla JavaScript Gantt Chart: Adding Task Editing Features (Part 2)",
      "summary": "In this article, we will enhance the Gantt Chart component with some interaction possibilities for editing the jobs. In doing so, we will continue to work with Vanilla JS and Web Components and look at some JavaScript libraries that can greatly simplify the effort of developing a fully functional Gantt Chart.",
      "content_html": "<p>This article is a sponsored by <a href=\"https://www.bryntum.com?aw=smash-jun2022\">Bryntum</a></p>\n<p>In <a href=\"https://www.smashingmagazine.com/2021/08/interactive-gantt-chart-component-vanilla-javascript/\">Part 1</a> of this article, we developed a web component for an interactive Gantt Chart. Now we will enhance the Gantt Chart component with some interaction possibilities for editing the jobs: the job bars are made resizable by mouse-dragging, and we also implement an editing dialogue that can be used to modify the start and end dates of a job. In doing so, we will continue to work with Vanilla JS and Web Components. In the end, we will look at some JavaScript libraries that can greatly simplify the effort of developing a fully functional Gantt Chart.</p>\n<p>The following video shows what we are going to build in this article. First, we will add a drag handle on the right-hand side of each job that can be used for resizing the job bar (in the picture, it’s shown as a narrow gray vertical bar). In the next step, we will further extend the behavior of the jobs so that double-clicking on a job bar opens an editing dialogue.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4c84083c-2c30-45c6-ad3e-41ad88e136d7/2-vanilla-javascript-gantt-chart-part-2.png\" /></p>\n<p>Building on this, the functionality of the chart can be extended further.</p>\n<h3>JavaScript Gantt Chart By Bryntum</h3>\n<p>Another example that is worth considering is the <a href=\"https://www.bryntum.com/products/gantt?aw=smash-jun2022\">Bryntum Gantt</a> library, “a super-fast and fully customizable Gantt chart suite.” </p>\n<p>After downloading <a href=\"https://www.bryntum.com/download?aw=smash-jun2022\">a free trial of the library</a>, you will get a build folder with CSS and JavaScript files for creating interactive Gantt charts. You can integrate these files into your web app and then immediately configure your individual chart. A simple <a href=\"https://www.bryntum.com/docs/gantt/guide/Gantt/getting_started?aw=smash-jun2022\">getting started guide</a> provides a quick introduction to the component. For example, a basic chart could look like this with the Bryntum Gantt library:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d73c5155-481b-4767-9126-cc0317fd61c1/6-vanilla-javascript-gantt-chart-part-2.png\" /></p>\n<p>You will learn a lot about the numerous customization options in the <a href=\"https://www.bryntum.com/docs/gantt?aw=smash-jun2022\">full Bryntum Gantt documentation</a>. You will also explore how the tool can be integrated with popular frameworks like Angular, React, Vue, and many more or how to organize the loading and saving of data (CRUD data management). </p>\n<p>The <a href=\"https://bryntum.com/examples/gantt?aw=smash-jun2022\">examples section</a> provides a visual overview of the various features of Bryntum Gantt.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a0a6ccbf-3695-47ac-a606-8b76d0e2fe7a/7-vanilla-javascript-gantt-chart-part-2.png\" /></p>\n<p>They also offer <a href=\"https://www.bryntum.com/products/scheduler-pro?aw=smash-jun2022\">Bryntum Scheduler</a> — a library for resource planning.</p>\n<h3>JavaScript Gantt Chart By Webix</h3>\n<p>With <a href=\"https://webix.com/gantt/\">Webix Gantt</a>, another commercial Gantt library with rich functionality is available. The uncomplicated steps for installing, creating, and configuring a Gantt chart are <a href=\"https://docs.webix.com/gantt__installing.html\">documented in detail</a>.</p>\n<p>You can try out the tool in a <a href=\"https://webix.com/demos/gantt/\">full-screen interactive demo</a>:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/17c80535-2cdc-45bb-92b2-83c0e0f09537/8-vanilla-javascript-gantt-chart-part-2.png\" /></p>\nConclusion\n<p>Gantt Charts are a valuable visualization for project management, planning, and task organization. There are many ways to integrate Gantt Charts into a web application. In the last two articles, we built an interactive Gantt Chart from scratch, and in doing so, we learned a lot about CSS grids, Web Components, and JavaScript events. If you have more complex requirements, it is worth looking at the commercial JS libraries, which are often very powerful.</p>",
      "content_text": "This article is a sponsored by Bryntum\nIn Part 1 of this article, we developed a web component for an interactive Gantt Chart. Now we will enhance the Gantt Chart component with some interaction possibilities for editing the jobs: the job bars are made resizable by mouse-dragging, and we also implement an editing dialogue that can be used to modify the start and end dates of a job. In doing so, we will continue to work with Vanilla JS and Web Components. In the end, we will look at some JavaScript libraries that can greatly simplify the effort of developing a fully functional Gantt Chart.\nThe following video shows what we are going to build in this article. First, we will add a drag handle on the right-hand side of each job that can be used for resizing the job bar (in the picture, it’s shown as a narrow gray vertical bar). In the next step, we will further extend the behavior of the jobs so that double-clicking on a job bar opens an editing dialogue.\n\nBuilding on this, the functionality of the chart can be extended further.\nJavaScript Gantt Chart By Bryntum\nAnother example that is worth considering is the Bryntum Gantt library, “a super-fast and fully customizable Gantt chart suite.” \nAfter downloading a free trial of the library, you will get a build folder with CSS and JavaScript files for creating interactive Gantt charts. You can integrate these files into your web app and then immediately configure your individual chart. A simple getting started guide provides a quick introduction to the component. For example, a basic chart could look like this with the Bryntum Gantt library:\n\nYou will learn a lot about the numerous customization options in the full Bryntum Gantt documentation. You will also explore how the tool can be integrated with popular frameworks like Angular, React, Vue, and many more or how to organize the loading and saving of data (CRUD data management). \nThe examples section provides a visual overview of the various features of Bryntum Gantt.\n\nThey also offer Bryntum Scheduler — a library for resource planning.\nJavaScript Gantt Chart By Webix\nWith Webix Gantt, another commercial Gantt library with rich functionality is available. The uncomplicated steps for installing, creating, and configuring a Gantt chart are documented in detail.\nYou can try out the tool in a full-screen interactive demo:\n\nConclusion\nGantt Charts are a valuable visualization for project management, planning, and task organization. There are many ways to integrate Gantt Charts into a web application. In the last two articles, we built an interactive Gantt Chart from scratch, and in doing so, we learned a lot about CSS grids, Web Components, and JavaScript events. If you have more complex requirements, it is worth looking at the commercial JS libraries, which are often very powerful.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c3b4b9df-4f79-4eef-8ebc-2d1f86843d45/vanilla-javascript-gantt-chart-part-2.jpg",
      "date_published": "2022-06-23T11:30:00.000Z",
      "date_modified": "2022-06-23T11:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/how-test-mvp-within-weeks/",
      "url": "https://smashingmagazine.com/2022/06/how-test-mvp-within-weeks/",
      "title": "How To Test Your MVP Within 2 Weeks (Or Less)",
      "summary": "Looking for ways to test your product faster? In this article, Sergey Krasotin uncovers common mistakes startup product designers make that lead to longer MVP testing times. To test your product within two weeks or even less, follow these simple practices proven by Sergey’s experience with over 100 startups and accelerators.",
      "content_html": "<p>As both an entrepreneur and designer, I understand the ways startup founders think. Most of them start a project with visions of a perfect product in their head. However, in reality, a well-performing product will likely look way different than an initial concept. Instead of seeking perfection from the outset, beginning with a <strong>Minimum Viable Product (MVP)</strong> is the smartest route to success. An MVP is a crucial part of the product design process and allows businesses to validate their idea at the minimum expense and time.</p>\n<p>But while a lot of startups already know that an MVP is essential, a majority of the startups that I have mentored over the years have categorically encountered the same problem across all sectors of their process: an MVPs time to market. It simply takes too long for an idea to get into the hands of a consumer.</p>\n<p>Because the truth is, if an MVP testing process takes longer than two weeks, you’re probably doing something wrong. From my experience, most startup product designers make these three common mistakes that lead to longer MVP testing times: </p>\n<ul>\n<li>Using the wrong definition of a product value proposition;</li>\n<li>Underestimating the risks in a design hypothesis;</li>\n<li>Overloading the product with extra features.</li>\n</ul>\n<p>Why are startups missing these important steps in the process? I believe there are some tendencies among startups to pursue goals that fundamentally and often accidentally create a blind spot for these common mistakes. </p>\nMeasure And Lean Your MVP\n<p>In Eric Ries’s book <a href=\"https://www.amazon.com/Lean-Startup-Entrepreneurs-Continuous-Innovation/dp/0307887898/ref=sr_1_1?crid=1F2VQLD66U42X&amp;dchild=1&amp;keywords=the+lean+startup+eric+ries&amp;qid=1599634054&amp;sprefix=the+lean+startup%2Caps%2C970&amp;sr=8-1\"><em>The Lean Startup</em></a>, his definition of the MVP states:</p>\n<blockquote>“The minimum viable product is that version of a new product which allows a team to collect the maximum amount of validated learning about customers with the least effort.”<br /><br />— Eric Ries</blockquote>\n\n<p>When approaching a new idea, a startup founder might feel compelled to build upon the complexities of the function as a way of seeing their vision come to life rather than compose enough of the fundamental core components to create a hypothesis that they can then test. Ries differentiates between these approaches in his book when he discusses the process of measuring and leaning. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/99d7fd80-02b5-488e-8068-35cc1e6bc041/1-how-test-mvp-within-2-weeks.png\" /></p>\n<p>One of the major benefits of an MVP is lean production. It allows entrepreneurs and companies to produce a product that helps them prove their value proposition while also cutting costs. <strong>The clearer the theory, the stronger the MVP, and the more valuable information collected throughout the MVP process.</strong></p>\n<p>An MVP is not only designed to determine the viability of a product’s value proposition but also to test the product’s technical elements and target audiences. Even a simple MVP or acceptance testing that inquires whether the intended audience is interested in using the product in the first place could be more helpful to the progress of a startup’s journey to success than establishing the perfect product right away. </p>\n<p>The answers that an MVP can prove may be as simple as the MVP itself but highly valuable when continuing down a startup path that includes high-risk and particular investors. In the most general sense, a product is viable when it successfully fulfills a need in the market. And as easy as it seems, the most challenging part of this simple question is determining what exactly is necessary and what is not, as the features that you deem important to your product are, in fact, important. </p>\n<p>Discernment and clarity are not as easy as it seems, and a large part of being concise when approaching your MVP is keeping the time to market low. This is why I find the importance of testing your MVP within two weeks or less to be a crucial factor in achieving successful results. The key to a highly effective MVP is <strong>defining the problem as clearly and specifically as possible</strong>.</p>\nRenters Rewards: A Case Study\n<p>Before we dive into some tips, let’s first take a look at a case study that features a mobile app startup. This app is designed to help people find a property to rent while also providing them with opportunities to earn cashback. </p>\n<p>In this example, a startup saw an opportunity to develop a platform that lets people search for a rental, pay for the application, sign a lease, and continue to pay rent on the property indefinitely — all from one place. To take this product to the next level, we had an idea to offer people who pay on time a 1% cashback match if they pay before their rent due date.</p>\n<p>We wanted to test this hypothesis, so first, we had to develop our problem; in doing this, we could determine the approach and figure out a plan of action to receive valuable results in a couple of weeks. We decided that using the overarching idea of trying to test whether users would pay the rent early if they were offered a 1% cashback was not only too risky but a tough sell to landlords who could find it too costly upfront. </p>\n<p>Instead, we thought of a way to apply a slightly incremental change to the user’s digital experience that could provide us with preliminary information as to whether or not the users would be interested in this opportunity. We sent out emails to 100 app users stating that if they paid their rent before the end of the month, we would credit $20 to their accounts.</p>\n<p>The test was simple, concise, and succinct enough to give us quick and valuable feedback on our hypothesis, which then could set the app up for a border change to the platform and infrastructure. Over 80% of the app users who received the email opted for the $20 cashback and paid their rent early, determining that if the app were to implement this in a more grand scope, their success would likely be very high. In short, the incentive worked, and it was a quick and low-cost MVP that proved it.</p>\nFive Effective Strategies For Testing Your MVP\n<p>Now that you understand the importance of a short MVP time to market, we can explore some useful tips that will help you put forth the most successful product for your startup.</p>\n<h3>1. Properly Formulate A Product Value Proposition</h3>\n<p>The first and most important tip for any startup looking to test an MVP is to <strong>determine the most effective value proposition for your product</strong>. In regards to the aforementioned case study, we talked about how the value proposition began — as a 1% rewards incentive for app users. After understanding how the value prop would be most effectively tested — solidifying a quick and concise testing procedure — we came up with an MVP that highlighted only the most necessary measurable metrics. </p>\n<p>By determining that the same hypothesis could be discovered by providing 100 users with a $20 incentive as by giving 1% cashback to all users across the platform, we were able to concur that the value proposition for this case study filled a market need. </p>\n<h3>2. Identify The Vital MVP Features And Avoid Any Extra</h3>\n<p>You might be noticing a pattern that keeping your MVP simple, clear, and to the point is very important to not only getting the most viable results from testing your MVP but getting you that information quickly. How do you hone in on that particular specificity that will move your MVP to a truly professional level? Start broad and then simplify. Don’t stop until you find the nucleus of the hypothesis that will help you determine the vital features of your product.</p>\n<p>Sure the end goal is to have a wide range of features — all the bells and whistles — that give your product the star power to rise above its competitors. But in the MVP, those extra features are unnecessary and could hinder your goals if you left them in when establishing the MVP for your product. </p>\n<p>For example, landing pages can be a great MVP when looking for information about a potential product. If a user finds their way to your site because the product is relevant to them, a landing page offers a simple breakdown of the product offers and goals, as well as a sign-up field where the inquirer can add their email to learn more. This can help you determine your target audience without having to invest in a spectrum of functional features. It can also clue you what kinds of buyers are interested in your product and provide information about needs and interests that you didn’t even consider. </p>\n<p>Instead of throwing up a landing page that reads “website coming soon” or an overly detailed investigation of your potential product, consider using it as a tool to link the vital features of your product with your target audience. It’s a simple way to collect customer feedback and start a killer email list. </p>\n<h3>3. Detect The Risks In Your Assumption</h3>\n<p>There are many typical startup risks, and a lot of those flow down into the process of testing an MVP. Yet these risks are very important to take into consideration because if not, they could negatively impact the outcome of your MVP and cost you time and money. Here are a few that we have highlighted as the most significant risks to consider when testing your MVP:</p>\n<ul>\n<li><strong>Users might not recognize a product’s value</strong><br />For example, if you have added a crypto trading option to your product, your users might not recognise the value in the product because they are already committed to third-party platforms like Coinbase and Revolut.</li>\n<li><strong>Hard to acquire users</strong><br />If you don’t take into consideration the scope and breadth of your direct competition or inherently the market that you are pushing a product through, it is likely that you might not realise if your target audience is available or hard to acquire. Take, for instance, an app in Europe that helps you find a healthcare provider in your area. But it turns out that most major cities have one of their own, and they have more advanced knowledge and access to the target audience than you do. This means while your idea might be good, you will have an incredibly hard time converting users to your platform. But using these risks to help you determine your hypothesis and strengthen your MVP is the key to unlocking your product’s potential.</li>\n<li><strong>Difficult to scale the product</strong><br />When conceptualizing your product, while you want to narrow in on an MVP that uses minimal product but provides maximum learning, the same isn’t so for understanding the scope of your product idea. Suppose you are setting up a moving company, and once your app receives over 100 requests, it cannot handle any more inquiries. In that case, you have a major salability issue that will never allow your product to meet its full potential. </li>\n<li><strong>Revenue-generation problem</strong><br />This is a tough risk to understand while you are in the testing phases of your MVP and your startup. All projects of this nature are inherently risky and don’t often produce early financial results that put you in the green. But when you are looking at the cost-benefit analysis and going over P&amp;L statements from the first waves of use of your product, there should be a lot of green flags that point to profit. If your product P&amp;L sees nothing but red, it might be time to reevaluate your goals. </li>\n</ul>\n<h3>4. Pick The One Risk You’re Most Likely To Face And Work It Out</h3>\n<p>Pick the one risk that is most likely to align with your MVP and take the time to work through it. Consider it alongside your value proposition and develop a product increment that will take you from hypothesis to MVP in a concise and effective way. Apply the lean approach to ensure you are not over-focusing on unnecessary features and push your MVP into the hands of customers quickly. </p>\n<p>As in the renters rewards example, it didn’t make sense to take the time to update the app with a new interface or add extra features. Instead, the test was as simple and quick as setting up an email system, and the highest identified risk was easily mitigated by eliminating the need for extra costs or unavailable users. The results were simple but extremely viable, and the MVP time to market was less than two weeks. </p>\n<h3>5. Test Product Branding</h3>\n<p>Testing is awesome and essential! But testing features isn’t the only way to effectively test your product and receive useful information. Branding is becoming increasingly important, as most consumers like to be emotionally tied to a product. That emotional element can often be the determining factor of success against a product’s competitors. If your startup is interested in rebranding or gaining more perspective on how their audience connects with their brand storytelling, using MVP testing is a great way to discover valuable data that can inform new and impactful brand strategies. </p>\n<p>When it comes to branding, we want to assess the user-feedback-related risk of a negative perception of the brand. You could easily drive new branding with limited updates to the logo, landing page, and app images, while it is probably best to hold off on any hard investments like merch, billboards, and deck templates until the new strategy is proven.</p>\n<p>Two things come into play when determining what types of branding elements to test:</p>\n<ol>\n<li>Is it easy to produce/costly?</li>\n<li>Is it crucial? </li>\n</ol>\n<p>User experience is becoming the number one factor in branding that determines a wide range of benefits for the product. Pay attention to colors, tone of voice, icons, illustrations, and landings — these are 99% of the things your users will see all the time. These are easy to create and are a touchpoint during every client experience. It is safe to say that these key branding elements play a decisive part in your update.</p>\nHow Best To Test Your MVP: The Bottomline\n<p>There is any number of combinations of techniques and strategies that will work best for you and your startup based on the type of MVP you have and the best ways for you to test it. Deciding which ways are best for you, my advice is to start small and grow. It is easier to manage the testing of a hypothesis on a simple email blast or landing page brief than with a whole app features update that affects thousands of users.</p>\n<p> You can always grow and scale your MVP strategy as you gain more insight into your product. There will be many chances to apply MVP testing while you make your way through your startup roadmap.</p>\n<p>The only thing that matters is that you should approach the MVP test as a way of providing you verifiable insights on whether your final product will have a fair, if not successful, share of the market after it finally launches. </p>",
      "content_text": "As both an entrepreneur and designer, I understand the ways startup founders think. Most of them start a project with visions of a perfect product in their head. However, in reality, a well-performing product will likely look way different than an initial concept. Instead of seeking perfection from the outset, beginning with a Minimum Viable Product (MVP) is the smartest route to success. An MVP is a crucial part of the product design process and allows businesses to validate their idea at the minimum expense and time.\nBut while a lot of startups already know that an MVP is essential, a majority of the startups that I have mentored over the years have categorically encountered the same problem across all sectors of their process: an MVPs time to market. It simply takes too long for an idea to get into the hands of a consumer.\nBecause the truth is, if an MVP testing process takes longer than two weeks, you’re probably doing something wrong. From my experience, most startup product designers make these three common mistakes that lead to longer MVP testing times: \n\nUsing the wrong definition of a product value proposition;\nUnderestimating the risks in a design hypothesis;\nOverloading the product with extra features.\n\nWhy are startups missing these important steps in the process? I believe there are some tendencies among startups to pursue goals that fundamentally and often accidentally create a blind spot for these common mistakes. \nMeasure And Lean Your MVP\nIn Eric Ries’s book The Lean Startup, his definition of the MVP states:\n“The minimum viable product is that version of a new product which allows a team to collect the maximum amount of validated learning about customers with the least effort.”— Eric Ries\n\nWhen approaching a new idea, a startup founder might feel compelled to build upon the complexities of the function as a way of seeing their vision come to life rather than compose enough of the fundamental core components to create a hypothesis that they can then test. Ries differentiates between these approaches in his book when he discusses the process of measuring and leaning. \n\nOne of the major benefits of an MVP is lean production. It allows entrepreneurs and companies to produce a product that helps them prove their value proposition while also cutting costs. The clearer the theory, the stronger the MVP, and the more valuable information collected throughout the MVP process.\nAn MVP is not only designed to determine the viability of a product’s value proposition but also to test the product’s technical elements and target audiences. Even a simple MVP or acceptance testing that inquires whether the intended audience is interested in using the product in the first place could be more helpful to the progress of a startup’s journey to success than establishing the perfect product right away. \nThe answers that an MVP can prove may be as simple as the MVP itself but highly valuable when continuing down a startup path that includes high-risk and particular investors. In the most general sense, a product is viable when it successfully fulfills a need in the market. And as easy as it seems, the most challenging part of this simple question is determining what exactly is necessary and what is not, as the features that you deem important to your product are, in fact, important. \nDiscernment and clarity are not as easy as it seems, and a large part of being concise when approaching your MVP is keeping the time to market low. This is why I find the importance of testing your MVP within two weeks or less to be a crucial factor in achieving successful results. The key to a highly effective MVP is defining the problem as clearly and specifically as possible.\nRenters Rewards: A Case Study\nBefore we dive into some tips, let’s first take a look at a case study that features a mobile app startup. This app is designed to help people find a property to rent while also providing them with opportunities to earn cashback. \nIn this example, a startup saw an opportunity to develop a platform that lets people search for a rental, pay for the application, sign a lease, and continue to pay rent on the property indefinitely — all from one place. To take this product to the next level, we had an idea to offer people who pay on time a 1% cashback match if they pay before their rent due date.\nWe wanted to test this hypothesis, so first, we had to develop our problem; in doing this, we could determine the approach and figure out a plan of action to receive valuable results in a couple of weeks. We decided that using the overarching idea of trying to test whether users would pay the rent early if they were offered a 1% cashback was not only too risky but a tough sell to landlords who could find it too costly upfront. \nInstead, we thought of a way to apply a slightly incremental change to the user’s digital experience that could provide us with preliminary information as to whether or not the users would be interested in this opportunity. We sent out emails to 100 app users stating that if they paid their rent before the end of the month, we would credit $20 to their accounts.\nThe test was simple, concise, and succinct enough to give us quick and valuable feedback on our hypothesis, which then could set the app up for a border change to the platform and infrastructure. Over 80% of the app users who received the email opted for the $20 cashback and paid their rent early, determining that if the app were to implement this in a more grand scope, their success would likely be very high. In short, the incentive worked, and it was a quick and low-cost MVP that proved it.\nFive Effective Strategies For Testing Your MVP\nNow that you understand the importance of a short MVP time to market, we can explore some useful tips that will help you put forth the most successful product for your startup.\n1. Properly Formulate A Product Value Proposition\nThe first and most important tip for any startup looking to test an MVP is to determine the most effective value proposition for your product. In regards to the aforementioned case study, we talked about how the value proposition began — as a 1% rewards incentive for app users. After understanding how the value prop would be most effectively tested — solidifying a quick and concise testing procedure — we came up with an MVP that highlighted only the most necessary measurable metrics. \nBy determining that the same hypothesis could be discovered by providing 100 users with a $20 incentive as by giving 1% cashback to all users across the platform, we were able to concur that the value proposition for this case study filled a market need. \n2. Identify The Vital MVP Features And Avoid Any Extra\nYou might be noticing a pattern that keeping your MVP simple, clear, and to the point is very important to not only getting the most viable results from testing your MVP but getting you that information quickly. How do you hone in on that particular specificity that will move your MVP to a truly professional level? Start broad and then simplify. Don’t stop until you find the nucleus of the hypothesis that will help you determine the vital features of your product.\nSure the end goal is to have a wide range of features — all the bells and whistles — that give your product the star power to rise above its competitors. But in the MVP, those extra features are unnecessary and could hinder your goals if you left them in when establishing the MVP for your product. \nFor example, landing pages can be a great MVP when looking for information about a potential product. If a user finds their way to your site because the product is relevant to them, a landing page offers a simple breakdown of the product offers and goals, as well as a sign-up field where the inquirer can add their email to learn more. This can help you determine your target audience without having to invest in a spectrum of functional features. It can also clue you what kinds of buyers are interested in your product and provide information about needs and interests that you didn’t even consider. \nInstead of throwing up a landing page that reads “website coming soon” or an overly detailed investigation of your potential product, consider using it as a tool to link the vital features of your product with your target audience. It’s a simple way to collect customer feedback and start a killer email list. \n3. Detect The Risks In Your Assumption\nThere are many typical startup risks, and a lot of those flow down into the process of testing an MVP. Yet these risks are very important to take into consideration because if not, they could negatively impact the outcome of your MVP and cost you time and money. Here are a few that we have highlighted as the most significant risks to consider when testing your MVP:\n\nUsers might not recognize a product’s valueFor example, if you have added a crypto trading option to your product, your users might not recognise the value in the product because they are already committed to third-party platforms like Coinbase and Revolut.\nHard to acquire usersIf you don’t take into consideration the scope and breadth of your direct competition or inherently the market that you are pushing a product through, it is likely that you might not realise if your target audience is available or hard to acquire. Take, for instance, an app in Europe that helps you find a healthcare provider in your area. But it turns out that most major cities have one of their own, and they have more advanced knowledge and access to the target audience than you do. This means while your idea might be good, you will have an incredibly hard time converting users to your platform. But using these risks to help you determine your hypothesis and strengthen your MVP is the key to unlocking your product’s potential.\nDifficult to scale the productWhen conceptualizing your product, while you want to narrow in on an MVP that uses minimal product but provides maximum learning, the same isn’t so for understanding the scope of your product idea. Suppose you are setting up a moving company, and once your app receives over 100 requests, it cannot handle any more inquiries. In that case, you have a major salability issue that will never allow your product to meet its full potential. \nRevenue-generation problemThis is a tough risk to understand while you are in the testing phases of your MVP and your startup. All projects of this nature are inherently risky and don’t often produce early financial results that put you in the green. But when you are looking at the cost-benefit analysis and going over P&L statements from the first waves of use of your product, there should be a lot of green flags that point to profit. If your product P&L sees nothing but red, it might be time to reevaluate your goals. \n\n4. Pick The One Risk You’re Most Likely To Face And Work It Out\nPick the one risk that is most likely to align with your MVP and take the time to work through it. Consider it alongside your value proposition and develop a product increment that will take you from hypothesis to MVP in a concise and effective way. Apply the lean approach to ensure you are not over-focusing on unnecessary features and push your MVP into the hands of customers quickly. \nAs in the renters rewards example, it didn’t make sense to take the time to update the app with a new interface or add extra features. Instead, the test was as simple and quick as setting up an email system, and the highest identified risk was easily mitigated by eliminating the need for extra costs or unavailable users. The results were simple but extremely viable, and the MVP time to market was less than two weeks. \n5. Test Product Branding\nTesting is awesome and essential! But testing features isn’t the only way to effectively test your product and receive useful information. Branding is becoming increasingly important, as most consumers like to be emotionally tied to a product. That emotional element can often be the determining factor of success against a product’s competitors. If your startup is interested in rebranding or gaining more perspective on how their audience connects with their brand storytelling, using MVP testing is a great way to discover valuable data that can inform new and impactful brand strategies. \nWhen it comes to branding, we want to assess the user-feedback-related risk of a negative perception of the brand. You could easily drive new branding with limited updates to the logo, landing page, and app images, while it is probably best to hold off on any hard investments like merch, billboards, and deck templates until the new strategy is proven.\nTwo things come into play when determining what types of branding elements to test:\n\nIs it easy to produce/costly?\nIs it crucial? \n\nUser experience is becoming the number one factor in branding that determines a wide range of benefits for the product. Pay attention to colors, tone of voice, icons, illustrations, and landings — these are 99% of the things your users will see all the time. These are easy to create and are a touchpoint during every client experience. It is safe to say that these key branding elements play a decisive part in your update.\nHow Best To Test Your MVP: The Bottomline\nThere is any number of combinations of techniques and strategies that will work best for you and your startup based on the type of MVP you have and the best ways for you to test it. Deciding which ways are best for you, my advice is to start small and grow. It is easier to manage the testing of a hypothesis on a simple email blast or landing page brief than with a whole app features update that affects thousands of users.\n You can always grow and scale your MVP strategy as you gain more insight into your product. There will be many chances to apply MVP testing while you make your way through your startup roadmap.\nThe only thing that matters is that you should approach the MVP test as a way of providing you verifiable insights on whether your final product will have a fair, if not successful, share of the market after it finally launches. ",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/752d3db1-1cfa-4d73-8052-a5cd9980c6a4/how-test-mvp-within-weeks.jpg",
      "date_published": "2022-06-22T09:00:00.000Z",
      "date_modified": "2022-06-22T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/things-to-know-earlier-in-your-career/",
      "url": "https://smashingmagazine.com/2022/06/things-to-know-earlier-in-your-career/",
      "title": "Things I Wish I’d Known Earlier In My Career",
      "summary": "Do you feel stuck in your company? Do you believe you deserve a raise but it never happens? Do you think you might need to quit the job? Let’s figure it out. In this article, Vitaly looks at some things he wishes he’d known earlier in his career.",
      "content_html": "<p>We often focus on the latest techniques and tooling, trying to optimize our workflows and processes. However, in the end, every single person has their own <strong>goals and ambitions</strong>, and too often, our individual goals are left far behind the company’s goals and product development roadmaps.</p>\n<p>Over the last few weeks, I’ve been receiving a few emails asking about the right ways to <strong>negotiate salary</strong>, <strong>get promoted</strong> and notice red flags early. So I thought that having spent around 20 years in this industry, it might be a good idea to write down a few <strong>personal observations</strong> that I wish somebody had told me earlier in my career.</p>\nA Bit Of A Backstory\n<p>I started designing and building websites around 1999, just around the glorious era of VRML and <strong>Macromedia Shockwave</strong>. At the time, I had started my first job in a small digital agency where I worked for a few years all around PHP and shiny new CSS layout — mostly having barely a clue about what I was doing. I was studying computer science, while also earning a bit of money as a freelancer. I did so until early 2006 when I completed my studies and moved on to co-found Smashing Magazine. It seemed to be just a hobby initially, but eventually with the magazine came many products, from books to conferences to the job board and Smashing Membership.</p>\n<p>Throughout the years, I would write and edit articles about the web day and night, and I absolutely loved every single bit of it. When people asked me about how many hours do I work a week, I felt a bit confused because all of it didn't feel like work at all. This hasn't changed a bit today. Yet around mid 2010s I felt like I'm missing actual front-end work on actual projects. So around 2014, I slowly started working on projects with companies small and large, mostly as a <a href=\"https://www.linkedin.com/in/vitalyfriedman/\">contractor</a>, and often on long-term projects. Eventually, I launched a <a href=\"https://smart-interface-design-patterns.com/\">video course on interface design</a>, and am currently writing a book that I hope to finish by late 2022.</p>\n<p>Over all these years, I’ve been working with dozens of companies and organizations, in various roles and projects, from front-end optimization to UX and quite a bit in-between. Over all these years, I’ve been reminding myself of a few observations that I made somewhere between chains of emails and Slack conversations, backroom meetings and stories from colleagues and friends whom I had a pleasure to be working.</p>\n<p>We’ll start with one of the most mundane issues that I've been noticing repeating over and over again: telling about salary expectations too early in the interview process.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b3343c7d-ecdc-4fd6-a4c5-fb031f46aecf/goals-illu.jpg\" /></p>\n1. Never Tell Your Salary Expectations First\n<p>Usually it doesn’t take long until a recruiter or HR manager asks you about your salary expectations or estimated total cost in an interview. Of course, you’d like to make a good first impression, and my first instinct has always been to provide a slightly <strong>discounted ballpark figure</strong>.</p>\n<p>What I didn’t realize for many years is that many recruiters and HR managers have their own KPIs, and often they earn premiums based on how far they can negotiate down the industry’s average salaries or total cost of the engagement. That’s why it’s not uncommon to see experienced professionals being hired for “lower” positions, with a lower salary but similar responsibilities and similar scope of work.</p>\n<p><strong>Salary isn’t everything, but it is important</strong>. Be very careful and strategic when negotiating your salary. If you are asked about your salary expectations, politely decline that question and <strong>ask for an offer first</strong>. You first need to assess the complexity of the project and the inner workings and expertise of the team; otherwise, your ballpark figure is just guesswork and often an inaccurate one. Most importantly, never provide a number right away, and defer it to an email that you’ll be sending later. This gives you a bit of time to think and avoid estimates that you might regret later.</p>\n<p>Some HR managers will insist on some ballpark figures early. That’s why it’s critical to <strong>do your research upfront</strong>. Don’t focus too much on your current salary as it might not account for inflation, gender gap, and other costs. Instead, explore what a reasonable salary for your role is and for your level of experience in your region — with <a href=\"https://www.glassdoor.com/\">Glassdoor</a> and similar sites. You might even increase it a bit to leave enough room to negotiate later.</p>\n<p>Even with these preparations in place, though, always <strong>avoid exact numbers</strong> and provide a range that feels comfortable for you. In fact, a good way of pricing your work is by asking yourself what salary would make you <strong>enthusiastic enough</strong> to be heavily invested in the product and deliver your best work.</p>\n2. Switching Companies Is How You Make More Money\n<p>Sometimes the same recruiters who signed up with you one year, getting in touch just a year later, with another exciting opportunity from another exciting company. That’s wonderful for <strong>climbing the career ladder</strong> and salary increases, yet as a result, often you end up without any ownership at all — just because you don't get enough time to contribute and see the <strong>impact of your contributions</strong> in real projects. And to me, that’s always been very important, and more important than the salary.</p>\n<p>In the industry, it’s common to be jumping between companies every 12–18 months, and in fact that’s how you usually would make more money. Sadly, what I see as a result is that when some of my colleagues look back at their career, they realize that it’s difficult for them to feel some sense of <strong>significant achievement and pride</strong> for the incredible work done — mostly because they never had a change to really finish what they started. Undoubtedly, these achievements reflecting in the incredible wall of incredible companies on your CV, but this often doesn’t turn into some deep feeling of self-realization.</p>\n<p>If you feel valued and appreciated, the team is great and salary is fine, consider staying in the same company for around <strong>2–3 years</strong>. Feel free to take job interviews in-between, of course, but you do need a bit of time to become fluent and proficient in a specific company's context. Once you are, either grow in your company or do switch to another challenge. Just make sure it doesn’t feel like it’s too early.</p>\n3. Pay Attention To Your Job Title\n<p>We often think that titles don’t matter as much as the work that we are actually doing. Yet throughout the years, I’ve been proved wrong over and over again. <strong>Titles do matter</strong>. In fact, in many large companies and organizations, <strong>titles define salary levels</strong>. It might feel acceptable to start from a lower position and grow your way into a senior position, yet in practice, it’s much more difficult than I have anticipated (more on that later).</p>\n<p><strong>Be very careful and strategic</strong> about the role that you apply for and the role that you are given in the contract. There are significant differences between <em>UX Designer</em> and <em>Senior UX Designer</em> roles, for example.</p>\n<p>At first, this seems very obvious, but for a long time, I didn’t really pay attention to it until I noticed significant differences in salaries between people doing similar work but hired for different positions. This also applies to responsibilities and, most importantly, your position in the team.</p>\n4. Keep Record Of Your Achievements\n<p>So why is it so difficult to grow from one role into another? Well, we often think that if we just work hard enough, we will get noticed, and we will be promoted to senior positions, with the salary and responsibilities adjusted accordingly.</p>\n<p>However, your growth heavily depends on how attentive and caring your managers are. Sometimes you might indeed get noticed, but more often than not, you won’t. Managers change, companies evolve, teams get restructured, and as these changes are happening, you might not ever get to be promoted. Because everything is shifting all the time, and with all the managers coming and leaving, it’s difficult to stay on track around the right time for your promotion or raise. That’s why many people choose a safe strategy and raise salary by jumping from one company to another every 18-24 months.</p>\n<p>Many companies have <strong>feedback loops</strong> (“one-on-one” s, 360 reviews, etc.), where you get feedback from your team and from your managers a few times a year. This is a great opportunity to raise the question about your personal growth and what you need to do to move to the next level. Use this opportunity in your favor.</p>\n<p>Maintain an <strong>up-to-date record of your achievements</strong>, milestones, projects and learnings, workshops and trainings you’ve attended, articles you’ve written and talks you’ve given, your help with onboarding new employees, your contribution to weekly UX meetings, etc. (a Google Doc would do). This will help you argue better during salary negotiations. <strong>You have to be proactive</strong> about your salary increase — you are unlikely to be promoted on your own, so make sure that your managers provide time and space for you to bring up your question about your career, personal growth, responsibilities and salary.</p>\n5. You Can’t Have It All\n<p>Who doesn’t want to have a lovely combination of ownership in the team, a decent salary with stock options, stability, great managers, fantastic people, and a good work-life balance? It was quite a surprise to me that getting everything neatly packaged in one job opening was quite an unrealistic expectation.</p>\n<p>In a <strong>start-up environment</strong>, you might have a lot of ownership, but with it often comes slightly chaotic management with last-minute changes and mid-night fixes.</p>\n<p>In <strong>large corporations</strong>, you would have a reasonable salary and stability, but you probably won’t feel like you make significant contributions to the product. You are likely to be working on tiny adjustments, often not even knowing if your work will ever see the light of day. However, you learn a lot from your team and grow significantly as a professional.</p>\n<p>As a <strong>contractor or freelancer</strong>, you always need to chase your projects, and with it comes a healthy dose of accounting, estimates, scopes of work, and eventually, last-minute changes and deadlines. Sometimes you might have too many projects, and the next month you might be looking for work. This adds to the pressure and stress levels that you might want to avoid.</p>\n<p>What about <strong>agencies and outsourcing companies</strong>? Frankly, I wish that in my early 20s, I’d have worked with them more than I did (just around a year, really). Mostly because I’d love to have learned more about different knowledge domains to be able to apply this knowledge to my ongoing projects. Right now, every time I have to deep dive and learn a lot about every single industry, and this takes a remarkable amount of time and effort.</p>\n<p>There is no magic space where you can have it all. And more often than not, it’s not really needed. <strong>Figure out what is important to you.</strong> Personally, I’d choose to work with good people on a great product over salary and stock options any time of the day. The choice of the company would be influenced by this very decision.</p>\n<p>What’s the best option? There is probably none. To myself, I’d recommend to <strong>start out working in an agency</strong> or outsourcing company. Learn different knowledge domains, learn how the business works, get to know skilled people, and make connections.</p>\n<p>Then move to a product team to see how products are built and maintained and how teams are working together. Then switch to a larger company to learn from incredible people and understand slightly more complex sides of the product and business.</p>\n<p>Eventually, either become a consultant or build a company of your own or move back to a product team. This might not be for everyone, but it would make me have ownership over some parts of the product, feel stable, learn, and be surrounded by people I can learn from.</p>\n6. Pay Attention To Your Estimates\n<p>As humans, we are incredibly bad in estimating work, and the best way to get better at it is to break down the scope of work into smaller units of work. Many managers assume that just because we have around eight working hours a day, we are actually working productively during that entire timeframe. That, however, doesn’t account for so many things, from routine messaging on Slack and urgent errands to sick days and interruptions.</p>\n<p>When asked to estimate the amount of time you need to deliver, I always try to count on around <strong>6–6.5 productive working hours a day</strong>. Feel free to underpromise and overdeliver, but always include the cost of over-delivery in your estimates.</p>\n<p>I definitely spend more time in spreadsheets these days compared to the early days, and that might be one of the bigger changes throughout the years. It pays off to invest enough time into <strong>writing detailed scope of work</strong>, explaining:</p>\n<ul>\n<li>how you understood the problem,</li>\n<li>what the solution requires (with a breakdown of tasks),</li>\n<li>what your assumptions are,</li>\n<li>how you are planning to solve it,</li>\n<li>when customer’s (timely) input will be needed,</li>\n<li>what the milestones and timeline are,</li>\n<li>what delivery date we commit to (for the fixed scope),</li>\n<li>how the pricing and payment are going to work.</li>\n</ul>\n<p>Most importantly, make sure that everybody understands that you are <strong>estimating delivery for a fixed scope of work</strong>, and late changes will be expensive and might delay the delivery. In fact, you might want to repeat that last sentence multiple times in your scope of work and make sure that you get an unambiguous sign-off from your client (preferably with a signature).</p>\n7. Test The Company During Your Probation Period\n<p>We often think about the probation period being a test for us as employees, but you can also see it as an important test for the company, too. <strong>Watch out for red flags</strong>: do people leave for strange reasons? Do managers change frequently? Are designers and developers being listened to in the company? What are some of the recent changes that were implemented based on users’ feedback?</p>\n<p>Engage in conversations about what the impact of work is, just to make sure that you don’t put your hard work and efforts into something that might not even be worth your energy. You are talented, skilled, and hard-working, and there are plenty of good uses for your skills out there.</p>\n8. Think About Passive Income Early\n<p>When you are in your 20s, it’s easy to dismiss the notion of <strong>passive income</strong>. After all, you have all the time in the world to make your financial decisions later. But I can’t stress it enough: <strong>do think early about your passive income</strong> — the earlier you start investing into ETFs or creating digital products, templates and books, the more you can accumulate over the years. That’s a valuable — and the most important — investment of your time for the decades to come.</p>\n<p>Your best asset is the time you have, and the longer you keep investing, the more impactful your interest is going to be after just a few decades. You don’t need much money to start building up your passive income. Even putting aside $100 a month <a href=\"https://smartasset.com/investing/investment-calculator#bUuwyGpt6Q\">will pay off long term</a>.</p>\n<p>Also, find like-minded people and start cultivating your user base. Once you know what you like doing, try to do as much as possible around that niche to make sure that when the topic comes up, your name, or the resources that you have created, come up along with it.</p>\n<p>This requires <strong>visibility</strong> — writing, publishing, releasing, and open-sourcing. Set aside a bit of time every week to invest in it — it’s worth every second of your time.</p>\nWrapping Up\n<p>Of course, everybody has their own experiences, so the things I’ve mentioned here might not be quite what you’d recommend and might not align with your current situation.</p>\n<p>However, I strongly believe that many of these points will be important to consider or think about before switching companies, confirming an offer, or passing the probation period.</p>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2015/05/rekindling-your-passion-for-web-design/\">Rekindling Your Passion For Web Design</a>,” Jeremy Girard</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/01/ten-tips-aspiring-designer-beginners-part1/\">Ten Tips For Aspiring Designer Beginners</a>,” Luis Ouriach</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/04/collaborative-coding-ultimate-career-hack/\">Why Collaborative Coding Is The Ultimate Career Hack</a>,” Bobby Sebolao</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2018/01/work-life-balance-tips-community/\">Work-Life Balance: Tips From The Community</a>,” Ricky Onsman</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2017/09/design-career-best-education/\">Launching Your Design Career: Which Type Of Education Is Best For You?</a>,” Alec McGuffey</li>\n</ul>",
      "content_text": "We often focus on the latest techniques and tooling, trying to optimize our workflows and processes. However, in the end, every single person has their own goals and ambitions, and too often, our individual goals are left far behind the company’s goals and product development roadmaps.\nOver the last few weeks, I’ve been receiving a few emails asking about the right ways to negotiate salary, get promoted and notice red flags early. So I thought that having spent around 20 years in this industry, it might be a good idea to write down a few personal observations that I wish somebody had told me earlier in my career.\nA Bit Of A Backstory\nI started designing and building websites around 1999, just around the glorious era of VRML and Macromedia Shockwave. At the time, I had started my first job in a small digital agency where I worked for a few years all around PHP and shiny new CSS layout — mostly having barely a clue about what I was doing. I was studying computer science, while also earning a bit of money as a freelancer. I did so until early 2006 when I completed my studies and moved on to co-found Smashing Magazine. It seemed to be just a hobby initially, but eventually with the magazine came many products, from books to conferences to the job board and Smashing Membership.\nThroughout the years, I would write and edit articles about the web day and night, and I absolutely loved every single bit of it. When people asked me about how many hours do I work a week, I felt a bit confused because all of it didn't feel like work at all. This hasn't changed a bit today. Yet around mid 2010s I felt like I'm missing actual front-end work on actual projects. So around 2014, I slowly started working on projects with companies small and large, mostly as a contractor, and often on long-term projects. Eventually, I launched a video course on interface design, and am currently writing a book that I hope to finish by late 2022.\nOver all these years, I’ve been working with dozens of companies and organizations, in various roles and projects, from front-end optimization to UX and quite a bit in-between. Over all these years, I’ve been reminding myself of a few observations that I made somewhere between chains of emails and Slack conversations, backroom meetings and stories from colleagues and friends whom I had a pleasure to be working.\nWe’ll start with one of the most mundane issues that I've been noticing repeating over and over again: telling about salary expectations too early in the interview process.\n\n1. Never Tell Your Salary Expectations First\nUsually it doesn’t take long until a recruiter or HR manager asks you about your salary expectations or estimated total cost in an interview. Of course, you’d like to make a good first impression, and my first instinct has always been to provide a slightly discounted ballpark figure.\nWhat I didn’t realize for many years is that many recruiters and HR managers have their own KPIs, and often they earn premiums based on how far they can negotiate down the industry’s average salaries or total cost of the engagement. That’s why it’s not uncommon to see experienced professionals being hired for “lower” positions, with a lower salary but similar responsibilities and similar scope of work.\nSalary isn’t everything, but it is important. Be very careful and strategic when negotiating your salary. If you are asked about your salary expectations, politely decline that question and ask for an offer first. You first need to assess the complexity of the project and the inner workings and expertise of the team; otherwise, your ballpark figure is just guesswork and often an inaccurate one. Most importantly, never provide a number right away, and defer it to an email that you’ll be sending later. This gives you a bit of time to think and avoid estimates that you might regret later.\nSome HR managers will insist on some ballpark figures early. That’s why it’s critical to do your research upfront. Don’t focus too much on your current salary as it might not account for inflation, gender gap, and other costs. Instead, explore what a reasonable salary for your role is and for your level of experience in your region — with Glassdoor and similar sites. You might even increase it a bit to leave enough room to negotiate later.\nEven with these preparations in place, though, always avoid exact numbers and provide a range that feels comfortable for you. In fact, a good way of pricing your work is by asking yourself what salary would make you enthusiastic enough to be heavily invested in the product and deliver your best work.\n2. Switching Companies Is How You Make More Money\nSometimes the same recruiters who signed up with you one year, getting in touch just a year later, with another exciting opportunity from another exciting company. That’s wonderful for climbing the career ladder and salary increases, yet as a result, often you end up without any ownership at all — just because you don't get enough time to contribute and see the impact of your contributions in real projects. And to me, that’s always been very important, and more important than the salary.\nIn the industry, it’s common to be jumping between companies every 12–18 months, and in fact that’s how you usually would make more money. Sadly, what I see as a result is that when some of my colleagues look back at their career, they realize that it’s difficult for them to feel some sense of significant achievement and pride for the incredible work done — mostly because they never had a change to really finish what they started. Undoubtedly, these achievements reflecting in the incredible wall of incredible companies on your CV, but this often doesn’t turn into some deep feeling of self-realization.\nIf you feel valued and appreciated, the team is great and salary is fine, consider staying in the same company for around 2–3 years. Feel free to take job interviews in-between, of course, but you do need a bit of time to become fluent and proficient in a specific company's context. Once you are, either grow in your company or do switch to another challenge. Just make sure it doesn’t feel like it’s too early.\n3. Pay Attention To Your Job Title\nWe often think that titles don’t matter as much as the work that we are actually doing. Yet throughout the years, I’ve been proved wrong over and over again. Titles do matter. In fact, in many large companies and organizations, titles define salary levels. It might feel acceptable to start from a lower position and grow your way into a senior position, yet in practice, it’s much more difficult than I have anticipated (more on that later).\nBe very careful and strategic about the role that you apply for and the role that you are given in the contract. There are significant differences between UX Designer and Senior UX Designer roles, for example.\nAt first, this seems very obvious, but for a long time, I didn’t really pay attention to it until I noticed significant differences in salaries between people doing similar work but hired for different positions. This also applies to responsibilities and, most importantly, your position in the team.\n4. Keep Record Of Your Achievements\nSo why is it so difficult to grow from one role into another? Well, we often think that if we just work hard enough, we will get noticed, and we will be promoted to senior positions, with the salary and responsibilities adjusted accordingly.\nHowever, your growth heavily depends on how attentive and caring your managers are. Sometimes you might indeed get noticed, but more often than not, you won’t. Managers change, companies evolve, teams get restructured, and as these changes are happening, you might not ever get to be promoted. Because everything is shifting all the time, and with all the managers coming and leaving, it’s difficult to stay on track around the right time for your promotion or raise. That’s why many people choose a safe strategy and raise salary by jumping from one company to another every 18-24 months.\nMany companies have feedback loops (“one-on-one” s, 360 reviews, etc.), where you get feedback from your team and from your managers a few times a year. This is a great opportunity to raise the question about your personal growth and what you need to do to move to the next level. Use this opportunity in your favor.\nMaintain an up-to-date record of your achievements, milestones, projects and learnings, workshops and trainings you’ve attended, articles you’ve written and talks you’ve given, your help with onboarding new employees, your contribution to weekly UX meetings, etc. (a Google Doc would do). This will help you argue better during salary negotiations. You have to be proactive about your salary increase — you are unlikely to be promoted on your own, so make sure that your managers provide time and space for you to bring up your question about your career, personal growth, responsibilities and salary.\n5. You Can’t Have It All\nWho doesn’t want to have a lovely combination of ownership in the team, a decent salary with stock options, stability, great managers, fantastic people, and a good work-life balance? It was quite a surprise to me that getting everything neatly packaged in one job opening was quite an unrealistic expectation.\nIn a start-up environment, you might have a lot of ownership, but with it often comes slightly chaotic management with last-minute changes and mid-night fixes.\nIn large corporations, you would have a reasonable salary and stability, but you probably won’t feel like you make significant contributions to the product. You are likely to be working on tiny adjustments, often not even knowing if your work will ever see the light of day. However, you learn a lot from your team and grow significantly as a professional.\nAs a contractor or freelancer, you always need to chase your projects, and with it comes a healthy dose of accounting, estimates, scopes of work, and eventually, last-minute changes and deadlines. Sometimes you might have too many projects, and the next month you might be looking for work. This adds to the pressure and stress levels that you might want to avoid.\nWhat about agencies and outsourcing companies? Frankly, I wish that in my early 20s, I’d have worked with them more than I did (just around a year, really). Mostly because I’d love to have learned more about different knowledge domains to be able to apply this knowledge to my ongoing projects. Right now, every time I have to deep dive and learn a lot about every single industry, and this takes a remarkable amount of time and effort.\nThere is no magic space where you can have it all. And more often than not, it’s not really needed. Figure out what is important to you. Personally, I’d choose to work with good people on a great product over salary and stock options any time of the day. The choice of the company would be influenced by this very decision.\nWhat’s the best option? There is probably none. To myself, I’d recommend to start out working in an agency or outsourcing company. Learn different knowledge domains, learn how the business works, get to know skilled people, and make connections.\nThen move to a product team to see how products are built and maintained and how teams are working together. Then switch to a larger company to learn from incredible people and understand slightly more complex sides of the product and business.\nEventually, either become a consultant or build a company of your own or move back to a product team. This might not be for everyone, but it would make me have ownership over some parts of the product, feel stable, learn, and be surrounded by people I can learn from.\n6. Pay Attention To Your Estimates\nAs humans, we are incredibly bad in estimating work, and the best way to get better at it is to break down the scope of work into smaller units of work. Many managers assume that just because we have around eight working hours a day, we are actually working productively during that entire timeframe. That, however, doesn’t account for so many things, from routine messaging on Slack and urgent errands to sick days and interruptions.\nWhen asked to estimate the amount of time you need to deliver, I always try to count on around 6–6.5 productive working hours a day. Feel free to underpromise and overdeliver, but always include the cost of over-delivery in your estimates.\nI definitely spend more time in spreadsheets these days compared to the early days, and that might be one of the bigger changes throughout the years. It pays off to invest enough time into writing detailed scope of work, explaining:\n\nhow you understood the problem,\nwhat the solution requires (with a breakdown of tasks),\nwhat your assumptions are,\nhow you are planning to solve it,\nwhen customer’s (timely) input will be needed,\nwhat the milestones and timeline are,\nwhat delivery date we commit to (for the fixed scope),\nhow the pricing and payment are going to work.\n\nMost importantly, make sure that everybody understands that you are estimating delivery for a fixed scope of work, and late changes will be expensive and might delay the delivery. In fact, you might want to repeat that last sentence multiple times in your scope of work and make sure that you get an unambiguous sign-off from your client (preferably with a signature).\n7. Test The Company During Your Probation Period\nWe often think about the probation period being a test for us as employees, but you can also see it as an important test for the company, too. Watch out for red flags: do people leave for strange reasons? Do managers change frequently? Are designers and developers being listened to in the company? What are some of the recent changes that were implemented based on users’ feedback?\nEngage in conversations about what the impact of work is, just to make sure that you don’t put your hard work and efforts into something that might not even be worth your energy. You are talented, skilled, and hard-working, and there are plenty of good uses for your skills out there.\n8. Think About Passive Income Early\nWhen you are in your 20s, it’s easy to dismiss the notion of passive income. After all, you have all the time in the world to make your financial decisions later. But I can’t stress it enough: do think early about your passive income — the earlier you start investing into ETFs or creating digital products, templates and books, the more you can accumulate over the years. That’s a valuable — and the most important — investment of your time for the decades to come.\nYour best asset is the time you have, and the longer you keep investing, the more impactful your interest is going to be after just a few decades. You don’t need much money to start building up your passive income. Even putting aside $100 a month will pay off long term.\nAlso, find like-minded people and start cultivating your user base. Once you know what you like doing, try to do as much as possible around that niche to make sure that when the topic comes up, your name, or the resources that you have created, come up along with it.\nThis requires visibility — writing, publishing, releasing, and open-sourcing. Set aside a bit of time every week to invest in it — it’s worth every second of your time.\nWrapping Up\nOf course, everybody has their own experiences, so the things I’ve mentioned here might not be quite what you’d recommend and might not align with your current situation.\nHowever, I strongly believe that many of these points will be important to consider or think about before switching companies, confirming an offer, or passing the probation period.\nFurther Reading on Smashing Magazine\n\n“Rekindling Your Passion For Web Design,” Jeremy Girard\n“Ten Tips For Aspiring Designer Beginners,” Luis Ouriach\n“Why Collaborative Coding Is The Ultimate Career Hack,” Bobby Sebolao\n“Work-Life Balance: Tips From The Community,” Ricky Onsman\n“Launching Your Design Career: Which Type Of Education Is Best For You?,” Alec McGuffey\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b3343c7d-ecdc-4fd6-a4c5-fb031f46aecf/goals-illu.jpg",
      "date_published": "2022-06-21T13:00:00.000Z",
      "date_modified": "2022-06-21T13:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/precise-timing-web-animations-api/",
      "url": "https://smashingmagazine.com/2022/06/precise-timing-web-animations-api/",
      "title": "Precise Timing With Web Animations API",
      "summary": "In JavaScript, it’s natural to reach for timers when something is to happen on time. But when something is to happen at the exact moment because other things depend on it, you quickly learn timers are more of a problem than a solution. They are never on time, really. Web Animations API could eliminate the need for timers in certain cases while being precise.",
      "content_html": "<p>I previously viewed animations as something playful. Something that adds fuzziness to interfaces. Apart from that, in good hands, animation can make interfaces clearer. One property of animations on the Web that I didn’t hear much about is their precision. That Web Animations API allows us to drop workarounds concerned with JavaScript timing issues. In this article, you’ll see how not to do animations and how to coordinate animation of several elements.</p>\n<p>When you work on a visual presentation of something that requires to be precise, you quickly learn that you spend too much time working around JavaScript’s inability to be exact about when code will actually execute. Try to implement something that relies on rhythm or shared timing and you will get my point. You might get close in certain cases but it’s never perfect.</p>\n<p>One of the things I find helpful when working on complex problems is to <strong>break them down into smaller, simpler problems</strong>. It happens that smaller pieces — even if plenty — have something that unifies them. Something that allows you to treat them uniformly. In the case of animations, now that you have many more elements to deal with, you need something that will guarantee a level of timing precision that would exclude the possibility of drift, of elements going “off-beat”.</p>\n<p>First, let’s see what could go wrong with typical tools JavaScript has to offer.</p>\nJavaScript Timing Issues: In Order But Off Beat\n<p>In JavaScript, every task goes through a queue. Your code, user interactions, network events. Each task waits its turn to be performed by an event loop. That way, it guarantees that things happen in order: when you call a function, you can be sure no sudden mouse move would inject itself in the middle. When you need things to happen later, you can register an event listener or a timer.</p>\n<p>When event fires or a timer is due, the task you defined in a callback goes into the queue. Once the event loop gets to it, your code gets executed. It’s a powerful concept that allows us to mostly ignore concurrency. It works well, but you better understand how it works.</p>\n<p>We’ll look into the consequences of this in the context of animations. I encourage you to learn this topic deeper. Understanding the nature of how JavaScript work, will save you hours and will keep color in your hair. <a href=\"https://github.com/jakearchibald/\">Jake Archibald</a> has done a great job of breaking it all down in his “<a href=\"https://jakearchibald.com/2015/tasks-microtasks-queues-and-schedules/\">Tasks, Microtasks, Queues and Schedules</a>” article and more recently in his “<a href=\"https://www.youtube.com/watch?v=cCOL7MC4Pl0\">In The Loop</a>” talk at JSConf.</p>\n<p>Here’s what awaits you once you’ve decided to do animations with <code>setTimeout</code> or <code>setInteval</code>:</p>\n<ul>\n<li><a href=\"#low-precision\">Low Precision</a></li>\n<li><a href=\"#pile-ups\">Pile Ups</a></li>\n<li><a href=\"#crowded-queue\">Crowded Queue </a></li>\n</ul>\n<h3>Low Precision</h3>\n<p>We can define exactly how long a timeout should wait before placing our task in the queue. What we cannot predict is what will be in the queue at the moment. It is possible to implement self-adjusting timers by checking the difference between the planned tick length and the actual moment the code is executed. That difference is applied to the next tick timeout.</p>\n<p>It mostly works, but if the required distance between ticks is measured in two-digit milliseconds or less, it will rarely hit at the right moment. Also, its nature (that it adjusts on execution) makes it hard to visualize something rhythmical. It will show the precise state when it was called, but not the exact moment the state has changed.</p>\n<p>That is because <code>setTimeout</code> guarantees minimum delay before a thing gets put in the queue. But there’s no way to tell what will be in the queue already.</p>\n<h3>Pile Ups</h3>\n<p>If low precision is fine for you occasionally, you’ll get a pile. Things you’ve meant to be spaced out in time might be executed all at once if there were many tasks for the event loop to work on — or it could all get suspended.</p>\n<p>Advancements in battery life come with better hardware and efficient software. Browser tabs might get suspended to reduce power consumption when not in use. When the tabs are in focus again, the event loop might find itself with a handful of callbacks — some of which are issued by timers — in the queue to process.</p>\n<p>Once I had to implement randomly flipping tiles for a website, and one of the bugs was caused by sleepy tabs. Because each tile maintained its own timer, they all fired simultaneously when the tab became active.</p>\n<p>Notice how the top row blocks are delayed and then flip three at once. (See the Pen <a href=\"https://codepen.io/smashingmag/pen/BaYVLGo\">CodePen Home Timeouts vs DocumentTimeline</a> by <a href=\"https://codepen.io/kirillmyshkin\">Kirill Myshkin</a>)</p>\n<h3>Crowded Queue</h3>\n<p>Likely, your code is already constrained by libraries and frameworks. That means callbacks from your timers are more likely to be put in a queue at an unfortunate moment. You might not have much opportunity for optimization, as there is already much code running around.</p>\n<p>The shortcomings above might be resolved in certain cases. You decide for yourself what’s valued more in each particular project. If all your elements could be managed by a single timer, you might be able to make it work.</p>\n<p>Still, I would look at <code>requestAnimationFrame</code> instead of timers to manage animations. The talk by Jake I linked to above illustrates it brilliantly. What it gives you is rhythm. You can be sure that <strong>your code will be executed right before the user is able to see anything</strong>. Because you have a timestamp of when your function is called, you can use that to calculate the exact state you need to have.</p>\n<p>It’s up to you what’s worth your time to deal with. It might well be that a particular workaround is fine, and you can move on with whatever you’re trying to implement. You are a better judge of what works in your case.</p>\n<p>If the thing you’re trying to implement fits into animations realm, you will benefit from moving it off the queue. Let’s see how we get to a place where time is king.</p>\nWeb Animations API: Where Things Are In Sync\n<p>In my previous article, “<a href=\"https://www.smashingmagazine.com/2021/09/orchestrating-complexity-web-animations-api/\">Orchestrating Complexity With Web Animations API</a>,” we looked at ways to make several animations be controllable as if they were one. Now we’ll look into how to make sure that all your animations start at the right moment.</p>\n<h3>Timeline</h3>\n<p>Web Animations API introduces a notion of a timeline. By default, all the animations are tied to the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Document/timeline\">timeline of the <code>document</code></a>. That means animations share the same “inner clock” — a clock that starts at the page load.</p>\n<p>That shared clock is what allows us to coordinate animations. Whether it’s a certain rhythm or a pattern, you don’t need to worry that something will drag or go ahead of itself.</p>\n<h3>Start Time</h3>\n<p>To make an animation start at a certain moment, you use the<a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Animation/startTime\"><code>startTime</code> property</a>. The value of <code>startTime</code> is measured in milliseconds from the page load. Animations with a start time set to <code>1000.5</code> will start their playback exactly when the document timeline’s <code>currentTime</code> property equals <code>1000.5</code>.</p>\n<p>Notice the dot in the start time value? Yes, you can use fractions of milliseconds, it’s that precise. However, exact precision depends on <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/AnimationTimeline/currentTime#reduced_time_precision\">browser settings</a>.</p>\n<p>Another useful thing is that start time can be negative as well. You’re free to set it to a moment in the future or a moment in the past. Set the value to <code>-1000</code>, and your animation state would be like it has been played for a second already when the page loads. For the user, it would seem as if the animation had started playing before they even thought to visit your page.</p>\n<p><strong>Note</strong>: <em>Beware that <code>timeline</code> and <code>startTime</code> are still experimental technologies.</em></p>\n<h3>Demo</h3>\n<p>To demonstrate how you can use it, I’ve set up a demo. I’ve implemented an indicator that, more than any other, depends on time precision — a clock. Well I did two, that way, one would reveal the greatness of the other. Certain things in this demo are simple enough to demonstrate the basics. There’re also some tricky parts that show you where this approach is lacking.</p>\n<p>Digital and analog clock, both implemented digitally. (See the Pen <a href=\"https://codepen.io/smashingmag/pen/BaYVLMj\">Clock</a> by <a href=\"https://codepen.io/kirillmyshkin\">Kirill Myshkin</a>)  </p>\n<p>The movement of the analog clock is quite simple. Three hands do the same single-turn rotation — quite optimistically — infinite times. Because the clock is a precise instrument, I’ve made the seconds and minutes hands change their position at the exact moment their corresponding values change. That helps to illustrate that they change at the exact moment as their cousins on the digital clock below.</p>\n<pre><code>const clock = document.getElementById(\"analog-clock\");\nconst second = clock.querySelector(\".second\");\nconst minute = clock.querySelector(\".minute\");\nconst hour = clock.querySelector(\".hour\");\n\nconst s = 1000;\nconst m = s * 60;\nconst h = m * 60;\nconst d = h * 24;\n\nconst hands = [second, minute, hour];\nconst hand_durations = [m, h, d];\nconst steps = [60, 60, 120];\n\nconst movement = hands.map(function (hand, index) {\n    return hand.animate(\n        [\n            {transform: \"rotate(0turn)\"},\n            {transform: \"rotate(1turn)\"}\n        ],\n        {\n            duration: hand_durations[index],\n            iterations: Infinity,\n            easing: `steps(${steps[index]}, end)`\n        }\n    );\n});\n\nmovement.forEach(function (move) {\n    move.startTime = start_time;\n});\n</code></pre>\n\n<p>Animation for each of the three hands differs in how long they do their rotation and in how many steps it’s divided. Seconds hand does a single revolution in sixty thousand milliseconds. Minutes hand does it sixty times slower than that. Hours hand — because it’s a <a href=\"https://en.wikipedia.org/wiki/24-hour_analog_dial\">twenty-four-hour clock</a> — does one in equal time it takes the minutes hand to make twenty four revolutions.</p>\n<p>To tie the clock hands operation to the same notion of time (to make sure the minutes hand updates its position exactly at the moment the seconds hand finishes its rotation), I used the <code>startTime</code> property. All the animations in this demo are set to the same start time. And that’s all you need. Don’t worry about the queue, suspended tabs, or piles of timeouts. Define it <em>once</em> and it’s done.</p>\n<p>The digital clock, on the other hand, is a bit counterintuitive. Each digit is a container with <code>overflow: hidden;</code>. Inside, there’s a row of numbers from zero to one sitting in equal width cells. Each digit is revealed by translating the row horizontally by width of a cell times the digit value. As with the hands on the analog clock, it was a question of setting the right duration for each digit. While all the digits from milliseconds to minutes were easy to do, the hours required some tricks — which I’ll cover below.</p>\n<p>Let’s look at the value of <code>start_time</code> variable:</p>\n<pre><code>const start_time = (function () {\n    const time = new Date();\n    const hour_diff = time.getHours() - time.getUTCHours();\n    const my_current_time = (Number(time) % d) + (hour_diff * h);\n\n    return document.timeline.currentTime - my_current_time;\n}());\n</code></pre>\n\n<p>To calculate the exact moment all the elements have to be started at (which is past midnight), I took the value of <code>Date.now()</code> (milliseconds since January 1, 1970), stripped full days from it, and adjusted it by the difference with UTC time. That left me with the number of milliseconds that have passed since the start of today. It is the only piece of data my clock needs to show what it is destined to show: <strong>hours</strong>, <strong>minutes</strong> and <strong>seconds</strong>.</p>\n<p>To convert that value to the realm of the document, I need to adjust it based on how much time has passed since the load of this demo’s page until <code>Date.now()</code> call. To do that, I subtracted it from the <code>currentTime</code> of the document. Applying the result to an animation means that this particular animation has been playing since midnight. Apply that to all the animations, and you get a demo that has been playing since midnight.</p>\n<p>Theoretically, we could have a clock that runs since January 1, 1970 (52 years as of this writing), but some browsers have undocumented limits for the value of animation’s duration. It would also feel right to apply some CSS to artificially age such clock — as there won’t be any other distinction from the one that has run since last night. Both of those clocks would be in perfect sync.</p>\nShortcomings Of This Approach\n<p>It is empowering to be able to implement something of this precision without any sophisticated calculations. But it only works for cases where the things you’re trying to implement could be defined with keyframes. You should decide, based on your particular case, where it would be beneficial and where it would become more cumbersome and costly to deal with shortcomings.</p>\n<p>An alternative to Web Animations API would be to use <code>requestAnimationFrame</code> or <code>performance.now()</code>. With those, you would need to calculate interpolation yourself.</p>\n<p>If you choose to rely on Web Animations API, you would have to face the fact that <strong>things fit differently into a keyframe definition</strong>. Some things might take practically no work to define because they naturally fit. Others require workarounds. Whether those workarounds add much cost or not to what you’re trying to implement should dictate your approach.</p>\n<p>The clock demo has examples of both cases. The hands themselves were the easiest thing to do. It is a keyframe of one turn rotation with <code>steps</code> easing function to make them tick. In the end, the main movement of the demo clock took almost no work to do. I wish I could say that the digital clock was as easy to implement. But that is due to my own shortcomings, I would say.</p>\n<p>There are three examples of workarounds I had to revert to. I hope they give you an idea of what you might need to do if you go with the animations approach. They aren’t a good representation of Web Animations API limits, they only show how a particular implementation I’ve chosen had to be changed to fit. Let’s see where I had to do additional work.</p>\n<h3>Some Properties Won’t Animate As You Want Them To</h3>\n<p>If you look closely, each hand on the analog clock has a shadow. They add some depth and make the clock look nicer. Shadows are easily applied using <code>box-shadow</code> or <code>filter</code> CSS properties. It is animatable to a degree, but where it comes short is in the animation of the shadow direction. You don’t set it with angle value but by coordinates.</p>\n<p>I couldn’t find a way to implement a circular movement of a shadow using two coordinates. Instead, I broke down each hand into three elements animated separately (see my previous article “<a href=\"https://www.smashingmagazine.com/2021/09/orchestrating-complexity-web-animations-api/\">Orchestrating Complexity With Web Animations API</a>” for that technique). The first one is a wrapper that contains the other two parts of a hand: body and shadow. The wrapper is the element to which the main rotation is applied to. The body defines shape, size, and color of a hand, while the shadow copies the body properties (except for the color). Plus, it has its own animation defined — it rotates around the center of its hand.</p>\n<p>Multiplying the number of elements to deal with might seem harder to do. In the case of the shadow, though, the fact that it was eventually separated from the hand gave more flexibility. You could style it using the CSS. And because the timing has already been dealt with, having more elements doesn’t make it harder.</p>\n<h3>Division Doesn’t Always Result In Equal Shares</h3>\n<p>The second workaround was required for the hours section of the digital clock. The clock is implemented with single digit elements. Three for milliseconds, two for seconds, and two for minutes. Hour digits don’t fit in a logic of looping keyframe.</p>\n<p>The loops aren’t regular because there are only four hours in the twenties. I had to introduce a “wide” digit to tackle this. The wide digit has the same logic as a normal digit would have, only that it supports numbers from zero to ninety-nine — which is plenty for this case. In the end, the digital clock’s hour indicator reused the same timing options as the hours hand on the analog clocks.</p>\n<h3>You Never Know How Long The Next Month Would Be Without Checking The Calendar</h3>\n<p>The third workaround is for the date complication. Now that I had “wide” digits element, I’ve reused it to show dates and just increased the duration from hours to days.</p>\n<p>The problem with that approach was that the month length didn’t map perfectly with the same length animations used in the demo. You see, the calendar we use today has a messy history and is hard to fit into a simple loop. One would have to define all the exceptions of the Gregorian calendar in a single keyframe. I’ll skip doing that. I’m here to show you a workaround.</p>\n<p>I chose to rely on <code>Date</code> instead of defining yet another flawed calendar. Who knows how many days the months will have in the future, right?</p>\n<pre><code>function month() {\n    const now = new Date();\n    return digits(\n        (new Date(now.getFullYear(), now.getMonth() + 1, 0)).getDate(),\n        false\n    );\n}\n\nfunction create_animation(digit) {\n    const nr_digits = digit.firstElementChild.children.length;\n    const duration = d * nr_digits;\n    return digit.firstElementChild.animate(\n        [\n            {transform: \"translateX(0)\"},\n            {transform: \"translateX(calc(var(--len) * -2ch)\"}\n        ],\n        {\n            duration,\n            easing: `steps(${nr_digits}, end)`,\n            iterationStart: (d * ((new Date()).getDate() - 1)) / duration\n        }\n    );\n}\n\n(function set_up_date_complication() {\n    const day = document.querySelector(\".day\");\n\n    const new_day = day.cloneNode();\n    new_day.append(month());\n    day.replaceWith(new_day);\n\n    Array.from(new_day.children).forEach(function (digit) {\n        const complication = create_animation(digit);\n        complication.startTime = start_time;\n        complication.finished.then(set_up_date_complication);\n    });\n}());\n</code></pre>\n\n<p>To make the date complication bulletproof, I defined its duration to be the length of the current month. To keep using the same start time and to avoid the limit on <code>duration</code> value, we “rewind” the animation to the correct date using <code>iterationStart</code> property.</p>\n<p>When the month ends, we need to rebuild the date complication for the next month. The right moment to do that would be when the complication animations had finished. Unlike other animations in this demo, the date doesn’t iterate, so we will create a new date using the <code>finished</code> promise of the current month animation.</p>\n<p>That approach suffers from the shortcomings described at the start of this article. But in the case of months, we might close our eyes on slight imprecision.</p>\n<p>You would have to believe my word that it works. Otherwise, return to this article any last day of a month close to midnight. Who knows, you could find me on the same page, with eyes full of hope and fingers crossed.</p>\nConclusion\n<p>Animations share the same time reference, and by adjusting their <code>startTime</code> property, you can align them to any pattern you need. You can be sure they won’t drift.</p>\n<p>Web Animations API comes with powerful tools that allow you to dramatically reduce the amount of work that your application and you have to do. It also comes with a precision that opens possibilities to implement new kinds of applications.</p>\n<p>That power is contained in the animations realm. Whether it is suitable for your case or not is something you decide based on your needs. I hope the examples I provided in this article will give you a better idea of what path to choose.</p>\n<h3>Further Reading On Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/09/orchestrating-complexity-web-animations-api/\">Orchestrating Complexity With Web Animations API</a>,” Kirill Myshkin</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/04/easing-functions-css-animations-transitions/\">Understanding Easing Functions For CSS Animations And Transitions</a>,” Adrian Bece  </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2015/06/practical-techniques-on-designing-animation/\">Practical Techniques On Designing Animation</a>,” Sarah Drasner</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/09/design-reduced-motion-sensitivities/\">Designing With Reduced Motion For Motion Sensitivities</a>,” Val Head</li>\n</ul>",
      "content_text": "I previously viewed animations as something playful. Something that adds fuzziness to interfaces. Apart from that, in good hands, animation can make interfaces clearer. One property of animations on the Web that I didn’t hear much about is their precision. That Web Animations API allows us to drop workarounds concerned with JavaScript timing issues. In this article, you’ll see how not to do animations and how to coordinate animation of several elements.\nWhen you work on a visual presentation of something that requires to be precise, you quickly learn that you spend too much time working around JavaScript’s inability to be exact about when code will actually execute. Try to implement something that relies on rhythm or shared timing and you will get my point. You might get close in certain cases but it’s never perfect.\nOne of the things I find helpful when working on complex problems is to break them down into smaller, simpler problems. It happens that smaller pieces — even if plenty — have something that unifies them. Something that allows you to treat them uniformly. In the case of animations, now that you have many more elements to deal with, you need something that will guarantee a level of timing precision that would exclude the possibility of drift, of elements going “off-beat”.\nFirst, let’s see what could go wrong with typical tools JavaScript has to offer.\nJavaScript Timing Issues: In Order But Off Beat\nIn JavaScript, every task goes through a queue. Your code, user interactions, network events. Each task waits its turn to be performed by an event loop. That way, it guarantees that things happen in order: when you call a function, you can be sure no sudden mouse move would inject itself in the middle. When you need things to happen later, you can register an event listener or a timer.\nWhen event fires or a timer is due, the task you defined in a callback goes into the queue. Once the event loop gets to it, your code gets executed. It’s a powerful concept that allows us to mostly ignore concurrency. It works well, but you better understand how it works.\nWe’ll look into the consequences of this in the context of animations. I encourage you to learn this topic deeper. Understanding the nature of how JavaScript work, will save you hours and will keep color in your hair. Jake Archibald has done a great job of breaking it all down in his “Tasks, Microtasks, Queues and Schedules” article and more recently in his “In The Loop” talk at JSConf.\nHere’s what awaits you once you’ve decided to do animations with setTimeout or setInteval:\n\nLow Precision\nPile Ups\nCrowded Queue \n\nLow Precision\nWe can define exactly how long a timeout should wait before placing our task in the queue. What we cannot predict is what will be in the queue at the moment. It is possible to implement self-adjusting timers by checking the difference between the planned tick length and the actual moment the code is executed. That difference is applied to the next tick timeout.\nIt mostly works, but if the required distance between ticks is measured in two-digit milliseconds or less, it will rarely hit at the right moment. Also, its nature (that it adjusts on execution) makes it hard to visualize something rhythmical. It will show the precise state when it was called, but not the exact moment the state has changed.\nThat is because setTimeout guarantees minimum delay before a thing gets put in the queue. But there’s no way to tell what will be in the queue already.\nPile Ups\nIf low precision is fine for you occasionally, you’ll get a pile. Things you’ve meant to be spaced out in time might be executed all at once if there were many tasks for the event loop to work on — or it could all get suspended.\nAdvancements in battery life come with better hardware and efficient software. Browser tabs might get suspended to reduce power consumption when not in use. When the tabs are in focus again, the event loop might find itself with a handful of callbacks — some of which are issued by timers — in the queue to process.\nOnce I had to implement randomly flipping tiles for a website, and one of the bugs was caused by sleepy tabs. Because each tile maintained its own timer, they all fired simultaneously when the tab became active.\nNotice how the top row blocks are delayed and then flip three at once. (See the Pen CodePen Home Timeouts vs DocumentTimeline by Kirill Myshkin)\nCrowded Queue\nLikely, your code is already constrained by libraries and frameworks. That means callbacks from your timers are more likely to be put in a queue at an unfortunate moment. You might not have much opportunity for optimization, as there is already much code running around.\nThe shortcomings above might be resolved in certain cases. You decide for yourself what’s valued more in each particular project. If all your elements could be managed by a single timer, you might be able to make it work.\nStill, I would look at requestAnimationFrame instead of timers to manage animations. The talk by Jake I linked to above illustrates it brilliantly. What it gives you is rhythm. You can be sure that your code will be executed right before the user is able to see anything. Because you have a timestamp of when your function is called, you can use that to calculate the exact state you need to have.\nIt’s up to you what’s worth your time to deal with. It might well be that a particular workaround is fine, and you can move on with whatever you’re trying to implement. You are a better judge of what works in your case.\nIf the thing you’re trying to implement fits into animations realm, you will benefit from moving it off the queue. Let’s see how we get to a place where time is king.\nWeb Animations API: Where Things Are In Sync\nIn my previous article, “Orchestrating Complexity With Web Animations API,” we looked at ways to make several animations be controllable as if they were one. Now we’ll look into how to make sure that all your animations start at the right moment.\nTimeline\nWeb Animations API introduces a notion of a timeline. By default, all the animations are tied to the timeline of the document. That means animations share the same “inner clock” — a clock that starts at the page load.\nThat shared clock is what allows us to coordinate animations. Whether it’s a certain rhythm or a pattern, you don’t need to worry that something will drag or go ahead of itself.\nStart Time\nTo make an animation start at a certain moment, you use thestartTime property. The value of startTime is measured in milliseconds from the page load. Animations with a start time set to 1000.5 will start their playback exactly when the document timeline’s currentTime property equals 1000.5.\nNotice the dot in the start time value? Yes, you can use fractions of milliseconds, it’s that precise. However, exact precision depends on browser settings.\nAnother useful thing is that start time can be negative as well. You’re free to set it to a moment in the future or a moment in the past. Set the value to -1000, and your animation state would be like it has been played for a second already when the page loads. For the user, it would seem as if the animation had started playing before they even thought to visit your page.\nNote: Beware that timeline and startTime are still experimental technologies.\nDemo\nTo demonstrate how you can use it, I’ve set up a demo. I’ve implemented an indicator that, more than any other, depends on time precision — a clock. Well I did two, that way, one would reveal the greatness of the other. Certain things in this demo are simple enough to demonstrate the basics. There’re also some tricky parts that show you where this approach is lacking.\nDigital and analog clock, both implemented digitally. (See the Pen Clock by Kirill Myshkin)  \nThe movement of the analog clock is quite simple. Three hands do the same single-turn rotation — quite optimistically — infinite times. Because the clock is a precise instrument, I’ve made the seconds and minutes hands change their position at the exact moment their corresponding values change. That helps to illustrate that they change at the exact moment as their cousins on the digital clock below.\nconst clock = document.getElementById(\"analog-clock\");\nconst second = clock.querySelector(\".second\");\nconst minute = clock.querySelector(\".minute\");\nconst hour = clock.querySelector(\".hour\");\n\nconst s = 1000;\nconst m = s * 60;\nconst h = m * 60;\nconst d = h * 24;\n\nconst hands = [second, minute, hour];\nconst hand_durations = [m, h, d];\nconst steps = [60, 60, 120];\n\nconst movement = hands.map(function (hand, index) {\n    return hand.animate(\n        [\n            {transform: \"rotate(0turn)\"},\n            {transform: \"rotate(1turn)\"}\n        ],\n        {\n            duration: hand_durations[index],\n            iterations: Infinity,\n            easing: `steps(${steps[index]}, end)`\n        }\n    );\n});\n\nmovement.forEach(function (move) {\n    move.startTime = start_time;\n});\n\n\nAnimation for each of the three hands differs in how long they do their rotation and in how many steps it’s divided. Seconds hand does a single revolution in sixty thousand milliseconds. Minutes hand does it sixty times slower than that. Hours hand — because it’s a twenty-four-hour clock — does one in equal time it takes the minutes hand to make twenty four revolutions.\nTo tie the clock hands operation to the same notion of time (to make sure the minutes hand updates its position exactly at the moment the seconds hand finishes its rotation), I used the startTime property. All the animations in this demo are set to the same start time. And that’s all you need. Don’t worry about the queue, suspended tabs, or piles of timeouts. Define it once and it’s done.\nThe digital clock, on the other hand, is a bit counterintuitive. Each digit is a container with overflow: hidden;. Inside, there’s a row of numbers from zero to one sitting in equal width cells. Each digit is revealed by translating the row horizontally by width of a cell times the digit value. As with the hands on the analog clock, it was a question of setting the right duration for each digit. While all the digits from milliseconds to minutes were easy to do, the hours required some tricks — which I’ll cover below.\nLet’s look at the value of start_time variable:\nconst start_time = (function () {\n    const time = new Date();\n    const hour_diff = time.getHours() - time.getUTCHours();\n    const my_current_time = (Number(time) % d) + (hour_diff * h);\n\n    return document.timeline.currentTime - my_current_time;\n}());\n\n\nTo calculate the exact moment all the elements have to be started at (which is past midnight), I took the value of Date.now() (milliseconds since January 1, 1970), stripped full days from it, and adjusted it by the difference with UTC time. That left me with the number of milliseconds that have passed since the start of today. It is the only piece of data my clock needs to show what it is destined to show: hours, minutes and seconds.\nTo convert that value to the realm of the document, I need to adjust it based on how much time has passed since the load of this demo’s page until Date.now() call. To do that, I subtracted it from the currentTime of the document. Applying the result to an animation means that this particular animation has been playing since midnight. Apply that to all the animations, and you get a demo that has been playing since midnight.\nTheoretically, we could have a clock that runs since January 1, 1970 (52 years as of this writing), but some browsers have undocumented limits for the value of animation’s duration. It would also feel right to apply some CSS to artificially age such clock — as there won’t be any other distinction from the one that has run since last night. Both of those clocks would be in perfect sync.\nShortcomings Of This Approach\nIt is empowering to be able to implement something of this precision without any sophisticated calculations. But it only works for cases where the things you’re trying to implement could be defined with keyframes. You should decide, based on your particular case, where it would be beneficial and where it would become more cumbersome and costly to deal with shortcomings.\nAn alternative to Web Animations API would be to use requestAnimationFrame or performance.now(). With those, you would need to calculate interpolation yourself.\nIf you choose to rely on Web Animations API, you would have to face the fact that things fit differently into a keyframe definition. Some things might take practically no work to define because they naturally fit. Others require workarounds. Whether those workarounds add much cost or not to what you’re trying to implement should dictate your approach.\nThe clock demo has examples of both cases. The hands themselves were the easiest thing to do. It is a keyframe of one turn rotation with steps easing function to make them tick. In the end, the main movement of the demo clock took almost no work to do. I wish I could say that the digital clock was as easy to implement. But that is due to my own shortcomings, I would say.\nThere are three examples of workarounds I had to revert to. I hope they give you an idea of what you might need to do if you go with the animations approach. They aren’t a good representation of Web Animations API limits, they only show how a particular implementation I’ve chosen had to be changed to fit. Let’s see where I had to do additional work.\nSome Properties Won’t Animate As You Want Them To\nIf you look closely, each hand on the analog clock has a shadow. They add some depth and make the clock look nicer. Shadows are easily applied using box-shadow or filter CSS properties. It is animatable to a degree, but where it comes short is in the animation of the shadow direction. You don’t set it with angle value but by coordinates.\nI couldn’t find a way to implement a circular movement of a shadow using two coordinates. Instead, I broke down each hand into three elements animated separately (see my previous article “Orchestrating Complexity With Web Animations API” for that technique). The first one is a wrapper that contains the other two parts of a hand: body and shadow. The wrapper is the element to which the main rotation is applied to. The body defines shape, size, and color of a hand, while the shadow copies the body properties (except for the color). Plus, it has its own animation defined — it rotates around the center of its hand.\nMultiplying the number of elements to deal with might seem harder to do. In the case of the shadow, though, the fact that it was eventually separated from the hand gave more flexibility. You could style it using the CSS. And because the timing has already been dealt with, having more elements doesn’t make it harder.\nDivision Doesn’t Always Result In Equal Shares\nThe second workaround was required for the hours section of the digital clock. The clock is implemented with single digit elements. Three for milliseconds, two for seconds, and two for minutes. Hour digits don’t fit in a logic of looping keyframe.\nThe loops aren’t regular because there are only four hours in the twenties. I had to introduce a “wide” digit to tackle this. The wide digit has the same logic as a normal digit would have, only that it supports numbers from zero to ninety-nine — which is plenty for this case. In the end, the digital clock’s hour indicator reused the same timing options as the hours hand on the analog clocks.\nYou Never Know How Long The Next Month Would Be Without Checking The Calendar\nThe third workaround is for the date complication. Now that I had “wide” digits element, I’ve reused it to show dates and just increased the duration from hours to days.\nThe problem with that approach was that the month length didn’t map perfectly with the same length animations used in the demo. You see, the calendar we use today has a messy history and is hard to fit into a simple loop. One would have to define all the exceptions of the Gregorian calendar in a single keyframe. I’ll skip doing that. I’m here to show you a workaround.\nI chose to rely on Date instead of defining yet another flawed calendar. Who knows how many days the months will have in the future, right?\nfunction month() {\n    const now = new Date();\n    return digits(\n        (new Date(now.getFullYear(), now.getMonth() + 1, 0)).getDate(),\n        false\n    );\n}\n\nfunction create_animation(digit) {\n    const nr_digits = digit.firstElementChild.children.length;\n    const duration = d * nr_digits;\n    return digit.firstElementChild.animate(\n        [\n            {transform: \"translateX(0)\"},\n            {transform: \"translateX(calc(var(--len) * -2ch)\"}\n        ],\n        {\n            duration,\n            easing: `steps(${nr_digits}, end)`,\n            iterationStart: (d * ((new Date()).getDate() - 1)) / duration\n        }\n    );\n}\n\n(function set_up_date_complication() {\n    const day = document.querySelector(\".day\");\n\n    const new_day = day.cloneNode();\n    new_day.append(month());\n    day.replaceWith(new_day);\n\n    Array.from(new_day.children).forEach(function (digit) {\n        const complication = create_animation(digit);\n        complication.startTime = start_time;\n        complication.finished.then(set_up_date_complication);\n    });\n}());\n\n\nTo make the date complication bulletproof, I defined its duration to be the length of the current month. To keep using the same start time and to avoid the limit on duration value, we “rewind” the animation to the correct date using iterationStart property.\nWhen the month ends, we need to rebuild the date complication for the next month. The right moment to do that would be when the complication animations had finished. Unlike other animations in this demo, the date doesn’t iterate, so we will create a new date using the finished promise of the current month animation.\nThat approach suffers from the shortcomings described at the start of this article. But in the case of months, we might close our eyes on slight imprecision.\nYou would have to believe my word that it works. Otherwise, return to this article any last day of a month close to midnight. Who knows, you could find me on the same page, with eyes full of hope and fingers crossed.\nConclusion\nAnimations share the same time reference, and by adjusting their startTime property, you can align them to any pattern you need. You can be sure they won’t drift.\nWeb Animations API comes with powerful tools that allow you to dramatically reduce the amount of work that your application and you have to do. It also comes with a precision that opens possibilities to implement new kinds of applications.\nThat power is contained in the animations realm. Whether it is suitable for your case or not is something you decide based on your needs. I hope the examples I provided in this article will give you a better idea of what path to choose.\nFurther Reading On Smashing Magazine\n\n“Orchestrating Complexity With Web Animations API,” Kirill Myshkin\n“Understanding Easing Functions For CSS Animations And Transitions,” Adrian Bece  \n“Practical Techniques On Designing Animation,” Sarah Drasner\n“Designing With Reduced Motion For Motion Sensitivities,” Val Head\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/942ab9f6-c68c-4eab-9dba-b98905b2b8b7/precise-timing-web-animations-api.jpg",
      "date_published": "2022-06-20T09:00:00.000Z",
      "date_modified": "2022-06-20T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/easy-build-support-tables-figma/",
      "url": "https://smashingmagazine.com/2022/06/easy-build-support-tables-figma/",
      "title": "How To Easily Build And Support Tables In Figma",
      "summary": "In this article, Andrii shares his approach to managing tables in Figma in an easier, more streamlined way when there is a need to support different screen resolutions, change the order of columns, and use real-life content.",
      "content_html": "<p>The table is one of the most painful components designers have to deal with in their daily design lives. The table element is often a complex combination of text components, lines, rectangles, icons, and more. It soon may become a nightmare to work with, especially if you also want to support different screen resolutions, change the order of columns, and use real-life content.</p>\n<p>In my projects, approximately half of the user interface designs I am working on are <strong>tables</strong>. This is why in this article, I’d like to share my approach to managing tables in Figma in an easier, more streamlined way. </p>\n<p>I’m not a fan of long reads with too many unnecessary details, so I’ll “jump” into the subject right away. My guide consists of several parts; thus, you can stop reading at any point when you understand that what you have learned so far covers your needs at the moment, and you can go back/or jump forward to any section when you want to refresh your memory or learn about the more complex workflows. Let’s go!</p>\n<p><strong>Table of Contents</strong></p>\n<ul>\n<li><a href=\"#cells-and-table-structure\">Cells and Table Structure</a></li>\n<li><a href=\"#real-data-and-column-size-corrections\">Real Data and Column Size Corrections</a></li>\n<li><a href=\"#responsive-tables\">Responsive Tables</a></li>\n<li><a href=\"#basic-table-kit-and-states\">Basic Table Kit and States</a></li>\n<li><a href=\"#figma-design-file\">Figma Design file</a></li>\n<li><a href=\"#conclusion\">Conclusion</a></li>\n</ul>\n<p><strong>Note:</strong> <em>This article is aimed at people with some experience using Figma Design. If you are an absolute beginner in the Figma field, I would suggest first checking some basic Figma tutorials. To make things easier for you, near the end of the article (check</em> <a href=\"#figma-design-file\"><strong><em>Figma Design File</em></strong></a> section)<em>, I have provided my Figma Design which you can use for deconstruction and learning purposes.</em></p>\nCells And Table Structure\n<p>I often use the <a href=\"https://ant.design/\">Ant Design System</a> in my projects. Let’s take their table components as an example.</p>\n<p>To start, we need to make only <strong>two</strong> simple components in Figma:</p>\n<ul>\n<li>a head cell,</li>\n<li>a row cell.</li>\n</ul>\n<p>Use <code>Left</code> and <code>Center</code> in <code>Constraints</code> to align the text.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0b67cf31-0f93-45e1-b865-b0788751b01d/1-how-build-support-tables-figma.png\" /></p>\n<blockquote><strong>Aside on keyboard shortcuts:</strong><br /><br />Ctrl/Cmd — Win/Mac<br />Alt/Option — Win/Mac<br />Shift — Win and Mac<br /><br />Figma is a tool that works on both Windows and Mac. For example, the following keyboard shortcut combo Ctrl/Cmd + D means, “Press Ctrl + D on Windows, or press Cmd + D on Mac.”</blockquote>\n\n<p>Then we need to copy the components for our future table:</p>\n<ul>\n<li>hold Alt/Option + Shift + left mouse button for copying</li>\n<li>and Ctrl/Cmd + D to repeat the last action in Figma.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2fef7d90-888e-496b-884a-4e8cca16e250/4-how-build-support-tables-figma.png\" /></p>\n<p>How to create the table lines? Start here:</p>\n<ul>\n<li>press and hold Alt/Option + Shift + mouse left for copying,</li>\n<li>and Ctrl/Cmd+ D to repeat the last action in Figma.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/27da4225-7ba9-4ff9-8d1e-ee5ab122e4c3/6-how-build-support-tables-figma.png\" /></p>\n<p>How did I do it? Here are the steps:</p>\n<ol>\n<li>group the table row elements into a single frame;</li>\n<li>set corners’ radius to 15 <code>px</code>;</li>\n<li>set outline stroke to 1 <code>px</code>, <code>#49E36B</code>;</li>\n<li>set frame fill color to <code>#278EEE</code>.</li>\n</ol>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/00ca485b-c3c1-4929-8665-8fed4e4ed39b/7-how-build-support-tables-figma.jpeg\" /></p>\n<p>To help you better imagine how it works, here is a quick illustration that I made:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/03bbb5f6-56ae-432a-b74d-26cbb4e77516/8-how-build-support-tables-figma.png\" /></p>\n<p>The frame is for coloring the table lines between the rows and the table stroke (the outside table border). And you will need to add “crop frame content” and “corner radius” to shape the table.</p>\n<p>If you add “Auto layout,” it would work like this:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4ef3d701-0596-45ac-a051-fe5174a0ec66/11-how-build-support-tables-figma.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4f299511-298c-4a71-ab58-0409572335e2/12-how-build-support-tables-figma.png\" /></p>\n<p>As a result, you would get this behavior. Hold Shift and double-click to highlight it, then resize the column.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8231abeb-46e2-44cf-96f9-4a474456af06/14-how-build-support-tables-figma.png\" /></p>\n<p>For fixed-size cells, we apply <code>Fixed</code> horizontally:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/27e8459e-f303-47b9-a249-9aed5ff68cee/15-how-build-support-tables-figma.png\" /></p>\n<p>For the responsive cells, we need to set <code>Fill</code> horizontally:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/69cdcfd2-621c-43d3-b8ae-269c13ad5ca6/16-how-build-support-tables-figma.png\" /></p>\n<p>Then we turn this table into a <code>Frame</code>, and every row inside the <code>Frame</code> should have horizontal <code>Constraints</code> set as <code>Left and right</code>:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/46fb80a2-2971-4f4c-9fb6-1f20350e5442/17-how-build-support-tables-figma.png\" /></p>\n<p>Voilà, we’re fully responsive now!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0ae461fe-06d2-4b4c-a7aa-6d73294c3b30/19-how-build-support-tables-figma.png\" /></p>\n<p><strong>The kit structure:</strong></p>\n<ul>\n<li>icons we use in the table,</li>\n<li>basic header states,</li>\n<li>basic cell states.</li>\n</ul>\n<h3>Icons</h3>\n<p>Using any icon library, you can have a few hundred icons. As a result, this can push you to inconsistency (using different icons for the same goals, for example), especially if you have more than one designer on your team. Table icons as a separate library will help you manage and support consistency on big projects.</p>\n<h3>Combinations</h3>\n<p>There are a few main combinations we have: </p>\n<ul>\n<li>just text in a cell,</li>\n<li>just an icon or a set of icons in a cell,</li>\n<li>a variety of text, icons, and other objects (checkbox, toggle, action, select, and so on) in a different order within a cell.</li>\n</ul>\n<p>Avoid hidden layers! You will know that you used them while building a design system, and you will certainly forget about them later. In addition, people who will use your design system may not know about these hidden layers at all.</p>\n<p>You will have an idea of how to create them based on the illustration above (<strong>Building a basic table kit</strong>), but I’ll specify a few more complex components for beginner designers.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/489e4dd9-1354-4d7f-889f-b20b7f356b8e/21-how-build-support-tables-figma.jpeg\" /></p>\n<p>And we use <code>Auto layout</code> with the following parameters in the second component example:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8cb2ab41-9de7-4a12-b3ce-d222ad42036a/22-how-build-support-tables-figma.jpg\" /></p>\n<p>So, remember the table that we built using only two components? It’s time to update it!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0b324946-e254-43fb-b579-5e7193e305a0/24-how-build-support-tables-figma.jpeg\" /></p>\n<p>Also, you can use “Figma Properties” to make it compact. All the instructions you can find in the following tutorial video created by the Figma team during <a href=\"https://www.figma.com/blog/config-2022-thinking-big-and-acting-with-urgency/\">Figma Config 2022</a>: “Jumping into component properties.”</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f761a45b-8829-4f7f-ba69-906dc63dd2a6/25-how-build-support-tables-figma.png\" /></p>\n<p>It’s only one example of how I structured the basic table kit in this article. You can use a similar workflow or create your own. In my projects, kits are much more complex, so I’ll leave this choice to you. </p>\n<h3>Figma Design File</h3>\n<p>I have prepared a <a href=\"https://www.figma.com/file/UTy6ZCJ7MAnFz5udAZp2gB/SM?node-id=0%3A1\"><strong>Figma Design file</strong></a> that may help you go through some of the steps of my tutorial. If you have questions or need help, do post your questions in the comments section at the end of the article.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4ea18d2c-e663-40d2-9774-8b8a5f4d1415/26-how-build-support-tables-figma.png\" /></p>\nConclusion\n<p>The way I am working with tables in Figma is not as black and white. The approach mainly depends on the product you’re designing and, of course, there are a few possible ways you could achieve the same goals.</p>\n<p>Here are a few general recommendations I can make from my own practice:</p>\n<ul>\n<li>Keeping the line components on the design system side provides a chance to update tables for the whole project from one place. But every time you want to make an update, you will need to publish changes on the <strong>design system-level</strong>.</li>\n<li>If you keep tasks in different documents, don’t forget to <strong>disconnect that file from the design system</strong>. This would help avoid uncontrolled updates that you will miss.</li>\n<li>At first, using resizable components seems too tempting… until you need to begin supporting different styles in every size. If you have tables with varying line heights, <strong>it’s better to create individual components for each one of them.</strong></li>\n<li>There is an approach that consists of using <em>as few components</em> as possible. But most of the time, you don’t look at your components — instead, you use “variants” to switch between them. So, it’s <strong>better to have enough separate components and, as a result, “variants”</strong> than to use hidden layers, the “Auto layout” option, and components inside other components that would be hard to manage later on.</li>\n<li>Check that all table cells support <strong>at least</strong> two lines of text. You can use 16 <code>px</code> line spacing to make it happen.  </li>\n<li>I recommend using the <strong>minimum width for parent components</strong> (minimum width for each column). But these default minimum sizes have to be discussed with the front-end developers as they may sometimes have their own limitations. Therefore you need to ensure that everything in the design can be implemented in the later development stages.</li>\n<li><strong>Create a color palette in your Design System for the tables</strong>, so you would be able to control all the colors from one place. Of course, you can use shared colors from the palette, but once you need to change text color in the tables, background, or something else, you will get into trouble. </li>\n<li><strong>Create different text styles for the tables.</strong> For example, we use smaller line spacing in tables than in news feeds or articles. Having separate text settings would help you avoid future conflicts.</li>\n</ul>\n<p>Thank you for following me along! As I already said, tables are a complex component, and I can talk about this topic for days. But maybe better to stop here and give you a chance to try this approach for yourself. Then, if you have questions, I’d be happy to reply and help! Or I could write another article: “Working With Tables in Figma: The Pro Level.” ;-)</p>\n<h3>Further Reading</h3>\n<p>I have collected a few links to resources (tutorials, plugins, discussions, etc.) related to working with tables in Figma:</p>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2019/09/creating-tables-in-figma/\">Creating Tables In Figma</a>,” Sasha Belichenko<br /><em>A guide about one possible way of working with tables in Figma: how to create a table using components and Atomic Design methodology, and then how to integrate the table into your design system.</em></li>\n<li>“<a href=\"https://spin.atomicobject.com/2022/02/15/google-sheets-sync/\">Create a Figma Prototype with Data from Google Sheets</a>,” Bryan Elkus<br /><em>The article covers in detail a plugin for Figma called</em> <strong><em>Google Sheets Sync.</em></strong> <em>It allows a user to pull in content directly from Google Sheets which is super-useful if you want to use this to populate your designs with more realistic data.</em></li>\n<li>“<a href=\"https://www.figma.com/community/file/809752704119681183\">Creating Tables in Figma with Auto Layout</a>”, Gavin McFarland<br /><em>In this tutorial, Gavin explains how to modify tables in Figma which are completely fluid (with the Auto Layout feature). You can inspect the components in Figma Design to see how they were created.</em></li>\n</ul>\n<h4>Tweets</h4>\n<blockquote><p>I spend my whole Figma life designing tables. I imagine other designers too. <a href=\"https://twitter.com/figma?ref_src=twsrc%5Etfw\">@figma</a> can you please give us more features, like draggable horizontal rows AND vertical columns? Moving data around should be super easy, like Google Sheets.</p>— Joshua Sortino (@sortino) <a href=\"https://twitter.com/sortino/status/1513577995407179784?ref_src=twsrc%5Etfw\">April 11, 2022</a></blockquote> \n\n<blockquote><p>I have a love/hate relationship with tables, so here's how I set up my design system to make things easier. Rows vs. columns, cell variants, and a \"module\" component with a variable toolbar and variable pagination.<a href=\"https://t.co/0MbCROJAmp\">https://t.co/0MbCROJAmp</a> <a href=\"https://t.co/xztjdwoVeL\">pic.twitter.com/xztjdwoVeL</a></p>— Jon Moore (@TheJMoore) <a href=\"https://twitter.com/TheJMoore/status/1513844779431387151?ref_src=twsrc%5Etfw\">April 12, 2022</a></blockquote> \n\n<blockquote><p>We hear tables in <a href=\"https://twitter.com/figma?ref_src=twsrc%5Etfw\">@figma</a> are hard, and we agree.<br /><br />Here's how we leveraged our internal design tools to create a more seamless workflow for designers across the <a href=\"https://twitter.com/DesigningUber?ref_src=twsrc%5Etfw\">@DesigningUber</a> team ➡️ <a href=\"https://t.co/R8PwiYdebK\">pic.twitter.com/R8PwiYdebK</a></p>— Vincent van der Meulen (@vincentmvdm) <a href=\"https://twitter.com/vincentmvdm/status/1513630608274051074?ref_src=twsrc%5Etfw\">April 11, 2022</a></blockquote> \n\n<p><em>A short Twitter thread on this topic, also mentioning the Configurator plugin that Vincent’s team made.</em></p>\n<blockquote><p>I found a pretty reliable way to create flexible, responsive custom tables in Figma. I’ll do a video walkthrough at some point, but if you want to play… <a href=\"https://t.co/cibZI3Uk4g\">https://t.co/cibZI3Uk4g</a></p>— Buzz Usborne (@buzzusborne) <a href=\"https://twitter.com/buzzusborne/status/1511604883748622343?ref_src=twsrc%5Etfw\">April 6, 2022</a></blockquote> \n\n<blockquote><p>Did I make a full video about building tables in Figma? Yes. Do I regret going down this rabbit hole? Also yes. 📺🕳️ <a href=\"https://t.co/JCyLxEBktG\">https://t.co/JCyLxEBktG</a></p>— Buzz Usborne (@buzzusborne) <a href=\"https://twitter.com/buzzusborne/status/1514098048796065798?ref_src=twsrc%5Etfw\">April 13, 2022</a></blockquote> \n\n<blockquote><p>Tips time!<br /><br />Using component props, we can create \"infinite tables\"<br /><br />So we can toggle on however many columns / rows we need in designs<br /><br />This prevents us maintaining large variant sets for every permutation of table 🍽<br /><br />Community file to play with: <a href=\"https://t.co/WqNM5SMjSE\">https://t.co/WqNM5SMjSE</a> <a href=\"https://t.co/yhefqrNImC\">pic.twitter.com/yhefqrNImC</a></p>— luis. (@disco_lu) <a href=\"https://twitter.com/disco_lu/status/1531278254723567616?ref_src=twsrc%5Etfw\">May 30, 2022</a></blockquote>\n\n<p><em>Note: This technique is interesting if you have just a few tables in the product design. Otherwise it would be a problem to scale the system.</em></p>\n<p>As you can see, dealing with tables is a “hot topic” 🔥 in the Figma design community! I hope that you could find something useful here, too.</p>",
      "content_text": "The table is one of the most painful components designers have to deal with in their daily design lives. The table element is often a complex combination of text components, lines, rectangles, icons, and more. It soon may become a nightmare to work with, especially if you also want to support different screen resolutions, change the order of columns, and use real-life content.\nIn my projects, approximately half of the user interface designs I am working on are tables. This is why in this article, I’d like to share my approach to managing tables in Figma in an easier, more streamlined way. \nI’m not a fan of long reads with too many unnecessary details, so I’ll “jump” into the subject right away. My guide consists of several parts; thus, you can stop reading at any point when you understand that what you have learned so far covers your needs at the moment, and you can go back/or jump forward to any section when you want to refresh your memory or learn about the more complex workflows. Let’s go!\nTable of Contents\n\nCells and Table Structure\nReal Data and Column Size Corrections\nResponsive Tables\nBasic Table Kit and States\nFigma Design file\nConclusion\n\nNote: This article is aimed at people with some experience using Figma Design. If you are an absolute beginner in the Figma field, I would suggest first checking some basic Figma tutorials. To make things easier for you, near the end of the article (check Figma Design File section), I have provided my Figma Design which you can use for deconstruction and learning purposes.\nCells And Table Structure\nI often use the Ant Design System in my projects. Let’s take their table components as an example.\nTo start, we need to make only two simple components in Figma:\n\na head cell,\na row cell.\n\nUse Left and Center in Constraints to align the text.\n\nAside on keyboard shortcuts:Ctrl/Cmd — Win/MacAlt/Option — Win/MacShift — Win and MacFigma is a tool that works on both Windows and Mac. For example, the following keyboard shortcut combo Ctrl/Cmd + D means, “Press Ctrl + D on Windows, or press Cmd + D on Mac.”\n\nThen we need to copy the components for our future table:\n\nhold Alt/Option + Shift + left mouse button for copying\nand Ctrl/Cmd + D to repeat the last action in Figma.\n\n\nHow to create the table lines? Start here:\n\npress and hold Alt/Option + Shift + mouse left for copying,\nand Ctrl/Cmd+ D to repeat the last action in Figma.\n\n\nHow did I do it? Here are the steps:\n\ngroup the table row elements into a single frame;\nset corners’ radius to 15 px;\nset outline stroke to 1 px, #49E36B;\nset frame fill color to #278EEE.\n\n\nTo help you better imagine how it works, here is a quick illustration that I made:\n\nThe frame is for coloring the table lines between the rows and the table stroke (the outside table border). And you will need to add “crop frame content” and “corner radius” to shape the table.\nIf you add “Auto layout,” it would work like this:\n\n\nAs a result, you would get this behavior. Hold Shift and double-click to highlight it, then resize the column.\n\nFor fixed-size cells, we apply Fixed horizontally:\n\nFor the responsive cells, we need to set Fill horizontally:\n\nThen we turn this table into a Frame, and every row inside the Frame should have horizontal Constraints set as Left and right:\n\nVoilà, we’re fully responsive now!\n\nThe kit structure:\n\nicons we use in the table,\nbasic header states,\nbasic cell states.\n\nIcons\nUsing any icon library, you can have a few hundred icons. As a result, this can push you to inconsistency (using different icons for the same goals, for example), especially if you have more than one designer on your team. Table icons as a separate library will help you manage and support consistency on big projects.\nCombinations\nThere are a few main combinations we have: \n\njust text in a cell,\njust an icon or a set of icons in a cell,\na variety of text, icons, and other objects (checkbox, toggle, action, select, and so on) in a different order within a cell.\n\nAvoid hidden layers! You will know that you used them while building a design system, and you will certainly forget about them later. In addition, people who will use your design system may not know about these hidden layers at all.\nYou will have an idea of how to create them based on the illustration above (Building a basic table kit), but I’ll specify a few more complex components for beginner designers.\n\nAnd we use Auto layout with the following parameters in the second component example:\n\nSo, remember the table that we built using only two components? It’s time to update it!\n\nAlso, you can use “Figma Properties” to make it compact. All the instructions you can find in the following tutorial video created by the Figma team during Figma Config 2022: “Jumping into component properties.”\n\nIt’s only one example of how I structured the basic table kit in this article. You can use a similar workflow or create your own. In my projects, kits are much more complex, so I’ll leave this choice to you. \nFigma Design File\nI have prepared a Figma Design file that may help you go through some of the steps of my tutorial. If you have questions or need help, do post your questions in the comments section at the end of the article.\n\nConclusion\nThe way I am working with tables in Figma is not as black and white. The approach mainly depends on the product you’re designing and, of course, there are a few possible ways you could achieve the same goals.\nHere are a few general recommendations I can make from my own practice:\n\nKeeping the line components on the design system side provides a chance to update tables for the whole project from one place. But every time you want to make an update, you will need to publish changes on the design system-level.\nIf you keep tasks in different documents, don’t forget to disconnect that file from the design system. This would help avoid uncontrolled updates that you will miss.\nAt first, using resizable components seems too tempting… until you need to begin supporting different styles in every size. If you have tables with varying line heights, it’s better to create individual components for each one of them.\nThere is an approach that consists of using as few components as possible. But most of the time, you don’t look at your components — instead, you use “variants” to switch between them. So, it’s better to have enough separate components and, as a result, “variants” than to use hidden layers, the “Auto layout” option, and components inside other components that would be hard to manage later on.\nCheck that all table cells support at least two lines of text. You can use 16 px line spacing to make it happen.  \nI recommend using the minimum width for parent components (minimum width for each column). But these default minimum sizes have to be discussed with the front-end developers as they may sometimes have their own limitations. Therefore you need to ensure that everything in the design can be implemented in the later development stages.\nCreate a color palette in your Design System for the tables, so you would be able to control all the colors from one place. Of course, you can use shared colors from the palette, but once you need to change text color in the tables, background, or something else, you will get into trouble. \nCreate different text styles for the tables. For example, we use smaller line spacing in tables than in news feeds or articles. Having separate text settings would help you avoid future conflicts.\n\nThank you for following me along! As I already said, tables are a complex component, and I can talk about this topic for days. But maybe better to stop here and give you a chance to try this approach for yourself. Then, if you have questions, I’d be happy to reply and help! Or I could write another article: “Working With Tables in Figma: The Pro Level.” ;-)\nFurther Reading\nI have collected a few links to resources (tutorials, plugins, discussions, etc.) related to working with tables in Figma:\n\n“Creating Tables In Figma,” Sasha BelichenkoA guide about one possible way of working with tables in Figma: how to create a table using components and Atomic Design methodology, and then how to integrate the table into your design system.\n“Create a Figma Prototype with Data from Google Sheets,” Bryan ElkusThe article covers in detail a plugin for Figma called Google Sheets Sync. It allows a user to pull in content directly from Google Sheets which is super-useful if you want to use this to populate your designs with more realistic data.\n“Creating Tables in Figma with Auto Layout”, Gavin McFarlandIn this tutorial, Gavin explains how to modify tables in Figma which are completely fluid (with the Auto Layout feature). You can inspect the components in Figma Design to see how they were created.\n\nTweets\nI spend my whole Figma life designing tables. I imagine other designers too. @figma can you please give us more features, like draggable horizontal rows AND vertical columns? Moving data around should be super easy, like Google Sheets.— Joshua Sortino (@sortino) April 11, 2022 \n\nI have a love/hate relationship with tables, so here's how I set up my design system to make things easier. Rows vs. columns, cell variants, and a \"module\" component with a variable toolbar and variable pagination.https://t.co/0MbCROJAmp pic.twitter.com/xztjdwoVeL— Jon Moore (@TheJMoore) April 12, 2022 \n\nWe hear tables in @figma are hard, and we agree.Here's how we leveraged our internal design tools to create a more seamless workflow for designers across the @DesigningUber team ➡️ pic.twitter.com/R8PwiYdebK— Vincent van der Meulen (@vincentmvdm) April 11, 2022 \n\nA short Twitter thread on this topic, also mentioning the Configurator plugin that Vincent’s team made.\nI found a pretty reliable way to create flexible, responsive custom tables in Figma. I’ll do a video walkthrough at some point, but if you want to play… https://t.co/cibZI3Uk4g— Buzz Usborne (@buzzusborne) April 6, 2022 \n\nDid I make a full video about building tables in Figma? Yes. Do I regret going down this rabbit hole? Also yes. 📺🕳️ https://t.co/JCyLxEBktG— Buzz Usborne (@buzzusborne) April 13, 2022 \n\nTips time!Using component props, we can create \"infinite tables\"So we can toggle on however many columns / rows we need in designsThis prevents us maintaining large variant sets for every permutation of table 🍽Community file to play with: https://t.co/WqNM5SMjSE pic.twitter.com/yhefqrNImC— luis. (@disco_lu) May 30, 2022\n\nNote: This technique is interesting if you have just a few tables in the product design. Otherwise it would be a problem to scale the system.\nAs you can see, dealing with tables is a “hot topic” 🔥 in the Figma design community! I hope that you could find something useful here, too.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/47932465-87b0-41aa-97c3-4a2690860dd8/easy-build-support-tables-figma.jpg",
      "date_published": "2022-06-17T09:00:00.000Z",
      "date_modified": "2022-06-17T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/web-design-done-well-delightful-data-visualization-examples/",
      "url": "https://smashingmagazine.com/2022/06/web-design-done-well-delightful-data-visualization-examples/",
      "title": "Web Design Done Well: Delightful Data Visualization Examples",
      "summary": "All the data in the world won’t do anyone any good if we can’t make sense of it. Or better yet, make it sing. Here are some stunning examples of data visualization in the wild, and some pointers on how to start making your own.",
      "content_html": "<p>They say we are entering the Data Age. There’s certainly enough of the stuff about. Between analytics, public records, and the slow yet steady growth of the Semantic Web, millions of data points are at our fingertips, just waiting to have their stories told.</p>\n<p>Telling captivating stories with data is easier said than done. Spreadsheets don’t exactly get hearts singing. Big pieces of JSON don’t inspire so much as they horrify. It doesn’t need to be that way, though. Data can dance. Data <em>should</em> dance. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/285ede95-9012-4824-b51c-ec82facf8b17/wind-map-window.png\" /></p>\n<p>The site is a testament to the importance of publically available data (this will be a running theme in this article). The numbers are pulled through from the <a href=\"https://www.ncei.noaa.gov/products/weather-climate-models/national-digital-forecast-database\">National Digital Forecast Database</a> which is updated hourly. As creators <a href=\"http://www.fernandaviegas.com/\">Fernanda Viégas</a> and <a href=\"https://www.bewitched.com/\">Martin Wattenberg</a> put it, this makes Wind Map a “living portrait” of wind patterns in the contiguous United States.</p>\nDivineComedy.digital\n<p>Data visualization isn’t just about showing information — it’s about showing the connections between information. <a href=\"https://divinecomedy.digital/#/eng/landing\">DivineComedy.digital</a> is a “digital humanities tool” which shows how Dante’s <em>Divine Comedy</em> has manifested itself in the art across the seven centuries since it was published. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bf18f37f-03fc-435c-90e9-6a2da7938f70/divine-comedy-digital-window.png\" /></p>\n<p>The sections of the book have been broken down into chapters, and the chapters into passages. Each contains a wealth of artworks inspired by the text — from over 70 museums by more than 90 authors. The project is a testament to Dante’s original work, the works it has since inspired, and the power of digital tools to capture the true interconnectedness of things.  </p>\nThe Linked Open Data Cloud\n<p>Speaking of the interconnectedness of things, here’s something I became aware of while researching the <a href=\"https://www.smashingmagazine.com/2020/10/developing-semantic-web/\">Semantic Web</a> a couple of years ago. The Linked Open Data Cloud visualizes more that 16,000 links between 1,300 data sources on the Web.  </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/59432fb3-65e3-4cb7-a8e0-e43d13d890f1/linked-open-data-cloud-window.png\" /></p>\n<p>Maintained by <a href=\"http://john.mccr.ae/\">John Philip McCrae</a> for the <a href=\"https://www.insight-centre.org/\">Insight Centre for Digital Analytics</a>, the graph is built using <a href=\"https://github.com/lod-cloud/lod-cloud-draw\">LOD Cloud Draw</a>. (Though <a href=\"https://github.com/d3/d3-force\">D3’s force-directed graph</a> is perhaps a more mainstream equivalent.) The LODC has come a long way since starting with 12 datasets in 2007.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8d6377fb-e0bf-49a6-b99a-d3fc8aef04e4/1-web-design-done-well-delightful-data-visualization-examples.png\" /></p>\n<p>For those interested in learning more about linked data, <a href=\"https://dbpedia.org/page/Linked_data\">DPpedia</a> is a fine place to start. Data visualization tools aren’t much good without data to work their magic on, so networks like this (and the ethos of openness and sharing behind them) are vital.</p>\nUnited Nations Refugee Project\n<p>I hope you’ve noticed a common theme so far. Data visualization carries extra weight when it has purpose — when it’s more than just something nice to look at. <strong>The magic of data visualization is that it can take complex data sets about complex topics and present them in ways that almost anyone can understand.</strong> Data visualization can tell stories no other medium can. This <a href=\"https://unhcr.github.io/dataviz-streamgraph-explorer/#types=1-2-3-4-5-6-7\">stream chart of refugee movement in the 20th and 21st century</a> is a stunning example of that — packed with information yet accessible and clear. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5ccb02d6-d965-4595-877c-b471bd524d8f/un-refugee-stream-graph-window.png\" /></p>\n<p>This was commissioned by the United Nations Refugee Agency and masterminded by the brilliant <a href=\"https://twitter.com/currankelleher\">Curran Kelleher</a> (more on him later). You can almost see the ebb and flow of a crowd of millions. It’s powerful stuff, and just as importantly, it hasn’t watered down the subject matter. Instead, it has brought it to life. </p>\nFinancial Times’ Covid Chart\n<p>Sometimes only a line chart will do. The Financial Times data visualization team knocked it out of the park with <a href=\"https://ig.ft.com/coronavirus-chart/?areas=eur&amp;areas=usa&amp;areas=bra&amp;areas=gbr&amp;areas=rus&amp;areas=rou&amp;areasRegional=usny&amp;areasRegional=usla&amp;areasRegional=usnd&amp;areasRegional=usak&amp;areasRegional=usfl&amp;areasRegional=ustn&amp;cumulative=0&amp;logScale=0&amp;per100K=1&amp;startDate=2020-09-01&amp;values=deaths\">their tracking of Covid infections</a>, which became a major point of reference during the early days of the pandemic. It is a true team effort, the culmination of work by developers, designers, and reporters.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5453064c-faf3-4680-a53b-2bfaa3830155/ft-covid-tracker-window.png\" /></p>\n<p>Something I especially like about this example of data visualization is the amount of space dedicated to methodology and sources. It takes the time to explain the data and why it’s presented the way it is. Very occasionally these decisions speak for themselves, but it’s best to default to transparency. Give readers the full context.</p>\n<blockquote>\n<p>Data visualization can be beautiful. Well documented data visualization is even better.</p>\n</blockquote>\nSingapore’s Open Data\n<p>Data dashboards have become a lynchpin of the modern web. Singapore’s <a href=\"https://data.gov.sg\">data.gov.sg</a> is an especially good example of a government making data not just publically available, but readable too. It’s a vast, explorable data dashboard — one we can all learn from, both in terms of design and accessibility. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/29b6420c-3883-45c5-83f5-819a4dd79765/singapore-public-data-window.png\" /></p>\n<p>With almost 2,000 data sets on subjects ranging from property prices to short story programmes, the site feels like a virtual library. Browsing is easy and intuitive. The data is accessible in every sense of the word, trying to live up to <a href=\"https://data.gov.sg/about\">its own data sharing principles</a>: </p>\n<ul>\n<li>data shall be made easily accessible;</li>\n<li>data shall be made available for co-creation;</li>\n<li>data shall be released in a timely manner;</li>\n<li>data shall be shared in machine-readable format;</li>\n<li>data shall be as raw as possible.</li>\n</ul>\n<p>Hear, hear.</p>\nThe Pudding Explores The Pitch Of Pop Music\n<p>It’s a question that keeps all of us awake at night — are men singing at a higher pitch in pop music than they used to? Luckily, this project by data viz magicians <em>The Pudding</em> gives us the answer. <a href=\"https://pudding.cool/2019/08/register/\">Are Men Singing Higher in Pop Music?</a> uses vocal register data from Pandora to find the average pitch of every song featured in the Billboard Hot 100 since 1958. No, really. They did.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7f408cc4-9945-4590-ab2e-9923ae9a18d5/pudding-high-notes-window.png\" /></p>\n<p>What on the surface may seem a silly (if fun) idea quickly unfolds into a fascinating exploration of music trends, weaving together audio, video, and god honest line graphs into one colorful package. </p>\n<p>The piece is also an (admittedly inverted) glimpse into the possibilities of <a href=\"https://sonification.design/\">data sonification</a>, a concept hauntingly realized by data journalist <a href=\"http://www.journalist.sh/\">Simon Huwiler</a> with his <a href=\"http://www.journalist.sh/\">covid deaths music box</a>.</p>\nSolar Eclipse Map\n<p>Masterminded by visual journalist <a href=\"https://www.deniselu.com/\">Denise Lu</a>, this <a href=\"https://www.washingtonpost.com/graphics/national/eclipse/?utm_term=.4cc3027f54e0\">eclipse map</a> by the <em>Washington Post</em> is both stunning and useful — a winning data viz combination if ever there was one. The article asks for your year of birth, then displays every solar eclipse in your lifetime (provided you live to 100). How does it do this? On the globe, of course.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7e923e8a-3af9-44db-8ba2-5aa752836d2c/eclipse-globe-window.png\" /></p>\n<p>What by rights should appear extremely complicated is here made simple and intuitive. As is typical of the very best uses of data visualization, you wonder how or why anyone would ever want to present the same information another way. And the globe screenshotted above is just the tip of the iceberg. The article goes on to explore all sorts of fascinating stuff — from degrees of eclipse to the path of totality. </p>\nIMPF Dashboard\n<p>The seismic impact of the Covid pandemic has lent itself especially well to data visualization over the last couple of years. Infections, hospitalisations, deaths, reinfections, vaccinations… all this and more add up to the story of the pandemic. And that’s to say nothing of its impact on politics, economies, and culture. The amount of data available is overwhelming, but as <a href=\"https://impfdashboard.de/en/\">this dashboard by the German Federal Ministry of Health</a> shows, it can be wrangled into forms we can all understand.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/db40e4da-26b0-4afb-8f52-0048b098d9d5/impf-covid-vaccination-dashboard-window.png\" /></p>\n<p>Delving into vaccination data by region, age group, and even manufacturers, the dashboard is its own little masterclass in data visualization. It’s beautifully designed too, with an appealing palette and impressive range of styles giving each visual a distinctive look and feel. Government data doesn’t have to be boring or opaque. And again, it’s all available to download. </p>\nLunar Open Architecture\n<p>I don’t think we ever truly lose our childlike wonder for space exploration. Now more than ever humankind is reaching for the stars - but who’s doing what? And how’s it going? <a href=\"https://loa.mit.edu/\">Lunar Open Architecture (LOA)</a> seeks to answer those questions and a whole lot more. A collaboration between MIT Media Lab’s <a href=\"https://www.media.mit.edu/groups/space-exploration\">Space Exploration Initiative</a> and the <a href=\"https://www.openlunar.org/\">Open Lunar Foundation</a>, LOA includes a stunning, outer space-like data visualization of missions since 1958.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/cc6e25e7-715a-407f-9f58-e9b503eb1751/lunar-open-architecture-window.png\" /></p>\n<p>By grouping missions together by organizations, type, and status, the constellation of nodes gives you an immediate sense of how space exploration has evolved over time — and how it’s likely to evolve in the future. As MIT put it, “the future of lunar exploration is getting crowded.” Projects like this show that fact is something the masses can and should understand. It’s not rocket science. </p>\nNationscape Insights\n<p>There’s an awful lot of bluster around when it comes to the will of the people. Many claim to know what it is, yet seldom do they reach the same conclusions. Probably because they often don’t consult the people themselves. The <a href=\"https://eu.usatoday.com/storytelling/2020-election-voters-nationscape-insights/?question=abortion_conditions#demographic\">Nationscape Insights</a> project — a collaboration between the Democracy Fund Voter Study Group, UCLA, and <em>USA Today</em> — is an attempt to strip away the rhetoric from politics and show what voters actually think.  </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/19d5cac5-add2-4d20-9b99-977ec249361f/usa-today-voter-issues-window.png\" /></p>\n<p>Containing 80 weeks of survey data collected in the build up to the 2020 US election, the Nationscapes Insights project allows you to explore public opinions on topics ranging from gun control to the Green New Deal, with filters for region, demographics, and political party. It’s a remarkable dataset. The interface is intuitive, clear, and — I think — impressively nonpartisan. The methodology is clear. You can see the questions interviewees were asked. It is data visualization that clarifies rather than clouds, and that’s always a worthy goal. </p>\nGet Your Data Viz On\n<p>The data visualization examples shared here present but a fraction of what’s possible. If a data set exists, it can be expressed in fascinating, informative ways. It just needs storytellers (who show their methodology).</p>\n<p>In the interests of furthering data visualization everywhere, below is a selection of learning resources, libraries, articles, websites, and  other resources to sink your teeth into. Explore, play, do the unexpected. Go make something beautiful.</p>\n<h3>Learning resources</h3>\n<ul>\n<li><a href=\"https://www.coursera.org/specializations/data-analysis-visualization-foundations\">Data Analysis and Visualization Foundations Specialization</a>, a free Coursera course by IBM</li>\n<li><a href=\"https://www.freecodecamp.org/learn/data-visualization/\">freeCodeCamp D3 basics</a></li>\n<li><a href=\"https://www.freecodecamp.org/news/learn-data-visualization-in-this-free-17-hour-course/\">freeCodeCamp’s 17-hour data visualization course</a> taught by Curran Kelleher. D3, React, SVGs — this is the real deal, and you can code along. You’ll be amazed at the stuff you’re making by the end of it.</li>\n</ul>\n<h3>Libraries</h3>\n<ul>\n<li><a href=\"https://d3js.org/\">D3</a></li>\n<li><a href=\"https://threejs.org/\">Three</a></li>\n<li><a href=\"https://p5js.org/\">P5.js</a></li>\n<li><a href=\"https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API\">WebGL</a></li>\n<li><a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></li>\n</ul>\n<h3>For Your Bookmarks</h3>\n<ul>\n<li><a href=\"https://pudding.cool/\">The Pudding</a></li>\n<li><a href=\"https://www.theguardian.com/interactive\">The Guardian’s visual journalism</a></li>\n<li><a href=\"https://www.nytimes.com/spotlight/visual-investigations\">NYT visuals team</a></li>\n<li><a href=\"https://fivethirtyeight.com/\">FiveThirtyEight</a></li>\n<li>The <a href=\"https://www.reddit.com/r/dataisbeautiful/\">/r/dataisbeautiful</a> subreddit</li>\n<li><a href=\"https://sigmaawards.org/projects/\">Sigma Awards</a></li>\n<li><a href=\"https://ourworldindata.org/\">Our World in Data</a></li>\n<li><a href=\"https://www.lanacion.com.ar/\">La Nacion</a> </li>\n<li><a href=\"https://texty.org.ua/\">Texty.org.ua</a></li>\n</ul>\n<h3>Further Reading</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/11/dashboard-design-research-decluttering-data-viz/\">From Good To Great In Dashboard Design: Research, Decluttering And Data Viz</a>”, Adam Fard</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/11/data-visualization-apexcharts/\">Data Visualization With ApexCharts</a>”, Nefe Emadamerho-Atori</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/05/data-visualization-mobile-web-experience/\">Can Data Visualization Improve The Mobile Web Experience?</a>”, Suzanne Scacca</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2015/09/making-svg-maps-from-natural-earth-data/\">A Guide To Building SVG Maps From Natural Earth Data</a>”, Chris Youderian</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2015/03/fun-with-physics-in-data-visualization/\">Fun With Physics In Data Visualization</a>”, Antanas Marcelionis</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2009/09/25-useful-data-visualization-and-infographics-resources/\">Data Visualization and Infographics Resources</a>”, Cameron Chapman</li>\n</ul>",
      "content_text": "They say we are entering the Data Age. There’s certainly enough of the stuff about. Between analytics, public records, and the slow yet steady growth of the Semantic Web, millions of data points are at our fingertips, just waiting to have their stories told.\nTelling captivating stories with data is easier said than done. Spreadsheets don’t exactly get hearts singing. Big pieces of JSON don’t inspire so much as they horrify. It doesn’t need to be that way, though. Data can dance. Data should dance. \n\nThe site is a testament to the importance of publically available data (this will be a running theme in this article). The numbers are pulled through from the National Digital Forecast Database which is updated hourly. As creators Fernanda Viégas and Martin Wattenberg put it, this makes Wind Map a “living portrait” of wind patterns in the contiguous United States.\nDivineComedy.digital\nData visualization isn’t just about showing information — it’s about showing the connections between information. DivineComedy.digital is a “digital humanities tool” which shows how Dante’s Divine Comedy has manifested itself in the art across the seven centuries since it was published. \n\nThe sections of the book have been broken down into chapters, and the chapters into passages. Each contains a wealth of artworks inspired by the text — from over 70 museums by more than 90 authors. The project is a testament to Dante’s original work, the works it has since inspired, and the power of digital tools to capture the true interconnectedness of things.  \nThe Linked Open Data Cloud\nSpeaking of the interconnectedness of things, here’s something I became aware of while researching the Semantic Web a couple of years ago. The Linked Open Data Cloud visualizes more that 16,000 links between 1,300 data sources on the Web.  \n\nMaintained by John Philip McCrae for the Insight Centre for Digital Analytics, the graph is built using LOD Cloud Draw. (Though D3’s force-directed graph is perhaps a more mainstream equivalent.) The LODC has come a long way since starting with 12 datasets in 2007.\n\nFor those interested in learning more about linked data, DPpedia is a fine place to start. Data visualization tools aren’t much good without data to work their magic on, so networks like this (and the ethos of openness and sharing behind them) are vital.\nUnited Nations Refugee Project\nI hope you’ve noticed a common theme so far. Data visualization carries extra weight when it has purpose — when it’s more than just something nice to look at. The magic of data visualization is that it can take complex data sets about complex topics and present them in ways that almost anyone can understand. Data visualization can tell stories no other medium can. This stream chart of refugee movement in the 20th and 21st century is a stunning example of that — packed with information yet accessible and clear. \n\nThis was commissioned by the United Nations Refugee Agency and masterminded by the brilliant Curran Kelleher (more on him later). You can almost see the ebb and flow of a crowd of millions. It’s powerful stuff, and just as importantly, it hasn’t watered down the subject matter. Instead, it has brought it to life. \nFinancial Times’ Covid Chart\nSometimes only a line chart will do. The Financial Times data visualization team knocked it out of the park with their tracking of Covid infections, which became a major point of reference during the early days of the pandemic. It is a true team effort, the culmination of work by developers, designers, and reporters.\n\nSomething I especially like about this example of data visualization is the amount of space dedicated to methodology and sources. It takes the time to explain the data and why it’s presented the way it is. Very occasionally these decisions speak for themselves, but it’s best to default to transparency. Give readers the full context.\n\nData visualization can be beautiful. Well documented data visualization is even better.\n\nSingapore’s Open Data\nData dashboards have become a lynchpin of the modern web. Singapore’s data.gov.sg is an especially good example of a government making data not just publically available, but readable too. It’s a vast, explorable data dashboard — one we can all learn from, both in terms of design and accessibility. \n\nWith almost 2,000 data sets on subjects ranging from property prices to short story programmes, the site feels like a virtual library. Browsing is easy and intuitive. The data is accessible in every sense of the word, trying to live up to its own data sharing principles: \n\ndata shall be made easily accessible;\ndata shall be made available for co-creation;\ndata shall be released in a timely manner;\ndata shall be shared in machine-readable format;\ndata shall be as raw as possible.\n\nHear, hear.\nThe Pudding Explores The Pitch Of Pop Music\nIt’s a question that keeps all of us awake at night — are men singing at a higher pitch in pop music than they used to? Luckily, this project by data viz magicians The Pudding gives us the answer. Are Men Singing Higher in Pop Music? uses vocal register data from Pandora to find the average pitch of every song featured in the Billboard Hot 100 since 1958. No, really. They did.\n\nWhat on the surface may seem a silly (if fun) idea quickly unfolds into a fascinating exploration of music trends, weaving together audio, video, and god honest line graphs into one colorful package. \nThe piece is also an (admittedly inverted) glimpse into the possibilities of data sonification, a concept hauntingly realized by data journalist Simon Huwiler with his covid deaths music box.\nSolar Eclipse Map\nMasterminded by visual journalist Denise Lu, this eclipse map by the Washington Post is both stunning and useful — a winning data viz combination if ever there was one. The article asks for your year of birth, then displays every solar eclipse in your lifetime (provided you live to 100). How does it do this? On the globe, of course.\n\nWhat by rights should appear extremely complicated is here made simple and intuitive. As is typical of the very best uses of data visualization, you wonder how or why anyone would ever want to present the same information another way. And the globe screenshotted above is just the tip of the iceberg. The article goes on to explore all sorts of fascinating stuff — from degrees of eclipse to the path of totality. \nIMPF Dashboard\nThe seismic impact of the Covid pandemic has lent itself especially well to data visualization over the last couple of years. Infections, hospitalisations, deaths, reinfections, vaccinations… all this and more add up to the story of the pandemic. And that’s to say nothing of its impact on politics, economies, and culture. The amount of data available is overwhelming, but as this dashboard by the German Federal Ministry of Health shows, it can be wrangled into forms we can all understand.\n\nDelving into vaccination data by region, age group, and even manufacturers, the dashboard is its own little masterclass in data visualization. It’s beautifully designed too, with an appealing palette and impressive range of styles giving each visual a distinctive look and feel. Government data doesn’t have to be boring or opaque. And again, it’s all available to download. \nLunar Open Architecture\nI don’t think we ever truly lose our childlike wonder for space exploration. Now more than ever humankind is reaching for the stars - but who’s doing what? And how’s it going? Lunar Open Architecture (LOA) seeks to answer those questions and a whole lot more. A collaboration between MIT Media Lab’s Space Exploration Initiative and the Open Lunar Foundation, LOA includes a stunning, outer space-like data visualization of missions since 1958.\n\nBy grouping missions together by organizations, type, and status, the constellation of nodes gives you an immediate sense of how space exploration has evolved over time — and how it’s likely to evolve in the future. As MIT put it, “the future of lunar exploration is getting crowded.” Projects like this show that fact is something the masses can and should understand. It’s not rocket science. \nNationscape Insights\nThere’s an awful lot of bluster around when it comes to the will of the people. Many claim to know what it is, yet seldom do they reach the same conclusions. Probably because they often don’t consult the people themselves. The Nationscape Insights project — a collaboration between the Democracy Fund Voter Study Group, UCLA, and USA Today — is an attempt to strip away the rhetoric from politics and show what voters actually think.  \n\nContaining 80 weeks of survey data collected in the build up to the 2020 US election, the Nationscapes Insights project allows you to explore public opinions on topics ranging from gun control to the Green New Deal, with filters for region, demographics, and political party. It’s a remarkable dataset. The interface is intuitive, clear, and — I think — impressively nonpartisan. The methodology is clear. You can see the questions interviewees were asked. It is data visualization that clarifies rather than clouds, and that’s always a worthy goal. \nGet Your Data Viz On\nThe data visualization examples shared here present but a fraction of what’s possible. If a data set exists, it can be expressed in fascinating, informative ways. It just needs storytellers (who show their methodology).\nIn the interests of furthering data visualization everywhere, below is a selection of learning resources, libraries, articles, websites, and  other resources to sink your teeth into. Explore, play, do the unexpected. Go make something beautiful.\nLearning resources\n\nData Analysis and Visualization Foundations Specialization, a free Coursera course by IBM\nfreeCodeCamp D3 basics\nfreeCodeCamp’s 17-hour data visualization course taught by Curran Kelleher. D3, React, SVGs — this is the real deal, and you can code along. You’ll be amazed at the stuff you’re making by the end of it.\n\nLibraries\n\nD3\nThree\nP5.js\nWebGL\nWeb Audio API\n\nFor Your Bookmarks\n\nThe Pudding\nThe Guardian’s visual journalism\nNYT visuals team\nFiveThirtyEight\nThe /r/dataisbeautiful subreddit\nSigma Awards\nOur World in Data\nLa Nacion \nTexty.org.ua\n\nFurther Reading\n\n“From Good To Great In Dashboard Design: Research, Decluttering And Data Viz”, Adam Fard\n“Data Visualization With ApexCharts”, Nefe Emadamerho-Atori\n“Can Data Visualization Improve The Mobile Web Experience?”, Suzanne Scacca\n“A Guide To Building SVG Maps From Natural Earth Data”, Chris Youderian\n“Fun With Physics In Data Visualization”, Antanas Marcelionis\n“Data Visualization and Infographics Resources”, Cameron Chapman\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6b1a5a7a-d478-4c0c-b4c8-782bf7fa7f42/web-design-done-well-delightful-data-visualization-examples.jpg",
      "date_published": "2022-06-16T09:00:00.000Z",
      "date_modified": "2022-06-16T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/guide-windows-high-contrast-mode/",
      "url": "https://smashingmagazine.com/2022/06/guide-windows-high-contrast-mode/",
      "title": "The Guide To Windows High Contrast Mode",
      "summary": "In this article, we’ll see how to make our sites friendly for Windows High Contrast Mode by using a good set of practices, including the media query `forced-colors` and its toolset.",
      "content_html": "<p>When we talk about accessibility, we tend to talk about many things — such as dark mode, keyboard navigation, prefers-reduced-motion, and screen readers — but there is one thing that does not receive that much attention: Windows High Contrast Mode (from now on, abbreviated as WHCM). This is a tendency I have seen in some websites at a point where we have normalized some practices that can harm users’ experience in WHCM. In this article, I want to explain what it is and give a good set of practices we can keep in mind to make our sites more usable with this mode.</p>\nAbout Windows High Contrast Mode\n<p>High Contrast mode is an accessibility feature that changes the look of our website and Windows applications by replacing the color of the different elements (like background, buttons, or text) with some user’s set up colors. This has multiple purposes, like increasing readability, reducing a website’s visual noise by removing certain elements (and by extension, allowing them to have a better focus), and giving users full control of the website’s contrast. You can check out by going to Settings, then clicking on Accessibility, and finally clicking on High Contrast.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8872c207-9ae7-4822-a97d-b1ebe82dd093/1-guide-windows-high-contrast-mode.jpg\" /></p>\n<p>To talk about some statistics, according to <a href=\"https://github.com/melanierichards/talks/blob/main/2019/color-contrast-view-source/slides/melanie-richards-the-tailored-web--with-notes.pdf\">Melanie Richard in her talk “The tailored web: effectively honoring visual preferences”</a>, around 4% of active devices use Windows High Contrast Mode, and thanks to <a href=\"https://webaim.org/projects/lowvisionsurvey2/#at\">WebAIM’s Survey of Users with Low Vision</a> we can estimate that around 30% of users with low vision user Windows High Contrast Mode. All this should give you some perspective about the importance of making our website friendly with this mode.</p>\n<p>The name “High Contrast Mode” is a bit misleading because the user can choose their preferred colors, leading to a color palette that has <strong>lower</strong> contrast than usual — which is not a very odd case. According to WebAIM’s survey, <a href=\"https://webaim.org/projects/lowvisionsurvey2/#contrastMode\">around 3% of users of Windows High Contrast Mode</a> set it up to create a low contrast color pallete. The users with migraines or light sensitivity can do that to mitigate their disabilities’ impact. Just to give you a quick example:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f2c7f3bf-270f-4fb9-a421-98d4dfdd9ccc/2-guide-windows-high-contrast-mode.jpg\" /></p>\n<p>I’m sure you understand the importance of making our website friendly with WHCM, and you might think that due to its nature of replacing a big part of our styles, making a website that works for that mode can be hard. Great news, it’s not! We just need to consider some important issues to ensure the user experience is not harmed.</p>\nConsiderations About Windows High Contrast Mode\n<p>Despite how much control we lose when our website is displayed in WHCM, we can make it work without too much effort as long as we keep in mind some considerations. Before I start with that, I’d like you to keep in mind the golden rule with this mode: above all things, High Contrast Mode is about usability, and we need to respect that above any other aesthetics matter. Our biggest priority with this mode is <strong>easing readability and not harming the user experience in any way</strong>. </p>\n<p>How can we ensure readability and usability works in WHCM? We can have certain important considerations for that:</p>\n<h3>Use Semantic HTML</h3>\n<p>This has been a very important topic when we talk about accessibility due to its importance for screen readers, and it’s very important in WHCM as well! Why? Because Windows will add the styles depending on the semantics of an element and not because of how it looks outside WHCM. A link will have the <em>hyperlinks</em> styles, a button will have the <em>Button Text</em> styles, and so on.</p>\n<p>Some devs (for some reason) decide to use aria roles on divs to camouflage them as buttons for assistive technology. However, in WHCM, aria roles are irrelevant for Windows to determine which style to apply, so we depend on semantics to make our website works properly in this mode.</p>\n<p>To validate this point, let’s check how a div that acts as real button and a link would behave in High Contrast Mode using the same styles.</p>\n<pre><code>&lt;div role=\"button\" class=\"button\" tabindex=0&gt;\n  Not a button\n&lt;/div&gt;\n&lt;button class=\"button\"&gt;\n  Definitely a button\n&lt;/button&gt;\n&lt;a href=\"#\" class=\"button\"&gt;\n  This is a link\n&lt;/a&gt;\n</code></pre>\n\n<pre><code>\n.button {\n  padding: 0.5em 1em;\n  border: 2px solid hotpink;\n  background-color: hotpink;\n  width: fit-content;\n  border-radius: 0.5em;\n  font-size: 1.5rem;\n  font-family: sans-serif;\n  text-decoration: none;\n  color: black;\n}\n</code></pre>\n\n<p>In default settings, the div and the button <strong>will have the same colors</strong> but remember: users can change that. Let’s use this color palette, and let’s check the results:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e0cd1cfc-9ccd-416c-9a8d-700f62dc9ccd/3-guide-windows-high-contrast-mode.jpg\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b66efe53-dc98-40d3-b440-cd1b73041f2d/4-guide-windows-high-contrast-mode.jpg\" /></p>\n<p>Notice that semantics have a significant matter in WHCM for styling. Remember, in this mode, we have to focus on not harming the user’s experience, and choosing the wrong element can confuse users. </p>\n<h3><code>transparent</code> Properties Are Useful!</h3>\n<p>When we style certain interactive components like buttons or links, we tend to remove certain properties with <code>border: none</code>, <code>outline: none</code>, or <code>text-decoration: none</code> because those properties might not match with our design system. Usually, that’s not a bad idea as long as you keep in mind things like hover or focus state for those components. For WHCM, however,it is a serious problem because background elements are completely overwritten, and we’ll depend on borders to differentiate those components from the background.</p>\n<p>Just to give you an example, a very common design pattern I have seen is with the primary and secondary buttons, where the former has a background color and no border, and the latter has just a border and no background. It looks good, but when you see them under High Contrast Mode: </p>\n<pre><code>&lt;button class=\"primary\"&gt;\n  Primary action\n&lt;/button&gt;\n&lt;button class=\"secondary\"&gt;\n  Secondary action\n&lt;/button&gt;\n</code></pre>  \n\n<pre><code>\n    button {\n      font-size: 1.3em;\n      padding: 0.5em 1em;\n      border: none;\n      font-family: sans-serif;\n      border-radius: 0.4em;\n      background-color: transparent;\n    }\n\n    .primary {\n      background-color: hotpink;\n    }\n\n    .secondary {\n      border: 2px solid hotpink\n    }\n</code></pre>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/50b967b0-9aa7-41b9-b96c-78d1d0395944/5-guide-windows-high-contrast-mode.png\" /></p>\n<p>The primary button can be easily mistaken for a normal text! This is where transparent borders come into play because transparencies will be visible under a High Contrast Mode. So by replacing the border property in the button element with this: <code>2px solid transparent</code>, we’ll have this result:</p>\n<pre><code>\n    button {\n      border: 2px solid transparent\n    }\n</code></pre>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4ac7764d-426b-4342-944e-93773239cf11/6-guide-windows-high-contrast-mode.png\" /></p>\n<p>As you can imagine, that also happens with links if you use the property <code>text-decoration-color: transparent</code>, and with outlines if you use <code>outline-color: transparent</code>. Let’s check some quick examples about those properties.</p>\n<p><code>text-decoration-color: transparent</code> is useful if you’re using another element to represent a link in your site. Just to give an example, you can use background-image to animate the underline, as you can see in <a href=\"https://www.youtube.com/watch?v=_1vEGYWaaQY\">this video made by Kevin Powell</a>. However, in WHCM, you’ll only depend on the color the user has in his settings, so if you want to give an additional visual cue, a transparent underline will work great there! </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/64212eb1-8657-4225-b73e-ddca027c16c9/7-guide-windows-high-contrast-mode.png\" /></p>\n<p>Outlines are a particularly important topic in this mode because some developers rely on other properties to add focus states to interactive elements — such as changing the <code>background-color</code> or even the <code>box-shadow</code> hack (even if it’s not necessary nowadays because now the outline will follow the element’s <code>border-radius</code> since Chrome 94 and Firefox 88). However, all those things are completely overwritten in this mode, so outline remains as <strong>the only reliable way to apply a focus state on an element in WHCM</strong>. Always keep that in mind: if you’re going to use something different than an outline to highlight a focus state in an element, add the property <code>outline-color: transparent</code> as a fallback to not missing a focus state in this mode.</p>\n<h3>Keep In Mind Scrollbars</h3>\n<p>Scrollbars <strong>can</strong> be styled, but does that mean we <strong>should</strong> style them? There are some usability and accessibility concerns about this topic. The one I want to bring here is the fact that, depending on how you style it in WHCM, they’ll look clunky in the best of cases, or they won’t be visible at all at worst of scenarios.</p>\n<p>Is there a way to solve that? That depends on how you decide to style a scrollbar. Some people decide to use a solid color to fill the scrollbar’s thumb, and that does have a very easy fix. Let’s suppose we decided to style our scrollbar that way, then you will go for something like:</p>\n<pre><code>\n    ::-webkit-scrollbar {\n      width: 20px; \n    }\n\n    ::-webkit-scrollbar-track {\n      background-color: #e4e4e4;\n      border-radius: 100px;\n    }\n\n    ::-webkit-scrollbar-thumb {\n      border-radius: 100px;\n      background-color: green;\n    }\n    </code></pre>\n\n<p>As you might guess, the scrollbar won’t be visible in WHCM due to its <code>background-color</code> property being forcedly replaced. The great news is that we have already seen how to remediate this problem!</p>\n<p>Transparent borders can cover this situation. You can use them to cover all the scrollbar’s thumb, and it’ll look like it’ll have a solid color (the one you choose as text color in settings) which will be pretty similar to how it works as a default scrollbar in this mode. To follow our previous example, if we use the property <code>border: 10px solid transparent</code>, it will make it look like it has a solid background in WHCM.</p>\n<p>Be careful using this technique with scrollbar thumbs styled with <code>box-shadow</code> insets, though. If you do that, it’ll make it invisible. Not in WHCM, I mean invisible <strong>outside</strong> of it. You can check this problem in <a href=\"https://codepen.io/shadeed/pen/VwpOReG\">this scrollbar style made by Ahmad Shadeed</a>, go to the scrollbar thumb styles, and add the same style we added before (<code>border: 10px solid transparent</code>) . You’ll see it’ll become invisible, a good way to make it visible (both regularly and in WHCM) is just using a smaller border (something like <code>2px</code> instead of <code>10px</code>) to make it look like this in WHCM:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b0f79dfe-e917-40dc-aee4-968b17502336/8-guide-windows-high-contrast-mode.png\" /></p>\n<p>It looks good! The only problem is that it looks a bit weird outside of WHCM, so keep this in mind if you decide to style a scrollbar using an inset <code>box-shadow</code>.</p>\n<p>Remember that all that applies only to Chromium-based browsers, as Firefox has a different way to style scrollbars using <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/scrollbar-color\"><code>scrollbar-color</code></a> and <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/scrollbar-width\"><code>scrollbar-width</code></a> properties. The good news is that in WHCM, you won’t have to do a thing to make it work properly! The colors will be overwritten, and the scrollbar’s thumb will have the same color user has set up as text color.</p>\n<h3>Behavior Of Images</h3>\n<p>We have different ways to use images on a site: using the tag <code>img</code>, the <code>background-image</code> CSS property, using SVGs, and even CSS art! Let’s dig about those quickly. <code>img</code> tag will behave the same in WHCM, so let’s talk about the other three.</p>\n<p>First, we have the <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/background-image\"><code>background-image</code></a> property — and this one will remain the same in WHCM <strong>as long as you’re using the <code>url()</code> value.</strong> A gradient made with <code>background-image</code> will be overwritten by WHCM’s background color. However, there is only one catch with this. Even though Firefox supports background images in High Contrast Mode since around 2018-2019, <strong>it won’t be visible if you put <code>background-image</code> <em>in the</em> <code>body</code> element</strong>.</p>\n<p>You can try it out by seeing the CodePen I made to try to open it while using WHCM. So keep that in mind in case you’re using a background image like that.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/62b06924-8f40-429a-8ebf-1b509e8535c1/9-guide-windows-high-contrast-mode.png\" /></p>\n<p>That’s a bit problematic. Even when we normally want SVG to remain the same, there should be a way to manage those situations for specific scenarios. The good news is that, indeed, there is one! But let’s put a pin on this topic for now.</p>\n<p>Keep in mind that this scenario only happens in Chromium-based browsers — Firefox has its own way to manage this. SVGs inside an anchor that use the <code>currentColor</code> property will receive the same color as the link color user has set up. It’ll even respect whatever color the theme uses as a visited link, as this picture shows:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ae18e544-4f65-4e51-8e35-47e88dbb5833/10-guide-windows-high-contrast-mode.png\" /></p>\n<p>Finally, we have CSS art. Due to its nature of using elements like box shadows and background gradients, you might guess it won’t look good in WHCM — and you’re absolutely right. Due to its artistic nature, it’s no big deal, so you should be fine. But, if it does have a purpose in your website, we need to look for a way to make it visible. Just a quick note about CSS art: remember you can — and should — <a href=\"https://alvaromontoro.com/blog/67979/creating-accessible-css-art\">make your CSS art accessible</a>!</p>\n<p>As long as you keep in mind those small suggestions, our website will be almost done for WHCM! As you saw, some elements would need some tweaks to make them work to their full extent in this mode, but luckily for us, CSS has a way to help us to get this last part of the job done!</p>\nMedia Query Forced-Colors\n<p>Microsoft made an effort to create a standard to support WHCM, and the result of this work was the <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/@media/forced-colors\">media query</a> <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/@media/forced-colors\"><code>forced-colors</code></a>, which will help us to detect if the browser or operating system has enabled a mode that limits a website’s styles to a user-chosen color palette. As you might guess, WHCM is the most popular choice among them.</p>\n<p>This media query will act a bit differently due to how WHCM works. Some properties will be limited to certain values, some won’t be able to be overwritten at all, and we have new properties’ values to work with! But before digging into what we can do with this tool, let’s remember that WHCM (and other modes that restrict user’s color palettes) prioritize usability, and this is something we need to respect. So <strong>don’t use those properties unless it’s necessary to tweak some elements in your website</strong> to give it good usability in this mode.</p>\n<p>With that said, let’s start talking about the media query itself. It has two values: none and active. The former will detect when there is no forced colors mode active, and the second one will detect when there is. Under forced colors mode, the next properties will be replaced with the ones that are set up by the user:</p>\n<ul>\n<li><code>color</code></li>\n<li><code>background-color</code></li>\n<li><code>text-decoration-color</code></li>\n<li><code>text-emphasis-color</code></li>\n<li><code>border-color</code></li>\n<li><code>outline-color</code></li>\n<li><code>column-rule-color</code></li>\n<li><code>-webkit-tap-highlight-color</code></li>\n<li>SVG <code>fill</code> and <code>stroke</code> attributes</li>\n</ul>\n<p>Additionally, there are some properties that will have a forced behavior:</p>\n<table>\n  <tr>\n    <th>Property</th>\n    <th>Value</th>\n  </tr>\n  <tr>\n    <td><code>box-shadow</code></td>\n    <td><code>none</code></td>\n  </tr>\n  <tr>\n    <td><code>text-shadow</code></td>\n    <td><code>none</code></td>\n  </tr>\n  <tr>\n    <td><code>background-image</code></td>\n    <td><code>none</code> (unless it’s <code>url()</code> )</td>\n  </tr>\n  <tr>\n    <td><code>color-scheme</code></td>\n    <td><code>light dark</code></td>\n  </tr>\n  <tr>\n    <td><code>accent-color</code></td>\n    <td><code>auto</code></td>\n  </tr>\n  <tr>\n    <td><code>scrollbar-color</code> (Firefox)</td>\n    <td><code>auto</code></td>\n  </tr>\n</table>\n\n<p>With that explained, let’s dig into two tools we have we can use to enhance the experience in this mode.</p>\n<h3>Forced-Color-Adjust</h3>\n<p>Now, how can we change how those properties behave? There is a way to avoid WHCM overwrites colors, and this is by using the property <code>forced-color-adjust</code>. This property has two values: <code>auto</code> and <code>none</code>, and it’ll let us decide if we want an element’s colors will be replaced by the user agent’s colors or not, respectively. Let’s check an example of how those work, and there aren’t better examples than the ones we left uncovered in the previous section!</p>\n<p>Let’s check the link with the external link’s SVG we used earlier. Keep in mind that in Chromium-based browsers, this SVG won’t change its color to match the one that is used as a link color because SVGs have a default value of none. So, if we add the property <code>forced-color-adjust: auto</code> to our SVG as follows:</p>\n<pre><code>.inline-icon {\n  /* Previous CSS properties */\n  forced-color-adjust: auto;\n}\n</code></pre>\n\n<p>This will be our result:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/353b9638-ae89-4b22-864c-899c756543a8/11-guide-windows-high-contrast-mode.png\" /></p>\n<p>I know this section is about the media query itself, and usually, what you’d do is put that rule inside the media query like this:</p>\n<pre><code>@media screen and (forced-colors: active) {\n  .inline-icon {\n    forced-color-adjust: auto;\n  }\n}\n</code></pre>\n\n<p>That’s a valid approach (and, honestly, the most intuitive one). However, while I did some experiments for this article, I noticed that you can put this property in an element without the need to use the media query, and you’ll get the same result! And because this property will affect only the behavior of this element in a forced colors scenario, it won’t give you any unexpected behavior. </p>\n<p>Now, with CSS art, we want the opposite to be true (again, as long as this CSS is necessary to give enough context to the user), so we can use <code>forced-color-adjust: none</code> in the art’s parent element, and now all of it will be visible in WHCM.</p>\n<p>You may be thinking that this is not a common use case of <code>forced-color-adjust: none</code>, and you’d be right, so let’s check a more realistic one: showing color palletes on your website! Let’s take a look at any pallete generated by <a href=\"https://mycolor.space/\">mycolor.space</a> for example:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/178ecb9c-e794-4c21-912a-1ddfc291567d/12-guide-windows-high-contrast-mode.png\" /></p>\n<p>Those colors are not visible, and it’s an important part of the website, so if we go to the color container element and we add this property, we’ll solve this problem. </p>\n<h3>System Colors</h3>\n<p>Now let’s talk about colors. With media query <code>forced-colors</code> we have a handful of system colors we can use. You can see a list of colors in <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/color_value#system_colors\">MDN’s documentation</a>, and we can use this list of colors to replace certain properties. Using the property <code>color: LinkText</code> will make it look like a link, for example.</p>\n<p>Just remember: those colors are closely related to HTML semantics, so maybe you’d be better changing an element to its correct tag instead of trying to change how it looks in WHCM. That doesn’t mean it doesn’t have its uses. We just have to be sure we are doing this for the right reasons. Which is a good reason to use this? Well, that depends on the complexity of what you are creating. Let’s take, as an example, this link I created with the help of the <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/clip-path\"><code>clip-path</code></a> property.</p>\n<pre><code>.link {\n  --clip-path: polygon(0% 0%, calc(100% - 0.8em) 0%, 100% 0.8em, 100% 100%, 0.8em 100%, 0% calc(100% - 0.8em));\n  font-size: 2rem;\n  padding: 0.1em;\n  border: none;\n  background-color: #0E0054;\n  clip-path: var(--clip-path);\n  font-family: sans-serif;\n}\n\n.link:focus {\n  outline: none;\n}\n\n.link:focus span, .link:hover span {\n  outline-offset: -0.5em;\n  outline: 3px solid transparent;\n  background-color: #0E0054;\n  color: white;\n  text-decoration-color: white;\n}\n\n.link span {\n  display: inline-block;\n  padding: 0.5em 1.2em;\n  clip-path: var(--clip-path);\n  background-color: white;\n  color: #0E0054;\n  text-decoration: underline #0E0054;\n  text-underline-offset: 2px;\n}\n\n.link span {\n  display: inline-block;\n  padding: 0.5em 1.2em;\n  clip-path: var(--clip-path);\n  background-color: white;\n  color: #0E0054;\n  text-decoration: underline #0E0054;\n  text-underline-offset: 2px;\n}\n</code></pre>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/748c893b-9792-4654-a001-c86eab10492c/13-guide-windows-high-contrast-mode.png\" /></p>\n<p>Let’s make a quick check of the problems with this element in WHCM:</p>\n<ul>\n<li>I used a <code>background-color</code> to mimic a border with this element, but because it’s a background, it won’t be visible in WHCM.</li>\n<li>Even if I used a transparent outline to make a focus state in this mode, its color would be the one that the system uses as a link color, instead of the one WHCM’s usual outline color.</li>\n</ul>\n<p>With this in mind, we can tweak system colors using the media query <code>forced-colors</code> to give enough visual feedback to users by showing them that that is a link.</p>\n<pre><code>@media screen and (forced-colors: active) {\n  .link {\n    background-color: LinkText;\n  }\n\n  .link:visited {\n    background-color: VisitedText;\n  }\n\n  .link:focus span {\n    outline-color: Highlight;\n  }\n}\n</code></pre>\n\n<p>Remember Firefox has a visited state color for links, so to respect that. We should add the <code>VisitedText</code> system color in the <code>visited</code> pseudo-class of our link. With that said, this is our result:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f3b67973-8d36-44bf-8fae-19fee8c6ed3f/14-guide-windows-high-contrast-mode.png\" /></p>\n<p>Another simple example of how we can use system colors to tweak the experience is something we saw in the previous section: scrollbars! Let’s suppose that, for some reason, transparent borders are not an option. In this case, we can use system colors to make our scrollbar looks good in this mode! Let’s come back to one of the examples we used previously, and instead of using a transparent border, we’ll use the media query to tweak the scrollbar’s thumb’s color.</p>\n<pre><code>::-webkit-scrollbar {\n  width: 20px;\n}\n\n::-webkit-scrollbar-track {\n  background-color: #e4e4e4;\n  border-radius: 100px;\n}\n\n::-webkit-scrollbar-thumb {\n  border-radius: 100px;\n  background-color: green;\n}\n\n@media screen and (forced-colors: active) {\n  ::-webkit-scrollbar-thumb {\n    background-color: CanvasText;\n  }\n}\n</code></pre>   \n\n<h3>Other Uses Of This Media Query</h3>\n<p>As you read, forced-color-adjust and system colors are great tools to tweak our design if needed, but that’s not all we can do with this media query. Yes, we saw that some properties are restricted to certain uses, but most of them can be used normally! Remember, this is just to improve usability in WHCM, so there is no need to go too wild with that. Use it just when it’s needed.</p>\n<p>Let’s come back to the clip-path link we used. You could decide that the approach to how it looks in WHCM is to use a simpler design, like maybe just using a regular bordered element. We can do that! Let’s ignore the CSS rules I used in my previous example, and let’s use those instead:</p>\n<pre><code>@media screen and (forced-colors: active) {\n  .link {\n    --clip-path: none;\n    border: 3px solid transparent;\n    border-radius: 8px;\n  }\n\n  .link:focus {\n    outline: 3px solid transparent;\n    outline-offset: 3px;\n  }\n\n  .link:focus span {\n    outline: none;\n  }\n}\n</code></pre>\n\n<p>And this is our result:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f0ac5d68-c42f-41e1-b2b0-c9decc6d983d/15-guide-windows-high-contrast-mode.png\" /></p>\n<p>With that approach, you still show the user this is a link, and you avoid any possible confusion with this topic. Uses of CSS properties in this media query can open some interesting doors to improve how sites work. You can remove a merely decorative image in this mode — with <code>display: none</code> (if you used an img tag) or <code>background-image: none</code> (if you added it with CSS) — if you consider it can bring a better experience — it might have very bright colors for users with migraine, or it can be a bit distracting, for example.</p>\n<p>As long as you prioritize usability in your website with this mode, it should be good enough. However, most of the times you might not need it as long as you keep into consideration the previous suggestions I mentioned.</p>\n<p>You can also use custom properties in this mode, which will lead to some interesting uses, as you can see in <a href=\"https://www.smashingmagazine.com/2022/03/windows-high-contrast-colors-mode-css-custom-properties/\">this article by Eric Bailey</a>.</p>\nOther Resources\n<p>It’s important to note that in the case you still need to support Internet Explorer, media query <code>forced-colors</code> won’t work. If you want to know how to give support to High Contrast Mode in this browser, you can read about it in this <a href=\"https://www.gwhitworth.com/posts/2017/how-to-use-ms-high-contrast/\">article written by Greg Whitworth</a> and <a href=\"https://adrianroselli.com/2021/02/whcm-and-system-colors.html\">this one by Adrian Roselli</a>. For the topics covered in this article, you can read the following articles:</p>\n<ul>\n<li>“<a href=\"https://blogs.windows.com/msedgedev/2020/09/17/styling-for-windows-high-contrast-with-new-standards-for-forced-colors/\">Styling for Windows high contrast with new standards for forced colors</a>” by Microsoft Edge Team.</li>\n<li>“<a href=\"https://www.scottohara.me//blog/2021/10/01/detect-high-contrast-and-dark-modes.html\">Using JavaScript to detect high contrast and dark modes</a>” by Scott O’Hara.</li>\n<li>“<a href=\"https://blog.khanacademy.org/making-websites-work-with-windows-high-contrast-mode/\">Making Websites Work with Windows High Contrast Mode</a>” by Dietra Rater, a case study of Khan Academy website about this topic.</li>\n</ul>\nWrapping Up\n<p>Windows High Contrast Mode is something I have seen some websites overlook, which can create problems for people who use this accessibility feature. The good news is that we have enough tools to make our website works great in WHCM, even more with Microsoft’s efforts to create the media query <code>forced-colors</code> — which opens new doors to make our sites look better in this mode. Just remember: it’s an accessibility and usability feature so keep this in mind when you want to tweak your project in this mode!</p>\n<h3>Further Reading On Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/03/windows-high-contrast-colors-mode-css-custom-properties/\">Windows High Contrast Mode, Forced Colors Mode And CSS Custom Properties</a>,” Eric Bailey </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/accessible-design-system-themes-css-color-contrast/\">Manage Accessible Design System Themes With CSS Color-Contrast()</a>,” Daniel Yuschik </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/06/css-javascript-requirements-accessible-components/\">When CSS Isn’t Enough: JavaScript Requirements For Accessible Components</a>,” Stephanie Eckles </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/03/complete-guide-accessible-front-end-components/\">A Complete Guide To Accessible Front-End Components</a>,” Vitaly Friedman </li>\n</ul>",
      "content_text": "When we talk about accessibility, we tend to talk about many things — such as dark mode, keyboard navigation, prefers-reduced-motion, and screen readers — but there is one thing that does not receive that much attention: Windows High Contrast Mode (from now on, abbreviated as WHCM). This is a tendency I have seen in some websites at a point where we have normalized some practices that can harm users’ experience in WHCM. In this article, I want to explain what it is and give a good set of practices we can keep in mind to make our sites more usable with this mode.\nAbout Windows High Contrast Mode\nHigh Contrast mode is an accessibility feature that changes the look of our website and Windows applications by replacing the color of the different elements (like background, buttons, or text) with some user’s set up colors. This has multiple purposes, like increasing readability, reducing a website’s visual noise by removing certain elements (and by extension, allowing them to have a better focus), and giving users full control of the website’s contrast. You can check out by going to Settings, then clicking on Accessibility, and finally clicking on High Contrast.\n\nTo talk about some statistics, according to Melanie Richard in her talk “The tailored web: effectively honoring visual preferences”, around 4% of active devices use Windows High Contrast Mode, and thanks to WebAIM’s Survey of Users with Low Vision we can estimate that around 30% of users with low vision user Windows High Contrast Mode. All this should give you some perspective about the importance of making our website friendly with this mode.\nThe name “High Contrast Mode” is a bit misleading because the user can choose their preferred colors, leading to a color palette that has lower contrast than usual — which is not a very odd case. According to WebAIM’s survey, around 3% of users of Windows High Contrast Mode set it up to create a low contrast color pallete. The users with migraines or light sensitivity can do that to mitigate their disabilities’ impact. Just to give you a quick example:\n\nI’m sure you understand the importance of making our website friendly with WHCM, and you might think that due to its nature of replacing a big part of our styles, making a website that works for that mode can be hard. Great news, it’s not! We just need to consider some important issues to ensure the user experience is not harmed.\nConsiderations About Windows High Contrast Mode\nDespite how much control we lose when our website is displayed in WHCM, we can make it work without too much effort as long as we keep in mind some considerations. Before I start with that, I’d like you to keep in mind the golden rule with this mode: above all things, High Contrast Mode is about usability, and we need to respect that above any other aesthetics matter. Our biggest priority with this mode is easing readability and not harming the user experience in any way. \nHow can we ensure readability and usability works in WHCM? We can have certain important considerations for that:\nUse Semantic HTML\nThis has been a very important topic when we talk about accessibility due to its importance for screen readers, and it’s very important in WHCM as well! Why? Because Windows will add the styles depending on the semantics of an element and not because of how it looks outside WHCM. A link will have the hyperlinks styles, a button will have the Button Text styles, and so on.\nSome devs (for some reason) decide to use aria roles on divs to camouflage them as buttons for assistive technology. However, in WHCM, aria roles are irrelevant for Windows to determine which style to apply, so we depend on semantics to make our website works properly in this mode.\nTo validate this point, let’s check how a div that acts as real button and a link would behave in High Contrast Mode using the same styles.\n<div role=\"button\" class=\"button\" tabindex=0>\n  Not a button\n</div>\n<button class=\"button\">\n  Definitely a button\n</button>\n<a href=\"#\" class=\"button\">\n  This is a link\n</a>\n\n\n\n.button {\n  padding: 0.5em 1em;\n  border: 2px solid hotpink;\n  background-color: hotpink;\n  width: fit-content;\n  border-radius: 0.5em;\n  font-size: 1.5rem;\n  font-family: sans-serif;\n  text-decoration: none;\n  color: black;\n}\n\n\nIn default settings, the div and the button will have the same colors but remember: users can change that. Let’s use this color palette, and let’s check the results:\n\n\nNotice that semantics have a significant matter in WHCM for styling. Remember, in this mode, we have to focus on not harming the user’s experience, and choosing the wrong element can confuse users. \ntransparent Properties Are Useful!\nWhen we style certain interactive components like buttons or links, we tend to remove certain properties with border: none, outline: none, or text-decoration: none because those properties might not match with our design system. Usually, that’s not a bad idea as long as you keep in mind things like hover or focus state for those components. For WHCM, however,it is a serious problem because background elements are completely overwritten, and we’ll depend on borders to differentiate those components from the background.\nJust to give you an example, a very common design pattern I have seen is with the primary and secondary buttons, where the former has a background color and no border, and the latter has just a border and no background. It looks good, but when you see them under High Contrast Mode: \n<button class=\"primary\">\n  Primary action\n</button>\n<button class=\"secondary\">\n  Secondary action\n</button>\n  \n\n\n    button {\n      font-size: 1.3em;\n      padding: 0.5em 1em;\n      border: none;\n      font-family: sans-serif;\n      border-radius: 0.4em;\n      background-color: transparent;\n    }\n\n    .primary {\n      background-color: hotpink;\n    }\n\n    .secondary {\n      border: 2px solid hotpink\n    }\n\n\n\nThe primary button can be easily mistaken for a normal text! This is where transparent borders come into play because transparencies will be visible under a High Contrast Mode. So by replacing the border property in the button element with this: 2px solid transparent, we’ll have this result:\n\n    button {\n      border: 2px solid transparent\n    }\n\n\n\nAs you can imagine, that also happens with links if you use the property text-decoration-color: transparent, and with outlines if you use outline-color: transparent. Let’s check some quick examples about those properties.\ntext-decoration-color: transparent is useful if you’re using another element to represent a link in your site. Just to give an example, you can use background-image to animate the underline, as you can see in this video made by Kevin Powell. However, in WHCM, you’ll only depend on the color the user has in his settings, so if you want to give an additional visual cue, a transparent underline will work great there! \n\nOutlines are a particularly important topic in this mode because some developers rely on other properties to add focus states to interactive elements — such as changing the background-color or even the box-shadow hack (even if it’s not necessary nowadays because now the outline will follow the element’s border-radius since Chrome 94 and Firefox 88). However, all those things are completely overwritten in this mode, so outline remains as the only reliable way to apply a focus state on an element in WHCM. Always keep that in mind: if you’re going to use something different than an outline to highlight a focus state in an element, add the property outline-color: transparent as a fallback to not missing a focus state in this mode.\nKeep In Mind Scrollbars\nScrollbars can be styled, but does that mean we should style them? There are some usability and accessibility concerns about this topic. The one I want to bring here is the fact that, depending on how you style it in WHCM, they’ll look clunky in the best of cases, or they won’t be visible at all at worst of scenarios.\nIs there a way to solve that? That depends on how you decide to style a scrollbar. Some people decide to use a solid color to fill the scrollbar’s thumb, and that does have a very easy fix. Let’s suppose we decided to style our scrollbar that way, then you will go for something like:\n\n    ::-webkit-scrollbar {\n      width: 20px; \n    }\n\n    ::-webkit-scrollbar-track {\n      background-color: #e4e4e4;\n      border-radius: 100px;\n    }\n\n    ::-webkit-scrollbar-thumb {\n      border-radius: 100px;\n      background-color: green;\n    }\n    \n\nAs you might guess, the scrollbar won’t be visible in WHCM due to its background-color property being forcedly replaced. The great news is that we have already seen how to remediate this problem!\nTransparent borders can cover this situation. You can use them to cover all the scrollbar’s thumb, and it’ll look like it’ll have a solid color (the one you choose as text color in settings) which will be pretty similar to how it works as a default scrollbar in this mode. To follow our previous example, if we use the property border: 10px solid transparent, it will make it look like it has a solid background in WHCM.\nBe careful using this technique with scrollbar thumbs styled with box-shadow insets, though. If you do that, it’ll make it invisible. Not in WHCM, I mean invisible outside of it. You can check this problem in this scrollbar style made by Ahmad Shadeed, go to the scrollbar thumb styles, and add the same style we added before (border: 10px solid transparent) . You’ll see it’ll become invisible, a good way to make it visible (both regularly and in WHCM) is just using a smaller border (something like 2px instead of 10px) to make it look like this in WHCM:\n\nIt looks good! The only problem is that it looks a bit weird outside of WHCM, so keep this in mind if you decide to style a scrollbar using an inset box-shadow.\nRemember that all that applies only to Chromium-based browsers, as Firefox has a different way to style scrollbars using scrollbar-color and scrollbar-width properties. The good news is that in WHCM, you won’t have to do a thing to make it work properly! The colors will be overwritten, and the scrollbar’s thumb will have the same color user has set up as text color.\nBehavior Of Images\nWe have different ways to use images on a site: using the tag img, the background-image CSS property, using SVGs, and even CSS art! Let’s dig about those quickly. img tag will behave the same in WHCM, so let’s talk about the other three.\nFirst, we have the background-image property — and this one will remain the same in WHCM as long as you’re using the url() value. A gradient made with background-image will be overwritten by WHCM’s background color. However, there is only one catch with this. Even though Firefox supports background images in High Contrast Mode since around 2018-2019, it won’t be visible if you put background-image in the body element.\nYou can try it out by seeing the CodePen I made to try to open it while using WHCM. So keep that in mind in case you’re using a background image like that.\n\nThat’s a bit problematic. Even when we normally want SVG to remain the same, there should be a way to manage those situations for specific scenarios. The good news is that, indeed, there is one! But let’s put a pin on this topic for now.\nKeep in mind that this scenario only happens in Chromium-based browsers — Firefox has its own way to manage this. SVGs inside an anchor that use the currentColor property will receive the same color as the link color user has set up. It’ll even respect whatever color the theme uses as a visited link, as this picture shows:\n\nFinally, we have CSS art. Due to its nature of using elements like box shadows and background gradients, you might guess it won’t look good in WHCM — and you’re absolutely right. Due to its artistic nature, it’s no big deal, so you should be fine. But, if it does have a purpose in your website, we need to look for a way to make it visible. Just a quick note about CSS art: remember you can — and should — make your CSS art accessible!\nAs long as you keep in mind those small suggestions, our website will be almost done for WHCM! As you saw, some elements would need some tweaks to make them work to their full extent in this mode, but luckily for us, CSS has a way to help us to get this last part of the job done!\nMedia Query Forced-Colors\nMicrosoft made an effort to create a standard to support WHCM, and the result of this work was the media query forced-colors, which will help us to detect if the browser or operating system has enabled a mode that limits a website’s styles to a user-chosen color palette. As you might guess, WHCM is the most popular choice among them.\nThis media query will act a bit differently due to how WHCM works. Some properties will be limited to certain values, some won’t be able to be overwritten at all, and we have new properties’ values to work with! But before digging into what we can do with this tool, let’s remember that WHCM (and other modes that restrict user’s color palettes) prioritize usability, and this is something we need to respect. So don’t use those properties unless it’s necessary to tweak some elements in your website to give it good usability in this mode.\nWith that said, let’s start talking about the media query itself. It has two values: none and active. The former will detect when there is no forced colors mode active, and the second one will detect when there is. Under forced colors mode, the next properties will be replaced with the ones that are set up by the user:\n\ncolor\nbackground-color\ntext-decoration-color\ntext-emphasis-color\nborder-color\noutline-color\ncolumn-rule-color\n-webkit-tap-highlight-color\nSVG fill and stroke attributes\n\nAdditionally, there are some properties that will have a forced behavior:\n\n  \n    Property\n    Value\n  \n  \n    box-shadow\n    none\n  \n  \n    text-shadow\n    none\n  \n  \n    background-image\n    none (unless it’s url() )\n  \n  \n    color-scheme\n    light dark\n  \n  \n    accent-color\n    auto\n  \n  \n    scrollbar-color (Firefox)\n    auto\n  \n\n\nWith that explained, let’s dig into two tools we have we can use to enhance the experience in this mode.\nForced-Color-Adjust\nNow, how can we change how those properties behave? There is a way to avoid WHCM overwrites colors, and this is by using the property forced-color-adjust. This property has two values: auto and none, and it’ll let us decide if we want an element’s colors will be replaced by the user agent’s colors or not, respectively. Let’s check an example of how those work, and there aren’t better examples than the ones we left uncovered in the previous section!\nLet’s check the link with the external link’s SVG we used earlier. Keep in mind that in Chromium-based browsers, this SVG won’t change its color to match the one that is used as a link color because SVGs have a default value of none. So, if we add the property forced-color-adjust: auto to our SVG as follows:\n.inline-icon {\n  /* Previous CSS properties */\n  forced-color-adjust: auto;\n}\n\n\nThis will be our result:\n\nI know this section is about the media query itself, and usually, what you’d do is put that rule inside the media query like this:\n@media screen and (forced-colors: active) {\n  .inline-icon {\n    forced-color-adjust: auto;\n  }\n}\n\n\nThat’s a valid approach (and, honestly, the most intuitive one). However, while I did some experiments for this article, I noticed that you can put this property in an element without the need to use the media query, and you’ll get the same result! And because this property will affect only the behavior of this element in a forced colors scenario, it won’t give you any unexpected behavior. \nNow, with CSS art, we want the opposite to be true (again, as long as this CSS is necessary to give enough context to the user), so we can use forced-color-adjust: none in the art’s parent element, and now all of it will be visible in WHCM.\nYou may be thinking that this is not a common use case of forced-color-adjust: none, and you’d be right, so let’s check a more realistic one: showing color palletes on your website! Let’s take a look at any pallete generated by mycolor.space for example:\n\nThose colors are not visible, and it’s an important part of the website, so if we go to the color container element and we add this property, we’ll solve this problem. \nSystem Colors\nNow let’s talk about colors. With media query forced-colors we have a handful of system colors we can use. You can see a list of colors in MDN’s documentation, and we can use this list of colors to replace certain properties. Using the property color: LinkText will make it look like a link, for example.\nJust remember: those colors are closely related to HTML semantics, so maybe you’d be better changing an element to its correct tag instead of trying to change how it looks in WHCM. That doesn’t mean it doesn’t have its uses. We just have to be sure we are doing this for the right reasons. Which is a good reason to use this? Well, that depends on the complexity of what you are creating. Let’s take, as an example, this link I created with the help of the clip-path property.\n.link {\n  --clip-path: polygon(0% 0%, calc(100% - 0.8em) 0%, 100% 0.8em, 100% 100%, 0.8em 100%, 0% calc(100% - 0.8em));\n  font-size: 2rem;\n  padding: 0.1em;\n  border: none;\n  background-color: #0E0054;\n  clip-path: var(--clip-path);\n  font-family: sans-serif;\n}\n\n.link:focus {\n  outline: none;\n}\n\n.link:focus span, .link:hover span {\n  outline-offset: -0.5em;\n  outline: 3px solid transparent;\n  background-color: #0E0054;\n  color: white;\n  text-decoration-color: white;\n}\n\n.link span {\n  display: inline-block;\n  padding: 0.5em 1.2em;\n  clip-path: var(--clip-path);\n  background-color: white;\n  color: #0E0054;\n  text-decoration: underline #0E0054;\n  text-underline-offset: 2px;\n}\n\n.link span {\n  display: inline-block;\n  padding: 0.5em 1.2em;\n  clip-path: var(--clip-path);\n  background-color: white;\n  color: #0E0054;\n  text-decoration: underline #0E0054;\n  text-underline-offset: 2px;\n}\n\n\n\nLet’s make a quick check of the problems with this element in WHCM:\n\nI used a background-color to mimic a border with this element, but because it’s a background, it won’t be visible in WHCM.\nEven if I used a transparent outline to make a focus state in this mode, its color would be the one that the system uses as a link color, instead of the one WHCM’s usual outline color.\n\nWith this in mind, we can tweak system colors using the media query forced-colors to give enough visual feedback to users by showing them that that is a link.\n@media screen and (forced-colors: active) {\n  .link {\n    background-color: LinkText;\n  }\n\n  .link:visited {\n    background-color: VisitedText;\n  }\n\n  .link:focus span {\n    outline-color: Highlight;\n  }\n}\n\n\nRemember Firefox has a visited state color for links, so to respect that. We should add the VisitedText system color in the visited pseudo-class of our link. With that said, this is our result:\n\nAnother simple example of how we can use system colors to tweak the experience is something we saw in the previous section: scrollbars! Let’s suppose that, for some reason, transparent borders are not an option. In this case, we can use system colors to make our scrollbar looks good in this mode! Let’s come back to one of the examples we used previously, and instead of using a transparent border, we’ll use the media query to tweak the scrollbar’s thumb’s color.\n::-webkit-scrollbar {\n  width: 20px;\n}\n\n::-webkit-scrollbar-track {\n  background-color: #e4e4e4;\n  border-radius: 100px;\n}\n\n::-webkit-scrollbar-thumb {\n  border-radius: 100px;\n  background-color: green;\n}\n\n@media screen and (forced-colors: active) {\n  ::-webkit-scrollbar-thumb {\n    background-color: CanvasText;\n  }\n}\n   \n\nOther Uses Of This Media Query\nAs you read, forced-color-adjust and system colors are great tools to tweak our design if needed, but that’s not all we can do with this media query. Yes, we saw that some properties are restricted to certain uses, but most of them can be used normally! Remember, this is just to improve usability in WHCM, so there is no need to go too wild with that. Use it just when it’s needed.\nLet’s come back to the clip-path link we used. You could decide that the approach to how it looks in WHCM is to use a simpler design, like maybe just using a regular bordered element. We can do that! Let’s ignore the CSS rules I used in my previous example, and let’s use those instead:\n@media screen and (forced-colors: active) {\n  .link {\n    --clip-path: none;\n    border: 3px solid transparent;\n    border-radius: 8px;\n  }\n\n  .link:focus {\n    outline: 3px solid transparent;\n    outline-offset: 3px;\n  }\n\n  .link:focus span {\n    outline: none;\n  }\n}\n\n\nAnd this is our result:\n\nWith that approach, you still show the user this is a link, and you avoid any possible confusion with this topic. Uses of CSS properties in this media query can open some interesting doors to improve how sites work. You can remove a merely decorative image in this mode — with display: none (if you used an img tag) or background-image: none (if you added it with CSS) — if you consider it can bring a better experience — it might have very bright colors for users with migraine, or it can be a bit distracting, for example.\nAs long as you prioritize usability in your website with this mode, it should be good enough. However, most of the times you might not need it as long as you keep into consideration the previous suggestions I mentioned.\nYou can also use custom properties in this mode, which will lead to some interesting uses, as you can see in this article by Eric Bailey.\nOther Resources\nIt’s important to note that in the case you still need to support Internet Explorer, media query forced-colors won’t work. If you want to know how to give support to High Contrast Mode in this browser, you can read about it in this article written by Greg Whitworth and this one by Adrian Roselli. For the topics covered in this article, you can read the following articles:\n\n“Styling for Windows high contrast with new standards for forced colors” by Microsoft Edge Team.\n“Using JavaScript to detect high contrast and dark modes” by Scott O’Hara.\n“Making Websites Work with Windows High Contrast Mode” by Dietra Rater, a case study of Khan Academy website about this topic.\n\nWrapping Up\nWindows High Contrast Mode is something I have seen some websites overlook, which can create problems for people who use this accessibility feature. The good news is that we have enough tools to make our website works great in WHCM, even more with Microsoft’s efforts to create the media query forced-colors — which opens new doors to make our sites look better in this mode. Just remember: it’s an accessibility and usability feature so keep this in mind when you want to tweak your project in this mode!\nFurther Reading On Smashing Magazine\n\n“Windows High Contrast Mode, Forced Colors Mode And CSS Custom Properties,” Eric Bailey \n“Manage Accessible Design System Themes With CSS Color-Contrast(),” Daniel Yuschik \n“When CSS Isn’t Enough: JavaScript Requirements For Accessible Components,” Stephanie Eckles \n“A Complete Guide To Accessible Front-End Components,” Vitaly Friedman \n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/df6515d2-12da-42e0-879e-cbfbdf245daf/guide-windows-high-contrast-mode.jpg",
      "date_published": "2022-06-15T09:30:00.000Z",
      "date_modified": "2022-06-15T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/adding-search-website-sitesearch360/",
      "url": "https://smashingmagazine.com/2022/06/adding-search-website-sitesearch360/",
      "title": "Adding Search To Your Site In 15 Minutes",
      "summary": "Do you need search for your site, but haven’t found the time to add it? Within 15 minutes, Leonardo Losoviz explains how you can add a super powerful search that also looks super good. In this article, you’ll learn how to go from 0 to 100 with search.",
      "content_html": "<p>This article is a sponsored by <a href=\"https://www.sitesearch360.com/\">Site Search 360</a></p>\n<p>My site has been created using a static site generator and deployed to a CDN, so I’m super happy with how fast it is. But there has been a functionality that I’ve been missing all along: search.</p>\n<p>As it’s been mentioned many times, Jamstack doesn’t mean “static” — we can perfectly create fully dynamic sites powered by JavaScript on the client-side interacting with (mostly third-party) APIs. Search falls within this category.</p>\n<p>All this time, I hadn’t added search to my site because I was weary it would prove to be a difficult task. I’m not exceptionally skilled in JavaScript or CSS, so I feared that creating an elegant (or, at least, respectable) search input that suggests results as the user types, and integrating it into my site, would fall outside of my abilities.</p>\n<p>And then, all of a sudden, in actually less than 15 minutes, I had search on my site!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/cd43dd1b-f03d-4f0f-8a2e-cef7374c1a58/1-adding-search-website-sitesearch360.png\" /></p>\n<p>After this, the service will spend a minute or two indexing your site (or maybe a few more, depending on how much content your site has), and then inform you that it’s all ready.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e8eb87db-63ac-4a6c-9786-08013d4f7bc1/2-adding-search-website-sitesearch360.png\" /></p>\n<p>Click on “Let’s Get Started!” to go to the application dashboard, where an onboarding process will guide you in setting-up search for your site.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fec796b2-9b8f-4531-af62-cb203c7e629d/3-adding-search-website-sitesearch360.png\" /></p>\n<p>Since your site’s content has been indexed by now, when clicking on “Test now!” the preview of the search UI will already use your site’s actual content. Notice how, even before you start customizing the look and feel, it looks great!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/db50c01f-3cab-4b4e-b42f-5a589138de8d/4-adding-search-website-sitesearch360.png\" /></p>\n<p>Click on “More results” in the suggestions dropdown to visualize what the search results will look like. (Below, we’ll see how this list, initially displaying the item’s thumbnail, title, URL, and excerpt with the matching term in bold, can be modified.)</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/64f87a80-ac5e-4ded-9d22-54d31caa1761/5-adding-search-website-sitesearch360.png\" /></p>\n<p>Click on the “Search Designer” button to customize the search UI, and replicate the style on your site. This step is not a one-time off: you can come back to it at any moment (even after your custom configuration has been published and search is already installed on your site).</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/142ead2f-a7e3-41c4-a07f-14fa55bb427d/6-adding-search-website-sitesearch360.png\" /></p>\n<p>The welcome screen asks how we’d like to start. Since we are new users, we must start from scratch and click on “Start now”.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c9726ba6-5724-4dae-b799-51d671f96a4d/7-adding-search-website-sitesearch360.png\" /></p>\n<p>We are now using the <a href=\"https://www.sitesearch360.com/blog/create-your-site-search-experience-with-our-no-code-tool/\">Search Designer</a> which will help you edit the visual appearance of the search input, dropdown, and results.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b5c58a4a-821e-420b-b31f-6be21908c523/8-adding-search-website-sitesearch360.png\" /></p>\n<p>As you edit the styles, these are immediately reflected on the right-side pane.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/93c65bd2-a6df-4d44-b014-3307fb91d319/9-adding-search-website-sitesearch360.png\" /></p>\n<p>In the Search Designer, you can configure the following elements (among many more):</p>\n<ul>\n<li>The primary, secondary, background, text, icon and border colors, text size, rounded corners size, and other styles;</li>\n<li>The language (from among 19 supported languages to date);</li>\n<li>Using a search input you already have on your site or the one by Site Search 360;</li>\n<li>Enabling autocomplete suggestions (displayed as the user is typing);</li>\n<li>Connect to Google Analytics and Google Tag Manager;</li>\n<li>Enabling voice search;</li>\n<li>Layouts to display results on desktop and mobile.</li>\n</ul>\n<p>The search dropdown can be further configured, allowing to display the previously-searched queries and also predefined queries. In my case, I’ve decided to already suggest those search queries that make my site rank high on Google.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/aaf454c7-2867-4245-8a8b-bc823ed235f6/10-adding-search-website-sitesearch360.png\" /></p>\n<p>Once done with the configuration, let’s go back to the onboarding process.</p>\n<p>The next step is to tweak the search results, indicating how to extract the data (for the title, images, and excerpt) from the webpage. The default automatic configuration already works very well (extracting the data from the <code>&lt;meta&gt;</code> attributes), so you can quite likely skip this step.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/96191660-dc2e-42c5-9e1e-44b5f8eb801c/11-adding-search-website-sitesearch360.png\" /></p>\n<p>You’re pretty much done by now! All there’s left to do is to publish the configuration.</p>\n<p>Go back to the onboarding process, and click on “Install now!”. This will open a modal window; copy the HTML code and paste it into your site’s source code (before the closing <code>&lt;/body&gt;</code>), and click on “Publish.”</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4acf9f9f-886b-4b34-ade1-3c4063ab6e28/12-adding-search-website-sitesearch360.png\" /></p>\n<p>Re-deploy your site, refresh the browser, and what do you have? Your site now has search!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/edfbf412-8387-4bbf-a3be-3790c00f65b0/13-adding-search-website-sitesearch360.png\" /></p>\nUpdating The Visual Appearance\n<p>As I mentioned earlier on, you can keep configuring the search UI even after search is live. From now on, you can easily access the Search Designer from the application menu on the left (under the item “Design &amp; Publish”). After doing some modification, clicking on “Publish” will already apply the new style on your site without having to copy/paste any new code or re-deploy the site.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/23ef599f-f7d5-4aba-91c8-f2f6cd9db55e/14-adding-search-website-sitesearch360.png\" /></p>\n<p>In my case, I tweaked the configuration a bit more. I changed my mind about the position of the search input, preferring to display it on top of the navigation. The solution was to wrap the navigation menu in a new <code>&lt;div id=\"nav-wrapper\"&gt;</code>  element and then inject the input “Before” the <code>#nav-wrapper</code> selector.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2bd71e73-49bb-419d-a95c-b758810a4ec5/15-adding-search-website-sitesearch360.png\" /></p>\n<p>I also noticed that the layout didn’t look right on mobile because the search input was being aligned to the center, while the logo and navigation menu were aligned to the left.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d64a4c2e-396d-4730-8756-68f5aa0f22a0/16-adding-search-website-sitesearch360.png\" /></p>\n<p>The Search Designer accepts custom CSS, so I could provide a snippet of additional CSS code to override the default style of the search input, aligning it to the left.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/72e42d48-3309-42f2-97e9-aca768192c9b/17-adding-search-website-sitesearch360.png\" /></p>\n<p>I clicked on “Publish”, refreshed the browser, and now the style in mobile looks right.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b09d42d9-3fa7-4ec7-96c4-ebf786f52140/18-adding-search-website-sitesearch360.png\" /></p>\n<p>Finally, I also decided to enable the “Result Groups” feature, which splits the results into different categories of our own choosing. (What pages are contained in a group is defined via a URL pattern; for instance, I’ve set group “Blog” to contain URLs of type <code>/blog/...</code>.) In my case, I want to display results from groups “Blog,” “Guides,” and “Meta” and hide results from “Tags.”</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ffca9ebd-85cb-4a6c-8765-fdd9190466ac/19-adding-search-website-sitesearch360.png\" /></p>\n<p>Now, when the visitor inputs a search query, the results in the dropdown are organized by the chosen groups, which makes it much easier to find the desired information. For instance, when searching for “namespacing”, “Meta” will contain a page describing the feature; “Guides” will contain pages explaining how to use and configure this feature; and “Blog” will display those blog posts announcing the feature.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e604c568-7852-4ea6-9d89-5f76e460184c/20-adding-search-website-sitesearch360.png\" /></p>\n<p>Likewise, when clicking on “Show all results”, the modal window is organized into tabs (at one tab per group), which makes it easy to scroll down and browse the results within each group.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c8556cfb-5f45-43e9-a904-2f66f874987a/21-adding-search-website-sitesearch360.png\" /></p>\n<p>I’m super happy with these results! It took just 15 min to go from 0 to 100, the user interface looks really good, and the search is super fast. Overall, the experience for my visitors is compelling. Head over to <a href=\"https://graphql-api.com/\">my site</a> and play with the search input to understand why I’m so satisfied with it.</p>\nRefining Search\n<p>What I showed above is barely scratching the surface, as <strong>it’s what’s included in the free plan!</strong> Check out the <a href=\"https://www.sitesearch360.com/pricing/\">pricing page</a> to see all the other features available in the service for each of the different tiers.</p>\n<p>For instance, if you have a content-rich site, such as a blog or an online store, and would like to filter your search results (by category, date, price, and so on), you can do so:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/49e7487b-12a0-44ea-bfcf-db32dcc555fe/22-adding-search-website-sitesearch360.png\" /></p>\n<p>And then, Site Search 360 has a superpower that makes it stand out from its competitors: its AI-powered <a href=\"https://www.sitesearch360.com/ecommerce/\">semantic product search engine</a> continuously optimizes search result rankings, promoting the most popular results to the top. If you have eCommerce search enabled, just indicate what’s important for you to sell in your online store, and the engine will automatically re-arrange the results based on multiple ranking factors.</p>\nWrapping Up\n<p>I was personally quite impressed by <a href=\"https://www.sitesearch360.com/\">Site Search 360</a>’s powerful search offer. In only 15 minutes, my site had a search functionality which I had been postponing for such a long time. Problem solved!</p>\n<p>If you too want to effortlessly add search to your site, then go <a href=\"https://app.sitesearch360.com/signup\">check it out</a>.</p>",
      "content_text": "This article is a sponsored by Site Search 360\nMy site has been created using a static site generator and deployed to a CDN, so I’m super happy with how fast it is. But there has been a functionality that I’ve been missing all along: search.\nAs it’s been mentioned many times, Jamstack doesn’t mean “static” — we can perfectly create fully dynamic sites powered by JavaScript on the client-side interacting with (mostly third-party) APIs. Search falls within this category.\nAll this time, I hadn’t added search to my site because I was weary it would prove to be a difficult task. I’m not exceptionally skilled in JavaScript or CSS, so I feared that creating an elegant (or, at least, respectable) search input that suggests results as the user types, and integrating it into my site, would fall outside of my abilities.\nAnd then, all of a sudden, in actually less than 15 minutes, I had search on my site!\n\nAfter this, the service will spend a minute or two indexing your site (or maybe a few more, depending on how much content your site has), and then inform you that it’s all ready.\n\nClick on “Let’s Get Started!” to go to the application dashboard, where an onboarding process will guide you in setting-up search for your site.\n\nSince your site’s content has been indexed by now, when clicking on “Test now!” the preview of the search UI will already use your site’s actual content. Notice how, even before you start customizing the look and feel, it looks great!\n\nClick on “More results” in the suggestions dropdown to visualize what the search results will look like. (Below, we’ll see how this list, initially displaying the item’s thumbnail, title, URL, and excerpt with the matching term in bold, can be modified.)\n\nClick on the “Search Designer” button to customize the search UI, and replicate the style on your site. This step is not a one-time off: you can come back to it at any moment (even after your custom configuration has been published and search is already installed on your site).\n\nThe welcome screen asks how we’d like to start. Since we are new users, we must start from scratch and click on “Start now”.\n\nWe are now using the Search Designer which will help you edit the visual appearance of the search input, dropdown, and results.\n\nAs you edit the styles, these are immediately reflected on the right-side pane.\n\nIn the Search Designer, you can configure the following elements (among many more):\n\nThe primary, secondary, background, text, icon and border colors, text size, rounded corners size, and other styles;\nThe language (from among 19 supported languages to date);\nUsing a search input you already have on your site or the one by Site Search 360;\nEnabling autocomplete suggestions (displayed as the user is typing);\nConnect to Google Analytics and Google Tag Manager;\nEnabling voice search;\nLayouts to display results on desktop and mobile.\n\nThe search dropdown can be further configured, allowing to display the previously-searched queries and also predefined queries. In my case, I’ve decided to already suggest those search queries that make my site rank high on Google.\n\nOnce done with the configuration, let’s go back to the onboarding process.\nThe next step is to tweak the search results, indicating how to extract the data (for the title, images, and excerpt) from the webpage. The default automatic configuration already works very well (extracting the data from the <meta> attributes), so you can quite likely skip this step.\n\nYou’re pretty much done by now! All there’s left to do is to publish the configuration.\nGo back to the onboarding process, and click on “Install now!”. This will open a modal window; copy the HTML code and paste it into your site’s source code (before the closing </body>), and click on “Publish.”\n\nRe-deploy your site, refresh the browser, and what do you have? Your site now has search!\n\nUpdating The Visual Appearance\nAs I mentioned earlier on, you can keep configuring the search UI even after search is live. From now on, you can easily access the Search Designer from the application menu on the left (under the item “Design & Publish”). After doing some modification, clicking on “Publish” will already apply the new style on your site without having to copy/paste any new code or re-deploy the site.\n\nIn my case, I tweaked the configuration a bit more. I changed my mind about the position of the search input, preferring to display it on top of the navigation. The solution was to wrap the navigation menu in a new <div id=\"nav-wrapper\">  element and then inject the input “Before” the #nav-wrapper selector.\n\nI also noticed that the layout didn’t look right on mobile because the search input was being aligned to the center, while the logo and navigation menu were aligned to the left.\n\nThe Search Designer accepts custom CSS, so I could provide a snippet of additional CSS code to override the default style of the search input, aligning it to the left.\n\nI clicked on “Publish”, refreshed the browser, and now the style in mobile looks right.\n\nFinally, I also decided to enable the “Result Groups” feature, which splits the results into different categories of our own choosing. (What pages are contained in a group is defined via a URL pattern; for instance, I’ve set group “Blog” to contain URLs of type /blog/....) In my case, I want to display results from groups “Blog,” “Guides,” and “Meta” and hide results from “Tags.”\n\nNow, when the visitor inputs a search query, the results in the dropdown are organized by the chosen groups, which makes it much easier to find the desired information. For instance, when searching for “namespacing”, “Meta” will contain a page describing the feature; “Guides” will contain pages explaining how to use and configure this feature; and “Blog” will display those blog posts announcing the feature.\n\nLikewise, when clicking on “Show all results”, the modal window is organized into tabs (at one tab per group), which makes it easy to scroll down and browse the results within each group.\n\nI’m super happy with these results! It took just 15 min to go from 0 to 100, the user interface looks really good, and the search is super fast. Overall, the experience for my visitors is compelling. Head over to my site and play with the search input to understand why I’m so satisfied with it.\nRefining Search\nWhat I showed above is barely scratching the surface, as it’s what’s included in the free plan! Check out the pricing page to see all the other features available in the service for each of the different tiers.\nFor instance, if you have a content-rich site, such as a blog or an online store, and would like to filter your search results (by category, date, price, and so on), you can do so:\n\nAnd then, Site Search 360 has a superpower that makes it stand out from its competitors: its AI-powered semantic product search engine continuously optimizes search result rankings, promoting the most popular results to the top. If you have eCommerce search enabled, just indicate what’s important for you to sell in your online store, and the engine will automatically re-arrange the results based on multiple ranking factors.\nWrapping Up\nI was personally quite impressed by Site Search 360’s powerful search offer. In only 15 minutes, my site had a search functionality which I had been postponing for such a long time. Problem solved!\nIf you too want to effortlessly add search to your site, then go check it out.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b95673f7-c059-4fae-a74a-bd1929230b29/adding-search-website-sitesearch360.jpg",
      "date_published": "2022-06-14T09:00:00.000Z",
      "date_modified": "2022-06-14T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/user-experience-principles-embedded-systems/",
      "url": "https://smashingmagazine.com/2022/06/user-experience-principles-embedded-systems/",
      "title": "How To Apply UX Principles To Embedded Systems: Learnings From The Field",
      "summary": "In this article, Eva gives an overview of what embedded systems are and how they impact our lives. She presents three main learnings gained across her quest for creating better-embedded systems to enable the world as we know it.",
      "content_html": "<p><a href=\"https://www.oreilly.com/library/view/making-embedded-systems/9781449308889/ch01.html\">Embedded systems mean different things to different people</a>; they can be standalone and independent, working by themselves, or be a part of a larger system. They are purpose-built for a particular application, designed to perform a specific function or set of tasks. Complexities of embedded systems range <a href=\"https://embeddedcomputing.com/technology/software-and-os/embedded-software-how-complex-can-it-get\">from very simple to highly sophisticated implementations</a>, depending on the functions and features that need to be performed and its interactions and connections with other systems. Some examples are autonomous driving, artificial intelligence, and the internet of things. </p>\n<p>To provide some context, embedded systems have been around for a long-time. Two examples are the <a href=\"https://plato.stanford.edu/entries/computing-history/\">difference engine devised by Charles Babbage</a> in the 1830s and the <a href=\"https://en.wikipedia.org/wiki/Apollo_Guidance_Computer\">Apollo Guidance Computer</a> built in the 1960s and considered to be the first modern embedded system. A key component of an embedded system is its software. Embedded software brings a system to life, performing tasks on your behalf. <a href=\"https://www.mckinsey.com/industries/advanced-electronics/our-insights/cracking-the-complexity-code-in-embedded-systems-development\">Software is where most of the design effort and complexity of embedded systems lie</a>. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f640bfdb-b2b7-4d1e-87a8-ee06a7dd071b/2-papplying-user-experience-principles-embedded-systems.jpg\" /></p>\n<p>In this article, I share three key learnings I have gained from applying UX and human-centered approaches when working with embedded software. These three takeaways include the complexity and advantage of addressing the needs of multiple stakeholders, how to benefit from understanding the dependencies between different components (by definition, embedded means integrated onto something), and how to overcome the challenge of communicating the value of technology that’s often invisible.</p>\n<ol>\n<li><a href=\"##learning-1-embrace-complexity-in-your-projects-and-designs\">Embrace Complexity In Your Projects And Designs</a></li>\n<li><a href=\"#learning-2-find-ways-to-learn-fast-and-don-t-go-solo\">Find Ways To Learn Fast And Don’t Go Solo</a></li>\n<li><a href=\"#learning-3-communicate-the-value-of-embedded-software\">Communicate The Value Of Embedded Software</a></li>\n</ol>\nLearning #1: Embrace Complexity In Your Projects And Designs\n<blockquote>Different stakeholders will have different sets of challenges and goals interacting with your product.</blockquote>\n\n<p>Let’s take a typical car as an example and imagine you develop software for its <a href=\"https://en.wikipedia.org/wiki/Advanced_driver-assistance_systems\">advanced driver-assistance (ADAS) system</a>. There are three stakeholders in this example:</p>\n<ul>\n<li>the driver of the car, who is the end-user; </li>\n<li>the person that integrates the software into the car is the user;</li>\n<li>the person in charge of purchasing what goes into the final car is the customer.</li>\n</ul>\n<p>Even then, this is a bit of a simplification. In real-life projects, there are even more dependencies and stakeholders involved. </p>\n<p>Thus, who should you take into account when building and designing your solution? More than who to design software for, it is about thinking of what’s important for each stakeholder. In this example, the end-user cares about the experience and that everything works as expected or even better; the user is after a complete feature set and possibilities; the customer tends to care about cost-efficiency. In the end, you need to meet end-user expectations (who don’t even know they are interacting with embedded software) while making your product easy to integrate for the user and ensuring the customer that they are getting the best solution for an optimal price. </p>\n<p>Additionally, embedded systems are, in many cases, resource-constrained in power processing or memory, yet the expectation is that the whole system works seamlessly and in a sophisticated way. Therefore, you need to find a balance between performance and reliability without hurting the experience. Optimizing this interaction requires a great level of expertise and specialized knowledge, which comes at a price. </p>\n<p>When designing embedded software, it’s critical to spend time researching and understanding the <a href=\"https://onlinelibrary.wiley.com/doi/10.1002/9781119154822.ch2\">problem space</a>, the goals, and <a href=\"https://jtbd.info/2-what-is-jobs-to-be-done-jtbd-796b82081cca\">jobs to be done</a> by the different stakeholders in real life. The better you understand each stakeholder’s expectation, the less risk of spending time building features that would have no use in a real environment or falling short of features for the future. Performing software upgrades to support new use cases in embedded systems can be very challenging because sometimes these devices are located in places that are hard to reach or have no connectivity. </p>\n<p>Problem space exploration is <a href=\"https://interactions.acm.org/archive/view/january-february-2018/launching-problem-space-research-in-the-frenzy-of-software-production\">closely related to user research</a>. As such, there is plenty of literature, case studies, materials, frameworks and tools that you can use to collect data and gain insights into users’ needs and challenges. These activities usually include surveys, interviews, questionnaires, or market research. </p>\n<p>Here are some examples:</p>\n<ul>\n<li>“<a href=\"https://dschool.stanford.edu/resources/map-the-problem-space\">Map the Problem Space</a>”, Carissa Carter, Megan Stariha, Mark Grundberg</li>\n<li><a href=\"https://miro.com/miroverse/the-problem-space-workshop/\">The Problem Space Workshop</a>, Christy Cattin</li>\n<li>“<a href=\"https://www.svpg.com/product-strategy-insights/\">Product Strategy — Insights</a>”, Marty Cagan</li>\n</ul>\n<p>A key aspect of understanding the problem space is to be able to map the different <a href=\"https://www.toptal.com/designers/product-design/customer-journey-maps\">journeys</a> for each of your stakeholders and their touchpoints and where in those journeys you could implement those research tools and feedback mechanisms to help you with your planning of user research and problem discovery.</p>\n<p>The <a href=\"https://www.columbiaroad.com/blog/why-and-how-to-create-a-customer-journey-map-download-free-template\">template below from Columbia Road</a> is a great starting point. I have simply added a new dimension — <strong>Feedback tools</strong> — to be able to link feedback activities to the journey stages. There are also other activities that you don’t necessarily think of as feedback or research tools. Yet, there are incredibly rich practices for gathering information, and I will cover some of those in the next point. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/559b6b5b-c6b7-407b-831a-9c1f18db00ae/1-applying-user-experience-principles-embedded-systems.png\" /></p>\nLearning #2: Find Ways To Learn Fast And Don’t Go Solo\n<p>As mentioned, embedded systems have many dependencies. Something as trivial as a fridge can have <a href=\"https://www.st.com/en/applications/home-and-professional-appliances/refrigerators-and-freezers.html\">dozens of interrelated embedded systems</a>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3bf20b62-7b19-496a-b3c6-5becd4f492b5/3-applying-user-experience-principles-embedded-systems.jpg\" /></p>\n<p>The software runs on the hardware. Multiple systems need to interact in consonance with one another to deliver the expected functionality to the end-user. In practice, this dependency means that no matter how good of an idea you have, you will have to collaborate with someone to make it happen. Collaborations and joint efforts can take different shapes and forms, and here are a couple of tools and practices that I’ve found helpful:</p>\n<ul>\n<li><strong>Workshops and <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58858-8_6\">roadmap alignment</a> sessions involving customers and partners</strong> (handled as interactive events, not one-way presentations)<br />These sessions give you the opportunity to explain how you perceive the market and what end-users are doing based on data and experiences you’ve collected, and check with customers and partners whether they see the same problems in the field and align on a future direction. There isn’t a universal way of doing this. Still, there are multiple templates and resources available for building roadmaps that allow you to group features under the key categories — <em>themes</em> — that are relevant to your markets and customers and that also let you prioritize your initiatives in a way that is flexible to account for changes and potential scenarios for the product:<ul>\n<li><a href=\"https://airfocus.com/resources/ebook/roadmapping.pdf\">Roadmapping From A to Z</a> (pdf)</li>\n<li><a href=\"https://miro.com/templates/agile-roadmap/\">Agile Roadmap Template</a></li>\n<li>“<a href=\"https://www.productplan.com/learn/theme-based-roadmap/\">What is a Theme-Based Roadmap and Why Is it Important?</a>”</li>\n<li>“<a href=\"http://www.productstride.com/outcome-roadmaps/\">Outcome Roadmaps</a>”, Sean Sullivan</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/41e66eec-b33d-4805-b3c0-c0994ccdc615/4-applying-user-experience-principles-embedded-systems.png\" /></p>\n<p>An initiative, theme-based roadmap with broad timelines (now/next/later) helps you drive a discussion where to align your current focus, explore together ideas for the future, and discuss expectations. In other words, it helps to validate that you and the customer have the same understanding of the current landscape, a willingness to collaborate in the future and that your efforts are going into addressing the right problems. The cadence will vary depending on your business and your product release planning.</p>\n<ul>\n<li><strong>Joint demos and joint prototyping</strong> can also be used to validate assumptions, increase your knowledge, and test potential solutions. Research shows that <a href=\"https://osuva.uwasa.fi/bitstream/handle/10024/10665/Inter-organizational%20collaboration%20in%20software%20product%20development.pdf?sequence=2&amp;isAllowed=y\">inter-organizational product development initiatives have been growing</a> and that co-development <a href=\"https://www.researchgate.net/publication/328701312_Antecedents_of_co-development_and_its_effect_on_innovation_performance_A_business_ecosystem_perspective\">positively affects innovation</a>. In embedded fairs and events, it is common to see demos of a company on display at other vendors’ booths. Hardware vendors and manufacturers tend to lack software skills in-house, and software companies can better tune and optimize their products if they have a deeper access to the underlying hardware. </li>\n</ul>\n<p>Talent is highly specialized, and hiring prices in the industry can be relatively costly. Collaboration is a cost-effective way to work on proof of concepts for addressing emerging demands, finding new revenue streams, or reaching new markets. Joint prototyping can help you identify potential challenges and gather early feedback, as well as speed up the development process, spread out risks, and support your <a href=\"https://www.eetimes.com/timing-to-market-is-everything/\">time-to-market</a> strategy.</p>\n<p>In embedded, the saying “the whole is more/something else than the sum of its parts” is accurate. Being able to show how systems “talk” to each other and what is the jointly created value is very useful, especially when it comes to complex systems that can have a <a href=\"https://blog.seco-usa.com/designing-long-life-cycle-minimizing-cost-new-product-development/\">lifecycle of 5 to +10 years</a>. In these cases, it is essential to get things right or rather spot design mistakes early on and <a href=\"https://www.smashingmagazine.com/2021/11/concept-testing-part-of-product-design/\">validate your concepts</a> whenever possible.</p>\n<ul>\n<li><strong>Take all the chances you get for sharing your insights and ideas in panel discussions</strong>, contributing to communities specialized in a particular domain, or working on collaborative content like blog posts, whitepapers, and videos with other companies. This is a great way to gauge the interest in a given topic and get reactions and comments on your hypotheses.</li>\n</ul>\n<p>The embedded systems industry is highly competitive, with multiple players developing products in the same category. However, paradoxically, there’s still a reluctance to publicly engage in dialogues that may challenge the status quo and provoke new ways of thinking.</p>\n<p>I have found that the companies that end up being trusted (<a href=\"https://www.smashingmagazine.com/2021/02/building-user-trust-in-ux-design/\">and building trust is one of the central goals of user experience and goes beyond the bare visuals of a product </a>) and respected are those who show up and spark discussion, and share their points of view and ideas without fear of others taking credit. To quote a sentence from the TV series <a href=\"https://www.sho.com/billions\">Billions</a>, <em>“A lot of people watch Bruce Lee movies. It doesn’t mean they can do karate.”</em></p>\nLearning #3: Communicate The Value Of Embedded Software\n<blockquote>When software is hidden and goes unnoticed, find ways to communicate its value by pointing out the needs it solves and the impact it has on the end-user in real life.</blockquote>\n\n<p>You cannot differentiate your product with graphical interfaces, visual design elements, or aesthetics for software that performs tasks in the background and controls systems behind the scenes. Therefore, you need to find different ways to convey its value and relevance. Even if you are not able to directly interact with it, this type of software plays a key role in the end-user experience, impacting, for example, the performance of a device, its battery life, power consumption, and its overall behavior. Let’s see some examples:</p>\n<ul>\n<li><strong>Your Smart TV And Power Outage</strong><br />There was a power outage at home, and you were recording a program on it. What would you expect after the power comes back? Your TV is able to recover. You can turn it on again and boot successfully; all its settings are there, and even the program you were recording when losing power is there. To support this experience, the system needs to be designed to support power losses and not corrupt the file system or lose data — the software embedded in the TV should be reliable enough to take care of that.</li>\n<li><strong>Smartwatches And Battery Life</strong><br />Smartwatches are notoriously famous for their <a href=\"https://www.sciencedirect.com/science/article/pii/S1389128621001651\">challenges with battery life</a>. The need to regularly charge the battery affects the user experience, and it’s something that can be affected by optimizing memory and CPU consumption at the software level.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/047d0c93-8a94-42b0-9031-211e84b515a0/5-applying-user-experience-principles-embedded-systems.png\" /></p>\n<ul>\n<li><strong>Navigation Systems In Your Car And Network Communications</strong><br />When driving, you expect your maps and traffic info to be updated in real-time with minimal <a href=\"https://en.wikipedia.org/wiki/Latency_(engineering\">latency</a>), yet on the road, it is easy to lose network connectivity. Embedded software can help smooth that experience, gracefully behaving when the system is offline and caching the data until the system is back online and ensuring no data is missing. </li>\n</ul>\n<p>Thinking of the scenarios and systems holistically and then being able to explain how you help in the field and the impact you can make for the final user is an effective way to communicate the value of software and the impact it has in providing seamless experiences and meeting expectations. Find a story that resonates with your audience first, and from there, you can always go into more details for those interested in the hows and why their devices operate.</p>\nConclusion\n<p>We interact with embedded systems all the time by unawarely experiencing how they make our lives easier and enjoying all the features and benefits they bring. Quietly in the background, performing the tasks they were meant to, embedded systems are ubiquitous and have different levels of complexity, such as smartphones, traffic lights, manufacturing appliances, satellites, vehicles, medical equipment, and countless other devices. They are present in nearly every aspect of our lives.</p>\n<p> No matter how advanced or simple your product is and what is its place in the system, embedded systems will certainly play a role in the final user experience.</p>\n<p>Understanding the multiple dependencies to other components, the different needs of all the stakeholders you need to consider, and being able to validate your concepts and communicate your ideas early is crucial. It will help you design your embedded product in a way that lets you differentiate yourself through a better overall user experience and, silently behind the scenes, improve people’s lives.</p>",
      "content_text": "Embedded systems mean different things to different people; they can be standalone and independent, working by themselves, or be a part of a larger system. They are purpose-built for a particular application, designed to perform a specific function or set of tasks. Complexities of embedded systems range from very simple to highly sophisticated implementations, depending on the functions and features that need to be performed and its interactions and connections with other systems. Some examples are autonomous driving, artificial intelligence, and the internet of things. \nTo provide some context, embedded systems have been around for a long-time. Two examples are the difference engine devised by Charles Babbage in the 1830s and the Apollo Guidance Computer built in the 1960s and considered to be the first modern embedded system. A key component of an embedded system is its software. Embedded software brings a system to life, performing tasks on your behalf. Software is where most of the design effort and complexity of embedded systems lie. \n\nIn this article, I share three key learnings I have gained from applying UX and human-centered approaches when working with embedded software. These three takeaways include the complexity and advantage of addressing the needs of multiple stakeholders, how to benefit from understanding the dependencies between different components (by definition, embedded means integrated onto something), and how to overcome the challenge of communicating the value of technology that’s often invisible.\n\nEmbrace Complexity In Your Projects And Designs\nFind Ways To Learn Fast And Don’t Go Solo\nCommunicate The Value Of Embedded Software\n\nLearning #1: Embrace Complexity In Your Projects And Designs\nDifferent stakeholders will have different sets of challenges and goals interacting with your product.\n\nLet’s take a typical car as an example and imagine you develop software for its advanced driver-assistance (ADAS) system. There are three stakeholders in this example:\n\nthe driver of the car, who is the end-user; \nthe person that integrates the software into the car is the user;\nthe person in charge of purchasing what goes into the final car is the customer.\n\nEven then, this is a bit of a simplification. In real-life projects, there are even more dependencies and stakeholders involved. \nThus, who should you take into account when building and designing your solution? More than who to design software for, it is about thinking of what’s important for each stakeholder. In this example, the end-user cares about the experience and that everything works as expected or even better; the user is after a complete feature set and possibilities; the customer tends to care about cost-efficiency. In the end, you need to meet end-user expectations (who don’t even know they are interacting with embedded software) while making your product easy to integrate for the user and ensuring the customer that they are getting the best solution for an optimal price. \nAdditionally, embedded systems are, in many cases, resource-constrained in power processing or memory, yet the expectation is that the whole system works seamlessly and in a sophisticated way. Therefore, you need to find a balance between performance and reliability without hurting the experience. Optimizing this interaction requires a great level of expertise and specialized knowledge, which comes at a price. \nWhen designing embedded software, it’s critical to spend time researching and understanding the problem space, the goals, and jobs to be done by the different stakeholders in real life. The better you understand each stakeholder’s expectation, the less risk of spending time building features that would have no use in a real environment or falling short of features for the future. Performing software upgrades to support new use cases in embedded systems can be very challenging because sometimes these devices are located in places that are hard to reach or have no connectivity. \nProblem space exploration is closely related to user research. As such, there is plenty of literature, case studies, materials, frameworks and tools that you can use to collect data and gain insights into users’ needs and challenges. These activities usually include surveys, interviews, questionnaires, or market research. \nHere are some examples:\n\n“Map the Problem Space”, Carissa Carter, Megan Stariha, Mark Grundberg\nThe Problem Space Workshop, Christy Cattin\n“Product Strategy — Insights”, Marty Cagan\n\nA key aspect of understanding the problem space is to be able to map the different journeys for each of your stakeholders and their touchpoints and where in those journeys you could implement those research tools and feedback mechanisms to help you with your planning of user research and problem discovery.\nThe template below from Columbia Road is a great starting point. I have simply added a new dimension — Feedback tools — to be able to link feedback activities to the journey stages. There are also other activities that you don’t necessarily think of as feedback or research tools. Yet, there are incredibly rich practices for gathering information, and I will cover some of those in the next point. \n\nLearning #2: Find Ways To Learn Fast And Don’t Go Solo\nAs mentioned, embedded systems have many dependencies. Something as trivial as a fridge can have dozens of interrelated embedded systems.\n\nThe software runs on the hardware. Multiple systems need to interact in consonance with one another to deliver the expected functionality to the end-user. In practice, this dependency means that no matter how good of an idea you have, you will have to collaborate with someone to make it happen. Collaborations and joint efforts can take different shapes and forms, and here are a couple of tools and practices that I’ve found helpful:\n\nWorkshops and roadmap alignment sessions involving customers and partners (handled as interactive events, not one-way presentations)These sessions give you the opportunity to explain how you perceive the market and what end-users are doing based on data and experiences you’ve collected, and check with customers and partners whether they see the same problems in the field and align on a future direction. There isn’t a universal way of doing this. Still, there are multiple templates and resources available for building roadmaps that allow you to group features under the key categories — themes — that are relevant to your markets and customers and that also let you prioritize your initiatives in a way that is flexible to account for changes and potential scenarios for the product:\nRoadmapping From A to Z (pdf)\nAgile Roadmap Template\n“What is a Theme-Based Roadmap and Why Is it Important?”\n“Outcome Roadmaps”, Sean Sullivan\n\n\n\n\nAn initiative, theme-based roadmap with broad timelines (now/next/later) helps you drive a discussion where to align your current focus, explore together ideas for the future, and discuss expectations. In other words, it helps to validate that you and the customer have the same understanding of the current landscape, a willingness to collaborate in the future and that your efforts are going into addressing the right problems. The cadence will vary depending on your business and your product release planning.\n\nJoint demos and joint prototyping can also be used to validate assumptions, increase your knowledge, and test potential solutions. Research shows that inter-organizational product development initiatives have been growing and that co-development positively affects innovation. In embedded fairs and events, it is common to see demos of a company on display at other vendors’ booths. Hardware vendors and manufacturers tend to lack software skills in-house, and software companies can better tune and optimize their products if they have a deeper access to the underlying hardware. \n\nTalent is highly specialized, and hiring prices in the industry can be relatively costly. Collaboration is a cost-effective way to work on proof of concepts for addressing emerging demands, finding new revenue streams, or reaching new markets. Joint prototyping can help you identify potential challenges and gather early feedback, as well as speed up the development process, spread out risks, and support your time-to-market strategy.\nIn embedded, the saying “the whole is more/something else than the sum of its parts” is accurate. Being able to show how systems “talk” to each other and what is the jointly created value is very useful, especially when it comes to complex systems that can have a lifecycle of 5 to +10 years. In these cases, it is essential to get things right or rather spot design mistakes early on and validate your concepts whenever possible.\n\nTake all the chances you get for sharing your insights and ideas in panel discussions, contributing to communities specialized in a particular domain, or working on collaborative content like blog posts, whitepapers, and videos with other companies. This is a great way to gauge the interest in a given topic and get reactions and comments on your hypotheses.\n\nThe embedded systems industry is highly competitive, with multiple players developing products in the same category. However, paradoxically, there’s still a reluctance to publicly engage in dialogues that may challenge the status quo and provoke new ways of thinking.\nI have found that the companies that end up being trusted (and building trust is one of the central goals of user experience and goes beyond the bare visuals of a product ) and respected are those who show up and spark discussion, and share their points of view and ideas without fear of others taking credit. To quote a sentence from the TV series Billions, “A lot of people watch Bruce Lee movies. It doesn’t mean they can do karate.”\nLearning #3: Communicate The Value Of Embedded Software\nWhen software is hidden and goes unnoticed, find ways to communicate its value by pointing out the needs it solves and the impact it has on the end-user in real life.\n\nYou cannot differentiate your product with graphical interfaces, visual design elements, or aesthetics for software that performs tasks in the background and controls systems behind the scenes. Therefore, you need to find different ways to convey its value and relevance. Even if you are not able to directly interact with it, this type of software plays a key role in the end-user experience, impacting, for example, the performance of a device, its battery life, power consumption, and its overall behavior. Let’s see some examples:\n\nYour Smart TV And Power OutageThere was a power outage at home, and you were recording a program on it. What would you expect after the power comes back? Your TV is able to recover. You can turn it on again and boot successfully; all its settings are there, and even the program you were recording when losing power is there. To support this experience, the system needs to be designed to support power losses and not corrupt the file system or lose data — the software embedded in the TV should be reliable enough to take care of that.\nSmartwatches And Battery LifeSmartwatches are notoriously famous for their challenges with battery life. The need to regularly charge the battery affects the user experience, and it’s something that can be affected by optimizing memory and CPU consumption at the software level.\n\n\n\nNavigation Systems In Your Car And Network CommunicationsWhen driving, you expect your maps and traffic info to be updated in real-time with minimal latency), yet on the road, it is easy to lose network connectivity. Embedded software can help smooth that experience, gracefully behaving when the system is offline and caching the data until the system is back online and ensuring no data is missing. \n\nThinking of the scenarios and systems holistically and then being able to explain how you help in the field and the impact you can make for the final user is an effective way to communicate the value of software and the impact it has in providing seamless experiences and meeting expectations. Find a story that resonates with your audience first, and from there, you can always go into more details for those interested in the hows and why their devices operate.\nConclusion\nWe interact with embedded systems all the time by unawarely experiencing how they make our lives easier and enjoying all the features and benefits they bring. Quietly in the background, performing the tasks they were meant to, embedded systems are ubiquitous and have different levels of complexity, such as smartphones, traffic lights, manufacturing appliances, satellites, vehicles, medical equipment, and countless other devices. They are present in nearly every aspect of our lives.\n No matter how advanced or simple your product is and what is its place in the system, embedded systems will certainly play a role in the final user experience.\nUnderstanding the multiple dependencies to other components, the different needs of all the stakeholders you need to consider, and being able to validate your concepts and communicate your ideas early is crucial. It will help you design your embedded product in a way that lets you differentiate yourself through a better overall user experience and, silently behind the scenes, improve people’s lives.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3223ce3b-fbdf-44dc-aae4-149d03b2ce75/user-experience-principles-embedded-systems.jpg",
      "date_published": "2022-06-13T11:00:00.000Z",
      "date_modified": "2022-06-13T11:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/devfest-for-ukraine/",
      "url": "https://smashingmagazine.com/2022/06/devfest-for-ukraine/",
      "title": "DevFest For Ukraine, A Charity Conference On The Future Of Tech 🇺🇦",
      "summary": "[DevFest for Ukraine](https://devfest.gdg.org.ua/) is a charitable online conference that will bring together 20 industry-leading tech speakers in support of Ukraine. June 14–15.",
      "content_html": "<p>Every day, millions of Ukrainians show incredible courage and strength resisting Russian aggression. Volunteers, individuals and organizations are working together to provide support and raise funds for those in need.</p>\n\n<p>In times like these, uniting efforts and <strong>working together as a community</strong> matters more than ever. That’s why we’d like to highlight a wonderful initiative today. <strong><a href=\"https://devfest.gdg.org.ua/\">DevFest for Ukraine</a></strong>, a conference with world-class technical speakers and an important mission: to raise funds for Ukraine.</p>\n\n<p><em>DevFest for Ukraine</em> is a charitable tech conference that will bring together <strong>20 industry-leading speakers</strong> over two days (June 14–15), featuring live streams from London and Lviv. It will address key topics for the <strong>future of tech</strong>, including trends in Android, web, and AI.</p>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0e0a3698-69d2-4226-9d53-f691fdac18f4/devfest-for-ukraine-opt.png\" /></p>\nWhat Can You Expect At <em>DevFest For Ukraine</em>?\n\n<p>The conference will take place online <strong>June 14–15</strong>, featuring both live and recorded sessions from London and Lviv, along with live Q&amp;As. From <strong>tech sessions</strong> and inspirational keynotes to <strong>networking</strong> and overviews of the <strong>latest developer tools</strong>, <em>DevFest for Ukraine</em> brings together people who shape the future of Android, web, and AI technologies.</p> \n\n<p>Learn from industry-leading speakers like <strong>Romain Guy</strong> and <strong>Chet Haase</strong> who have been building Android since 1.0, <strong>Jhey Tompkins</strong> and <strong>Una Kravets</strong> from the Google Chrome team, or <strong>Robert Crowe</strong> from the TensorFlow team who will talk about trends in ML development. The participation is donation-based: your donation will give you access to the live stream and recordings after the event. For the detailed schedule, visit the <a href=\"https://devfest.gdg.org.ua/#schedule\"><em>DevFest for Ukraine</em> website</a>.</p>\n\nWhere Will Donations Go?\n\n<p>All funds raised will support different causes in a transparent, public way. If you want to learn more about the organizations, the <em>DevFest for Ukraine</em> team summarized <a href=\"https://devfest.gdg.org.ua/why-these-organizations/\">why they chose them</a>.</p>\n\n<p>The initial goal was to raise $50,000. Thanks to multiple donations from individuals and partners, they’ve already reached their $50,000 and $75,000 milestones. And now they set a new goal — raising $100,000. With these funds, they can buy about 1,000 first aid kits, or 320 bulletproof vests, or 60 tons of humanitarian aid, which can save the lives of thousands of our Ukrainian friends. Let’s do it together!</p>\n\nHow To Join\n\n<p><a href=\"https://devfest.gdg.org.ua/\"><strong>Join the conference</strong></a> to support Ukraine and gain knowledge from the speakers who are shaping the future of tech!</p>\n\n<p>Thank you for your kind support. 💙💛</p>",
      "content_text": "Every day, millions of Ukrainians show incredible courage and strength resisting Russian aggression. Volunteers, individuals and organizations are working together to provide support and raise funds for those in need.\n\nIn times like these, uniting efforts and working together as a community matters more than ever. That’s why we’d like to highlight a wonderful initiative today. DevFest for Ukraine, a conference with world-class technical speakers and an important mission: to raise funds for Ukraine.\n\nDevFest for Ukraine is a charitable tech conference that will bring together 20 industry-leading speakers over two days (June 14–15), featuring live streams from London and Lviv. It will address key topics for the future of tech, including trends in Android, web, and AI.\n\n\nWhat Can You Expect At DevFest For Ukraine?\n\nThe conference will take place online June 14–15, featuring both live and recorded sessions from London and Lviv, along with live Q&As. From tech sessions and inspirational keynotes to networking and overviews of the latest developer tools, DevFest for Ukraine brings together people who shape the future of Android, web, and AI technologies. \n\nLearn from industry-leading speakers like Romain Guy and Chet Haase who have been building Android since 1.0, Jhey Tompkins and Una Kravets from the Google Chrome team, or Robert Crowe from the TensorFlow team who will talk about trends in ML development. The participation is donation-based: your donation will give you access to the live stream and recordings after the event. For the detailed schedule, visit the DevFest for Ukraine website.\n\nWhere Will Donations Go?\n\nAll funds raised will support different causes in a transparent, public way. If you want to learn more about the organizations, the DevFest for Ukraine team summarized why they chose them.\n\nThe initial goal was to raise $50,000. Thanks to multiple donations from individuals and partners, they’ve already reached their $50,000 and $75,000 milestones. And now they set a new goal — raising $100,000. With these funds, they can buy about 1,000 first aid kits, or 320 bulletproof vests, or 60 tons of humanitarian aid, which can save the lives of thousands of our Ukrainian friends. Let’s do it together!\n\nHow To Join\n\nJoin the conference to support Ukraine and gain knowledge from the speakers who are shaping the future of tech!\n\nThank you for your kind support. 💙💛",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0e0a3698-69d2-4226-9d53-f691fdac18f4/devfest-for-ukraine-opt.png",
      "date_published": "2022-06-10T13:59:00.000Z",
      "date_modified": "2022-06-10T13:59:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/measuring-performance-typefaces-users-part2/",
      "url": "https://smashingmagazine.com/2022/06/measuring-performance-typefaces-users-part2/",
      "title": "Measuring The Performance Of Typefaces For Users (Part 2)",
      "summary": "In this article, Thomas Bohm explains ways to test typefaces and other typographic issues. Though this article is slightly high-end and academic, fear not. The content will be interesting, especially for committed typeface designers and typographers. If you like complex issues and problems, this is for you.",
      "content_html": "<p>In the first part of this article, we saw that measuring and comparing typefaces is not a simple task. Testing it (subjectively or objectively) also depends on the context — which can be very tricky. We saw how important it is to keep the typographic design parameters and variables the same to get a more accurate result while testing different typefaces.</p>\n<blockquote> Did you miss out on it? Don’t worry! Take a look at the <a href=\"https://www.smashingmagazine.com/2022/06/measuring-performance-typefaces-users-part1/\">first part of this article here</a> so you can get all the context you need to fully enjoy it.</blockquote>\n\n<p>Measuring, comparing, and testing typefaces may guide your project decisions towards a more accessible and highly legible typeface. Let’s dive into the specifics of typeface aspects so you can get the best out of your tests. So what aspects of typefaces could we measure?</p>\nAspects Specific To The Typeface Itself For Extended Reading Typefaces\n<h3>Ascender And Descender Height In Relation To X-height</h3>\n<ul>\n<li><strong>Validation:</strong><br />There seems to be some truth in a larger x-height and medium-length ascenders and descenders being ideal.</li>\n<li><strong>Description:</strong><br />The most efficient typefaces with the best ratio of x-height and cap-height seem to be <em>Wayfinding Sans Pro</em> and <em>Johnston Underground</em> with an x-height between 67% to 69% of the cap height. Learn more about it in Ralf Hermann’s (director of <a href=\"https://typography.guru\">Typography.Guru</a> paper, “<a href=\"https://typography.guru/journal/does-a-large-x-height-make-fonts-more-legible-r16/\">Does A Large X-Height Make Fonts More Legible?</a>.”</li>\n<li><strong>Measurement:</strong><br />Millimeters.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Aesthetic Quality In Relation To Other Similar Typefaces</h3>\n<ul>\n<li><strong>Validation:</strong><br />There would probably be other typefaces that the typeface would be similar to or would fit with, so how well does it compare?</li>\n<li><strong>Description:</strong><br />Expert review or opinion.</li>\n<li><strong>Measurement:</strong><br />Not good, okay, very good.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>Aesthetic Quality In Relation To Historical Revival Or Similarity</h3>\n<ul>\n<li><strong>Validation:</strong><br />There would probably be other typefaces that the typeface would be similar to or fit with. Therefore, how well does it perform when compared to other typefaces that are considered to be historically well done or have been revived well?</li>\n<li><strong>Description:</strong><br />Expert review or opinion.</li>\n<li><strong>Measurement:</strong><br />Not good, okay, very good.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>Character, Symbol, And Language Support</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how usable the typeface is, for different characters, symbols, languages, and information types.</li>\n<li><strong>Description:</strong><br />We know character and symbol support, like for maths and different languages, is desirable and needed.</li>\n<li><strong>Measurement:</strong><br />Numerical score or tick list against features and languages.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).  </li>\n</ul>\n<h3>Kerning</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how well the typeface has been kerned — because kerning leads to better and more legible typography.</li>\n<li><strong>Description:</strong><br />A kerning test based on the example below, from Veronika Burian and José Scaglione’s — directors of the font foundry TypeTogether — article “<a href=\"https://www.type-together.com/font-quality\">Quality type: How to spot fonts worth your money.</a>”</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ba032ab3-e5f3-4b92-aabc-1e6ca02cf650/1-v2-measuring-performance-typefaces-users-part2.jpg\" /></p>\n<ul>\n<li><strong>Measurement:</strong><br />Not good, okay, very good. Percentage value, maybe. Precise numerical score based on a standard test.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Accessibility (Children)</h3>\n<ul>\n<li><strong>Validation:</strong><br />We know that accessible characters and symbols lead to better, more legible, and easier-to-read typography.</li>\n<li><strong>Description:</strong><br />Infant characters as in my paper “<a href=\"https://typography.guru/journal/letters-symbols-misrecognition/\">Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition</a>.”</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b4b60483-9e55-4808-849c-7736bc72f73c/2-v2-measuring-performance-typefaces-users-part2.jpg\" /></p>\n<ul>\n<li><strong>Measurement:</strong><br />Numerical score based on the number of characters and symbols. Research and design effort based on not good, okay, very good.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Accessibility (Dyslexia)</h3>\n<ul>\n<li><strong>Validation:</strong><br />Dyslexic characters as in my paper “<a href=\"https://typography.guru/journal/letters-symbols-misrecognition/\">Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition</a>” and Robert Hillier’s (typeface designer and academic) PhD “<a href=\"https://www.sylexiad.com\">A typeface for the adult dyslexic reader</a>.”</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/110264a0-b3d8-4029-bf97-92c75d5f94c1/3-v2-measuring-performance-typefaces-users-part2.jpg\" /></p>\n<ul>\n<li><strong>Description:</strong><br />Numerical score based on the number of characters and symbols. </li>\n<li><strong>Measurement:</strong><br />Research and design effort based on not good, okay, very good.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Accessibility (Vision Impairment)</h3>\n<ul>\n<li><strong>Validation:</strong><br />Visually impaired characters as in my paper “<a href=\"https://typography.guru/journal/letters-symbols-misrecognition/\">Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition.</a>”</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7d233821-145a-405d-a869-d0833731b52a/4-v4-measuring-performance-typefaces-users-part2.jpg\" /></p>\n<ul>\n<li><strong>Measurement:</strong><br />Numerical score based on the number of characters and symbols.</li>\n<li><strong>Description:</strong><br />Research and design effort based on not good, okay, very good.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\nAspects Specific To The Reader/User For Extended Reading Typefaces\n<h3>Comprehension</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how much and how well information is absorbed, retained, and recalled from a typeface or different typefaces.</li>\n<li><strong>Description:</strong><br />This is a very difficult area to measure, and I would like to explain why:<ol>\n<li>Not everyone will be able to recall accurately everything they know or do not know in an exam or in test questions;</li>\n<li>What people say they know, fail to communicate, and what they actually do in the real world are very different things. Just because some cannot recall something or write it in an exam paper, it does not mean they do not know it. </li>\n</ol>\n</li>\n</ul>\n<blockquote>“Many previous reading studies investigated the effect of typography on reading speed. But we know that faster speed does not always equate to better comprehension. In fact, better comprehension is often associated with slower reading speed.”<br /><br />— <a href=\"http://sofiebeier.dk\">Sofie Beier</a> (legibility expert), “<a href=\"https://readabilitymatters.org/articles/dr-sofie-beier-bringing-together-science-and-typography\">Bringing together science and typography</a>”</blockquote>\n\n<ul>\n<li><strong>Measurement:</strong><br />A paragraph of text, or pages of text and information, followed by questions or set the users tasks to do based on the information.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>Speed</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how much, or how much more, they can read compared to what is considered normal/average from a typical typeface.</li>\n<li><strong>Description:</strong><br />This is another very difficult area to measure, let me explain why. I could quickly scan a single page of a book and, in theory, have read all the content in about 6 seconds (because I have scanned my eyes across all the text quickly). Although, just because I have, in theory, read (or scanned) the text, it does not necessarily mean I have understood or absorbed it. However, the result would be taken into consideration — and there would probably exist clear and strong differences in performance between comparing a script typeface (like <em>Snell Roundhand</em>) against a highly legible typeface (like the <em>Unit typeface</em>). So the <em>Unit typeface</em> would be much easier and quicker to read than <em>Snell Roundhand</em>.</li>\n<li><strong>Measurement:</strong><br />Eye-tracking (time, speed, and behavior) recording and data collection.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Facial Muscle Activation</h3>\n<ul>\n<li><strong>Validation:</strong><br />The zygomatic muscle activity (which controls smiling) is positively associated with positive emotional stimuli and a positive mood state.</li>\n<li><strong>Description:</strong><br />By placing tiny sensors over certain facial muscles, one can measure the minute changes in the muscles’ electrical activity, which reflects changes in muscle tension. Facial EMG (electromyography) studies have found that activity of the corrugator muscle (which lowers the eyebrow and is involved in producing frowns) varies inversely with the emotional valence of the presented stimuli and reports of mood state. You can see in the academics John Cacioppo, Lauren Bush, and Louis Tassinary’ paper “<a href=\"https://journals.sagepub.com/doi/10.1177/0146167292185001\">Microexpressive facial actions as a function of affective stimuli: Replication and extension</a>” and in the academic Ulf Dimberg’s writing “<a href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1469-8986.1990.tb01962.x\">Facial electromyography and emotional reactions</a>.”</li>\n<li><strong>Measurement:</strong><br />Use an electromyography (EMG) sensor placed on top of a muscle to measure the amount of electrical current in the muscle. You get frequency readings.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective) and maybe strong (objective).</li>\n</ul>\n<h3>Character, Symbol, Or Word-finding Test</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how quickly they can find information.</li>\n<li><strong>Description:</strong><br />The participants were asked to locate a specific character in a text with a color pen. The specific character was shown at the bottom of the sheet for easy referral. The response times were recorded. Find out more about this method in the academic <a href=\"https://research.polyu.edu.hk/en/persons/sze-hang-kwok\">Brian Sze-Hang Kwok’s</a> paper “<a href=\"https://benjamins.com/catalog/idj.22.3.02kwo\">Legibility of medicine labels.</a>”</li>\n<li><strong>Measurement:</strong><br />A numerical score of correct and incorrect.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Searching a Phrase Test</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how quickly readers can find information.</li>\n<li><strong>Description:</strong><br />The participants were required to locate a phrase in the context of a medicine label. The specific phrase was shown at the bottom of the sheet for easy referral. The response times were recorded. Find more about this method in the academic <a href=\"https://research.polyu.edu.hk/en/persons/sze-hang-kwok\">Brian Sze-Hang Kwok’s</a> paper “<a href=\"https://benjamins.com/catalog/idj.22.3.02kwo\">Legibility of medicine labels</a>.”</li>\n<li><strong>Measurement:</strong><br />A numerical score of correct and incorrect.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Read-aloud</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out if there are any issues or obvious difficulties between different typefaces, or different classifications of typefaces, and maybe weights (like thin, extra bold, italic or condensed).</li>\n<li><strong>Description:</strong><br />The subject producing a reader protocol is requested to read the text aloud and to immediately express any thoughts about the document. More about this method can be seen in the academics <a href=\"https://uu.academia.edu/LeoLentz\">Leo Lentz’s</a> and <a href=\"https://www.researchgate.net/profile/Henk-Maat\">Henk Pander Maat’s</a> paper “<a href=\"https://benjamins.com/catalog/idj.15.3.09len\">Reading aloud and the delay of feedback</a>.”</li>\n<li><strong>Measurement:</strong><br />Notes and recordings based on not good, okay, very good, and notes of specific problems.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>Think-aloud</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out if there are any issues and if any issues can be highlighted or discovered.</li>\n<li><strong>Description:</strong><br />Get people to perform certain specific tasks while using the document to vocalize the person’s thinking. From academics <a href=\"https://uu.academia.edu/LeoLentz\">Leo Lentz’s</a> and <a href=\"https://www.researchgate.net/profile/Henk-Maat\">Henk Pandar Maat’s</a> paper “<a href=\"https://benjamins.com/catalog/idj.15.3.09len\">Reading aloud and the delay of feedback</a>.”</li>\n<li><strong>Measurement:</strong><br />Notes and recording based on not good, okay, very good, and notes of specific problems.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>At-a-glance</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out if they can correctly identify a word, letter, or symbol and not misread it as another word, letter, or symbol in a quick response environment.</li>\n<li><strong>Description:</strong><br />Typefaces were individually sized to a height of 4 mm using the letter “H” as the reference. Participants viewed the monitor at a distance of approximately 70 cm. Participants’ distance to the screen was measured at the start of the session using a tape measure. Each individual trial followed the same sequence of presentation: a large fixation rectangle signifying the start of the new trial (400 ms), a masking stimulus composed of non-letter characters (200 ms), the stimulus of interest (variable timing, according to staircase rules as described above), a second masking stimulus of non-letter characters (200 ms), and then a response prompt (up to 5000ms). You can see more about this method in the paper “<a href=\"https://www.tandfonline.com/doi/full/10.1080/00140139.2020.1714748\">The great typography bake-off: comparing legibility at-a-glance</a>,” by Ben Sawyer’s (academic), <a href=\"http://jdobr.es\">Jonathan Dobres</a> (academic), <a href=\"https://arabictype.com\">Nadine Chahine</a> (typeface designer), and academic <a href=\"https://web.mit.edu/reimer/www/\">Bryan Reimer’s</a>.</li>\n<li><strong>Measurement:</strong><br />A numerical score based on the number of characters or symbols. The time measure is also checked.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Questionnaire</h3>\n<ul>\n<li><strong>Validation:</strong><br />People’s opinions, preferences, thoughts, concerns, views, likes, and dislikes.</li>\n<li><strong>Description:</strong><br />Question asking, interviews, and real-time observations.</li>\n<li><strong>Measurement:</strong><br />Notes and recordings.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>The Radner Reading Charts</h3>\n<ul>\n<li><strong>Validation:</strong><br />Test the person’s vision accuracy and acuity with a typeface.</li>\n<li><strong>Description:</strong><br />The Radner reading chart is a highly standardized multilingual reading test system. The result of the collaboration is a standardized, valid, and reliable reading test system available in numerous languages. The reading chart consists of sentence <em>optotypes</em>, which are optimized reading test items (standardized by construction), and statistical selection. Sentence optotypes consist of short sentences that are highly comparable in terms of the number of words (14 words), the word length, the position of words, the lexical difficulty, and the syntactic complexity. Language-specific characteristics were considered, as were the number of letters and syllables per word, line, and sentence. Get to know more from the legibility experts <a href=\"http://sofiebeier.dk\">Sofie Beier</a> and <a href=\"https://www.microsoft.com/en-us/research/people/kevlar/\">Kevin Larson</a>’s paper “<a href=\"https://benjamins.com/catalog/idj.20.1.02bei\">How does typeface familiarity affect reading performance and reader preference?</a>”</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/56a23750-75ec-416d-b04e-b89cc8bfd962/5-v2-measuring-performance-typefaces-users-part2.jpg\" /></p>\n<ul>\n<li><strong>Measurement:</strong><br />Correct or incorrect response. Note the point of failure or incapability to proceed anymore.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Legibility (Misrecognition)</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out if they can correctly identify a letter, number, word, or symbol and not misread it as another letter, word, or symbol.</li>\n<li><strong>Description:</strong><br />As in my paper, “<a href=\"https://typography.guru/journal/letters-symbols-misrecognition/\">Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition</a>.”</li>\n<li><strong>Measurement:</strong><br />Score for correct or incorrect identification. Time measure check also.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Legibility (At a Very Small Typeface Size)</h3>\n<ul>\n<li><strong>Validation:</strong><br />To push a person’s eyesight to the maximum and see what happens at a very small size.</li>\n<li><strong>Description:</strong><br />At small sizes, less than 8pt, for instance.</li>\n<li><strong>Measurement:</strong><br />x-height size measurement preferred over pt size. Also, maybe a rating of difficulty and time to read like: easy, reasonable, and hard.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Legibility (Distance)</h3>\n<ul>\n<li><strong>Validation:</strong><br />To see when a letter, symbol, or a word becomes unreadable and how far away it can be read or not recognized anymore.</li>\n<li><strong>Description:</strong><br />In <a href=\"https://www.robwaller.org\">Robert Waller’s</a> (information designer) article “<a href=\"https://benjamins.com/catalog/idj.15.1.01wal\">Comparing typefaces for airport signs</a>” he says that you could use a screen, physical sign, or printed paper to display a word, letter, or symbol. A person needs to stand far away and then get closer to the display until they can correctly identify the word, letter, or symbol. If a screen is being used, the person can also be at a fixed distance from the screen and then you can make the word, letter, or symbol bigger on the screen, until they can correctly identify it. This would give us a legibility score and distance measurement in relation to the correct identification. The first presented character was the letter “d.” As identified in Miles Tinker’s book <a href=\"https://books.google.co.uk/books/about/Legibility_of_Print_Second_Printing.html?id=EdcCzQEACAAJ&amp;redir_esc=y\"><em>Legibility of print</em></a>, this character is one of the most easily recognizable letters. The purpose of this first exposure was to locate the individual vision threshold. The participant was placed at a distance of 10 meters from the screen and asked to move slowly forward until the presented letter was at the threshold of being identifiable. This was the distance at which the individual participant was tested — varying from 4.5–9 meters (with an average of 6 meters) from the screen. You can read more about this method in <a href=\"http://sofiebeier.dk\">Sofie Beier</a> (legibility expert) and <a href=\"https://www.microsoft.com/en-us/research/people/kevlar/\">Kevin Larson’s</a> (legibility expert) paper “<a href=\"https://benjamins.com/catalog/idj.18.2.03bei\">Design improvements for frequently misrecognised letters</a>.”</li>\n<li><strong>Measurement:</strong><br />Measurement in mm, cm or m.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Legibility (Rotated Information)</h3>\n<ul>\n<li><strong>Validation:</strong><br />To push a typeface and person’s eyesight to the maximum and see what happens at these extreme angles. Also, these angles are common in VR (virtual reality) software and products.</li>\n<li><strong>Description:</strong><br />At an angle: -45 degrees horizontally left and +45 degrees horizontally right, -45 degrees vertically up and +45 degrees vertically down.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/edf53744-8266-4a50-a7f5-0bf7a0b0e605/6-v2-measuring-performance-typefaces-users-part2.jpg\" /></p>\n<ul>\n<li><strong>Measurement:</strong><br />Legibility test (character, symbol, word) test.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Legibility (Degrading, Distortion, and Blurring)</h3>\n<ul>\n<li><strong>Validation:</strong><br />To push a typeface and person’s eyesight to the maximum and see what happens under these extreme conditions.</li>\n<li><strong>Description:</strong><br />Legibility degrading test as in Ralf Hermann’s (director of <a href=\"https://typography.guru\">Typography.Guru</a>) paper “<a href=\"https://typography.guru/journal/designing-the-ultimate-wayfinding-typeface-r30/\">Designing the ultimate wayfinding typeface</a>.”</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3fb24cc8-8b1f-4293-9c67-4ca4d5363380/7-v2-measuring-performance-typefaces-users-part2.jpg\" /></p>\n<ul>\n<li><strong>Measurement:</strong><br />The score for correct or incorrect identification. Time measure was also checked.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Appeal (Typeface Fitting Subject and Content)</h3>\n<ul>\n<li><strong>Validation:</strong><br />How well does it fit and suit the content?</li>\n<li><strong>Description:</strong><br />An appeal concerning the content, as an example, for content on gardening, when a slightly more organic, chiseled, and wavy typeface might communicate and fit the content better.</li>\n<li><strong>Measurement:</strong><br />Score based not good, okay, very good.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Appeal (User Feedback and Responses In Relation to Other Typefaces They May Know)</h3>\n<ul>\n<li><strong>Validation:</strong><br />How well does it fit and suit the content?</li>\n<li><strong>Description:</strong><br />Appeal in relation to the typeface itself. What does the user say they like or dislike about this typeface in relation to other typefaces they use and know about? This method could produce interesting observations and data, albeit highly subjective.</li>\n<li><strong>Measurement:</strong><br />Notes and recordings.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>Fixation Duration</h3>\n<ul>\n<li><strong>Validation:</strong><br />How quick or lengthy does the eye have to fixate to understand the information?</li>\n<li><strong>Description:</strong><br />Fixation duration is a period of time when the focus of the participant’s gaze is relatively still on an area and taking in information about that which is looked at, as in the academics Ivan Burmistrov, Tatiana Zlokazova, Iuliia Ishmuratova, and Maria Semenova’s paper “<a href=\"https://dl.acm.org/doi/10.1145/2971485.2996745\">Legibility of light and ultra-light fonts: eyetracking study</a>.”</li>\n<li><strong>Measurement:</strong><br />Milliseconds (ms).</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective) and maybe strong (objective).</li>\n</ul>\n<h3>Saccadic Amplitude</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out what behavior, movements, or patterns are happening.</li>\n<li><strong>Description:</strong><br />Saccadic amplitudes are a quick simultaneous movement of both eyes, like when you are reading a line of text. In this method, we monitor what happens with saccadic eye movements when reading, as in the academics Ivan Burmistrov, Tatiana Zlokazova, Iuliia Ishmuratova, and Maria Semenova’s paper “<a href=\"https://dl.acm.org/doi/10.1145/2971485.2996745\">Legibility of light and ultra-light fonts: eyetracking study</a>.”</li>\n<li><strong>Measurement:</strong><br />Degrees (°).</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective) and maybe strong (objective).</li>\n</ul>\nAspects Specific to The Users’ Environment and Situation\n<h3>Light</h3>\n<ul>\n<li><strong>Validation:</strong><br />To see how a typeface performs in lighting conditions and see how people respond in the lighting conditions.</li>\n<li><strong>Description:</strong><br />Low light or good light condition and see how it affects the information and performance.</li>\n<li><strong>Measurement:</strong><br />The score for correct or incorrect identification. Time measure is also checked. The light strength is measured in lumens (lm).</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Stress</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how typefaces would work better or worse, under stress and high-pressure situations, with quick stressed eye movements.</li>\n<li><strong>Description:</strong><br />Setup situations such as: booking a ticket and going through an airport, doing tasks after they have finished a 6-hour working day, or reading or doing tasks late at night — when it is more likely that they will be more tired.</li>\n<li><strong>Measurement:</strong><br />Accuracy and efficiency of users’ actions. Maybe blood pressure or heart rate testing.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>OpenType variable fonts and real-time responsive features</h3>\n<ul>\n<li><p><strong>Validation:</strong><br />Whereas a single non-variable font does not essentially change or alter itself, variable fonts can, and can be given settings to instruct them to work in different technological environments.</p>\n</li>\n<li><p><strong>Notes and Description:</strong><br />Variable fonts have the ability to alter and modify themselves in real-time to different screen sizes, media query responses, user customisations and environments. Variable fonts can utilise different aspects such as: weights, width, italic, slant, optical size and grade, to change and adapt, to help them work better in different and changing situations.  </p>\n</li>\n<li><p><strong>Measurement:</strong><br />Assessment (legibility, readability, comprehension, user preference) in relation to the changing circumstances. [Many measurement types in this area, too many to mention, but see other areas in this paper for aspects applyable.]</p>\n</li>\n<li><p><strong>Measure quality type:</strong><br />Weak (subjective) and maybe strong (objective).</p>\n</li>\n</ul>\n<h3>Time Pressure</h3>\n<ul>\n<li><strong>Validation:</strong><br />To find out how typefaces would work better (or worse) under time pressure and quick stressed eye movements.</li>\n<li><strong>Description:</strong><br />Setup situations like finding information within a certain timeframe, booking a taxi very quickly, or finding something in a telephone directory.</li>\n<li><strong>Measurement:</strong><br />Time measuring. Maybe a blood pressure test.</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective).</li>\n</ul>\n<h3>In Diverse Situations (Driving In a Car At Distance On a Road Sign Or Airport Sign)</h3>\n<ul>\n<li><strong>Validation:</strong><br />To push a person’s vision (length of view) and agility and see how typefaces respond.</li>\n<li><strong>Description:</strong><br />To test the extremes of people’s vision and ability, like driving in a car and reading a road sign where distance and orientation are factors. How does weather affect information and communication?</li>\n<li><strong>Measurement:</strong><br />In meters, centimeters, or millimeters.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\nAspects Specific to Technology for Extended Reading Typefaces\n<h3>Range of Weights</h3>\n<ul>\n<li><strong>Validation:</strong><br />It is always appreciated and helpful to use a typeface with a range of weights.</li>\n<li><strong>Notes and description of measuring type:</strong><br />Range of weights offered.</li>\n<li><strong>Measurement:</strong><br />Numerical score in the amount of weights.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>On-screen Rendering and Hinting</h3>\n<ul>\n<li><strong>Validation:</strong><br />Bad hinting and screen rendering leads to hard-to-read on-screen typography and illegibility.</li>\n<li><strong>Description:</strong><br />Analyze by taking a screengrab (then zooming-in), or by using a zoom-in device (magnifying glass), then analyzing the hinting.</li>\n<li><strong>Measurement:</strong><br />A score based on not good, okay, and very good. Also, use 3 different types of screens (low-resolution, HD and 4k+).</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>Font File Size</h3>\n<ul>\n<li><strong>Validation:</strong><br />Larger font sizes can take up more bandwidth, especially across larger websites, and be slower to load initially in a webpage’s first content paint.</li>\n<li><strong>Description:</strong><br />Look at the file size of the font.</li>\n<li><strong>Measurement:</strong><br />The file size (kb) would give a score, although this measure is certainly not very useful, as there is no escape from a typeface with a large symbol and language support, which cannot really be made any smaller in file size.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\n<h3>OpenType Features/Variable?</h3>\n<ul>\n<li><strong>Validation:</strong><br />If a typeface has more desirable features (such as small caps, different number styles, ligatures, and so on), it makes the typography better and typographically more usable.</li>\n<li><strong>Description:</strong><br />A typeface is better if it has the features required by users and information.</li>\n<li><strong>Measurement:</strong><br />Numerical score or tick list of features.</li>\n<li><strong>Measure quality type:</strong><br />Strong (objective).</li>\n</ul>\nSpecific Typographic Design Variables Affecting Performance\n<h3>Typographic Design</h3>\n<ul>\n<li><strong>Validation:</strong><br />They affect typeface and typographic communication.</li>\n<li><strong>Description:</strong><br />Tracking, leading, kerning, typeface weight, line length, word spacing, condensed weight, typeface size, typeface color, OpenType features.</li>\n<li><strong>Measurement:</strong><br />Various possible (must be controlled and precise, as mentioned in Ralf Hermann (director of <a href=\"https://typography.guru\">Typography.Guru</a>) paper “<a href=\"https://typography.guru/journal/what-makes-letters-legible-r37/\">What makes letters legible?</a>”).</li>\n<li><strong>Measure quality type:</strong><br />Weak (subjective) hard to measure accurately.</li>\n</ul>\nWhat Would Typeface Performance Measurements, Results, and Scores Potentially Look Like?\n<p>A data table, infographic, or some kind of graph could be used?</p>\nScientists And Designers Needing to Work Better Together\n<p><a href=\"http://sofiebeier.dk\">Sofie Beier</a> (legibility expert) in her paper “<a href=\"http://visiblelanguagejournal.com/issue/202/article/1372\">Letterform research: An academic orphan</a>” touches upon the different issues and constraints designers and academics have faced in the past:</p>\n<blockquote><p>“To produce findings that are relevant for the practicing designer, scientists benefit from consulting designers in the development of the experiments. While designers can contribute with design skills, they cannot always contribute with scientific rigor. Hence, researchers will profit from adopting a methodological approach that ensures both control of critical typographical variables and scientific validation. An interdisciplinary collaboration where scientists provide valid test methods and analysis and designers identify relevant research questions and develop test materials, will enable a project to reach more informed findings than what the two fields would be able to produce in isolation.”<br /><br />— <a href=\"http://sofiebeier.dk\">Sofie Beier</a> in <a href=\"http://visiblelanguagejournal.com/issue/202/article/1372\">Letterform Research: An Academic Orphan</a>\n</p></blockquote>\n\n<p>To recap, designers have tended to produce information lacking scientific rigor in the past. In contrast, scientists produce information that is hard to understand — with equations and lacks practical application. So both sides, whichever you are on, have their weaknesses and lack expertise.</p>\nAm I Making Typeface Designers’ Job Harder?\n<p>It is not my aim to make a typeface designer’s job any harder. It is commonly known that any typeface takes at least one year of hard work. The typeface designer <a href=\"https://martinmajoor.com/\">Martin Majoor</a> states that he designed the <em>Questa typeface</em> at irregular intervals over the course of 7 years. I have nothing but respect for typeface designers and the amazingly hard job they do. In fact, I have so much respect for the time and difficulty of designing a typeface, that I refuse even to try to attempt the task.</p>\nWhat Now?\n<ul>\n<li>Research into what is legible and what characteristics make letters and symbols more legible, go to the library and research online. For example, the academic journal <a href=\"http://visiblelanguagejournal.com\">Visible Language</a> has all journals available for free on their website. There is some incredible research and work done, that was done more than 50 years ago; </li>\n<li>Speak with people and speak with other typeface designers; </li>\n<li>Avoid designing and releasing typefaces done, expressed, and designed on your own;</li>\n<li>Test typefaces, try to do the test accurately and try to compare what you are designing with another typeface, to see where there are weaknesses and strengths in testing results with people and in different contexts and environments. How is it working (or not working) better than another typeface and in different contexts and environments?</li>\n<li>Test typefaces with different categories of people in different contexts and environments;</li>\n<li>Make your findings, design intentions, and tactical fixes available for free, as part of the typeface release, as a publication, or as some kind of central public list (like on GitHub), so we can start better and get to where we need to be quicker;</li>\n<li>Maybe a completely new typeface might not be as good of an idea as you think. Maybe extension, improvement, or modification to an existing typeface might be smarter. <strong>New is not automatically better</strong>.</li>\n</ul>\nConclusions\n<p>Do we, as users and designers, really need to assess typefaces and find out how they perform? Is it necessary? Well, whatever your thoughts are, in 2022, with a mass of typefaces available and 100s of years of designing and manufacturing typefaces, it is time to consider this topic. I think the time has come, and we are there. This is especially true for highly legible typefaces, some kind of measure or measures — even if new typefaces got released and they only had one performance measure (or say three), that would be a start.  </p>\n<p>We may also need some cross-measurable tests that are used, so everyone tests against the same (or as near as) thing. Because, as previously mentioned, if someone tests their typeface against a sans serif (like Arial), then another person tests their typeface using another typeface (like Helvetica), the data will not be cross-comparable. And furthermore, what typographic design and typesetting values the two people use, would most definitely be different, but actually, it would be highly desirable and more accurate if they were the same.</p>\n<p>I hope I have made your life more difficult and more confusing! Maybe I have asked a lot of pointless questions? Furthermore, in theory, just because a typeface does not score well (or score just as well as another typeface) does not necessarily mean it is an ineffective or bad typeface. It just means that, in theory, it may not score as well as another typeface in the same context. Nor does it mean that it would not perform well in reality. What did I say? I told you this was a difficult area!</p>\n<p>To confuse things even more, legibility expert <a href=\"https://www.microsoft.com/en-us/research/people/kevlar/\">Kevin Larson</a>, academic <a href=\"https://www.researchgate.net/profile/Richard-Hazlett\">Richard Hazlett</a>, usability expert <a href=\"https://faculty.erau.edu/Barbara.Chaparro\">Barbara Chaparro</a> and academic <a href=\"https://www.media.mit.edu/people/picard/overview/\">Rosalind Picard</a> in their paper “<a href=\"https://www.microsoft.com/en-us/research/uploads/prod/2021/06/Larson-Hazlett-Chaparro-Picard-2006-measuring-the-aesthetics-of-reading.pdf\">Measuring the aesthetics of reading</a>,” found that, when the typeface was set with no OpenType features in a normal body text paragraph (as typically found in a book), the users could read faster and understood more of the text. In other words, there were no ligatures, no small caps, no old-style figures, no real fractions, and no real superscripts and subscripts. I am not saying you should start typographically undesigning, disregarding years of best practice knowledge, but it goes to show that few things are certain in graphic communication.  </p>\n<p>Well whatever your thoughts are, in 2022 with a mass of typefaces available and 100s of years of designing and manufacturing typefaces, it is time to consider this topic, I think the time has come and we are there. This is especially true for highly legible typefaces, some kind of measure or measures, even if new typefaces got released and they only had one performance measure, or say three, this would be a start.</p>\n<h3>Acknowledgements</h3>\n<p><a href=\"https://twitter.com/almahoffmann\">Alma Hoffmann</a> (editing and feedback), <a href=\"https://www.microsoft.com/en-us/research/people/kevlar/\">Kevin Larson</a> (feedback), <a href=\"http://graphicdesign-research.com\">Karel van der Waarde</a> (extensive comments and feedback), and <a href=\"https://spiekermann.com\">Erik Spiekermann</a> (feedback).</p>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/05/micro-typography-space-kern-punctuation-marks-symbols/\">Micro-Typography: How To Space And Kern Punctuation Marks And Other Symbols</a>,” Thomas Bohm</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2018/06/reference-guide-typography-mobile-web-design/\">A Reference Guide For Typography In Mobile Web Design</a>,” Suzanne Scacca</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2019/07/gorgeous-free-open-source-typefaces/\">7 Gorgeous Free And Open-Source Typefaces And When To Use Them</a>,” Noemi Stauffer</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2013/12/freebie-exo-2-0-geometric-sans-serif-font/\">Exo 2.0, A Contemporary Geometric Sans Serif Font (Freebie)</a>,” Vitaly Friedman</li>\n</ul>",
      "content_text": "In the first part of this article, we saw that measuring and comparing typefaces is not a simple task. Testing it (subjectively or objectively) also depends on the context — which can be very tricky. We saw how important it is to keep the typographic design parameters and variables the same to get a more accurate result while testing different typefaces.\n Did you miss out on it? Don’t worry! Take a look at the first part of this article here so you can get all the context you need to fully enjoy it.\n\nMeasuring, comparing, and testing typefaces may guide your project decisions towards a more accessible and highly legible typeface. Let’s dive into the specifics of typeface aspects so you can get the best out of your tests. So what aspects of typefaces could we measure?\nAspects Specific To The Typeface Itself For Extended Reading Typefaces\nAscender And Descender Height In Relation To X-height\n\nValidation:There seems to be some truth in a larger x-height and medium-length ascenders and descenders being ideal.\nDescription:The most efficient typefaces with the best ratio of x-height and cap-height seem to be Wayfinding Sans Pro and Johnston Underground with an x-height between 67% to 69% of the cap height. Learn more about it in Ralf Hermann’s (director of Typography.Guru paper, “Does A Large X-Height Make Fonts More Legible?.”\nMeasurement:Millimeters.\nMeasure quality type:Strong (objective).\n\nAesthetic Quality In Relation To Other Similar Typefaces\n\nValidation:There would probably be other typefaces that the typeface would be similar to or would fit with, so how well does it compare?\nDescription:Expert review or opinion.\nMeasurement:Not good, okay, very good.\nMeasure quality type:Weak (subjective).\n\nAesthetic Quality In Relation To Historical Revival Or Similarity\n\nValidation:There would probably be other typefaces that the typeface would be similar to or fit with. Therefore, how well does it perform when compared to other typefaces that are considered to be historically well done or have been revived well?\nDescription:Expert review or opinion.\nMeasurement:Not good, okay, very good.\nMeasure quality type:Weak (subjective).\n\nCharacter, Symbol, And Language Support\n\nValidation:To find out how usable the typeface is, for different characters, symbols, languages, and information types.\nDescription:We know character and symbol support, like for maths and different languages, is desirable and needed.\nMeasurement:Numerical score or tick list against features and languages.\nMeasure quality type:Strong (objective).  \n\nKerning\n\nValidation:To find out how well the typeface has been kerned — because kerning leads to better and more legible typography.\nDescription:A kerning test based on the example below, from Veronika Burian and José Scaglione’s — directors of the font foundry TypeTogether — article “Quality type: How to spot fonts worth your money.”\n\n\n\nMeasurement:Not good, okay, very good. Percentage value, maybe. Precise numerical score based on a standard test.\nMeasure quality type:Strong (objective).\n\nAccessibility (Children)\n\nValidation:We know that accessible characters and symbols lead to better, more legible, and easier-to-read typography.\nDescription:Infant characters as in my paper “Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition.”\n\n\n\nMeasurement:Numerical score based on the number of characters and symbols. Research and design effort based on not good, okay, very good.\nMeasure quality type:Strong (objective).\n\nAccessibility (Dyslexia)\n\nValidation:Dyslexic characters as in my paper “Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition” and Robert Hillier’s (typeface designer and academic) PhD “A typeface for the adult dyslexic reader.”\n\n\n\nDescription:Numerical score based on the number of characters and symbols. \nMeasurement:Research and design effort based on not good, okay, very good.\nMeasure quality type:Strong (objective).\n\nAccessibility (Vision Impairment)\n\nValidation:Visually impaired characters as in my paper “Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition.”\n\n\n\nMeasurement:Numerical score based on the number of characters and symbols.\nDescription:Research and design effort based on not good, okay, very good.\nMeasure quality type:Strong (objective).\n\nAspects Specific To The Reader/User For Extended Reading Typefaces\nComprehension\n\nValidation:To find out how much and how well information is absorbed, retained, and recalled from a typeface or different typefaces.\nDescription:This is a very difficult area to measure, and I would like to explain why:\nNot everyone will be able to recall accurately everything they know or do not know in an exam or in test questions;\nWhat people say they know, fail to communicate, and what they actually do in the real world are very different things. Just because some cannot recall something or write it in an exam paper, it does not mean they do not know it. \n\n\n\n“Many previous reading studies investigated the effect of typography on reading speed. But we know that faster speed does not always equate to better comprehension. In fact, better comprehension is often associated with slower reading speed.”— Sofie Beier (legibility expert), “Bringing together science and typography”\n\n\nMeasurement:A paragraph of text, or pages of text and information, followed by questions or set the users tasks to do based on the information.\nMeasure quality type:Weak (subjective).\n\nSpeed\n\nValidation:To find out how much, or how much more, they can read compared to what is considered normal/average from a typical typeface.\nDescription:This is another very difficult area to measure, let me explain why. I could quickly scan a single page of a book and, in theory, have read all the content in about 6 seconds (because I have scanned my eyes across all the text quickly). Although, just because I have, in theory, read (or scanned) the text, it does not necessarily mean I have understood or absorbed it. However, the result would be taken into consideration — and there would probably exist clear and strong differences in performance between comparing a script typeface (like Snell Roundhand) against a highly legible typeface (like the Unit typeface). So the Unit typeface would be much easier and quicker to read than Snell Roundhand.\nMeasurement:Eye-tracking (time, speed, and behavior) recording and data collection.\nMeasure quality type:Strong (objective).\n\nFacial Muscle Activation\n\nValidation:The zygomatic muscle activity (which controls smiling) is positively associated with positive emotional stimuli and a positive mood state.\nDescription:By placing tiny sensors over certain facial muscles, one can measure the minute changes in the muscles’ electrical activity, which reflects changes in muscle tension. Facial EMG (electromyography) studies have found that activity of the corrugator muscle (which lowers the eyebrow and is involved in producing frowns) varies inversely with the emotional valence of the presented stimuli and reports of mood state. You can see in the academics John Cacioppo, Lauren Bush, and Louis Tassinary’ paper “Microexpressive facial actions as a function of affective stimuli: Replication and extension” and in the academic Ulf Dimberg’s writing “Facial electromyography and emotional reactions.”\nMeasurement:Use an electromyography (EMG) sensor placed on top of a muscle to measure the amount of electrical current in the muscle. You get frequency readings.\nMeasure quality type:Weak (subjective) and maybe strong (objective).\n\nCharacter, Symbol, Or Word-finding Test\n\nValidation:To find out how quickly they can find information.\nDescription:The participants were asked to locate a specific character in a text with a color pen. The specific character was shown at the bottom of the sheet for easy referral. The response times were recorded. Find out more about this method in the academic Brian Sze-Hang Kwok’s paper “Legibility of medicine labels.”\nMeasurement:A numerical score of correct and incorrect.\nMeasure quality type:Strong (objective).\n\nSearching a Phrase Test\n\nValidation:To find out how quickly readers can find information.\nDescription:The participants were required to locate a phrase in the context of a medicine label. The specific phrase was shown at the bottom of the sheet for easy referral. The response times were recorded. Find more about this method in the academic Brian Sze-Hang Kwok’s paper “Legibility of medicine labels.”\nMeasurement:A numerical score of correct and incorrect.\nMeasure quality type:Strong (objective).\n\nRead-aloud\n\nValidation:To find out if there are any issues or obvious difficulties between different typefaces, or different classifications of typefaces, and maybe weights (like thin, extra bold, italic or condensed).\nDescription:The subject producing a reader protocol is requested to read the text aloud and to immediately express any thoughts about the document. More about this method can be seen in the academics Leo Lentz’s and Henk Pander Maat’s paper “Reading aloud and the delay of feedback.”\nMeasurement:Notes and recordings based on not good, okay, very good, and notes of specific problems.\nMeasure quality type:Weak (subjective).\n\nThink-aloud\n\nValidation:To find out if there are any issues and if any issues can be highlighted or discovered.\nDescription:Get people to perform certain specific tasks while using the document to vocalize the person’s thinking. From academics Leo Lentz’s and Henk Pandar Maat’s paper “Reading aloud and the delay of feedback.”\nMeasurement:Notes and recording based on not good, okay, very good, and notes of specific problems.\nMeasure quality type:Weak (subjective).\n\nAt-a-glance\n\nValidation:To find out if they can correctly identify a word, letter, or symbol and not misread it as another word, letter, or symbol in a quick response environment.\nDescription:Typefaces were individually sized to a height of 4 mm using the letter “H” as the reference. Participants viewed the monitor at a distance of approximately 70 cm. Participants’ distance to the screen was measured at the start of the session using a tape measure. Each individual trial followed the same sequence of presentation: a large fixation rectangle signifying the start of the new trial (400 ms), a masking stimulus composed of non-letter characters (200 ms), the stimulus of interest (variable timing, according to staircase rules as described above), a second masking stimulus of non-letter characters (200 ms), and then a response prompt (up to 5000ms). You can see more about this method in the paper “The great typography bake-off: comparing legibility at-a-glance,” by Ben Sawyer’s (academic), Jonathan Dobres (academic), Nadine Chahine (typeface designer), and academic Bryan Reimer’s.\nMeasurement:A numerical score based on the number of characters or symbols. The time measure is also checked.\nMeasure quality type:Strong (objective).\n\nQuestionnaire\n\nValidation:People’s opinions, preferences, thoughts, concerns, views, likes, and dislikes.\nDescription:Question asking, interviews, and real-time observations.\nMeasurement:Notes and recordings.\nMeasure quality type:Weak (subjective).\n\nThe Radner Reading Charts\n\nValidation:Test the person’s vision accuracy and acuity with a typeface.\nDescription:The Radner reading chart is a highly standardized multilingual reading test system. The result of the collaboration is a standardized, valid, and reliable reading test system available in numerous languages. The reading chart consists of sentence optotypes, which are optimized reading test items (standardized by construction), and statistical selection. Sentence optotypes consist of short sentences that are highly comparable in terms of the number of words (14 words), the word length, the position of words, the lexical difficulty, and the syntactic complexity. Language-specific characteristics were considered, as were the number of letters and syllables per word, line, and sentence. Get to know more from the legibility experts Sofie Beier and Kevin Larson’s paper “How does typeface familiarity affect reading performance and reader preference?”\n\n\n\nMeasurement:Correct or incorrect response. Note the point of failure or incapability to proceed anymore.\nMeasure quality type:Strong (objective).\n\nLegibility (Misrecognition)\n\nValidation:To find out if they can correctly identify a letter, number, word, or symbol and not misread it as another letter, word, or symbol.\nDescription:As in my paper, “Letter and symbol misrecognition in highly legible typefaces for general, children, dyslexic, visually impaired and aging readers — 2019 fourth edition.”\nMeasurement:Score for correct or incorrect identification. Time measure check also.\nMeasure quality type:Strong (objective).\n\nLegibility (At a Very Small Typeface Size)\n\nValidation:To push a person’s eyesight to the maximum and see what happens at a very small size.\nDescription:At small sizes, less than 8pt, for instance.\nMeasurement:x-height size measurement preferred over pt size. Also, maybe a rating of difficulty and time to read like: easy, reasonable, and hard.\nMeasure quality type:Strong (objective).\n\nLegibility (Distance)\n\nValidation:To see when a letter, symbol, or a word becomes unreadable and how far away it can be read or not recognized anymore.\nDescription:In Robert Waller’s (information designer) article “Comparing typefaces for airport signs” he says that you could use a screen, physical sign, or printed paper to display a word, letter, or symbol. A person needs to stand far away and then get closer to the display until they can correctly identify the word, letter, or symbol. If a screen is being used, the person can also be at a fixed distance from the screen and then you can make the word, letter, or symbol bigger on the screen, until they can correctly identify it. This would give us a legibility score and distance measurement in relation to the correct identification. The first presented character was the letter “d.” As identified in Miles Tinker’s book Legibility of print, this character is one of the most easily recognizable letters. The purpose of this first exposure was to locate the individual vision threshold. The participant was placed at a distance of 10 meters from the screen and asked to move slowly forward until the presented letter was at the threshold of being identifiable. This was the distance at which the individual participant was tested — varying from 4.5–9 meters (with an average of 6 meters) from the screen. You can read more about this method in Sofie Beier (legibility expert) and Kevin Larson’s (legibility expert) paper “Design improvements for frequently misrecognised letters.”\nMeasurement:Measurement in mm, cm or m.\nMeasure quality type:Strong (objective).\n\nLegibility (Rotated Information)\n\nValidation:To push a typeface and person’s eyesight to the maximum and see what happens at these extreme angles. Also, these angles are common in VR (virtual reality) software and products.\nDescription:At an angle: -45 degrees horizontally left and +45 degrees horizontally right, -45 degrees vertically up and +45 degrees vertically down.\n\n\n\nMeasurement:Legibility test (character, symbol, word) test.\nMeasure quality type:Strong (objective).\n\nLegibility (Degrading, Distortion, and Blurring)\n\nValidation:To push a typeface and person’s eyesight to the maximum and see what happens under these extreme conditions.\nDescription:Legibility degrading test as in Ralf Hermann’s (director of Typography.Guru) paper “Designing the ultimate wayfinding typeface.”\n\n\n\nMeasurement:The score for correct or incorrect identification. Time measure was also checked.\nMeasure quality type:Strong (objective).\n\nAppeal (Typeface Fitting Subject and Content)\n\nValidation:How well does it fit and suit the content?\nDescription:An appeal concerning the content, as an example, for content on gardening, when a slightly more organic, chiseled, and wavy typeface might communicate and fit the content better.\nMeasurement:Score based not good, okay, very good.\nMeasure quality type:Strong (objective).\n\nAppeal (User Feedback and Responses In Relation to Other Typefaces They May Know)\n\nValidation:How well does it fit and suit the content?\nDescription:Appeal in relation to the typeface itself. What does the user say they like or dislike about this typeface in relation to other typefaces they use and know about? This method could produce interesting observations and data, albeit highly subjective.\nMeasurement:Notes and recordings.\nMeasure quality type:Weak (subjective).\n\nFixation Duration\n\nValidation:How quick or lengthy does the eye have to fixate to understand the information?\nDescription:Fixation duration is a period of time when the focus of the participant’s gaze is relatively still on an area and taking in information about that which is looked at, as in the academics Ivan Burmistrov, Tatiana Zlokazova, Iuliia Ishmuratova, and Maria Semenova’s paper “Legibility of light and ultra-light fonts: eyetracking study.”\nMeasurement:Milliseconds (ms).\nMeasure quality type:Weak (subjective) and maybe strong (objective).\n\nSaccadic Amplitude\n\nValidation:To find out what behavior, movements, or patterns are happening.\nDescription:Saccadic amplitudes are a quick simultaneous movement of both eyes, like when you are reading a line of text. In this method, we monitor what happens with saccadic eye movements when reading, as in the academics Ivan Burmistrov, Tatiana Zlokazova, Iuliia Ishmuratova, and Maria Semenova’s paper “Legibility of light and ultra-light fonts: eyetracking study.”\nMeasurement:Degrees (°).\nMeasure quality type:Weak (subjective) and maybe strong (objective).\n\nAspects Specific to The Users’ Environment and Situation\nLight\n\nValidation:To see how a typeface performs in lighting conditions and see how people respond in the lighting conditions.\nDescription:Low light or good light condition and see how it affects the information and performance.\nMeasurement:The score for correct or incorrect identification. Time measure is also checked. The light strength is measured in lumens (lm).\nMeasure quality type:Strong (objective).\n\nStress\n\nValidation:To find out how typefaces would work better or worse, under stress and high-pressure situations, with quick stressed eye movements.\nDescription:Setup situations such as: booking a ticket and going through an airport, doing tasks after they have finished a 6-hour working day, or reading or doing tasks late at night — when it is more likely that they will be more tired.\nMeasurement:Accuracy and efficiency of users’ actions. Maybe blood pressure or heart rate testing.\nMeasure quality type:Weak (subjective).\n\nOpenType variable fonts and real-time responsive features\n\nValidation:Whereas a single non-variable font does not essentially change or alter itself, variable fonts can, and can be given settings to instruct them to work in different technological environments.\n\nNotes and Description:Variable fonts have the ability to alter and modify themselves in real-time to different screen sizes, media query responses, user customisations and environments. Variable fonts can utilise different aspects such as: weights, width, italic, slant, optical size and grade, to change and adapt, to help them work better in different and changing situations.  \n\nMeasurement:Assessment (legibility, readability, comprehension, user preference) in relation to the changing circumstances. [Many measurement types in this area, too many to mention, but see other areas in this paper for aspects applyable.]\n\nMeasure quality type:Weak (subjective) and maybe strong (objective).\n\n\nTime Pressure\n\nValidation:To find out how typefaces would work better (or worse) under time pressure and quick stressed eye movements.\nDescription:Setup situations like finding information within a certain timeframe, booking a taxi very quickly, or finding something in a telephone directory.\nMeasurement:Time measuring. Maybe a blood pressure test.\nMeasure quality type:Weak (subjective).\n\nIn Diverse Situations (Driving In a Car At Distance On a Road Sign Or Airport Sign)\n\nValidation:To push a person’s vision (length of view) and agility and see how typefaces respond.\nDescription:To test the extremes of people’s vision and ability, like driving in a car and reading a road sign where distance and orientation are factors. How does weather affect information and communication?\nMeasurement:In meters, centimeters, or millimeters.\nMeasure quality type:Strong (objective).\n\nAspects Specific to Technology for Extended Reading Typefaces\nRange of Weights\n\nValidation:It is always appreciated and helpful to use a typeface with a range of weights.\nNotes and description of measuring type:Range of weights offered.\nMeasurement:Numerical score in the amount of weights.\nMeasure quality type:Strong (objective).\n\nOn-screen Rendering and Hinting\n\nValidation:Bad hinting and screen rendering leads to hard-to-read on-screen typography and illegibility.\nDescription:Analyze by taking a screengrab (then zooming-in), or by using a zoom-in device (magnifying glass), then analyzing the hinting.\nMeasurement:A score based on not good, okay, and very good. Also, use 3 different types of screens (low-resolution, HD and 4k+).\nMeasure quality type:Strong (objective).\n\nFont File Size\n\nValidation:Larger font sizes can take up more bandwidth, especially across larger websites, and be slower to load initially in a webpage’s first content paint.\nDescription:Look at the file size of the font.\nMeasurement:The file size (kb) would give a score, although this measure is certainly not very useful, as there is no escape from a typeface with a large symbol and language support, which cannot really be made any smaller in file size.\nMeasure quality type:Strong (objective).\n\nOpenType Features/Variable?\n\nValidation:If a typeface has more desirable features (such as small caps, different number styles, ligatures, and so on), it makes the typography better and typographically more usable.\nDescription:A typeface is better if it has the features required by users and information.\nMeasurement:Numerical score or tick list of features.\nMeasure quality type:Strong (objective).\n\nSpecific Typographic Design Variables Affecting Performance\nTypographic Design\n\nValidation:They affect typeface and typographic communication.\nDescription:Tracking, leading, kerning, typeface weight, line length, word spacing, condensed weight, typeface size, typeface color, OpenType features.\nMeasurement:Various possible (must be controlled and precise, as mentioned in Ralf Hermann (director of Typography.Guru) paper “What makes letters legible?”).\nMeasure quality type:Weak (subjective) hard to measure accurately.\n\nWhat Would Typeface Performance Measurements, Results, and Scores Potentially Look Like?\nA data table, infographic, or some kind of graph could be used?\nScientists And Designers Needing to Work Better Together\nSofie Beier (legibility expert) in her paper “Letterform research: An academic orphan” touches upon the different issues and constraints designers and academics have faced in the past:\n“To produce findings that are relevant for the practicing designer, scientists benefit from consulting designers in the development of the experiments. While designers can contribute with design skills, they cannot always contribute with scientific rigor. Hence, researchers will profit from adopting a methodological approach that ensures both control of critical typographical variables and scientific validation. An interdisciplinary collaboration where scientists provide valid test methods and analysis and designers identify relevant research questions and develop test materials, will enable a project to reach more informed findings than what the two fields would be able to produce in isolation.”— Sofie Beier in Letterform Research: An Academic Orphan\n\n\nTo recap, designers have tended to produce information lacking scientific rigor in the past. In contrast, scientists produce information that is hard to understand — with equations and lacks practical application. So both sides, whichever you are on, have their weaknesses and lack expertise.\nAm I Making Typeface Designers’ Job Harder?\nIt is not my aim to make a typeface designer’s job any harder. It is commonly known that any typeface takes at least one year of hard work. The typeface designer Martin Majoor states that he designed the Questa typeface at irregular intervals over the course of 7 years. I have nothing but respect for typeface designers and the amazingly hard job they do. In fact, I have so much respect for the time and difficulty of designing a typeface, that I refuse even to try to attempt the task.\nWhat Now?\n\nResearch into what is legible and what characteristics make letters and symbols more legible, go to the library and research online. For example, the academic journal Visible Language has all journals available for free on their website. There is some incredible research and work done, that was done more than 50 years ago; \nSpeak with people and speak with other typeface designers; \nAvoid designing and releasing typefaces done, expressed, and designed on your own;\nTest typefaces, try to do the test accurately and try to compare what you are designing with another typeface, to see where there are weaknesses and strengths in testing results with people and in different contexts and environments. How is it working (or not working) better than another typeface and in different contexts and environments?\nTest typefaces with different categories of people in different contexts and environments;\nMake your findings, design intentions, and tactical fixes available for free, as part of the typeface release, as a publication, or as some kind of central public list (like on GitHub), so we can start better and get to where we need to be quicker;\nMaybe a completely new typeface might not be as good of an idea as you think. Maybe extension, improvement, or modification to an existing typeface might be smarter. New is not automatically better.\n\nConclusions\nDo we, as users and designers, really need to assess typefaces and find out how they perform? Is it necessary? Well, whatever your thoughts are, in 2022, with a mass of typefaces available and 100s of years of designing and manufacturing typefaces, it is time to consider this topic. I think the time has come, and we are there. This is especially true for highly legible typefaces, some kind of measure or measures — even if new typefaces got released and they only had one performance measure (or say three), that would be a start.  \nWe may also need some cross-measurable tests that are used, so everyone tests against the same (or as near as) thing. Because, as previously mentioned, if someone tests their typeface against a sans serif (like Arial), then another person tests their typeface using another typeface (like Helvetica), the data will not be cross-comparable. And furthermore, what typographic design and typesetting values the two people use, would most definitely be different, but actually, it would be highly desirable and more accurate if they were the same.\nI hope I have made your life more difficult and more confusing! Maybe I have asked a lot of pointless questions? Furthermore, in theory, just because a typeface does not score well (or score just as well as another typeface) does not necessarily mean it is an ineffective or bad typeface. It just means that, in theory, it may not score as well as another typeface in the same context. Nor does it mean that it would not perform well in reality. What did I say? I told you this was a difficult area!\nTo confuse things even more, legibility expert Kevin Larson, academic Richard Hazlett, usability expert Barbara Chaparro and academic Rosalind Picard in their paper “Measuring the aesthetics of reading,” found that, when the typeface was set with no OpenType features in a normal body text paragraph (as typically found in a book), the users could read faster and understood more of the text. In other words, there were no ligatures, no small caps, no old-style figures, no real fractions, and no real superscripts and subscripts. I am not saying you should start typographically undesigning, disregarding years of best practice knowledge, but it goes to show that few things are certain in graphic communication.  \nWell whatever your thoughts are, in 2022 with a mass of typefaces available and 100s of years of designing and manufacturing typefaces, it is time to consider this topic, I think the time has come and we are there. This is especially true for highly legible typefaces, some kind of measure or measures, even if new typefaces got released and they only had one performance measure, or say three, this would be a start.\nAcknowledgements\nAlma Hoffmann (editing and feedback), Kevin Larson (feedback), Karel van der Waarde (extensive comments and feedback), and Erik Spiekermann (feedback).\nFurther Reading on Smashing Magazine\n\n“Micro-Typography: How To Space And Kern Punctuation Marks And Other Symbols,” Thomas Bohm\n“A Reference Guide For Typography In Mobile Web Design,” Suzanne Scacca\n“7 Gorgeous Free And Open-Source Typefaces And When To Use Them,” Noemi Stauffer\n“Exo 2.0, A Contemporary Geometric Sans Serif Font (Freebie),” Vitaly Friedman\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/22bde778-9f2e-45d3-97cd-ae5eedf4d0c0/measuring-performance-typaces-users-part2-card.jpg",
      "date_published": "2022-06-10T08:00:00.000Z",
      "date_modified": "2022-06-10T08:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/future-frontend-build-tools/",
      "url": "https://smashingmagazine.com/2022/06/future-frontend-build-tools/",
      "title": "The Future Of Frontend Build Tools",
      "summary": "This article explores the evolution and the future of frontend tooling, presenting a new set of tools featuring a change in paradigm, platform, or both.",
      "content_html": "<p>Frontend build tooling is crucial to the workflow of the modern frontend developer for a host of reasons classified under improved developer and user experiences. From the developer’s perspective, frontend tooling gives us: the ability to author modules, a dev server for local development, Hot Module Replacement (HMR) for a shorter feedback loop in development mode, the ability to target legacy browsers with polyfills, processing a host of filetypes apart from JavaScript, the list goes on. </p>\n<p>As a result, users can enjoy more capable and feature-rich applications that remain performant through techniques like code-splitting, caching, prefetching, and other resource optimization techniques — with some applications that are even able to work offline.</p>\n<p>Frontend tooling gives us so much today that it is hard to imagine that there was a time when it was not even needed at all. A trip down memory lane could help us understand how we got here.</p>\nThe Past\n<p>Before frontend applications became as complex as they are today, all JavaScript was used for was to add basic interactivity to otherwise simple HTML documents — similar to the way Adobe’s Flash was used. </p>\n<p>There were no complex “JavaScript-heavy” applications, so, no need for any tooling to make authoring and shipping JavaScript better, but that would not remain the case. </p>\n<p>As time went on and we started to create more involved user experiences on the web, we shifted from more static web pages to highly dynamic web applications serving user-specific data. These applications required more JavaScript than their traditional counterparts, and the limits of working with JavaScript became a lot more apparent.</p>\n<p>There are two major ways to load JavaScript in the browser. One is with a script tag referencing a JavaScript file, and the other is to write your JavaScript directly in the HTML inside script tags.</p>\n<pre><code>&lt;script src=\"my-javascript-file.js\"&gt;&lt;/script&gt;\n\n&lt;script&gt;\n    var a = 1;\n    var b = 2;\n\n    var result = a + b;\n&lt;/script&gt;\n</code></pre>\n\n<p>This limitation on loading JavaScript becomes a bottleneck when you have lots of JavaScript to load. There are browser limitations to loading many JavaScript files concurrently and maintainability issues with having one huge JavaScript file (like file size, scoping issues, namespace collision, and so on). </p>\n<p>We came up with solutions like Immediately Invoked Function Expressions (IIFEs) to help with encapsulation and some of the scoping issues after which, we gained the ability to write our JavaScript in many different files. Then, we needed a way for these many files to be combined into\none file to be served in the browser</p>\nThe present\n<p>Being able to split our JavaScript into different files with IIFEs, it seemed like all we needed was a way to concatenate these files and ship a single file to the browser. This need saw the rise of tools like Gulp, Grunt, Brocolli, and so forth. However, we soon realized that our thinking might have been a little too simplistic. </p>\n<p>As our applications got even more complex, matters like lack of dead code elimination, full rebuilds for small changes, and other performance issues made us realize that we needed something more than just concatenation. That gave rise to the more modern bundlers like Webpack, Parcel, and others.</p>\n<p>With the pace of advancement in the frontend space not slowing down, we have started to observe gaps and issues with the modern build tools.  </p>\n<p>Some of the major limitations include:  </p>\n<ul>\n<li>Complex setup and configuration of some of these existing bundlers;</li>\n<li>Increase in build times as applications get larger;</li>\n<li>Suboptimal performance in development mode.</li>\n</ul>\n<p>The rate at which things change in the JavaScript ecosystem is often fatiguing, but the upside is that the community quickly identifies problems and gets to work on potential solutions. With our sights set on improving the performance of frontend tooling, a new generation of build tools is being developed.</p>\nThe Future\n<p>The limitations of the mainstream build tools of the day have led to several attempts to reimagine what a frontend build tool should be and do, and there are quite a few new build tools in the wild today. </p>\n<p>Closer inspection will reveal that these new tools seem to be taking two major approaches to solving the problem (not necessarily mutually exclusive): a change in paradigm and a change in platform — both powered by new advancements in the web development ecosystem. </p>\nA Replatform\n<p>Frontend build tools have traditionally been built with JavaScript and, more recently, Typescript. This made sense, as JavaScript is the language of the web, and authoring build tools for the web in the same language makes it easier for more people to contribute to the effort and build a community around these tools. Still, there are inherent problems with this approach. </p>\n<p>As a high-level language, JavaScript cannot reach native levels of performance. This means that tools built on top of this platform have a cap on how performant they can be. So, to break out of this limitation, newer build tools are being built on lower-level, inherently more performant languages like Rust. </p>\n<p>Languages like Rust and Go have become popular options for authoring the next generation of build tools with a strong emphasis on performance. Rust, in particular, is popular not only for its performance but also for its impressive developer experience — voted the \"most-loved\" programming language six years in a row in the <a href=\"https://insights.stackoverflow.com/survey/2021#section-most-loved-dreaded-and-wanted-programming-scripting-and-markup-languages\">Stack Overflow Developer Survey</a>. </p>\n<p>In speaking about the decision to build <a href=\"https://rome.tools/\">Rome</a> (the build tool and not the city) with Rust, Jamie Kyle says:</p>\n<blockquote>“Many others have communicated the performance, memory, and safety benefits of Rust before us — let’s just say everyone who has ever said Rust is good is correct. However, our biggest concern was our own productivity.\n\n[...]<br />\nAfter some prototyping, however, we quickly realized we might actually be more productive in Rust”<br /><br />— <a href=\"https://jamie.build/\">Jamie Kyle</a> in <a href=\"https://rome.tools/blog/2021/09/21/rome-will-be-rewritten-in-rust\">Rome Will Be Written In Rust</a></blockquote>\n\n<p>The project <a href=\"https://swc.rs/\">SWC</a> is at the forefront of this idea of using Rust for frontend build tools. It is now powering projects like Next.js’s new compiler, Deno, Parcel, and others — with a performance that is many orders of magnitude above other existing build tools. </p>\n<p>Projects like SWC prove that with a change of the underlying platform, the performance of build tools can be significantly improved.</p>\nA paradigm shift\n<p>The way a typical frontend build pipeline works today is you author JavaScript modules in many different files, run a command, the build tool picks up these modules, bundles them into a single module, converts them to a format understood by browsers, and serves that file in the browser.</p>\n<p>To improve the performance in development mode, a lot of the optimizations that would take more time to complete are left out and are, instead run when we are bundling our production application. This ensures that it takes as little time as possible to spin up a dev server, run our application in development mode and get productive.</p>\n<p>The bundling process still takes quite some time, though and as a project grows, build times (even in development) only get longer and longer. Wouldn’t it be great if we could somehow skip bundling altogether while still being able to write modules as usual and have the browser understand how to work with them? A new set of build tools is taking this approach, known as Unbundled Development.</p>\n<p>Unbundled development is great. It solves a major issue with existing build tools: they often need to rebuild entire sections of your application for even trivial code changes, and build times get longer as the application grows. We lose the rapid feedback — essential for a pleasant development experience. </p>\n<p>One might wonder, if unbundled development is so great, why isn’t it the norm today? There are two major reasons why unbundled development is only starting to gain traction: browser compatibility for cutting edge features and processing node module imports.</p>\n<h3>1. Browser compatibility for cutting edge features</h3>\n<p>Unbundled Development is powered by ES Modules (ESM), which brings a standardized module system to JavaScript — supported natively across multiple runtimes, including the browser. With this new capability, we can mark our script tags as modules and can consequently use the <code>import</code> and <code>export</code> keywords that we are all familiar with;</p>\n<pre><code>&lt;script type=\"module\" src=\"main.js\"&gt;&lt;/script&gt;\n\n&lt;script type=\"module\"&gt;\n  /** JavaScript module code goes here */\n&lt;/script&gt;\n</code></pre>\n\n<p>ES modules have been around for quite some time. Still, we are only able to start taking advantage of it for things like unbundled development, mostly because of how long its standardization took across all the players in the web ecosystem. </p>\n<p>In her article about ES Modules, on Mozilla Hacks, Lin Clark says:</p>\n<blockquote>“ES modules bring an official, standardized module system to JavaScript. It took a while to get here, though — nearly 10 years of standardization work.”<br /><br />— <a href=\"https://twitter.com/linclark\">Lin Clark</a> in <a href=\"https://hacks.mozilla.org/2018/03/es-modules-a-cartoon-deep-dive/\">ES Modules: A Cartoon Deep-Dive</a></blockquote>\n\n<p>The issue of browser support or lack thereof has plagued frontend development for a long time. This is why we have vendor prefixing our CSS, sometimes the reason for polyfills, why we spend time ensuring cross-platform support for our web applications, and why it sometimes takes quite some time before we can take advantage of the latest and greatest web features in our day to day work. </p>\n<p>Try to visit a <a href=\"https://stackblitz.com/\">StackBlitz</a> project using Safari, and you will be greeted with the following screen communicating the lack of support for WebContainers in non-Chromium-based browsers.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/93ed49d1-0e83-489e-be0d-539d9ee36dc6/1-future-frontend-tooling.jpg\" /></p>\n<p>The pace of feature adoption is not the same across browser providers, and there are often variations in how different vendors implement certain features. However, the future looks bright with initiatives like <a href=\"https://web.dev/interop-2022/\">Interop 2022</a>.</p>\n<h3>2. Processing node module imports</h3>\n<p>Most, if not all, frontend applications we write today depend on external libraries from NPM. For a typical react application, We would import react at the top of our component files like so:</p>\n<pre><code>import React from 'react'\n\n/** The rest of your component code */\n</code></pre>\n\n<p>Trying to load this directly in the browser, as we would need to do for unbundled development, will lead to two issues. First, the browser does not know how to resolve the path to find <code>react</code> and secondly, the react library is published as a Common JS (CJS) module — which cannot run natively in the browser without some pre-processing.</p>\n<p>The latter is the bigger issue here, as it is possible, and even trivial, to simply replace our node module imports with relative paths to specific files. Still, the fact that most NPM packages are written in a module format more suitable for Node JS than the browser requires that our NPM dependencies are treated specially to facilitate unbundled development. </p>\n<p><a href=\"https://www.snowpack.dev/\">Snowpack</a>, in particular, handles this by processing application dependencies into separate Javascript files that can then be used directly in the browser. More on how Snowpack does this can be found <a href=\"https://www.snowpack.dev/concepts/how-snowpack-works#using-npm-dependencies\">here</a>.</p>\n<p>With ES Modules now being mainstream in most modern browsers, and clever workarounds for NPM dependencies, build tools like <a href=\"https://vitejs.dev/\">Vite</a> and <a href=\"https://www.snowpack.dev/\">Snowpack</a> can offer the option of unbundled development with drastically improved performance, snappy builds, besides super fast HMR.</p>\nFinal Thoughts\n<p>Frontend development has come a long way, and our needs are constantly evolving and increasing in complexity. Build tools are an essential part of how we build frontend applications, and existing tools are falling short of the mark sparking the development of new tools that reimagine how build tools should be designed.</p>\n<p>With a huge focus on performance, ease of use, and less complex configuration, the next generation of build tools are poised to power ambitious frontend applications for some time to come.</p>\n<p>Are you excited about the recent developments in this space? Let me know in the comments what you think about the upcoming innovations and the current landscape.</p>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/11/maintain-large-nextjs-application/\">How To Maintain A Large Next.js Application</a>,” Nirmalya Ghosh </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/06/breaking-down-bulky-builds-netlify-nextjs/\">Breaking Down Bulky Builds With Netlify And Next.js</a>,” Átila Fassina</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/06/getting-started-webpack/\">Getting Started With Webpack</a>,” Nwani Victory</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/whats-that-dev-tool/\">What’s That (Dev) Tool?</a>,” Patrick Brosset</li>\n</ul>",
      "content_text": "Frontend build tooling is crucial to the workflow of the modern frontend developer for a host of reasons classified under improved developer and user experiences. From the developer’s perspective, frontend tooling gives us: the ability to author modules, a dev server for local development, Hot Module Replacement (HMR) for a shorter feedback loop in development mode, the ability to target legacy browsers with polyfills, processing a host of filetypes apart from JavaScript, the list goes on. \nAs a result, users can enjoy more capable and feature-rich applications that remain performant through techniques like code-splitting, caching, prefetching, and other resource optimization techniques — with some applications that are even able to work offline.\nFrontend tooling gives us so much today that it is hard to imagine that there was a time when it was not even needed at all. A trip down memory lane could help us understand how we got here.\nThe Past\nBefore frontend applications became as complex as they are today, all JavaScript was used for was to add basic interactivity to otherwise simple HTML documents — similar to the way Adobe’s Flash was used. \nThere were no complex “JavaScript-heavy” applications, so, no need for any tooling to make authoring and shipping JavaScript better, but that would not remain the case. \nAs time went on and we started to create more involved user experiences on the web, we shifted from more static web pages to highly dynamic web applications serving user-specific data. These applications required more JavaScript than their traditional counterparts, and the limits of working with JavaScript became a lot more apparent.\nThere are two major ways to load JavaScript in the browser. One is with a script tag referencing a JavaScript file, and the other is to write your JavaScript directly in the HTML inside script tags.\n<script src=\"my-javascript-file.js\"></script>\n\n<script>\n    var a = 1;\n    var b = 2;\n\n    var result = a + b;\n</script>\n\n\nThis limitation on loading JavaScript becomes a bottleneck when you have lots of JavaScript to load. There are browser limitations to loading many JavaScript files concurrently and maintainability issues with having one huge JavaScript file (like file size, scoping issues, namespace collision, and so on). \nWe came up with solutions like Immediately Invoked Function Expressions (IIFEs) to help with encapsulation and some of the scoping issues after which, we gained the ability to write our JavaScript in many different files. Then, we needed a way for these many files to be combined into\none file to be served in the browser\nThe present\nBeing able to split our JavaScript into different files with IIFEs, it seemed like all we needed was a way to concatenate these files and ship a single file to the browser. This need saw the rise of tools like Gulp, Grunt, Brocolli, and so forth. However, we soon realized that our thinking might have been a little too simplistic. \nAs our applications got even more complex, matters like lack of dead code elimination, full rebuilds for small changes, and other performance issues made us realize that we needed something more than just concatenation. That gave rise to the more modern bundlers like Webpack, Parcel, and others.\nWith the pace of advancement in the frontend space not slowing down, we have started to observe gaps and issues with the modern build tools.  \nSome of the major limitations include:  \n\nComplex setup and configuration of some of these existing bundlers;\nIncrease in build times as applications get larger;\nSuboptimal performance in development mode.\n\nThe rate at which things change in the JavaScript ecosystem is often fatiguing, but the upside is that the community quickly identifies problems and gets to work on potential solutions. With our sights set on improving the performance of frontend tooling, a new generation of build tools is being developed.\nThe Future\nThe limitations of the mainstream build tools of the day have led to several attempts to reimagine what a frontend build tool should be and do, and there are quite a few new build tools in the wild today. \nCloser inspection will reveal that these new tools seem to be taking two major approaches to solving the problem (not necessarily mutually exclusive): a change in paradigm and a change in platform — both powered by new advancements in the web development ecosystem. \nA Replatform\nFrontend build tools have traditionally been built with JavaScript and, more recently, Typescript. This made sense, as JavaScript is the language of the web, and authoring build tools for the web in the same language makes it easier for more people to contribute to the effort and build a community around these tools. Still, there are inherent problems with this approach. \nAs a high-level language, JavaScript cannot reach native levels of performance. This means that tools built on top of this platform have a cap on how performant they can be. So, to break out of this limitation, newer build tools are being built on lower-level, inherently more performant languages like Rust. \nLanguages like Rust and Go have become popular options for authoring the next generation of build tools with a strong emphasis on performance. Rust, in particular, is popular not only for its performance but also for its impressive developer experience — voted the \"most-loved\" programming language six years in a row in the Stack Overflow Developer Survey. \nIn speaking about the decision to build Rome (the build tool and not the city) with Rust, Jamie Kyle says:\n“Many others have communicated the performance, memory, and safety benefits of Rust before us — let’s just say everyone who has ever said Rust is good is correct. However, our biggest concern was our own productivity.\n\n[...]\nAfter some prototyping, however, we quickly realized we might actually be more productive in Rust”— Jamie Kyle in Rome Will Be Written In Rust\n\nThe project SWC is at the forefront of this idea of using Rust for frontend build tools. It is now powering projects like Next.js’s new compiler, Deno, Parcel, and others — with a performance that is many orders of magnitude above other existing build tools. \nProjects like SWC prove that with a change of the underlying platform, the performance of build tools can be significantly improved.\nA paradigm shift\nThe way a typical frontend build pipeline works today is you author JavaScript modules in many different files, run a command, the build tool picks up these modules, bundles them into a single module, converts them to a format understood by browsers, and serves that file in the browser.\nTo improve the performance in development mode, a lot of the optimizations that would take more time to complete are left out and are, instead run when we are bundling our production application. This ensures that it takes as little time as possible to spin up a dev server, run our application in development mode and get productive.\nThe bundling process still takes quite some time, though and as a project grows, build times (even in development) only get longer and longer. Wouldn’t it be great if we could somehow skip bundling altogether while still being able to write modules as usual and have the browser understand how to work with them? A new set of build tools is taking this approach, known as Unbundled Development.\nUnbundled development is great. It solves a major issue with existing build tools: they often need to rebuild entire sections of your application for even trivial code changes, and build times get longer as the application grows. We lose the rapid feedback — essential for a pleasant development experience. \nOne might wonder, if unbundled development is so great, why isn’t it the norm today? There are two major reasons why unbundled development is only starting to gain traction: browser compatibility for cutting edge features and processing node module imports.\n1. Browser compatibility for cutting edge features\nUnbundled Development is powered by ES Modules (ESM), which brings a standardized module system to JavaScript — supported natively across multiple runtimes, including the browser. With this new capability, we can mark our script tags as modules and can consequently use the import and export keywords that we are all familiar with;\n<script type=\"module\" src=\"main.js\"></script>\n\n<script type=\"module\">\n  /** JavaScript module code goes here */\n</script>\n\n\nES modules have been around for quite some time. Still, we are only able to start taking advantage of it for things like unbundled development, mostly because of how long its standardization took across all the players in the web ecosystem. \nIn her article about ES Modules, on Mozilla Hacks, Lin Clark says:\n“ES modules bring an official, standardized module system to JavaScript. It took a while to get here, though — nearly 10 years of standardization work.”— Lin Clark in ES Modules: A Cartoon Deep-Dive\n\nThe issue of browser support or lack thereof has plagued frontend development for a long time. This is why we have vendor prefixing our CSS, sometimes the reason for polyfills, why we spend time ensuring cross-platform support for our web applications, and why it sometimes takes quite some time before we can take advantage of the latest and greatest web features in our day to day work. \nTry to visit a StackBlitz project using Safari, and you will be greeted with the following screen communicating the lack of support for WebContainers in non-Chromium-based browsers.\n\nThe pace of feature adoption is not the same across browser providers, and there are often variations in how different vendors implement certain features. However, the future looks bright with initiatives like Interop 2022.\n2. Processing node module imports\nMost, if not all, frontend applications we write today depend on external libraries from NPM. For a typical react application, We would import react at the top of our component files like so:\nimport React from 'react'\n\n/** The rest of your component code */\n\n\nTrying to load this directly in the browser, as we would need to do for unbundled development, will lead to two issues. First, the browser does not know how to resolve the path to find react and secondly, the react library is published as a Common JS (CJS) module — which cannot run natively in the browser without some pre-processing.\nThe latter is the bigger issue here, as it is possible, and even trivial, to simply replace our node module imports with relative paths to specific files. Still, the fact that most NPM packages are written in a module format more suitable for Node JS than the browser requires that our NPM dependencies are treated specially to facilitate unbundled development. \nSnowpack, in particular, handles this by processing application dependencies into separate Javascript files that can then be used directly in the browser. More on how Snowpack does this can be found here.\nWith ES Modules now being mainstream in most modern browsers, and clever workarounds for NPM dependencies, build tools like Vite and Snowpack can offer the option of unbundled development with drastically improved performance, snappy builds, besides super fast HMR.\nFinal Thoughts\nFrontend development has come a long way, and our needs are constantly evolving and increasing in complexity. Build tools are an essential part of how we build frontend applications, and existing tools are falling short of the mark sparking the development of new tools that reimagine how build tools should be designed.\nWith a huge focus on performance, ease of use, and less complex configuration, the next generation of build tools are poised to power ambitious frontend applications for some time to come.\nAre you excited about the recent developments in this space? Let me know in the comments what you think about the upcoming innovations and the current landscape.\nFurther Reading on Smashing Magazine\n\n“How To Maintain A Large Next.js Application,” Nirmalya Ghosh \n“Breaking Down Bulky Builds With Netlify And Next.js,” Átila Fassina\n“Getting Started With Webpack,” Nwani Victory\n“What’s That (Dev) Tool?,” Patrick Brosset\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5e3cc4f1-5fa4-463b-97b6-581fd51b1ef0/future-frontend-tooling-v5-sharing-card.jpg",
      "date_published": "2022-06-09T09:00:00.000Z",
      "date_modified": "2022-06-09T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/simplify-color-palette-css-color-mix/",
      "url": "https://smashingmagazine.com/2022/06/simplify-color-palette-css-color-mix/",
      "title": "Simplify Your Color Palette With CSS Color-Mix()",
      "summary": "CSS color-mix is an experimental function that blends two colors and can be used to simplify color palettes. You can define a color palette and theme without too much effort using CSS color-mix().",
      "content_html": "<p>There’s a reason for all the new, experimental color features CSS is introducing. And there’s a reason for all the excitement they’re stirring up.</p>\n<p>Colors are hard. Defining a base color palette can be time-consuming and involve quite a few stakeholders. And that’s not even considering contextual colors, like hover, active and inactive states. Defining these values requires even more time and more attention to accessibility. This can result in a bloated palette and an even more bloated set of design tokens.</p>\n<p>It can be a lot to juggle. 🤹 </p>\n<p>While the CSS <code>color-mix()</code> function may <em>only</em> blend two colors together, could it be used to simplify color palettes and streamline contextual values across themes?</p>\nThe CSS Color-Mix() Function\n<p>The CSS <code>color-mix()</code> function is an experimental feature that is currently a part of the <a href=\"https://www.w3.org/TR/css-color-5/#colorcontrast\">Color Module 5</a>. True to its name, the function will accept any two colors, mix them together and return a little <em>color Frankenstein</em>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d689d10c-559f-4174-9ce1-01703fd73d84/1-simplify-color-palette-css-color-mix.jpg\" /></p>\n<p>For the sake of this article, let’s define how these arguments will be called while using this example.</p>\n<ul>\n<li><strong>Color Space</strong> would refer to <code>HSL</code>;</li>\n<li><strong>Base Color</strong> would refer to <code>red</code>;</li>\n<li><strong>Base Percent</strong> would refer to <code>50%</code>;</li>\n<li><strong>Blend Color</strong> would refer to <code>white</code>;</li>\n<li><strong>Blend Percent</strong>, not shown in this example, will refer to a value covered later.</li>\n</ul>\n<p>There are quite a few moving pieces here, so let’s have a quick interactive visual to simulate the base color, base percent, and blend color.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d8c91d82-c781-4f5b-9e12-dd2b0bfe59dd/3-simplify-color-palette-css-color-mix.jpg\" /></p>\n<p>Building the linear color wheel was a lot of fun and a great dive into using <code>color-mix()</code>. It often helps when experimenting with a new feature to already know what the visual outcome should be. </p>\n<p>So how does this work?</p>\n<p>First: Define the base primary colors.</p>\n<pre><code>--primary-1: #ff0;\n--primary-2: #f00;\n--primary-3: #00f;\n</code></pre>\n\n<p>Next: Mix the primary colors to create the secondary colors.</p>\n<pre><code>--secondary-1: color-mix(in srgb, var(--primary-1) 50%, var(--primary-2));\n--secondary-2: color-mix(in srgb, var(--primary-2) 50%, var(--primary-3));\n--secondary-3: color-mix(in srgb, var(--primary-3) 50%, var(--primary-1));\n</code></pre>\n\n<p>Last: Mix the primary and secondary colors to create the tertiary colors.</p>\n<pre><code>--tertiary-1: color-mix(in srgb, var(--primary-1) 50%, var(--secondary-1));\n--tertiary-2: color-mix(in srgb, var(--secondary-1) 50%, var(--primary-2));\n--tertiary-3: color-mix(in srgb, var(--primary-2) 50%, var(--secondary-2));\n--tertiary-4: color-mix(in srgb, var(--secondary-2) 50%, var(--primary-3));\n--tertiary-5: color-mix(in srgb, var(--primary-3) 50%, var(--secondary-3));\n--tertiary-6: color-mix(in srgb, var(--secondary-3) 50%, var(--primary-1));\n</code></pre>\n\n<p>Of course, when I was in art class, there was only one set of paints. So if you wanted yellow, there was only one yellow. Red? There was only one red. Blue? Well, you get the idea. </p>\n<p>But the web and CSS offer a much wider selection of colors in the way of <em>‘color spaces.’</em> Some of these color spaces may already be familiar, but there were quite a few I hadn’t used before, including <a href=\"https://css-tricks.com/new-css-color-features-preview/\">four new CSS color features</a> which are gradually gaining support.</p>\n<p>Color spaces can calculate their colors differently from one another. Newer color spaces provide wider palettes with more vivid shades to maximize the latest screen technologies — like ultra-high-definition retina displays. It means that a single color may appear differently across each color space.</p>\n<p>Knowing the CSS <code>color-mix()</code> function supports using different color spaces, let’s experiment with color spaces by replacing the use of <code>srgb</code> from the previous example with a custom property to see how the color wheel changes.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/58f26747-9e38-413a-96fd-cc6aab9ffd91/6-simplify-color-palette-css-color-mix.jpg\" /></p>\n<p>While the <a href=\"https://www.w3.org/TR/css-color-5/#color-mix\">W3 docs</a> explain the calculations behind this functionality quite well, the math is a tad beyond my abilities to explain clearly — this is art class, after all. But, as best as I can put it:</p>\n<pre><code>--math-bg: color-mix(in srgb, red 20%, white 60%);\n</code></pre>\n\n<p>In this example, the base percentage is <code>20</code> while the blend percent is <code>60</code> creating a total of <code>80</code>. This gives us, what’s called, an alpha multiplier of <code>0.8</code> where <code>1 = 100</code> and <code>0.8 = 80%</code>.</p>\n<p>To fill in the gaps, the function will multiply the base and blend percentages by this alpha multiplier to scale them up to 100% while remaining relative to their original weights.</p>\n<pre><code>20% * 100/80 = 25%\n60% * 100/80 = 75%\n\n--math-bg: color-mix(in srgb, red 25%, white 75%);\n</code></pre>\n\n<p>If the base and blend percentages total more than 100, the inverse of this approach would be taken to round down to 100. Again, the math behind the scaling of these values, along with the general mixing calculations, is beyond my depth. For those interested in digging deeper into the technicalities of <code>color-mix()</code>, I would point to <a href=\"https://www.w3.org/TR/css-color-5/#color-mix-with-alpha\">the W3 docs</a>.</p>\n<p>However, that mathematical understanding isn’t required for the below demo, where both the base and blend percentages can be adjusted to view the result.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3d4c97f9-9172-478c-8aa3-a63764bd42f0/9-simplify-color-palette-css-color-mix.jpg\" /></p>\n<p>Because the <code>--background-color</code> property is <em>technically</em> defined, the fallback won’t trigger.</p>\n<p>However, that’s not to say <code>color-mix()</code> can’t be used progressively, though. It can be paired with the <code>@supports()</code> function, but be mindful if you decide to do so. As exciting as it may be, with such limited support and potential for syntax and/or functionality changes, it may be best to hold off on mixing this little gem into an entire codebase.</p>\n<pre><code>@supports (background: color-mix(in srgb, red 50%, blue)) {\n  --background-color: color-mix(in srgb, red 50%, blue);\n}\n</code></pre>\n\n<h3>CurrentColor Is Not Supported</h3>\n<p>A powerful little piece of CSS is being able to use <code>currentColor</code> as a value, keeping styles relative to their element. Unfortunately, this relative variable cannot be used with <code>color-mix()</code>.</p>\n<pre><code>button {\n  background: color-mix(in srgb, currentColor 50%, white);\n}\n</code></pre>\n\n<p>The hope was to have ever greater control over relative colors, but unfortunately, using <code>currentColor</code> in this way will not work. While <code>color-mix()</code> can’t achieve relative colors to this degree, the new relative color syntax is also coming to CSS. Read about CSS relative color syntax with <a href=\"https://www.stefanjudis.com/notes/new-in-css-relative-colors/\">Stefan Judis</a>.</p>\nWrapping Up\n<p>While <code>color-mix()</code> may not be as powerful as something like <code>color-contrast()</code>, there is definitely a place for it in a CSS tool belt — or kitchen cabinet. Wherever.</p>\n<p>The use cases for contextual colors are intriguing, while the integration into design systems and themes (to potentially simplify color palettes while retaining great flexibility) is where I want the most to experiment with in the feature. However, those experiments are likely still a ways off due to the current browser support. </p>\n<p>Personally, combining <code>color-mix()</code> with <code>color-contrast()</code> is an area that seems particularly exciting, but without proper browser support, it will still be difficult to fully explore.</p>\n<p>Where would you first implement <code>color-mix()</code>? 🤔 </p>\n<p>Maybe it could be used as a mixin to roughly replicate the <code>lighten()</code> and <code>darken()</code> SCSS functions. Could there be greater potential in the realm of user-generated themes? Or even web-based graphic editors and tools? Maybe it could be used as a simple color format converter based on device capabilities.</p>\n<p>Nevertheless, CSS is providing the web with plenty of new and exciting ingredients. It’s only a matter of time before we start mixing up some incredible recipes.</p>\n<h3>Further Reading On Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/accessible-design-system-themes-css-color-contrast/\">Manage Accessible Design System Themes With CSS Color-Contrast()</a>,” Daniel Yuschick </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/02/recipe-good-design-system/\">A Recipe For A Good Design System</a>,” Átila Fassina</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/11/guide-modern-css-colors/\">A Guide To Modern CSS Colors With RGB, HSL, HWB, LAB And LCH</a>,” Michelle Barker</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/07/color-tools-resources/\">Color Tools And Resources</a>,” Cosima Mielke</li>\n</ul>",
      "content_text": "There’s a reason for all the new, experimental color features CSS is introducing. And there’s a reason for all the excitement they’re stirring up.\nColors are hard. Defining a base color palette can be time-consuming and involve quite a few stakeholders. And that’s not even considering contextual colors, like hover, active and inactive states. Defining these values requires even more time and more attention to accessibility. This can result in a bloated palette and an even more bloated set of design tokens.\nIt can be a lot to juggle. 🤹 \nWhile the CSS color-mix() function may only blend two colors together, could it be used to simplify color palettes and streamline contextual values across themes?\nThe CSS Color-Mix() Function\nThe CSS color-mix() function is an experimental feature that is currently a part of the Color Module 5. True to its name, the function will accept any two colors, mix them together and return a little color Frankenstein.\n\nFor the sake of this article, let’s define how these arguments will be called while using this example.\n\nColor Space would refer to HSL;\nBase Color would refer to red;\nBase Percent would refer to 50%;\nBlend Color would refer to white;\nBlend Percent, not shown in this example, will refer to a value covered later.\n\nThere are quite a few moving pieces here, so let’s have a quick interactive visual to simulate the base color, base percent, and blend color.\n\nBuilding the linear color wheel was a lot of fun and a great dive into using color-mix(). It often helps when experimenting with a new feature to already know what the visual outcome should be. \nSo how does this work?\nFirst: Define the base primary colors.\n--primary-1: #ff0;\n--primary-2: #f00;\n--primary-3: #00f;\n\n\nNext: Mix the primary colors to create the secondary colors.\n--secondary-1: color-mix(in srgb, var(--primary-1) 50%, var(--primary-2));\n--secondary-2: color-mix(in srgb, var(--primary-2) 50%, var(--primary-3));\n--secondary-3: color-mix(in srgb, var(--primary-3) 50%, var(--primary-1));\n\n\nLast: Mix the primary and secondary colors to create the tertiary colors.\n--tertiary-1: color-mix(in srgb, var(--primary-1) 50%, var(--secondary-1));\n--tertiary-2: color-mix(in srgb, var(--secondary-1) 50%, var(--primary-2));\n--tertiary-3: color-mix(in srgb, var(--primary-2) 50%, var(--secondary-2));\n--tertiary-4: color-mix(in srgb, var(--secondary-2) 50%, var(--primary-3));\n--tertiary-5: color-mix(in srgb, var(--primary-3) 50%, var(--secondary-3));\n--tertiary-6: color-mix(in srgb, var(--secondary-3) 50%, var(--primary-1));\n\n\nOf course, when I was in art class, there was only one set of paints. So if you wanted yellow, there was only one yellow. Red? There was only one red. Blue? Well, you get the idea. \nBut the web and CSS offer a much wider selection of colors in the way of ‘color spaces.’ Some of these color spaces may already be familiar, but there were quite a few I hadn’t used before, including four new CSS color features which are gradually gaining support.\nColor spaces can calculate their colors differently from one another. Newer color spaces provide wider palettes with more vivid shades to maximize the latest screen technologies — like ultra-high-definition retina displays. It means that a single color may appear differently across each color space.\nKnowing the CSS color-mix() function supports using different color spaces, let’s experiment with color spaces by replacing the use of srgb from the previous example with a custom property to see how the color wheel changes.\n\nWhile the W3 docs explain the calculations behind this functionality quite well, the math is a tad beyond my abilities to explain clearly — this is art class, after all. But, as best as I can put it:\n--math-bg: color-mix(in srgb, red 20%, white 60%);\n\n\nIn this example, the base percentage is 20 while the blend percent is 60 creating a total of 80. This gives us, what’s called, an alpha multiplier of 0.8 where 1 = 100 and 0.8 = 80%.\nTo fill in the gaps, the function will multiply the base and blend percentages by this alpha multiplier to scale them up to 100% while remaining relative to their original weights.\n20% * 100/80 = 25%\n60% * 100/80 = 75%\n\n--math-bg: color-mix(in srgb, red 25%, white 75%);\n\n\nIf the base and blend percentages total more than 100, the inverse of this approach would be taken to round down to 100. Again, the math behind the scaling of these values, along with the general mixing calculations, is beyond my depth. For those interested in digging deeper into the technicalities of color-mix(), I would point to the W3 docs.\nHowever, that mathematical understanding isn’t required for the below demo, where both the base and blend percentages can be adjusted to view the result.\n\nBecause the --background-color property is technically defined, the fallback won’t trigger.\nHowever, that’s not to say color-mix() can’t be used progressively, though. It can be paired with the @supports() function, but be mindful if you decide to do so. As exciting as it may be, with such limited support and potential for syntax and/or functionality changes, it may be best to hold off on mixing this little gem into an entire codebase.\n@supports (background: color-mix(in srgb, red 50%, blue)) {\n  --background-color: color-mix(in srgb, red 50%, blue);\n}\n\n\nCurrentColor Is Not Supported\nA powerful little piece of CSS is being able to use currentColor as a value, keeping styles relative to their element. Unfortunately, this relative variable cannot be used with color-mix().\nbutton {\n  background: color-mix(in srgb, currentColor 50%, white);\n}\n\n\nThe hope was to have ever greater control over relative colors, but unfortunately, using currentColor in this way will not work. While color-mix() can’t achieve relative colors to this degree, the new relative color syntax is also coming to CSS. Read about CSS relative color syntax with Stefan Judis.\nWrapping Up\nWhile color-mix() may not be as powerful as something like color-contrast(), there is definitely a place for it in a CSS tool belt — or kitchen cabinet. Wherever.\nThe use cases for contextual colors are intriguing, while the integration into design systems and themes (to potentially simplify color palettes while retaining great flexibility) is where I want the most to experiment with in the feature. However, those experiments are likely still a ways off due to the current browser support. \nPersonally, combining color-mix() with color-contrast() is an area that seems particularly exciting, but without proper browser support, it will still be difficult to fully explore.\nWhere would you first implement color-mix()? 🤔 \nMaybe it could be used as a mixin to roughly replicate the lighten() and darken() SCSS functions. Could there be greater potential in the realm of user-generated themes? Or even web-based graphic editors and tools? Maybe it could be used as a simple color format converter based on device capabilities.\nNevertheless, CSS is providing the web with plenty of new and exciting ingredients. It’s only a matter of time before we start mixing up some incredible recipes.\nFurther Reading On Smashing Magazine\n\n“Manage Accessible Design System Themes With CSS Color-Contrast(),” Daniel Yuschick \n“A Recipe For A Good Design System,” Átila Fassina\n“A Guide To Modern CSS Colors With RGB, HSL, HWB, LAB And LCH,” Michelle Barker\n“Color Tools And Resources,” Cosima Mielke\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/57b9844c-e3aa-48e2-9d72-3938dbf553d0/simplify-color-palette-css-color-mix-sharing-card.jpg",
      "date_published": "2022-06-08T09:00:00.000Z",
      "date_modified": "2022-06-08T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/digital-museums-digital-history/",
      "url": "https://smashingmagazine.com/2022/06/digital-museums-digital-history/",
      "title": "Digital Museums For Digital History",
      "summary": "Computer technologies have simplified the process of recording historical events, technological breakthroughs, contemporary art, and everyday life. However, the notion of digital archiving can be deceptive. Often our technical footprints are carved in sand rather than stone.",
      "content_html": "<p>Technological development is an iterative process. One might assume that any engineer has at least a rough idea of how we got from the first wheel to self-driving cars or from the abacus to fintech applications, but this is a risky thing to take for granted. Even digital heritage needs museums to be preserved. Without them, the history of the Internet and the evolution of computers and software could be lost. </p>\n<p>Artefacts from the electronic era, together with information stored on diskettes, CDs, and DVDs, as well as magnetic or punched tapes, will soon disappear — much more quickly than canvas, paper, parchment or papyrus. Computer hardware loses its value quickly, and obsolete equipment is discarded. Entire generations of hardware that played an integral role in technological development and had an enormous impact on our society are destroyed. </p>\n<p>The desire to preserve these assets is what fueled our own efforts with the <a href=\"https://museum.dataart.com/en\">DataArt IT Museum</a> — digital heritage preserved digitally for anyone and everyone to see, hear, and watch. In this article, we explore the evolution of the museum, how recent innovations informed our own approach, and what you can do to help preserve IT history.</p>\nRise Of The Museum\n<p>The idea of a public museum is relatively new, dating to the seventeenth century, and fundamentally differs from private collections. Beginning with the <a href=\"https://kunstmuseumbasel.ch/\">Kunstmuseum Basel</a> (founded in 1661) and <a href=\"https://www.ashmolean.org/\">Oxford’s Ashmolean Museum</a> (1683), university and municipal chambers of curiosities were intended to be not just an attraction but an introduction to natural diversity or a brief history of human thought. With the rise of industrial exhibitions in the nineteenth century, this idea was taken to a new level.</p>\n<p>The Crystal Palace Exhibition held in London in 1851 showcased the achievements of the industrial revolution and established a tradition of craftsmanship museums. After the exhibition finished, many of the displays became part of the founding collections of the <a href=\"https://www.vam.ac.uk/\">Victoria and Albert Museum</a> and <a href=\"https://www.sciencemuseum.org.uk/home\">London’s Science Museum</a>. Similarly, exhibits from the 1873 Vienna World’s Fair formed the core of <a href=\"https://www.mak.at/en\">Vienna’s Museum of Applied Arts</a>. The 1881 International Exposition of Electricity served as an inspiration for Munich’s <a href=\"https://www.deutsches-museum.de/en\">Deutsches Museum</a>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/91837752-4046-4037-851f-b89a6229056f/6-digital-museums-for-digital-history.jpg\" /></p>\n<p>A similar trend was witnessed in the United States. <a href=\"https://www.si.edu/\">The Smithsonian Institution</a> owes much to the Centennial International Exhibition of 1876 held in Philadelphia, while Chicago’s <a href=\"https://www.scienceandindustrymuseum.org.uk/\">Science and Industry Museum</a> opened following the World’s Columbian Exposition in 1893. The scientist George Brown Goode, who oversaw many early exhibitions at the Smithsonian, believed that <strong>museums should serve as a vehicle for adult education, reminding people of the value of civilization</strong>. They should, in his own words, “<a href=\"https://www.jstor.org/stable/24450411\">be a house full of ideas</a>.”</p>\n<p>Machinery, unique items made by the best craftsmen, mass-produced goods, and even the pavilions themselves formed the core of future technical museum collections. These museums inspired engineers, just as art galleries inspire new generations of artists.</p>\nThe Museum As A Data Bank\n<p>Although a boon for creativity and opportunities to share knowledge accumulated in industrial (and art) museums was (and to an extent, remains) limited because physical presence was necessary. A tantalizing possibility of digital collections is that they can be viewed anywhere by anyone. </p>\n<p>The first digitization projects were started in the 1960s, and in 1967 the <a href=\"https://www.metmuseum.org/\">Metropolitan Museum of Art</a> initiated the <a href=\"https://mcn.edu/\">Museum Computer Network (MCN)</a>. In the beginning, it included 15 museums, and the number of participants grew rapidly. Now, the MCN’s stated mission is “to grow the digital capacity of museum professionals by connecting them to ideas, information, opportunities, proven practices, and each other.”</p>\n<p>Museums, archives, and libraries have experimented with digital alternatives but have principally been concerned with preserving physical objects that could be damaged over time. Digital copies have been available to a relatively small number of scholars. In 1991, the American Association of Museums named <a href=\"https://www.theworldofcdi.com/cd-i_encyclopedia/treasures-of-the-smithsonian/\">Treasures of the Smithsonian</a>, an interactive program on CD, its Muse Award winner. You can watch footage of it in action <a href=\"https://www.youtube.com/watch?v=HKoMwm2fblw\">on YouTube</a>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/53ba6474-9662-46de-8cbe-0740c9f818ad/8-digital-museums-for-digital-history.jpg\" /></p>\n<p>Mass scanning and modeling started only in the 1990s when the necessary hardware became less expensive, and broadband Internet created a new kind of consumer for digital materials. Users could enjoy a collection or conduct research from any location. Subsequently, museums enjoyed a new marketing tool to grow loyal audiences.</p>\n<p>Digital collections also made it possible to crosslink artefacts, taking knowledge exchange to a new level by allowing any item to be put into cultural context with a focus on time, tradition, mutual influence, or ideological kinship. <strong>The opportunity to upload videos, audio recordings, and hi-res pictures make these collections more engaging to a general audience, more useful for researchers, and more attractive for designers.</strong></p>\n<p>It was at this point in the evolution of the museum that we began developing our own.</p>\nDataArt Museum Project\n<p>Our project started with a collection of old hardware that had accumulated in one of our offices. Among the motley laptops, joysticks, terminals, and beepers, there were some very interesting things, although the collection hardly rivaled those of the <a href=\"https://computerhistory.org/\">Computer History Museum</a> in Silicon Valley or <a href=\"https://www.tnmoc.org/\">The National Museum of Computing</a> in Bletchley, England. </p>\n<p>Apart from these institutions, there are plenty of other computer museums in the world. Most focused on electronic curiosities interesting only to connoisseurs who can truly appreciate a Hewlett-Packard mainframe or a 1990s orange-screen laptop. For us, this was definitely not the way to go.</p>\n<p>What turns a collection into a museum? We think it’s the context. <strong>Put old dusty hardware into historical, social, or cultural surroundings to explain their historical significance, and the stories come alive</strong>.</p>\n<p>We realized we needed to focus on the specific story behind these relics, a story relevant to us and one only we could tell. Our collection might not be the most complete, but it would be perfect for the story we want to tell. For us, as a company founded by Eastern Europeans and at the very beginning hiring predominantly from this region, the choice was obvious. We decided to start with the IT story of the former Soviet bloc — from East Germany to Armenia.</p>\n<p>The first generations of Eastern European computer engineers grew up behind the Iron Curtain — penniless, without access to modern technology, the latest scientific publications, quality components, or home computers. In the face of such challenges, how did this region give birth to a professional culture that still produces brilliant IT specialists?</p>\n<p>In 1962, Hrachya Hovsepyan, an engineer from Yerevan, received a commission to clone the French CAB 500 computer. It seemed to be cutting-edge but used a bulky magnetic drum memory. Hrachya recalls:</p>\n<blockquote>“Our technologies did not allow us to reproduce the CAB 500, and my idea was completely different. I wanted to build a parallel-action machine with microprogrammed control. That’s why I kept a low profile and did my work on the sly.”</blockquote>\n\n<p>This is a typical situation that illustrates relations between engineers and their commissioners (only Soviet officials could place an order for any developers). Hovsepyan’s pilot project resulted in three generations of “Nairi” computers, and his team came closer to creating a machine for personal use than anyone else in the Eastern bloc. At the same time, there was little wonder that he was later fired from his position and spent years fighting for the right to leave the USSR.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/51858a2f-27d6-4eb0-9c08-7bfabc7bb988/3-digital-museums-for-digital-history.png\" /></p>\n<p><strong>We wanted to share the untold history and highlight the forgotten heroes of East and Central European IT</strong>, as well as learn about the details of their everyday jobs in the context of the industry’s strategic plans, along with the official and unofficial cultural scenes in the background. </p>\n<p>This includes scientists who worked in the first computer labs, young men and women responsible for the maintenance of the first computers, inventors creating unique platforms on ternary logic, military engineers developing the Soviet proto-Internet, and thousands of enthusiasts soldering together rudimentary computers in their kitchens. That reality — DIY by necessity — can still be seen behind the approaches taken by Eastern European developers.</p>\n<p>Vera Glushkova, an engineer, historian, and daughter of the cybernetics pioneer Victor Glushkov, told us about engineers in Kyiv:</p>\n<blockquote>“Business and commercial orders were a serious crime, but some people working in Kyiv assembled such incredible things for personal use and sometimes even on demand! One engineer, Evgeny Bondarenko, who worked on the pre-personal MIR-computer project, had all the desks in his office covered with tiny parts and circuits. He could design and assemble anything from a radio up to a pipeline processor.”</blockquote>\n\n<p>Local peculiarities of this kind make face-to-face interviews with active participants of any East European computer project especially important. Luckily, modern means of communication make it easier to contact them and do such recordings, no matter where they live now. We store these audio and video files in our collection alongside hardware, books, documents, etc., and publish their transcribed versions on our website and other media, either fully or in parts. We also try to support texts with auxiliary materials, scanning private archives’ photos and documents, digitizing videos, or simply linking our stories to relevant pieces we can find on the web.</p>\n<p>Thus we get together exclusive findings and public domain information, making new sources accessible to the audience and suggesting another view on some well-known facts. Such a combination seems to be essential to a digital museum that can partly separate itself from its physical collection and transform to follow its curators’ ideas. At the same time, it still needs to keep its role as an artefact storage not to lose its museum roots. Otherwise, it takes the risk of becoming an internet blog.</p>\n<p>Our museum is a balance between CSR and marketing projects. It’s consistent with the DataArt corporate culture, as we generally look upon ourselves as geeks, people interested in digging deeper than they must. At the same time, we’re glad to use our resources to help potential researchers. That’s why we add original audio, and sometimes video, to our projects — we would be glad to share full versions of our recordings with historians, social anthropologists, or scholars of any kind.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/292e2657-9160-44c8-a092-ccfc3284a730/1-digital-museums-for-digital-history.png\" /></p>\n<p>A comedy film called “<a href=\"https://www.youtube.com/watch?v=HOiUW_DrA7o\">The Heist at Midnight</a>”, directed by engineer Radik Ananyan, is an example of how different aspects of history can be linked by an artefact’s preservation. Ananyan founded an amateur studio in the Yerevan Institute of Mathematical Machines, where he and most of his actors and film crew worked. The movie was shot in the institute, and we can see several of the first-generation machines from the 1950s. At the same time, it’s evidence of a multidimensional cultural life circulating around the engineering community in Yerevan. Later, Radik digitalized the movie and let DataArt’s IT museum use it in our project relating to Armenian computing, which later became a book.</p>\n<p>We also try to look at IT history from different angles to stimulate discussion.</p>\nDonate Your Two Cents To Protect Civilization\n<p>Throughout history, a variety of catastrophes not only took human lives but destroyed a vast number of historical artefacts. Thousands of books and historical documents, art, design objects, and more were lost to the ages, destroying traditions and threatening identities. <a href=\"https://www.smashingmagazine.com/2022/02/we-all-are-ukraine/\">As recent events have shown</a>, such destruction is not a thing of the past. </p>\n<p>The preservation of knowledge is among the key skills demanded by any field of science, humanities, or fine art. There are ways to contribute to this succession, which is the core of our civilization. It’s not only about returning books to the library but also about preserving your personal history and helping store data collected on a much larger scale.</p>\n<p>Each of us collects photos and videos from our lives, documenting special occasions, our daily operations at work, vacations, and more. We scan our documents and complete online forms, write texts, create spreadsheets, and together generate billions of media files every day. We choose which files to keep and what should go into the bin. We store our archives in the way modern digital devices allow us, using metadata and giving names to every item. </p>\n<p>Providing descriptions for stored files is a good idea — you’ll appreciate it later. We also shouldn’t underestimate how fascinating such information and visuals (sometimes accidentally preserved in family files) could be for a researcher in the future.</p>\n<p>Several ideas for private data archiving:</p>\n<ul>\n<li>Look at your data and attempt a first glance analysis to get an idea of how you might prioritize and arrange your files.</li>\n<li>Divide your data into sections by origin or topic.</li>\n<li>Create folders based on the divisions and sort your files into them.</li>\n<li>Describe the data in the file name and add metadata where it is possible (e.g., geotags, or just tags, comments, and so on).</li>\n<li>Avoid copies or similar files that can consume archival space.</li>\n<li>Make regular backups of significant data and files and store them in the cloud and offline.</li>\n</ul>\n<p>Private archives are something we take care of ourselves, and you never know what information our heirs may find interesting one day. Take care of your own little pieces of history.</p>\n<p>It’s significantly more complicated to maintain the history of an organization, a professional community, a technology, an industry, a region, or even a war. These types of projects are partly supported by governments but can’t be totally covered by national institutions. At the same time, such data could be easily manipulated or erased from their archives. This is possible with digital artefacts, just as it is with paper, parchment, or clay tablets.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f69f8f05-fce4-478e-9ee0-d37c3a4b837c/7-digital-museums-for-digital-history.png\" /></p>\n<p>There are many non-profit organizations and individual enthusiasts who preserve copies of hard-printed or even digitally created materials. But they need our help, either in the form of a donation or through direct volunteer assistance.</p>\n<p>If you’re unsure where to start, here are some projects to support:</p>\n<ul>\n<li><a href=\"https://archive.org/donate\">Internet Archive</a></li>\n<li><a href=\"https://syrianarchive.org/\">Syrian Archive</a></li>\n<li><a href=\"https://www.thehistorymakers.org/about-us\">The HistoryMakers</a></li>\n<li><a href=\"https://digitalcountry.ua\">Digital Country</a></li>\n</ul>\n<p>Our digital heritage can be an incredible source of inspiration and enlightenment. Computer hardware is just as important as antique writing implements we see displayed in museums. It deserves the same respect and care. There are ways we can all take part in this mission, should we choose to accept it.</p>",
      "content_text": "Technological development is an iterative process. One might assume that any engineer has at least a rough idea of how we got from the first wheel to self-driving cars or from the abacus to fintech applications, but this is a risky thing to take for granted. Even digital heritage needs museums to be preserved. Without them, the history of the Internet and the evolution of computers and software could be lost. \nArtefacts from the electronic era, together with information stored on diskettes, CDs, and DVDs, as well as magnetic or punched tapes, will soon disappear — much more quickly than canvas, paper, parchment or papyrus. Computer hardware loses its value quickly, and obsolete equipment is discarded. Entire generations of hardware that played an integral role in technological development and had an enormous impact on our society are destroyed. \nThe desire to preserve these assets is what fueled our own efforts with the DataArt IT Museum — digital heritage preserved digitally for anyone and everyone to see, hear, and watch. In this article, we explore the evolution of the museum, how recent innovations informed our own approach, and what you can do to help preserve IT history.\nRise Of The Museum\nThe idea of a public museum is relatively new, dating to the seventeenth century, and fundamentally differs from private collections. Beginning with the Kunstmuseum Basel (founded in 1661) and Oxford’s Ashmolean Museum (1683), university and municipal chambers of curiosities were intended to be not just an attraction but an introduction to natural diversity or a brief history of human thought. With the rise of industrial exhibitions in the nineteenth century, this idea was taken to a new level.\nThe Crystal Palace Exhibition held in London in 1851 showcased the achievements of the industrial revolution and established a tradition of craftsmanship museums. After the exhibition finished, many of the displays became part of the founding collections of the Victoria and Albert Museum and London’s Science Museum. Similarly, exhibits from the 1873 Vienna World’s Fair formed the core of Vienna’s Museum of Applied Arts. The 1881 International Exposition of Electricity served as an inspiration for Munich’s Deutsches Museum.\n\nA similar trend was witnessed in the United States. The Smithsonian Institution owes much to the Centennial International Exhibition of 1876 held in Philadelphia, while Chicago’s Science and Industry Museum opened following the World’s Columbian Exposition in 1893. The scientist George Brown Goode, who oversaw many early exhibitions at the Smithsonian, believed that museums should serve as a vehicle for adult education, reminding people of the value of civilization. They should, in his own words, “be a house full of ideas.”\nMachinery, unique items made by the best craftsmen, mass-produced goods, and even the pavilions themselves formed the core of future technical museum collections. These museums inspired engineers, just as art galleries inspire new generations of artists.\nThe Museum As A Data Bank\nAlthough a boon for creativity and opportunities to share knowledge accumulated in industrial (and art) museums was (and to an extent, remains) limited because physical presence was necessary. A tantalizing possibility of digital collections is that they can be viewed anywhere by anyone. \nThe first digitization projects were started in the 1960s, and in 1967 the Metropolitan Museum of Art initiated the Museum Computer Network (MCN). In the beginning, it included 15 museums, and the number of participants grew rapidly. Now, the MCN’s stated mission is “to grow the digital capacity of museum professionals by connecting them to ideas, information, opportunities, proven practices, and each other.”\nMuseums, archives, and libraries have experimented with digital alternatives but have principally been concerned with preserving physical objects that could be damaged over time. Digital copies have been available to a relatively small number of scholars. In 1991, the American Association of Museums named Treasures of the Smithsonian, an interactive program on CD, its Muse Award winner. You can watch footage of it in action on YouTube.\n\nMass scanning and modeling started only in the 1990s when the necessary hardware became less expensive, and broadband Internet created a new kind of consumer for digital materials. Users could enjoy a collection or conduct research from any location. Subsequently, museums enjoyed a new marketing tool to grow loyal audiences.\nDigital collections also made it possible to crosslink artefacts, taking knowledge exchange to a new level by allowing any item to be put into cultural context with a focus on time, tradition, mutual influence, or ideological kinship. The opportunity to upload videos, audio recordings, and hi-res pictures make these collections more engaging to a general audience, more useful for researchers, and more attractive for designers.\nIt was at this point in the evolution of the museum that we began developing our own.\nDataArt Museum Project\nOur project started with a collection of old hardware that had accumulated in one of our offices. Among the motley laptops, joysticks, terminals, and beepers, there were some very interesting things, although the collection hardly rivaled those of the Computer History Museum in Silicon Valley or The National Museum of Computing in Bletchley, England. \nApart from these institutions, there are plenty of other computer museums in the world. Most focused on electronic curiosities interesting only to connoisseurs who can truly appreciate a Hewlett-Packard mainframe or a 1990s orange-screen laptop. For us, this was definitely not the way to go.\nWhat turns a collection into a museum? We think it’s the context. Put old dusty hardware into historical, social, or cultural surroundings to explain their historical significance, and the stories come alive.\nWe realized we needed to focus on the specific story behind these relics, a story relevant to us and one only we could tell. Our collection might not be the most complete, but it would be perfect for the story we want to tell. For us, as a company founded by Eastern Europeans and at the very beginning hiring predominantly from this region, the choice was obvious. We decided to start with the IT story of the former Soviet bloc — from East Germany to Armenia.\nThe first generations of Eastern European computer engineers grew up behind the Iron Curtain — penniless, without access to modern technology, the latest scientific publications, quality components, or home computers. In the face of such challenges, how did this region give birth to a professional culture that still produces brilliant IT specialists?\nIn 1962, Hrachya Hovsepyan, an engineer from Yerevan, received a commission to clone the French CAB 500 computer. It seemed to be cutting-edge but used a bulky magnetic drum memory. Hrachya recalls:\n“Our technologies did not allow us to reproduce the CAB 500, and my idea was completely different. I wanted to build a parallel-action machine with microprogrammed control. That’s why I kept a low profile and did my work on the sly.”\n\nThis is a typical situation that illustrates relations between engineers and their commissioners (only Soviet officials could place an order for any developers). Hovsepyan’s pilot project resulted in three generations of “Nairi” computers, and his team came closer to creating a machine for personal use than anyone else in the Eastern bloc. At the same time, there was little wonder that he was later fired from his position and spent years fighting for the right to leave the USSR.\n\nWe wanted to share the untold history and highlight the forgotten heroes of East and Central European IT, as well as learn about the details of their everyday jobs in the context of the industry’s strategic plans, along with the official and unofficial cultural scenes in the background. \nThis includes scientists who worked in the first computer labs, young men and women responsible for the maintenance of the first computers, inventors creating unique platforms on ternary logic, military engineers developing the Soviet proto-Internet, and thousands of enthusiasts soldering together rudimentary computers in their kitchens. That reality — DIY by necessity — can still be seen behind the approaches taken by Eastern European developers.\nVera Glushkova, an engineer, historian, and daughter of the cybernetics pioneer Victor Glushkov, told us about engineers in Kyiv:\n“Business and commercial orders were a serious crime, but some people working in Kyiv assembled such incredible things for personal use and sometimes even on demand! One engineer, Evgeny Bondarenko, who worked on the pre-personal MIR-computer project, had all the desks in his office covered with tiny parts and circuits. He could design and assemble anything from a radio up to a pipeline processor.”\n\nLocal peculiarities of this kind make face-to-face interviews with active participants of any East European computer project especially important. Luckily, modern means of communication make it easier to contact them and do such recordings, no matter where they live now. We store these audio and video files in our collection alongside hardware, books, documents, etc., and publish their transcribed versions on our website and other media, either fully or in parts. We also try to support texts with auxiliary materials, scanning private archives’ photos and documents, digitizing videos, or simply linking our stories to relevant pieces we can find on the web.\nThus we get together exclusive findings and public domain information, making new sources accessible to the audience and suggesting another view on some well-known facts. Such a combination seems to be essential to a digital museum that can partly separate itself from its physical collection and transform to follow its curators’ ideas. At the same time, it still needs to keep its role as an artefact storage not to lose its museum roots. Otherwise, it takes the risk of becoming an internet blog.\nOur museum is a balance between CSR and marketing projects. It’s consistent with the DataArt corporate culture, as we generally look upon ourselves as geeks, people interested in digging deeper than they must. At the same time, we’re glad to use our resources to help potential researchers. That’s why we add original audio, and sometimes video, to our projects — we would be glad to share full versions of our recordings with historians, social anthropologists, or scholars of any kind.\n\nA comedy film called “The Heist at Midnight”, directed by engineer Radik Ananyan, is an example of how different aspects of history can be linked by an artefact’s preservation. Ananyan founded an amateur studio in the Yerevan Institute of Mathematical Machines, where he and most of his actors and film crew worked. The movie was shot in the institute, and we can see several of the first-generation machines from the 1950s. At the same time, it’s evidence of a multidimensional cultural life circulating around the engineering community in Yerevan. Later, Radik digitalized the movie and let DataArt’s IT museum use it in our project relating to Armenian computing, which later became a book.\nWe also try to look at IT history from different angles to stimulate discussion.\nDonate Your Two Cents To Protect Civilization\nThroughout history, a variety of catastrophes not only took human lives but destroyed a vast number of historical artefacts. Thousands of books and historical documents, art, design objects, and more were lost to the ages, destroying traditions and threatening identities. As recent events have shown, such destruction is not a thing of the past. \nThe preservation of knowledge is among the key skills demanded by any field of science, humanities, or fine art. There are ways to contribute to this succession, which is the core of our civilization. It’s not only about returning books to the library but also about preserving your personal history and helping store data collected on a much larger scale.\nEach of us collects photos and videos from our lives, documenting special occasions, our daily operations at work, vacations, and more. We scan our documents and complete online forms, write texts, create spreadsheets, and together generate billions of media files every day. We choose which files to keep and what should go into the bin. We store our archives in the way modern digital devices allow us, using metadata and giving names to every item. \nProviding descriptions for stored files is a good idea — you’ll appreciate it later. We also shouldn’t underestimate how fascinating such information and visuals (sometimes accidentally preserved in family files) could be for a researcher in the future.\nSeveral ideas for private data archiving:\n\nLook at your data and attempt a first glance analysis to get an idea of how you might prioritize and arrange your files.\nDivide your data into sections by origin or topic.\nCreate folders based on the divisions and sort your files into them.\nDescribe the data in the file name and add metadata where it is possible (e.g., geotags, or just tags, comments, and so on).\nAvoid copies or similar files that can consume archival space.\nMake regular backups of significant data and files and store them in the cloud and offline.\n\nPrivate archives are something we take care of ourselves, and you never know what information our heirs may find interesting one day. Take care of your own little pieces of history.\nIt’s significantly more complicated to maintain the history of an organization, a professional community, a technology, an industry, a region, or even a war. These types of projects are partly supported by governments but can’t be totally covered by national institutions. At the same time, such data could be easily manipulated or erased from their archives. This is possible with digital artefacts, just as it is with paper, parchment, or clay tablets.\n\nThere are many non-profit organizations and individual enthusiasts who preserve copies of hard-printed or even digitally created materials. But they need our help, either in the form of a donation or through direct volunteer assistance.\nIf you’re unsure where to start, here are some projects to support:\n\nInternet Archive\nSyrian Archive\nThe HistoryMakers\nDigital Country\n\nOur digital heritage can be an incredible source of inspiration and enlightenment. Computer hardware is just as important as antique writing implements we see displayed in museums. It deserves the same respect and care. There are ways we can all take part in this mission, should we choose to accept it.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/87001d28-4e45-46cd-8a5c-be63cc0a413c/digital-museums-digital-history.jpg",
      "date_published": "2022-06-07T09:30:00.000Z",
      "date_modified": "2022-06-07T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/case-prisma-jamstack/",
      "url": "https://smashingmagazine.com/2022/06/case-prisma-jamstack/",
      "title": "The Case For Prisma In The Jamstack",
      "summary": "In this article, Sam Poder explores how Prisma integrates with the Jamstack and why it’s a great solution for Serverless databases in JavaScript or TypeScript-based projects.",
      "content_html": "<p>The Jamstack approach originated from a speech given by Netlify’s CEO Matt Biilmann at Smashing Magazine’s very own Smashing Conf in 2016.</p>\n<p>Jamstack sites serve static pre-rendered content through a CDN and generate dynamic content through microservices, APIs &amp; serverless functions. They are commonly created using JavaScript frameworks, such as Next.js or Gatsby, and static site generators — Hugo or Jekyll, for example. Jamstack sites often use a Git-based deployment workflow through tools, such as Vercel and Netlify. These deployment services can be used in tandem with a headless CMS, such as Strapi. </p>\n<p>The goal of using Jamstack to build a site is to create a site that is high performant and economical to run. These sites achieve high speeds by pre-rendering as much content as possible and by caching responses on “the edge” (A.K.A. executing on servers as close to the user as possible, e.g. serving a Mumbai-based user from a server in Singapore instead of San Francisco). </p>\n<p>Jamstack sites are more economical to run, as they don’t require using a dedicated server as a host. Instead, they can provision usage from cloud services (PAASs) / hosts / CDNs for a lower price. These services are also set up to scale in a cost-efficient manner, without developers changing their infrastructure and reducing their workload. </p>\n<p>The other tool that makes up this combination is Prisma — an open source ORM (object relational mapping) built for TypeScript &amp; JavaScript. </p>\n<blockquote>Prisma is a JavaScript / TypeScript tool that interpretes a schema written in Prisma’s standards and generates a type-safe module that provides methods to create records, read records, update records, and delete records (CRUD).</blockquote>\n\n<p>Prisma handles connections to the database (including pooling) and database migrations. It can connect with databases that use PostgreSQL, MySQL, SQL Server or SQLite (additionally MongoDB support is in preview).</p>\n<p>To help you get a sense of Prisma, here’s the some basic example code to handle the CRUD of users:</p>\n<pre><code>import { PrismaClient } from '@prisma/client'\n\nconst prisma = new PrismaClient()\n\nconst user = await prisma.user.create({\n  data: {\n    name: Sam,\n    email: 'sam@sampoder.com',\n  },\n})\n\nconst users = await prisma.user.findMany()\n\nconst updateUser = await prisma.user.update({\n  where: {\n    email: 'sam@sampoder.com',\n  },\n  data: {\n    email: 'deleteme@sampoder.com',\n  },\n})\n\nconst deleteUser = await prisma.user.delete({\n  where: {\n    email: 'deleteme@sampoder.com',\n  },\n})</code></pre>\n\n<p>The associated project’s Prisma schema would look like:</p>\n<pre><code>datasource db {\n  url      = env(\"DATABASE_URL\")\n  provider = \"postgresql\"\n}\n\ngenerator client {\n  provider = \"prisma-client-js\"\n}\n\nmodel User {\n  id        Int      @id @default(autoincrement())\n  email     String   @unique\n  name      String?\n}</code></pre>\n\n\n\nThe Use Cases for Prisma\n<p>Armed with a knowledge of how Prisma operates, let’s now explore where we can use it within Jamstack projects. Data is important in two aspects of the Jamstack: whilst pre-rendering static pages and on API routes. These are tasks often achieved using JavaScript tools, such as Next.js for static pages and Cloudfare Workers for API routes. Admitally, these aren’t always achieved with JavaScript — Jekyll, for example, uses Ruby! So, maybe I should amend the title for the case of Prisma in JavaScript-based Jamstack. Anyhow, onwards!</p>\n<p>A very common use-case for the Jamstack is a blog, where Prisma will come in handy for a blog to create a reactions system. You’d use it in API routes with one that would fetch and return the reaction count and another that could register a new reaction. To achieve this, you could use the <code>create</code> and <code>findMany</code> methods of Prisma!</p>\n<p>Another common use-case for the Jamstack is a landing page, and there’s nothing better than a landing with some awesome stats! In the Jamstack, we can pre-render these pages with stats pulled from our databases which we can achieve using Prisma’s reading methods.</p>\n<p>Sometimes, however, Prisma can be slightly overkill for certain tasks. I’d recommend avoiding using Prisma and relational databases in general for solutions that need only a single database table, as it adds additional and often unnecessary development complexity in these cases. For example, it’d be overkill to use Prisma for an email newsletter signup box or a contact form. </p>\nAlternatives to Prisma\n<p>So, we could use Prisma for these tasks, but we could use a plethora of other tools to achieve them. So, why Prisma? Let’s go through three Prisma alternatives, and I’ll try to convince you that Prisma is preferable.</p>\n<h3>Cloud Databases / Services</h3>\n<p>Services like Airtable are incredibly popular in the Jamstack space (I myself have used it a ton), they provide you with a database (like platform) that you can access through a REST API. They’re good fun to use and prototype with, however, Prisma is arguably a better choice for Jamstack projects.</p>\n<p>Firstly, with cost being a major factor in Jamstack’s appeal, you may want to avoid some of these services. For example, at Hack Club, we spent $671.54 on an Airtable Pro subscription last month for our small team (yikes!).</p>\n<p>On the other hand, hosting an equivalent PostgreSQL database on Heroku’s platform costs $9 a month. There certainly is an argument to make for these cloud services based on their UI and API, but I would respond by pointing you to Prisma’s Studio and aforementioned JavaScript / TypeScript client.</p>\n<p>Cloud services also suffer from a performance-issue, especially considering that you, as the user, have no ability to change / improve the performance. The cloud services providing the database put a middleman in between your program and the database they’re using, slowing down how fast you can get to the database. However, with Prisma you’re making direct calls to your database from your program which reduces the time to query / modify the database.</p>\n<h3>Writing Pure SQL</h3>\n<p>So, if we’re going to access our PostgreSQL database directly, why not just use the node-postgres module or — for many other databases — their equivalent drivers? I’d argue that the developer experience of using Prisma’s client makes it worth the slightly increased load.</p>\n<p>Where Prisma shines is with its typings. The module generated for you by Prisma is fully type-safe — it interprets the types from your Prisma schema — which helps you prevent type errors with your database. Furthermore, for projects using TypeScript, Prisma auto-generates type definitions that reflect the structure of your model. Prisma uses these types to validate database queries at compile-time to ensure they are type-safe.</p>\n<p>Even if you aren’t using TypeScript, Prisma also offers autocomplete / Intelli-sense, linting, and formatting through its Visual Studio Code extension. There are also community built / maintained plugins for Emacs (emacs-prisma-mode), neovim (coc-prisma), Jetbrains IDE (Prisma Support), and nova (the Prisma plugin) that implement the Prisma Language Server to achieve code validation. Syntax highlighting is also available for a wide array of editors through plugins.</p>\n<h3>Other ORMs</h3>\n<p>Prisma is, of course, not the only ORM available for JavaScript / TypeScript. For example, TypeORM is another high quality ORM for JavaScript projects. And in this case, it is going to come down to personal preference, and I encourage you to try a range of ORMs to find your favourite. I personally choose Prisma to use for my project for three reasons: the extensive documentation (especially <a href=\"https://www.prisma.io/docs/concepts/components/prisma-client/crud\">this CRUD page</a>, which is a lifesaver), the additional tooling within the Prisma ecosystem (e.g. Prisma Migrate and Prisma Studio), and the active community around the tool (e.g. Prisma Day and the Prisma Slack). </p>\nUsing Prisma in Jamstack Projects\n<p>So, if I’m looking to use Prisma in a Jamstack project, how do I do that?</p>\n<h3>Next.js</h3>\n<p>Next.js is growing to be a very popular framework in the Jamstack space, and Prisma is a perfect fit for it. The examples below will serve as pretty standard examples that you can transfer into other projects using different JavaScript / TypeScript Jamstack tools.</p>\n<p>The main rule of using Prisma within Next.js is that it must be used in a server-side setting, this means that it can be used in <code>getStaticProps</code>, <code>getServerSideProps</code>, and in API routes (e.g. <code>api/emojis.js</code>).</p>\n<p>In code, it looks like this (<a href=\"https://github.com/sampoder/prisma-day-2021\">example taken from a demo app</a> I made for a talk at Prisma Day 2021 which was a virtual sticker wall):</p>\n<pre><code>import prisma from '../../../lib/prisma'\nimport { getSession } from 'next-auth/client'\n\nfunction getRandomNum(min, max) {\n  return Math.random() * (max - min) + min\n}\n\nexport async function getRedemptions(username) {\n  let allRedemptions = await prisma.user.findMany({\n    where: {\n      name: username,\n    },\n    select: {\n      Redemptions: {\n        select: {\n          id: true,\n          Stickers: {\n            select: { nickname: true, imageurl: true, infourl: true },\n          },\n        },\n        distinct: ['stickerId'],\n      },\n    },\n  })\n  allRedemptions = allRedemptions[0].Redemptions.map(x =&gt; ({\n    number: getRandomNum(-30, 30),\n    ...x.Stickers,\n  }))\n  return allRedemptions\n}\n\nexport default async function RedeemCodeReq(req, res) {\n  let data = await getRedemptions(req.query.username)\n  res.send(data)\n}</code></pre>\n\n<p>As you can see, it integrates really well into a Next.js project. But you may notice something interesting: <code>'../../../lib/prisma'</code>. Previously, we imported Prisma like this:</p>\n<pre><code>import { PrismaClient } from '@prisma/client'\n\nconst prisma = new PrismaClient()</code></pre>\n\n<p>Unfortunately, this is due to a quirk in Next.js’ live refresh system. So, Prisma recommends you paste <a href=\"https://www.prisma.io/docs/support/help-articles/nextjs-prisma-client-dev-practices\">this code snippet</a> into a file and import the code into each file.</p>\n<h3>Redwood</h3>\n<p>Redwood is a bit of an anomaly in this section, as it isn’t necessarily a Jamstack framework. It began under the banner of bringing full stack to the Jamstack but has transitioned to being inspired by Jamstack. I’ve chosen to include it here, however, as it takes an interesting approach of including Prisma within the framework. </p>\n<p>It starts, as always, with creating a Prisma schema, this time in <code>api/db/schema.prisma</code> (Redwood adds this to every new project). However, to query and modify the database, you don’t use Prisma’s default client. Instead, in Redwood, GraphQL mutations and queries are used. For example, in Redwood’s example todo app, this is the GraphQL mutation used to create a new todo:</p>\n<pre><code>const CREATE_TODO = gql`\n  mutation AddTodo_CreateTodo($body: String!) {\n    createTodo(body: $body) {\n      id\n      __typename\n      body\n      status\n    }\n  }\n`</code></pre>\n\n<p>And in this case, the Prisma model for a todo is:</p>\n<pre><code>model Todo {\n  id     Int    @id @default(autoincrement())\n  body   String\n  status String @default(\"off\")\n}</code></pre>\n\n<p>To trigger the GraphQL mutation, we use the <code>useMutation</code> function which is based on Apollo’s GraphQL client imported from <code>@redwoodjs/web</code>:</p>\n<div>\n<pre><code>const [createTodo] = useMutation(CREATE_TODO, {\n    //  Updates Apollo's cache, re-rendering affected components\n    update: (cache, { data: { createTodo } }) =&gt; {\n      const { todos } = cache.readQuery({ query: TODOS })\n      cache.writeQuery({\n        query: TODOS,\n        data: { todos: todos.concat([createTodo]) },\n      })\n    },\n  })\n\n  const submitTodo = (body) =&gt; {\n    createTodo({\n      variables: { body },\n      optimisticResponse: {\n        __typename: 'Mutation',\n        createTodo: { __typename: 'Todo', id: 0, body, status: 'loading' },\n      },\n    })\n  }</code></pre>\n</div>\n\n<p>With Redwood, you don’t need to worry about setting up the GraphQL schema / SDLs after creating your Prisma schema, as you can use Redwood’s <code>scaffold</code> command to convert the Prisma schema into GraphQL SDLs and services — <code>yarn rw g sdl Todo</code>, for example.</p>\n<h3>Cloudfare Workers</h3>\n<p>Cloudfare Workers is a popular platform for hosting Jamstack APIs, as it puts your code on the “edge”. However, the platform has its limitations, including a lack of TCP support, which the traditional Prisma Client uses. Though now, through Prisma Data Proxy, it is possible.</p>\n<p>To use it, you’ll need a <a href=\"https://cloud.prisma.io/\">Prisma Cloud Platform</a> account which is currently free. Once you’ve followed the setup process (make sure to enable Prisma Data Proxy), you’ll be provided with a connection string that begins with <code>prisma://</code>. You can use that Prisma connection string in your <code>.env</code> file in place of the traditional database URL:</p>\n<pre><code>DATABASE_URL=\"prisma://aws-us-east-1.prisma-data.com/?api_key=•••••••••••••••••\"</code></pre>\n\n<p>And then, instead of using <code>npx prisma generate</code>, use this command to generate a Prisma client:</p>\n<pre><code>PRISMA_CLIENT_ENGINE_TYPE=dataproxy npx prisma generate</code></pre>\n\n<p>Your database requests will be proxied through, and you can use the Prisma Client as usual. It isn’t a perfect set-up, but for those looking for database connections on Cloudfare Workers, it’s a relatively good solution.</p>\nConclusion\n<p>To wrap up, if you’re looking for a way to connect Jamstack applications with a database, I wouldn’t look further than Prisma. Its developer experience, extensive tooling, and performance make it the perfect choice. Next.js, Redwood, and Cloudfare Workers — each of them has a unique way of using Prisma, but it still works very well in all of them. </p>\n<p>I hope you’ve enjoyed exploring Prisma with me. Thank you!</p>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/04/jamstack-rendering-patterns-evolution/\">Jamstack Rendering Patterns: The Evolution</a>,” Ekene Eze</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/09/interactive-learning-tools-front-end-developers/\">Interactive Learning Tools For Front-End Developers</a>,” Louis Lazaris</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/08/history-future-jamstack-cms/\">Jamstack CMS: The Past, The Present and The Future</a>,” Mike Neumegen</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/11/smashing-podcast-episode-29/\">Smashing Podcast Episode 29 With Leslie Cohn-Wein: How Does Netlify Dogfood The Jamstack?</a>,” Drew McLellan</li>\n</ul>",
      "content_text": "The Jamstack approach originated from a speech given by Netlify’s CEO Matt Biilmann at Smashing Magazine’s very own Smashing Conf in 2016.\nJamstack sites serve static pre-rendered content through a CDN and generate dynamic content through microservices, APIs & serverless functions. They are commonly created using JavaScript frameworks, such as Next.js or Gatsby, and static site generators — Hugo or Jekyll, for example. Jamstack sites often use a Git-based deployment workflow through tools, such as Vercel and Netlify. These deployment services can be used in tandem with a headless CMS, such as Strapi. \nThe goal of using Jamstack to build a site is to create a site that is high performant and economical to run. These sites achieve high speeds by pre-rendering as much content as possible and by caching responses on “the edge” (A.K.A. executing on servers as close to the user as possible, e.g. serving a Mumbai-based user from a server in Singapore instead of San Francisco). \nJamstack sites are more economical to run, as they don’t require using a dedicated server as a host. Instead, they can provision usage from cloud services (PAASs) / hosts / CDNs for a lower price. These services are also set up to scale in a cost-efficient manner, without developers changing their infrastructure and reducing their workload. \nThe other tool that makes up this combination is Prisma — an open source ORM (object relational mapping) built for TypeScript & JavaScript. \nPrisma is a JavaScript / TypeScript tool that interpretes a schema written in Prisma’s standards and generates a type-safe module that provides methods to create records, read records, update records, and delete records (CRUD).\n\nPrisma handles connections to the database (including pooling) and database migrations. It can connect with databases that use PostgreSQL, MySQL, SQL Server or SQLite (additionally MongoDB support is in preview).\nTo help you get a sense of Prisma, here’s the some basic example code to handle the CRUD of users:\nimport { PrismaClient } from '@prisma/client'\n\nconst prisma = new PrismaClient()\n\nconst user = await prisma.user.create({\n  data: {\n    name: Sam,\n    email: 'sam@sampoder.com',\n  },\n})\n\nconst users = await prisma.user.findMany()\n\nconst updateUser = await prisma.user.update({\n  where: {\n    email: 'sam@sampoder.com',\n  },\n  data: {\n    email: 'deleteme@sampoder.com',\n  },\n})\n\nconst deleteUser = await prisma.user.delete({\n  where: {\n    email: 'deleteme@sampoder.com',\n  },\n})\n\nThe associated project’s Prisma schema would look like:\ndatasource db {\n  url      = env(\"DATABASE_URL\")\n  provider = \"postgresql\"\n}\n\ngenerator client {\n  provider = \"prisma-client-js\"\n}\n\nmodel User {\n  id        Int      @id @default(autoincrement())\n  email     String   @unique\n  name      String?\n}\n\n\n\nThe Use Cases for Prisma\nArmed with a knowledge of how Prisma operates, let’s now explore where we can use it within Jamstack projects. Data is important in two aspects of the Jamstack: whilst pre-rendering static pages and on API routes. These are tasks often achieved using JavaScript tools, such as Next.js for static pages and Cloudfare Workers for API routes. Admitally, these aren’t always achieved with JavaScript — Jekyll, for example, uses Ruby! So, maybe I should amend the title for the case of Prisma in JavaScript-based Jamstack. Anyhow, onwards!\nA very common use-case for the Jamstack is a blog, where Prisma will come in handy for a blog to create a reactions system. You’d use it in API routes with one that would fetch and return the reaction count and another that could register a new reaction. To achieve this, you could use the create and findMany methods of Prisma!\nAnother common use-case for the Jamstack is a landing page, and there’s nothing better than a landing with some awesome stats! In the Jamstack, we can pre-render these pages with stats pulled from our databases which we can achieve using Prisma’s reading methods.\nSometimes, however, Prisma can be slightly overkill for certain tasks. I’d recommend avoiding using Prisma and relational databases in general for solutions that need only a single database table, as it adds additional and often unnecessary development complexity in these cases. For example, it’d be overkill to use Prisma for an email newsletter signup box or a contact form. \nAlternatives to Prisma\nSo, we could use Prisma for these tasks, but we could use a plethora of other tools to achieve them. So, why Prisma? Let’s go through three Prisma alternatives, and I’ll try to convince you that Prisma is preferable.\nCloud Databases / Services\nServices like Airtable are incredibly popular in the Jamstack space (I myself have used it a ton), they provide you with a database (like platform) that you can access through a REST API. They’re good fun to use and prototype with, however, Prisma is arguably a better choice for Jamstack projects.\nFirstly, with cost being a major factor in Jamstack’s appeal, you may want to avoid some of these services. For example, at Hack Club, we spent $671.54 on an Airtable Pro subscription last month for our small team (yikes!).\nOn the other hand, hosting an equivalent PostgreSQL database on Heroku’s platform costs $9 a month. There certainly is an argument to make for these cloud services based on their UI and API, but I would respond by pointing you to Prisma’s Studio and aforementioned JavaScript / TypeScript client.\nCloud services also suffer from a performance-issue, especially considering that you, as the user, have no ability to change / improve the performance. The cloud services providing the database put a middleman in between your program and the database they’re using, slowing down how fast you can get to the database. However, with Prisma you’re making direct calls to your database from your program which reduces the time to query / modify the database.\nWriting Pure SQL\nSo, if we’re going to access our PostgreSQL database directly, why not just use the node-postgres module or — for many other databases — their equivalent drivers? I’d argue that the developer experience of using Prisma’s client makes it worth the slightly increased load.\nWhere Prisma shines is with its typings. The module generated for you by Prisma is fully type-safe — it interprets the types from your Prisma schema — which helps you prevent type errors with your database. Furthermore, for projects using TypeScript, Prisma auto-generates type definitions that reflect the structure of your model. Prisma uses these types to validate database queries at compile-time to ensure they are type-safe.\nEven if you aren’t using TypeScript, Prisma also offers autocomplete / Intelli-sense, linting, and formatting through its Visual Studio Code extension. There are also community built / maintained plugins for Emacs (emacs-prisma-mode), neovim (coc-prisma), Jetbrains IDE (Prisma Support), and nova (the Prisma plugin) that implement the Prisma Language Server to achieve code validation. Syntax highlighting is also available for a wide array of editors through plugins.\nOther ORMs\nPrisma is, of course, not the only ORM available for JavaScript / TypeScript. For example, TypeORM is another high quality ORM for JavaScript projects. And in this case, it is going to come down to personal preference, and I encourage you to try a range of ORMs to find your favourite. I personally choose Prisma to use for my project for three reasons: the extensive documentation (especially this CRUD page, which is a lifesaver), the additional tooling within the Prisma ecosystem (e.g. Prisma Migrate and Prisma Studio), and the active community around the tool (e.g. Prisma Day and the Prisma Slack). \nUsing Prisma in Jamstack Projects\nSo, if I’m looking to use Prisma in a Jamstack project, how do I do that?\nNext.js\nNext.js is growing to be a very popular framework in the Jamstack space, and Prisma is a perfect fit for it. The examples below will serve as pretty standard examples that you can transfer into other projects using different JavaScript / TypeScript Jamstack tools.\nThe main rule of using Prisma within Next.js is that it must be used in a server-side setting, this means that it can be used in getStaticProps, getServerSideProps, and in API routes (e.g. api/emojis.js).\nIn code, it looks like this (example taken from a demo app I made for a talk at Prisma Day 2021 which was a virtual sticker wall):\nimport prisma from '../../../lib/prisma'\nimport { getSession } from 'next-auth/client'\n\nfunction getRandomNum(min, max) {\n  return Math.random() * (max - min) + min\n}\n\nexport async function getRedemptions(username) {\n  let allRedemptions = await prisma.user.findMany({\n    where: {\n      name: username,\n    },\n    select: {\n      Redemptions: {\n        select: {\n          id: true,\n          Stickers: {\n            select: { nickname: true, imageurl: true, infourl: true },\n          },\n        },\n        distinct: ['stickerId'],\n      },\n    },\n  })\n  allRedemptions = allRedemptions[0].Redemptions.map(x => ({\n    number: getRandomNum(-30, 30),\n    ...x.Stickers,\n  }))\n  return allRedemptions\n}\n\nexport default async function RedeemCodeReq(req, res) {\n  let data = await getRedemptions(req.query.username)\n  res.send(data)\n}\n\nAs you can see, it integrates really well into a Next.js project. But you may notice something interesting: '../../../lib/prisma'. Previously, we imported Prisma like this:\nimport { PrismaClient } from '@prisma/client'\n\nconst prisma = new PrismaClient()\n\nUnfortunately, this is due to a quirk in Next.js’ live refresh system. So, Prisma recommends you paste this code snippet into a file and import the code into each file.\nRedwood\nRedwood is a bit of an anomaly in this section, as it isn’t necessarily a Jamstack framework. It began under the banner of bringing full stack to the Jamstack but has transitioned to being inspired by Jamstack. I’ve chosen to include it here, however, as it takes an interesting approach of including Prisma within the framework. \nIt starts, as always, with creating a Prisma schema, this time in api/db/schema.prisma (Redwood adds this to every new project). However, to query and modify the database, you don’t use Prisma’s default client. Instead, in Redwood, GraphQL mutations and queries are used. For example, in Redwood’s example todo app, this is the GraphQL mutation used to create a new todo:\nconst CREATE_TODO = gql`\n  mutation AddTodo_CreateTodo($body: String!) {\n    createTodo(body: $body) {\n      id\n      __typename\n      body\n      status\n    }\n  }\n`\n\nAnd in this case, the Prisma model for a todo is:\nmodel Todo {\n  id     Int    @id @default(autoincrement())\n  body   String\n  status String @default(\"off\")\n}\n\nTo trigger the GraphQL mutation, we use the useMutation function which is based on Apollo’s GraphQL client imported from @redwoodjs/web:\n\nconst [createTodo] = useMutation(CREATE_TODO, {\n    //  Updates Apollo's cache, re-rendering affected components\n    update: (cache, { data: { createTodo } }) => {\n      const { todos } = cache.readQuery({ query: TODOS })\n      cache.writeQuery({\n        query: TODOS,\n        data: { todos: todos.concat([createTodo]) },\n      })\n    },\n  })\n\n  const submitTodo = (body) => {\n    createTodo({\n      variables: { body },\n      optimisticResponse: {\n        __typename: 'Mutation',\n        createTodo: { __typename: 'Todo', id: 0, body, status: 'loading' },\n      },\n    })\n  }\n\n\nWith Redwood, you don’t need to worry about setting up the GraphQL schema / SDLs after creating your Prisma schema, as you can use Redwood’s scaffold command to convert the Prisma schema into GraphQL SDLs and services — yarn rw g sdl Todo, for example.\nCloudfare Workers\nCloudfare Workers is a popular platform for hosting Jamstack APIs, as it puts your code on the “edge”. However, the platform has its limitations, including a lack of TCP support, which the traditional Prisma Client uses. Though now, through Prisma Data Proxy, it is possible.\nTo use it, you’ll need a Prisma Cloud Platform account which is currently free. Once you’ve followed the setup process (make sure to enable Prisma Data Proxy), you’ll be provided with a connection string that begins with prisma://. You can use that Prisma connection string in your .env file in place of the traditional database URL:\nDATABASE_URL=\"prisma://aws-us-east-1.prisma-data.com/?api_key=•••••••••••••••••\"\n\nAnd then, instead of using npx prisma generate, use this command to generate a Prisma client:\nPRISMA_CLIENT_ENGINE_TYPE=dataproxy npx prisma generate\n\nYour database requests will be proxied through, and you can use the Prisma Client as usual. It isn’t a perfect set-up, but for those looking for database connections on Cloudfare Workers, it’s a relatively good solution.\nConclusion\nTo wrap up, if you’re looking for a way to connect Jamstack applications with a database, I wouldn’t look further than Prisma. Its developer experience, extensive tooling, and performance make it the perfect choice. Next.js, Redwood, and Cloudfare Workers — each of them has a unique way of using Prisma, but it still works very well in all of them. \nI hope you’ve enjoyed exploring Prisma with me. Thank you!\nFurther Reading on Smashing Magazine\n\n“Jamstack Rendering Patterns: The Evolution,” Ekene Eze\n“Interactive Learning Tools For Front-End Developers,” Louis Lazaris\n“Jamstack CMS: The Past, The Present and The Future,” Mike Neumegen\n“Smashing Podcast Episode 29 With Leslie Cohn-Wein: How Does Netlify Dogfood The Jamstack?,” Drew McLellan\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/30c31583-7e46-4566-b2d3-bef54dd64152/case-prisma-jamstack.jpg",
      "date_published": "2022-06-06T09:00:00.000Z",
      "date_modified": "2022-06-06T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/measuring-performance-typefaces-users-part1/",
      "url": "https://smashingmagazine.com/2022/06/measuring-performance-typefaces-users-part1/",
      "title": "Measuring The Performance Of Typefaces For Users (Part 1)",
      "summary": "This is the first part of this article, written especially for typeface designers and typographers. See how typefaces work, how to test them, and other broader typographic issues.",
      "content_html": "<p>Our focus is on typefaces for reading large amounts of text and information in the most efficient, legible, pleasurable, comprehensible, and effective way possible. For instance, typefaces used for a novel, an academic paper in a journal, or a lengthy online article like this one that uses the <a href=\"https://processtypefoundry.com/fonts/elena/\">Elena</a> typeface, that you are reading now on this webpage. The questions that we will explore are:</p>\n<ul>\n<li>How well do typefaces for extended reading actually work?</li>\n<li>How well does a typeface work and perform against another similar typeface?</li>\n<li>How would we test to see if there is any difference between a good sans serif and a serif typeface with users?</li>\n<li>What would the world’s most ideal, best practice and design research-driven highly legible serif, sans serif, and slab serif possibly be like? What characteristics and themes would be most advisable, and do we need a central public list of aspects and features?</li>\n<li>There is both the aesthetic and functional aspect to a typeface, but what is the functional aspect, and how can it be investigated and measured?</li>\n<li>How good is a new typeface, and how good is it compared to a similar typeface designed in previous years?</li>\n</ul>\n<p>Should typefaces be measured? There is no simple answer. The short answer: yes. The long answer: it is a difficult and imprecise task. We will discuss the pros and the cons, and I will show you what things are involved and how we could go about doing it.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/03c2c51c-2063-42aa-b01b-dc4ba97d1f76/1-v3-measuring-performance-typefaces-users-part1.jpg\" /></p>\nA Very Short Introduction To Typefaces\n<p>For 100s of years, we have enjoyed using typefaces. These compiled systems for letters and symbols, which are representations of sounds and information, get a lot of use and are a large part of graphic communication.</p>\n<p>The first movable type machine, and therefore the first printing press, was created by a man named Bi Sheng, who lived in Yingshan, China, from what we believe to be 970–1051 AD — over four full centuries before Johannes Gutenberg was even born. The moveable type, sculptured in a lead-based alloy — which is essentially metal blocks of letters and symbols that can be moved, arranged, and used for mass printing — was <a href=\"https://en.wikipedia.org/wiki/Johannes_Gutenberg\">Johannes Gutenberg’s</a> contribution. Fast forward to the early 1960s, phototypesetting systems appeared. These devices consisted of glass disks (one per typeface) that spun in front of a light source, which exposed characters onto light-sensitive paper. Later on, in the 1980s, type started to be used in a digital context in computers. And today, we still have type in a digital context, but it travels through cables, wirelessly on smartphones, and in virtual reality glasses in 3D.</p>\n<p>There are many different classifications of typefaces. To name a few: sans serif, serif, slab serif, script, handwritten, display, ornamental, stencil, and monospace. In a way, technology also created new typeface classifications. Today, we even have mixed typefaces with elements of serif and sans serif, such as the Luc(as) de Groot’s typeface <a href=\"https://www.lucasfonts.com/fonts/the-mix\">TheMix</a>. This diversity adds to the difficulty and complexity of defining and testing typefaces.</p>\nReasons To Measure The Performance Of Typefaces?\n<p>Because technology has made it possible to design typefaces easier than ever before, we seem to be reinventing “different types of wheels” that already get the job done. However, rather than reinventing these typefaces, maybe we can get some objective measures, learn from what works and what does not work, and then design objectively better wheels (typefaces). </p>\n<p>If your aim is to produce a new typeface based on historical exemplars, tradition, or design, then fine, this is what you will be aiming for. Alternatively, if you want to do something new and expressive, or that has never been done before, then fine, of course. However, some contexts, situations, and users need and demand highly functional typefaces. </p>\n<p>As I briefly mentioned, measuring a typeface’s effectiveness is difficult. Since many new typefaces are not supplied with any objective concrete testing data, how do we determine how well they work and where they succeed or fail?</p>\nShould We Measure The Typeface Alone, And/Or The Context And Environment That The Typeface Is Used In?\n<p>When considering the questions above, we can see that this is a large and complex issue. There are many different types of information, situations in which information is used, types of environments, and there are many different categories of people. Here are some extreme examples:</p>\n<ul>\n<li>A person who is elderly trying to read road signs, driving home at night;</li>\n<li>An accountant doing a large amount of numerical calculations for a million-pound/dollar company, needing to turn around the work in 30 minutes;</li>\n<li>A young person learning to read for the first time, sitting in the back of a car full of people on bumpy roads;</li>\n<li>A person with dyslexia trying to read and complete their evening class assignment.</li>\n</ul>\nMeasuring Typefaces And The Resulting Performance Data\n<p>One of the reasons why measuring a typeface’s effectiveness is difficult is that we cannot accurately measure what goes on in people’s minds. Many factors are invisible, as <a href=\"https://twitter.com/typographer\">Paul Luna</a> — a professor at the <a href=\"https://www.reading.ac.uk/typography/\">University of Reading’s Department of Typography &amp; Graphic Communication</a> — mentions in this video <a href=\"https://www.podularity.com/thehedgehogandthefox/2021/10/28/paul-luna-on-the-typographers-task-video/\"><em>Paul Luna on the typographer’s task</em></a>. In addition, <a href=\"https://www.robwaller.org\">Robert Waller</a>, information designer at the <a href=\"https://www.simplificationcentre.org.uk\">Simplification Centre</a> states:</p>\n<blockquote>“Legibility research has a long history (going back to the 1870s). A wide range of issues has been studied, including type size, line spacing, line length, typestyle, serifs, and more. However, as Buckingham in <a href=\"https://books.google.co.uk/books/about/The_Yearbook_of_the_National_Society_for.html?id=Nz0WAAAAIAAJ&amp;redir_esc=y\">New data on the typography of textbooks</a> pointed out relatively early on, these factors interact in complex ways, apparently unrecognizable by many researchers. Indeed, in recent times a consensus has grown that the interaction of variables in type design is so complex that few generalizable findings can be found (see a longer review in Robert Waller’s “<a href=\"https://www.researchgate.net/publication/279925782_Typography_and_discourse\">Typography and discourse</a>”).”<br /><br />— <a href=\"https://www.robwaller.org\">Robert Waller</a> in <a href=\"https://benjamins.com/catalog/idj.15.1.01wal\">Comparing Typefaces For Airport Signs</a> \n</blockquote>\n\n<p>Furthermore, Ralf Hermann, director of <a href=\"https://typography.guru\">Typography.Guru</a> in his article says:</p>\n<blockquote>“Doing scientific studies to test which typefaces work best in this regard, is almost impossible to do. For a proper test setup you would need to modify one parameter while keeping every other parameter unchanged. But setting a letter or word in different typefaces can not be considered as “changing one parameter”, because a typeface consists of dozens of relevant parameters like x-height, weight, contrast, width — just to name a few. So scientific tests for typeface legibility are often full of flaws. Very often the typefaces are set at the same point size, but as every graphic designer should know, the point size does not reflect the actual size of the letters in print or on-screen. So if you come across a scientific legibility study that compares typefaces set at the same point size, don’t even bother to read on!”<br /><br />— <a href=\"https://typography.guru\">Ralf Hermann</a> at <a href=\"https://typography.guru/journal/what-makes-letters-legible-r37/\">What Makes Letters Legible?</a> \n</blockquote>\n\n<p>The observations expressed in these quotes demonstrate that testing typefaces involves many complex factors. Because of this complexity, it has to be carefully controlled and modified, but it may not even be worth the effort.</p>\nConsistency And Variables\n<p>When testing typefaces or a selection of typefaces against another, we need to keep the typographic design parameters and variables the same, so we do not introduce or change the previously tested type settings. One example is the difference between the typefaces’ x-height’s (the height of a lowercase x) of any two typefaces we are testing. It is unlikely that they will be the same, as x-heights differ greatly. Thus, one of the two typeface x-height’s will seem to be larger in size, although it may be the same point size in the software. I will show you more about typographic variables under the section “<a href=\"https://www.smashingmagazine.com/2022/06/measuring-performance-typefaces-users-part2/#specific-typographic-design-variables-affecting-performance\">Specific Typographic Design Variables Affecting Performance</a>” in the second part of this article.</p>\n<p><a href=\"https://www.robwaller.org\">Robert Waller</a> mentions in “<a href=\"https://www.simplificationcentre.org.uk/reports2/technical-paper-10-the-clear-print-standard-arguments-for-a-flexible-approach\">The Clear Print standard: arguments for a flexible approach</a>” that “although both point size and x-height are specified, it is the point size (pt) that is most commonly quoted — and point size is a notoriously imprecise measure.” It is, however, more effective and accurate to set an x-height measurement and set the typefaces being compared to that same x-height measurement. The x-height using point sizes actually results in different sizes — and does not look inconsistent between different typefaces.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fa0b707e-0371-47e7-8676-de455bf9d8e8/2-v2-measuring-performance-typefaces-users-part1.jpg\" /></p>\n<p>Notice on the 1st line that we can see that both typefaces are set to 26 pt in Adobe InDesign. However, if you look at the tops of the “erdana” you can see that they go slightly above the line, so the Verdana typeface is, in essence, larger than the Info Display typeface, even when they are both typeset at 26 points. On the 2nd line, both typefaces have been typeset to a consistent and accurate measurement of an x-height of 5.5 mm. Notice that while the x-height is the same for both typefaces on the 2nd line, it gives a different point size for each typeface. This is why point size is not an accurate way to measure typeface size and for testing and comparing two or more typefaces.</p>\n<p>Additionally, how you use and typeset the typeface in the actual typographic design and layout (line length, typeface size, color, spacing, leading, and so on) is probably more important than the actual typeface used. Thus, you could use one of the world’s most legible typefaces, but if you typeset it with a leading of -7 points and a line length of 100 characters, it would be rendered nearly useless.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/16fb7ddd-28ea-4ab0-9cce-d29f95b41dbd/3-v2-measuring-performance-typefaces-users-part1.jpg\" /></p>\n<p>As you can see, we can’t use a singular factor to measure typefaces. Instead, we need to address multiple factors within the design system. They all have to work well together to bring an ideal and effective final presentation.</p>\nDo We Need To Decide On A Base Default Typeface To Standardized Test Typefaces Against?\n<p>I would like to make things more complicated. (Remember when I told you this article had some difficult and complex issues?) So as an example, let’s say that we want to test a serif typeface against another serif and then again a sans serif against another sans serif. One would think that one of the two serifs or one of the sans serifs would perform better than the other, right? Well maybe, but not quite. Now, let’s say that we have the previous person testing two serif typefaces and two sans serif typefaces. What would happen if someone else did the same test but then tested their serif and sans serif against a <em>different</em> serif and sans serif typefaces that the 1st person used. Well, the result is simply that two people tested a serif and a sans serif typeface against different serif and sans serif typefaces, and <strong>they are not cross comparable</strong>.</p>\n<p>So, the question is: should we, as a community, decide on base typefaces to test against? So, for a serif, it is quite popular and common in academic journals to test against Times New Roman. So, for sans serif, Arial is again another popular base typeface typically used to test another sans serif against. Then for monospace, Courier?</p>\n<p>Last but not least, we have 2 people previously testing typefaces, but what typographic design and typesetting settings and variables did they use? Once again, even more inconsistency is introduced because they would most definitely test their typefaces with different typographic designs and typesetting settings. Do we need to set a base/default typographic design and typesetting, so everyone tests and measures against the same thing?</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/687b8f58-cabb-40aa-854d-e3a16dd21ebb/4-v3-measuring-performance-typefaces-users-part1.jpg\" /></p>\nThe Difference Between Near-identical Typefaces: Two Brief Discussions\n<p>There are many typefaces, and many of them are very similar or are nearly identical to previous or contemporary versions available. Here are some examples:</p>\n<ul>\n<li>Neue Haas Grotesk (1956), Helvetica (1957), Arial (1982), Bau (2002), Akkurat (2004), Aktiv Grotesk (2010), Acumin (2015), Real (2015);</li>\n<li>Frutiger (1976), Myriad (1992), Monotype SST (2017), Squad (2018), Silta (2018);</li>\n<li>Collis (1993), Novel (2008), Elena (2010), Permian (2011), Lava (2013).</li>\n</ul>\n<p><strong>Note:</strong> <em>For more information, see my article “<a href=\"https://typography.guru/journal/no-more-similiar-typefaces/\">No more new similar typefaces for extended reading, please!</a>”</em></p>\n<p>If we look at a typeface like Garamond, we can see that there are many versions of Garamond — all with slightly different interpretations of what the ultimate or most accurate version of Garamond is. Furthermore, they are all designed for slightly different uses, contexts, and technological choices:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/52d15539-d283-4521-b32f-ccbee74cffa3/5-v3-measuring-performance-typefaces-users-part1.jpg\" /></p>\n<p>Typeface designers and foundries supplying these versions of Garamond say theirs is the best, but which one is right? They were all designed for slightly different contexts and technological times. It would be interesting to find out what the performance differences are between these very similar typefaces.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/38401954-cf48-413e-a815-1dcd02bd77fb/6-v2-measuring-performance-typefaces-users-part1.jpg\" /></p>\n<p>Furthermore, if we compare a typeface like Minion Pro (which is quite robust and sturdy) against a typeface like Monotype Baskerville, we can observe that Minion Pro has more consistent stroke widths and slightly less personality than Monotype Baskerville. In contrast, Monotype Baskerville has more variance in stroke width, with more of a posh and sophisticated personality than Minion Pro. Therefore, how would these differences affect their performance? Perhaps there is no <em>one right answer</em> to these questions.</p>\n<p>I certainly feel, in 2022, that we, as designers, researchers, and academics, have certainly built up some fairly sensible and reasonable conclusions based on previous research and previous arguments over the last years. Nevertheless, the questions seem to remain around — what are the characteristics that make typefaces work a little bit better, and what would be “more advisable?”</p>\nKai Bernau’s Neutral Typeface\n<p>Neutral, a typeface designed by <a href=\"http://kaibernau.com\">Kai Bernau</a>, is an interesting example of how an ideal utopian legible typeface might look and be like. We can see in the image below that Bernau has analyzed the fine and very subtle characteristics that are common in neutral typefaces, such Univers, Helvetica, TheSans, and so on.</p>\n<p>The term “neutral” basically refers to a typeface design that does not say much or does not say anything and that has a very “no style/anonymous” feel and voice — like the color grey. Think of it like speaking to someone with little personality or who has a not-obvious personality. In his design, <a href=\"http://kaibernau.com\">Bernau</a> is attempting to find out what an almost merged letter skeleton of all these neutral typefaces would look like when comparing all these typefaces.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5cc588d0-bc1b-452f-b119-8915e162ef29/7-v2-measuring-performance-typefaces-users-part1.jpg\" /></p>\n<p>Kai Bernau’s Neutral typeface began as a graduation project at KABK (the <a href=\"https://www.kabk.nlRoyal\">Academy of Art, The Hague</a>), taking inspiration from typefaces that seem ageless, remain fresh and relevant even decades after they were designed. His project was constructed based on a set of parameters derived by measuring and averaging a number of popular 20th-century sans serif fonts (like Helvetica, Univers, Frutiger, Meta, and TheSans), trying to design the ultimate “neutral” font. It is a very interesting idea that builds on previous best practices to find an optimal solution. This is much more like the conceptual typeface design that we need to see in the future. For more, see the “<a href=\"https://www.typotheque.com/articles/an-idea-of-a-typeface\">An Idea of a typeface</a>” article by Kai Bernau.</p>\nCan A Utopian Highly Legible Typeface Exist?\n<p>Bernau’s typeface aims for neutrality and utopian legibility. However, if I asked the question: what would the world’s most legible sans serif, serif, or slab serif typeface look like? How much better than a typically good highly legible sans serif, serif, or slab serif typeface would it be? Furthermore, is it even worth the effort? </p>\n<p>Whatever your thoughts are, it is the designer’s job to design things that work and read well. Adding to this conversation, <a href=\"http://sofiebeier.dk\">Sofie Beier</a> (a legibility expert) says:</p>\n<blockquote>“In the history of design, there are many examples of designers proposing an “ideal typeface”. The fact is that there is no optimal typeface style. A thorough literature review shows that typeface legibility varies significantly depending on the reading situation.”<br /><br />— <a href=\"http://sofiebeier.dk\">Sofie Beier</a> in <a href=\"https://readabilitymatters.org/articles/dr-sofie-beier-bringing-together-science-and-typography\">Bringing Together Science And Typography</a></blockquote>\n\n<p>Perhaps, we should consider developing a central list of the elements, research, data, sources, and aspects to create legible and usable typefaces, so we can easily choose? This may lead to better typeface design decisions, choices, and better typefaces in the future.</p>\nChanging The Change: From What To What?\n<p>Another reason why we need to measure typefaces and know how well they work is highlighted by <a href=\"https://au.linkedin.com/in/david-sless-952185\">David Sless</a>, information design pioneer and director of the <em>Communication Research Institute</em> in Australia, in his article “Changing the change: from what to what?”:</p>\n<blockquote>“Change is good. Design is all about change; bringing something into the world that didn’t exist before; changing from an undesirable to a desirable state of affairs; improvement; progress! And now we are even <strong>changing the change</strong>! […]<br /><br />Benchmarking is that part of the design process where you ask how an existing system is performing against agreed performance requirements set at the scoping stage of the design process. Putting the matter simply, if you change something and then claim that the change is an improvement, you need to have some before and after measurements. […]<br /><br />Much design work… is redesign rather than design from scratch. An important part of redesign is to ask: where are we right now? What is the current performance of this design? What is happening in the world now which we don’t want to happen, or we’d like to change? Where do we want to go? What do we want to achieve here? […]<br /><br />So I’m all in favour of change, even <strong>changing the change</strong>. But we need to know what we are changing from. […]<br /><br />Unless we look carefully at what we are doing now before making a change, we might throw out some good bits.”<br /><br />— <a href=\"https://au.linkedin.com/in/david-sless-952185\">David Sless</a></blockquote>\n\n<p>This is one of the reasons we need to measure typefaces and know how well they perform. That way, when we design new ones in the future, we can learn from past data and then use that knowledge in future typefaces, rather than relying on a bit of research and personal self-expression. </p>\n<p>Redesigning typefaces makes us end up in the same place (whether good or bad), and we are not necessarily making and designing better typefaces. Although typeface design provides us with both the aesthetic appeal to meet the functional needs, it is the functional need and its functional aspect that is frequently missing. </p>\n<p>With the thoughts mentioned above, I would like to raise another debate, because I know that typographic discussions and debates are usually beneficial and productive for all involved.</p>\nAre Typefaces Tools, Software, Objects, Products Or What?\n<p>This is a question that is not easily answered. It depends on what position you decide to take. Kris Sowersby, director of <a href=\"https://klim.co.nz\">Klim Type Foundry</a> argues that typefaces are not tools in his article “<a href=\"https://klim.co.nz/blog/a-typeface-is-not-a-tool/\">A typeface is not a tool</a>”:</p>\n<blockquote>“In theory, designers could perform all of their typesetting jobs with the same one or two typefaces. But they don’t. I can almost guarantee this comes down to aesthetics. They choose a typeface for its emotive, visceral and visual qualities — how it looks and feels. Designers don’t use typefaces like a builder uses a hammer.<br /><br />The function of a typeface is to communicate visually and culturally.”<br /><br />— Kris Sowersby</blockquote>\n\n<p>Though Sowersby points out a functional aspect, he makes no mention that typefaces are used to achieve certain and precise responses and effects from users’ behaviors and emotional responses. For example, I might choose typefaces specifically because of their legibility — when a typeface is considered legible and easy-to-read by people with less-than-good eyesight. And so a well-designed typeface (or tool) is crucial.</p>\n<p>Another reason I may choose a typeface is to bring a certain “more ideal” and to bring a “more specific” response and behavior from people. So, I may also choose a typeface as a tool for better communication with specific audiences. This is similar to why we choose a hammer over another, even though they all do the same job. There are 100s of different types of hammers, but builders do seem to have an “emotional favorite.”</p>\n<p>In addition, typefaces can be more or less legible on different screens and monitor resolutions because they can be rendered with varying degrees of quality and sharpness.</p>\n<p>Let us move on to a more precise and probably more important aspect, and that is testing data value.</p>\nThe Two Types Of Testing Data: “Subjective” And “Objective”\n<p>When testing, there are two types of testing data: subjective (meaning mainly coming from a personal view and opinion) and objective (coming from a result from reality or the ability to do or not do something). They are valuable in their own ways. However, an objective measurement may be more desirable. It is <em>important</em> to know the difference between the two. Below is a brief description of both as it applies to our topic: </p>\n<ul>\n<li><strong>A subjective measure:</strong><br />A user says: “I can read this typeface better.” This may be the case and what the person feels. However, if the measurement, in this case, is “better,” then the questions are: how much better, what kind of a measure and how accurate a measure is “better,” and how much better (than what) is it? However, what one person likes may not be what another one likes. Is it better because I said so? They may not be able to describe or know why they like it, but they just say: “I like it.” Because this measure is based on what the person feels, it is not accurately measurable.  </li>\n<li><strong>An objective measure:</strong><br />A user identified a letter correctly and within a certain timeframe. The data is either correct or incorrect, they could or could not do it, and they did or did not do it in a measurable recorded time span.</li>\n</ul>\n<p><a href=\"https://www.microsoft.com/en-us/research/people/kevlar/\">Kevin Larson</a>, principal researcher on Microsoft’s Advanced Reading Technologies team, explains: </p>\n<blockquote>“While I generally agree with you on the importance of objective data, and most of my work has collected reading speed measures of one kind or another, I think there can be interesting subjective data.”<br /><br />— <a href=\"https://www.microsoft.com/en-us/research/people/kevlar/\">Kevin Larson</a></blockquote>\n\n<p>David Sless also states in his article “Choosing the right method for testing:”</p>\n<blockquote>“The first is that inexperienced, untrained, or misguided information designers ask the wrong questions: what do people think of my designs? Which of my designs do they prefer? What must my artifact look like? What information must my artifact contain? The second reason is that asking the wrong questions about the design, leads inevitably to certain ways of asking questions — methods of testing which give inadequate answers.”<br /><br />— <a href=\"https://au.linkedin.com/in/david-sless-952185\">David Sless</a></blockquote>\n\n<p>David Sless continues the discussion by adding [slightly reworded and edited by me]:</p>\n<blockquote>“Attitude and opinion surveys, preference tests, expert opinion, and content-based design, are based on the wrong questions and are highly subjective because they come from people’s views, knowledge build-ups and preferences… The right, or much better, more easily measurable and more accurate question, is based on user performance, setting them tasks to do, then using diagnostic testing to see if they can or cannot do the tasks, and making any notes, possibly recording how long it took them to do it. A far more useful question to ask before you design a new information artifact or redesign an existing one is: what do I want people to be able to do with this artifact?”</blockquote>\n\n<p>In summary, the most important question is: what do we want the users to do? Based on the previous examples and discussions in this article, we can see that not all data or information gained is necessarily useful or accurate.</p>\nWhat Do We Want People To Do With Highly Legible Typefaces?\n<p>Consulting Sless’ article “Changing the change: from what to what?” again:</p>\n<blockquote>“A far more useful question to ask before you design a new information artifact or redesign an existing one is: what do I want people to be able to do with this artifact?”<br /><br />— <a href=\"https://au.linkedin.com/in/david-sless-952185\">David Sless</a></blockquote>\n\n<p>Let’s try to outline what we want people to do with highly legible typefaces for extended reading, like reading large amounts of information, effectively and precisely:</p>\n<ul>\n<li>We want them to be able to recognize what each letter, word, and symbol is;</li>\n<li>We want the typeface to reflect and fit the content and message for the typeface to enhance and support it;</li>\n<li>We want them to understand, absorb and comprehend as much of the information as possible;</li>\n<li>We want to encourage, sustain and enable high motivation levels when looking at and reading the text;</li>\n<li>We want them to maybe form a bond with the text and typography, feeling that the information is high quality, respectful and worthy;</li>\n<li>We want to tire them as little as possible;</li>\n<li>We want to provide typography in the most efficient way, such as leading, tracking, kerning, typeface size, color, line length, hyphenation, capitalization, and word spacing;</li>\n<li>We want different categories of people — like people with vision impairments, people with low vision or very bad eyesight, people with dyslexia or aphasia, or who have specific letter requirements, like children learning to read — to at least have letters and symbols designed to support or fit their needs as best as possible. We want to allow accessibility via OpenType or stylistic options with the typeface, so they are available to use if needed. These points could be extended to language support as well.</li>\n</ul>\nMore Coming Up In Part 2\n<p>Let us dive into more of these amazing complex issues (as I said they would be) in the second part of this article — <a href=\"https://www.smashingmagazine.com/2022/06/measuring-performance-typefaces-users-part2/\">Measuring The Performance Of Typefaces For Users (Part 2)</a>. We will look deeply at how we can test typefaces, how to get the best out of every aspect of the process, and more!</p>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/05/micro-typography-space-kern-punctuation-marks-symbols/\">Micro-Typography: How To Space And Kern Punctuation Marks And Other Symbols</a>,” Thomas Bohm</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2018/06/reference-guide-typography-mobile-web-design/\">A Reference Guide For Typography In Mobile Web Design</a>,” Suzanne Scacca</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2019/07/gorgeous-free-open-source-typefaces/\">7 Gorgeous Free And Open-Source Typefaces And When To Use Them</a>,” Noemi Stauffer</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2013/12/freebie-exo-2-0-geometric-sans-serif-font/\">Exo 2.0, A Contemporary Geometric Sans Serif Font (Freebie)</a>,” Vitaly Friedman</li>\n</ul>",
      "content_text": "Our focus is on typefaces for reading large amounts of text and information in the most efficient, legible, pleasurable, comprehensible, and effective way possible. For instance, typefaces used for a novel, an academic paper in a journal, or a lengthy online article like this one that uses the Elena typeface, that you are reading now on this webpage. The questions that we will explore are:\n\nHow well do typefaces for extended reading actually work?\nHow well does a typeface work and perform against another similar typeface?\nHow would we test to see if there is any difference between a good sans serif and a serif typeface with users?\nWhat would the world’s most ideal, best practice and design research-driven highly legible serif, sans serif, and slab serif possibly be like? What characteristics and themes would be most advisable, and do we need a central public list of aspects and features?\nThere is both the aesthetic and functional aspect to a typeface, but what is the functional aspect, and how can it be investigated and measured?\nHow good is a new typeface, and how good is it compared to a similar typeface designed in previous years?\n\nShould typefaces be measured? There is no simple answer. The short answer: yes. The long answer: it is a difficult and imprecise task. We will discuss the pros and the cons, and I will show you what things are involved and how we could go about doing it.\n\nA Very Short Introduction To Typefaces\nFor 100s of years, we have enjoyed using typefaces. These compiled systems for letters and symbols, which are representations of sounds and information, get a lot of use and are a large part of graphic communication.\nThe first movable type machine, and therefore the first printing press, was created by a man named Bi Sheng, who lived in Yingshan, China, from what we believe to be 970–1051 AD — over four full centuries before Johannes Gutenberg was even born. The moveable type, sculptured in a lead-based alloy — which is essentially metal blocks of letters and symbols that can be moved, arranged, and used for mass printing — was Johannes Gutenberg’s contribution. Fast forward to the early 1960s, phototypesetting systems appeared. These devices consisted of glass disks (one per typeface) that spun in front of a light source, which exposed characters onto light-sensitive paper. Later on, in the 1980s, type started to be used in a digital context in computers. And today, we still have type in a digital context, but it travels through cables, wirelessly on smartphones, and in virtual reality glasses in 3D.\nThere are many different classifications of typefaces. To name a few: sans serif, serif, slab serif, script, handwritten, display, ornamental, stencil, and monospace. In a way, technology also created new typeface classifications. Today, we even have mixed typefaces with elements of serif and sans serif, such as the Luc(as) de Groot’s typeface TheMix. This diversity adds to the difficulty and complexity of defining and testing typefaces.\nReasons To Measure The Performance Of Typefaces?\nBecause technology has made it possible to design typefaces easier than ever before, we seem to be reinventing “different types of wheels” that already get the job done. However, rather than reinventing these typefaces, maybe we can get some objective measures, learn from what works and what does not work, and then design objectively better wheels (typefaces). \nIf your aim is to produce a new typeface based on historical exemplars, tradition, or design, then fine, this is what you will be aiming for. Alternatively, if you want to do something new and expressive, or that has never been done before, then fine, of course. However, some contexts, situations, and users need and demand highly functional typefaces. \nAs I briefly mentioned, measuring a typeface’s effectiveness is difficult. Since many new typefaces are not supplied with any objective concrete testing data, how do we determine how well they work and where they succeed or fail?\nShould We Measure The Typeface Alone, And/Or The Context And Environment That The Typeface Is Used In?\nWhen considering the questions above, we can see that this is a large and complex issue. There are many different types of information, situations in which information is used, types of environments, and there are many different categories of people. Here are some extreme examples:\n\nA person who is elderly trying to read road signs, driving home at night;\nAn accountant doing a large amount of numerical calculations for a million-pound/dollar company, needing to turn around the work in 30 minutes;\nA young person learning to read for the first time, sitting in the back of a car full of people on bumpy roads;\nA person with dyslexia trying to read and complete their evening class assignment.\n\nMeasuring Typefaces And The Resulting Performance Data\nOne of the reasons why measuring a typeface’s effectiveness is difficult is that we cannot accurately measure what goes on in people’s minds. Many factors are invisible, as Paul Luna — a professor at the University of Reading’s Department of Typography & Graphic Communication — mentions in this video Paul Luna on the typographer’s task. In addition, Robert Waller, information designer at the Simplification Centre states:\n“Legibility research has a long history (going back to the 1870s). A wide range of issues has been studied, including type size, line spacing, line length, typestyle, serifs, and more. However, as Buckingham in New data on the typography of textbooks pointed out relatively early on, these factors interact in complex ways, apparently unrecognizable by many researchers. Indeed, in recent times a consensus has grown that the interaction of variables in type design is so complex that few generalizable findings can be found (see a longer review in Robert Waller’s “Typography and discourse”).”— Robert Waller in Comparing Typefaces For Airport Signs \n\n\nFurthermore, Ralf Hermann, director of Typography.Guru in his article says:\n“Doing scientific studies to test which typefaces work best in this regard, is almost impossible to do. For a proper test setup you would need to modify one parameter while keeping every other parameter unchanged. But setting a letter or word in different typefaces can not be considered as “changing one parameter”, because a typeface consists of dozens of relevant parameters like x-height, weight, contrast, width — just to name a few. So scientific tests for typeface legibility are often full of flaws. Very often the typefaces are set at the same point size, but as every graphic designer should know, the point size does not reflect the actual size of the letters in print or on-screen. So if you come across a scientific legibility study that compares typefaces set at the same point size, don’t even bother to read on!”— Ralf Hermann at What Makes Letters Legible? \n\n\nThe observations expressed in these quotes demonstrate that testing typefaces involves many complex factors. Because of this complexity, it has to be carefully controlled and modified, but it may not even be worth the effort.\nConsistency And Variables\nWhen testing typefaces or a selection of typefaces against another, we need to keep the typographic design parameters and variables the same, so we do not introduce or change the previously tested type settings. One example is the difference between the typefaces’ x-height’s (the height of a lowercase x) of any two typefaces we are testing. It is unlikely that they will be the same, as x-heights differ greatly. Thus, one of the two typeface x-height’s will seem to be larger in size, although it may be the same point size in the software. I will show you more about typographic variables under the section “Specific Typographic Design Variables Affecting Performance” in the second part of this article.\nRobert Waller mentions in “The Clear Print standard: arguments for a flexible approach” that “although both point size and x-height are specified, it is the point size (pt) that is most commonly quoted — and point size is a notoriously imprecise measure.” It is, however, more effective and accurate to set an x-height measurement and set the typefaces being compared to that same x-height measurement. The x-height using point sizes actually results in different sizes — and does not look inconsistent between different typefaces.\n\nNotice on the 1st line that we can see that both typefaces are set to 26 pt in Adobe InDesign. However, if you look at the tops of the “erdana” you can see that they go slightly above the line, so the Verdana typeface is, in essence, larger than the Info Display typeface, even when they are both typeset at 26 points. On the 2nd line, both typefaces have been typeset to a consistent and accurate measurement of an x-height of 5.5 mm. Notice that while the x-height is the same for both typefaces on the 2nd line, it gives a different point size for each typeface. This is why point size is not an accurate way to measure typeface size and for testing and comparing two or more typefaces.\nAdditionally, how you use and typeset the typeface in the actual typographic design and layout (line length, typeface size, color, spacing, leading, and so on) is probably more important than the actual typeface used. Thus, you could use one of the world’s most legible typefaces, but if you typeset it with a leading of -7 points and a line length of 100 characters, it would be rendered nearly useless.\n\nAs you can see, we can’t use a singular factor to measure typefaces. Instead, we need to address multiple factors within the design system. They all have to work well together to bring an ideal and effective final presentation.\nDo We Need To Decide On A Base Default Typeface To Standardized Test Typefaces Against?\nI would like to make things more complicated. (Remember when I told you this article had some difficult and complex issues?) So as an example, let’s say that we want to test a serif typeface against another serif and then again a sans serif against another sans serif. One would think that one of the two serifs or one of the sans serifs would perform better than the other, right? Well maybe, but not quite. Now, let’s say that we have the previous person testing two serif typefaces and two sans serif typefaces. What would happen if someone else did the same test but then tested their serif and sans serif against a different serif and sans serif typefaces that the 1st person used. Well, the result is simply that two people tested a serif and a sans serif typeface against different serif and sans serif typefaces, and they are not cross comparable.\nSo, the question is: should we, as a community, decide on base typefaces to test against? So, for a serif, it is quite popular and common in academic journals to test against Times New Roman. So, for sans serif, Arial is again another popular base typeface typically used to test another sans serif against. Then for monospace, Courier?\nLast but not least, we have 2 people previously testing typefaces, but what typographic design and typesetting settings and variables did they use? Once again, even more inconsistency is introduced because they would most definitely test their typefaces with different typographic designs and typesetting settings. Do we need to set a base/default typographic design and typesetting, so everyone tests and measures against the same thing?\n\nThe Difference Between Near-identical Typefaces: Two Brief Discussions\nThere are many typefaces, and many of them are very similar or are nearly identical to previous or contemporary versions available. Here are some examples:\n\nNeue Haas Grotesk (1956), Helvetica (1957), Arial (1982), Bau (2002), Akkurat (2004), Aktiv Grotesk (2010), Acumin (2015), Real (2015);\nFrutiger (1976), Myriad (1992), Monotype SST (2017), Squad (2018), Silta (2018);\nCollis (1993), Novel (2008), Elena (2010), Permian (2011), Lava (2013).\n\nNote: For more information, see my article “No more new similar typefaces for extended reading, please!”\nIf we look at a typeface like Garamond, we can see that there are many versions of Garamond — all with slightly different interpretations of what the ultimate or most accurate version of Garamond is. Furthermore, they are all designed for slightly different uses, contexts, and technological choices:\n\nTypeface designers and foundries supplying these versions of Garamond say theirs is the best, but which one is right? They were all designed for slightly different contexts and technological times. It would be interesting to find out what the performance differences are between these very similar typefaces.\n\nFurthermore, if we compare a typeface like Minion Pro (which is quite robust and sturdy) against a typeface like Monotype Baskerville, we can observe that Minion Pro has more consistent stroke widths and slightly less personality than Monotype Baskerville. In contrast, Monotype Baskerville has more variance in stroke width, with more of a posh and sophisticated personality than Minion Pro. Therefore, how would these differences affect their performance? Perhaps there is no one right answer to these questions.\nI certainly feel, in 2022, that we, as designers, researchers, and academics, have certainly built up some fairly sensible and reasonable conclusions based on previous research and previous arguments over the last years. Nevertheless, the questions seem to remain around — what are the characteristics that make typefaces work a little bit better, and what would be “more advisable?”\nKai Bernau’s Neutral Typeface\nNeutral, a typeface designed by Kai Bernau, is an interesting example of how an ideal utopian legible typeface might look and be like. We can see in the image below that Bernau has analyzed the fine and very subtle characteristics that are common in neutral typefaces, such Univers, Helvetica, TheSans, and so on.\nThe term “neutral” basically refers to a typeface design that does not say much or does not say anything and that has a very “no style/anonymous” feel and voice — like the color grey. Think of it like speaking to someone with little personality or who has a not-obvious personality. In his design, Bernau is attempting to find out what an almost merged letter skeleton of all these neutral typefaces would look like when comparing all these typefaces.\n\nKai Bernau’s Neutral typeface began as a graduation project at KABK (the Academy of Art, The Hague), taking inspiration from typefaces that seem ageless, remain fresh and relevant even decades after they were designed. His project was constructed based on a set of parameters derived by measuring and averaging a number of popular 20th-century sans serif fonts (like Helvetica, Univers, Frutiger, Meta, and TheSans), trying to design the ultimate “neutral” font. It is a very interesting idea that builds on previous best practices to find an optimal solution. This is much more like the conceptual typeface design that we need to see in the future. For more, see the “An Idea of a typeface” article by Kai Bernau.\nCan A Utopian Highly Legible Typeface Exist?\nBernau’s typeface aims for neutrality and utopian legibility. However, if I asked the question: what would the world’s most legible sans serif, serif, or slab serif typeface look like? How much better than a typically good highly legible sans serif, serif, or slab serif typeface would it be? Furthermore, is it even worth the effort? \nWhatever your thoughts are, it is the designer’s job to design things that work and read well. Adding to this conversation, Sofie Beier (a legibility expert) says:\n“In the history of design, there are many examples of designers proposing an “ideal typeface”. The fact is that there is no optimal typeface style. A thorough literature review shows that typeface legibility varies significantly depending on the reading situation.”— Sofie Beier in Bringing Together Science And Typography\n\nPerhaps, we should consider developing a central list of the elements, research, data, sources, and aspects to create legible and usable typefaces, so we can easily choose? This may lead to better typeface design decisions, choices, and better typefaces in the future.\nChanging The Change: From What To What?\nAnother reason why we need to measure typefaces and know how well they work is highlighted by David Sless, information design pioneer and director of the Communication Research Institute in Australia, in his article “Changing the change: from what to what?”:\n“Change is good. Design is all about change; bringing something into the world that didn’t exist before; changing from an undesirable to a desirable state of affairs; improvement; progress! And now we are even changing the change! […]Benchmarking is that part of the design process where you ask how an existing system is performing against agreed performance requirements set at the scoping stage of the design process. Putting the matter simply, if you change something and then claim that the change is an improvement, you need to have some before and after measurements. […]Much design work… is redesign rather than design from scratch. An important part of redesign is to ask: where are we right now? What is the current performance of this design? What is happening in the world now which we don’t want to happen, or we’d like to change? Where do we want to go? What do we want to achieve here? […]So I’m all in favour of change, even changing the change. But we need to know what we are changing from. […]Unless we look carefully at what we are doing now before making a change, we might throw out some good bits.”— David Sless\n\nThis is one of the reasons we need to measure typefaces and know how well they perform. That way, when we design new ones in the future, we can learn from past data and then use that knowledge in future typefaces, rather than relying on a bit of research and personal self-expression. \nRedesigning typefaces makes us end up in the same place (whether good or bad), and we are not necessarily making and designing better typefaces. Although typeface design provides us with both the aesthetic appeal to meet the functional needs, it is the functional need and its functional aspect that is frequently missing. \nWith the thoughts mentioned above, I would like to raise another debate, because I know that typographic discussions and debates are usually beneficial and productive for all involved.\nAre Typefaces Tools, Software, Objects, Products Or What?\nThis is a question that is not easily answered. It depends on what position you decide to take. Kris Sowersby, director of Klim Type Foundry argues that typefaces are not tools in his article “A typeface is not a tool”:\n“In theory, designers could perform all of their typesetting jobs with the same one or two typefaces. But they don’t. I can almost guarantee this comes down to aesthetics. They choose a typeface for its emotive, visceral and visual qualities — how it looks and feels. Designers don’t use typefaces like a builder uses a hammer.The function of a typeface is to communicate visually and culturally.”— Kris Sowersby\n\nThough Sowersby points out a functional aspect, he makes no mention that typefaces are used to achieve certain and precise responses and effects from users’ behaviors and emotional responses. For example, I might choose typefaces specifically because of their legibility — when a typeface is considered legible and easy-to-read by people with less-than-good eyesight. And so a well-designed typeface (or tool) is crucial.\nAnother reason I may choose a typeface is to bring a certain “more ideal” and to bring a “more specific” response and behavior from people. So, I may also choose a typeface as a tool for better communication with specific audiences. This is similar to why we choose a hammer over another, even though they all do the same job. There are 100s of different types of hammers, but builders do seem to have an “emotional favorite.”\nIn addition, typefaces can be more or less legible on different screens and monitor resolutions because they can be rendered with varying degrees of quality and sharpness.\nLet us move on to a more precise and probably more important aspect, and that is testing data value.\nThe Two Types Of Testing Data: “Subjective” And “Objective”\nWhen testing, there are two types of testing data: subjective (meaning mainly coming from a personal view and opinion) and objective (coming from a result from reality or the ability to do or not do something). They are valuable in their own ways. However, an objective measurement may be more desirable. It is important to know the difference between the two. Below is a brief description of both as it applies to our topic: \n\nA subjective measure:A user says: “I can read this typeface better.” This may be the case and what the person feels. However, if the measurement, in this case, is “better,” then the questions are: how much better, what kind of a measure and how accurate a measure is “better,” and how much better (than what) is it? However, what one person likes may not be what another one likes. Is it better because I said so? They may not be able to describe or know why they like it, but they just say: “I like it.” Because this measure is based on what the person feels, it is not accurately measurable.  \nAn objective measure:A user identified a letter correctly and within a certain timeframe. The data is either correct or incorrect, they could or could not do it, and they did or did not do it in a measurable recorded time span.\n\nKevin Larson, principal researcher on Microsoft’s Advanced Reading Technologies team, explains: \n“While I generally agree with you on the importance of objective data, and most of my work has collected reading speed measures of one kind or another, I think there can be interesting subjective data.”— Kevin Larson\n\nDavid Sless also states in his article “Choosing the right method for testing:”\n“The first is that inexperienced, untrained, or misguided information designers ask the wrong questions: what do people think of my designs? Which of my designs do they prefer? What must my artifact look like? What information must my artifact contain? The second reason is that asking the wrong questions about the design, leads inevitably to certain ways of asking questions — methods of testing which give inadequate answers.”— David Sless\n\nDavid Sless continues the discussion by adding [slightly reworded and edited by me]:\n“Attitude and opinion surveys, preference tests, expert opinion, and content-based design, are based on the wrong questions and are highly subjective because they come from people’s views, knowledge build-ups and preferences… The right, or much better, more easily measurable and more accurate question, is based on user performance, setting them tasks to do, then using diagnostic testing to see if they can or cannot do the tasks, and making any notes, possibly recording how long it took them to do it. A far more useful question to ask before you design a new information artifact or redesign an existing one is: what do I want people to be able to do with this artifact?”\n\nIn summary, the most important question is: what do we want the users to do? Based on the previous examples and discussions in this article, we can see that not all data or information gained is necessarily useful or accurate.\nWhat Do We Want People To Do With Highly Legible Typefaces?\nConsulting Sless’ article “Changing the change: from what to what?” again:\n“A far more useful question to ask before you design a new information artifact or redesign an existing one is: what do I want people to be able to do with this artifact?”— David Sless\n\nLet’s try to outline what we want people to do with highly legible typefaces for extended reading, like reading large amounts of information, effectively and precisely:\n\nWe want them to be able to recognize what each letter, word, and symbol is;\nWe want the typeface to reflect and fit the content and message for the typeface to enhance and support it;\nWe want them to understand, absorb and comprehend as much of the information as possible;\nWe want to encourage, sustain and enable high motivation levels when looking at and reading the text;\nWe want them to maybe form a bond with the text and typography, feeling that the information is high quality, respectful and worthy;\nWe want to tire them as little as possible;\nWe want to provide typography in the most efficient way, such as leading, tracking, kerning, typeface size, color, line length, hyphenation, capitalization, and word spacing;\nWe want different categories of people — like people with vision impairments, people with low vision or very bad eyesight, people with dyslexia or aphasia, or who have specific letter requirements, like children learning to read — to at least have letters and symbols designed to support or fit their needs as best as possible. We want to allow accessibility via OpenType or stylistic options with the typeface, so they are available to use if needed. These points could be extended to language support as well.\n\nMore Coming Up In Part 2\nLet us dive into more of these amazing complex issues (as I said they would be) in the second part of this article — Measuring The Performance Of Typefaces For Users (Part 2). We will look deeply at how we can test typefaces, how to get the best out of every aspect of the process, and more!\nFurther Reading on Smashing Magazine\n\n“Micro-Typography: How To Space And Kern Punctuation Marks And Other Symbols,” Thomas Bohm\n“A Reference Guide For Typography In Mobile Web Design,” Suzanne Scacca\n“7 Gorgeous Free And Open-Source Typefaces And When To Use Them,” Noemi Stauffer\n“Exo 2.0, A Contemporary Geometric Sans Serif Font (Freebie),” Vitaly Friedman\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/63e5266a-c3c0-42f8-9d26-79a729c3db3f/measuring-performance-typaces-users-part1-card.jpg",
      "date_published": "2022-06-03T10:00:00.000Z",
      "date_modified": "2022-06-03T10:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/build-group-chat-app-vanillajs-twilio-nodejs/",
      "url": "https://smashingmagazine.com/2022/06/build-group-chat-app-vanillajs-twilio-nodejs/",
      "title": "How To Build A Group Chat App With Vanilla JS, Twilio And Node.js",
      "summary": "In this tutorial, you will learn how to create a group chat app. You will build a backend app using Node.js that will make group chats, authorize chat participants, and maintain sessions for them.",
      "content_html": "<p>Chat is becoming an increasingly popular communication medium in both business and social contexts. Businesses use chat for customer and employee intra-company communication like with <a href=\"https://slack.com/\">Slack</a>, <a href=\"https://www.microsoft.com/en-us/microsoft-teams/group-chat-software\">Microsoft Teams</a>, <a href=\"https://www.chanty.com/\">Chanty</a>, <a href=\"https://www.hubspot.com/products/crm/live-chat\">HubSpot Live Chat</a>, <a href=\"https://www.helpscout.com/\">Help Scout</a>, etc. Most social networks and communication apps also offer chat as an option by default, like on Instagram, Facebook, Reddit, and Twitter. Other apps like Discord, Whatsapp, and Telegram are mostly chat-based, with group chats being one of their main functionalities. </p>\n<p>While there exist numerous products to facilitate chat, you may need a custom-tailored solution for your site that fits your particular communication needs. For example, many of these products are stand-alone apps and may not be able to integrate within your own site. Having your users leave your website to chat may not be the greatest option as it can affect user experience and conversion. On the flip side, building a chat app from scratch can be a daunting and sometimes overwhelming task. However, by using APIs like <a href=\"https://www.twilio.com/conversations-api\">Twilio Conversations</a> you can simplify the process of creating them. These communication APIs handle group creation, adding participants, sending messages, notifications, among other important chat functions. Backend apps that use these APIs only have to handle authentication and make calls to these APIs. Front-end apps then display conversations, groups, and messages from the backend. </p>\n<p>In this tutorial, you will learn how to create a group chat app using the <a href=\"https://www.twilio.com/conversations-api\">Twilio Conversations API</a>. The front end for this app will be built using HTML, CSS, and Vanilla JavaScript. It will allow users to create group chats, send invites, login, as well as send and receive messages. The backend will be a Node.js app. It will provide authentication tokens for chat invitees and manage chat creation. </p>\nPrerequisites\n<p>Before you can start this tutorial, you need to have the following:</p>\n<ul>\n<li><a href=\"https://nodejs.org/en/\">Node.js</a> installed. You’ll use it primarily for the backend app and to install dependencies in the front-end app.<br /><em>You can get it using a pre-built installer available on the <a href=\"https://nodejs.org/en/download/\">Node.js downloads page</a>.</em></li>\n<li>A <a href=\"https://www.twilio.com/\">Twilio</a> account.<br /><em>You can create one <a href=\"https://www.twilio.com/try-twilio\">on the Twilio website at this link</a>.</em></li>\n<li><a href=\"https://www.npmjs.com/package/http-server\"><code>http-server</code></a> to serve the front-end app.<br /><em>You can install it by running <code>npm i -g http-server</code>. You can also run it with <code>npx http-server</code> for one-off runs.</em></li>\n<li><a href=\"https://www.mongodb.com/\">MongoDB</a> for session storage in the backend app.<br /><em>Its <a href=\"https://docs.mongodb.com/manual/installation/\">installation page</a> has a detailed guide on how to get it running.</em></li>\n</ul>\nThe Backend App\n<p>To send chat messages using Twilio API, you need a <strong>conversation</strong>. Chat messages are sent and received within a conversation. The people sending the messages are called <strong>participants</strong>. A participant can only send a message within a conversation if they are added to it. Both conversations and participants are created using the Twilio API. The backend app will perform this function.</p>\n<p>A participant needs an <strong><a href=\"https://www.twilio.com/docs/iam/access-tokens#token-anatomy\">access token</a></strong> to send a message and get their subscribed conversations. The front-end portion of this project will use this access token. The backend app creates the token and sends it to the frontend. There it will be used to load conversations and messages. </p>\n<h3>Project Starter</h3>\n<p>You’ll call the backend app <code>twilio-chat-server</code>. <a href=\"https://github.com/zaracooper/twilio-chat-server\">A scaffolded project starter for it is available on Github</a>. To clone the project and get the starter, run:</p>\n<pre><code>git clone https://github.com/zaracooper/twilio-chat-server.git\ncd twilio-chat-server\ngit checkout starter</code></pre>\n\n<p>The backend app takes this structure:</p>\n<pre><code>.\n├── app.js\n├── config/\n├── controllers/\n├── package.json\n├── routes/\n└── utils/</code></pre>\n\n<p>To run the app, you’ll use the <code>node index.js</code> command. </p>\n<h3>Dependencies</h3>\n<p>The backend app needs 8 dependencies. You can install them by running:</p>\n<pre><code>npm i </code></pre>\n\n<p>Here’s a list of each of the dependencies:</p>\n<ul>\n<li><code>connect-mongo</code> connects to MongoDB, which you’ll use as a session store;</li>\n<li><code>cors</code> handles <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\">CORS</a>;</li>\n<li><code>dotenv</code> loads environment variables from the <code>.env</code> file that you will create in a later step;</li>\n<li><code>express</code> is the web framework you’ll use for the backend;</li>\n<li><code>express-session</code> provides middleware to handle session data;</li>\n<li><code>http-errors</code> helps create server errors;</li>\n<li><code>morgan</code> handles logging;</li>\n<li><code>twilio</code> creates the Twilio client, generates tokens, creates conversations, and adds participants.</li>\n</ul>\n<h3>Configuration</h3>\n<p>The <code>config</code> folder is responsible for loading configuration from environment variables. The configuration is grouped into three categories: configuration for CORS, Twilio, and the MongoDB session DB. When the environment is <code>development</code>, you will load <code>config</code> from the <code>.env</code> file using <code>dotenv</code>.</p>\n<p>Start by creating the <code>.env</code> file on the terminal. This file is already added to the <code>.gitignore</code> file to prevent the sensitive values it contains from being checked into the repository.</p>\n<pre><code>touch .env</code></pre>\n\n<p>Here’s what your <code>.env</code> should look like:</p>\n<pre><code># Session DB Config\nSESSION_DB_HOST=XXXX\nSESSION_DB_USER=XXXX\nSESSION_DB_PASS=XXXX\nSESSION_DB_PORT=XXXX\nSESSION_DB_NAME=XXXX\nSESSION_DB_SECRET=XXXX\n\n# Twilio Config\nTWILIO_ACCOUNT_SID=XXXX\nTWILIO_AUTH_TOKEN=XXXX\nTWILIO_API_KEY=XXXX\nTWILIO_API_SECRET=XXXX\n\n# CORS Client Config\nCORS_CLIENT_DOMAIN=XXXX</code></pre>\n\n<p>You can <a href=\"https://docs.mongodb.com/manual/tutorial/create-users/\">learn how to create a user for your session DB from this MongoDB manual entry</a>. Once you create a session database and a user who can write to it, you can fill the <code>SESSION_DB_USER</code>, <code>SESSION_DB_PASS</code>, and <code>SESSION_DB_NAME</code> values. If you’re running a local instance of MongoDB, the <code>SESSION_DB_HOST</code> would be <code>localhost</code>, and the <code>SESSION_DB_PORT</code> usually is <code>27017</code>. The <code>SESSION_DB_SECRET</code> is <a href=\"https://github.com/expressjs/session#secret\">used by express-session to sign the session ID cookie</a>, and it can be any secret string you set. </p>\n<p>In the next step, you will get credentials from the <a href=\"https://console.twilio.com\">Twilio Console</a>. The credentials should be assigned to the variables with the <code>TWILIO_</code> prefix. During local development, the front-end client will run on <a href=\"http://localhost:3000\">http://localhost:3000</a>. So, you can use this value for the <code>CORS_CLIENT_DOMAIN</code> environment variable.   </p>\n<p>Add the following code to <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/config/index.js\"><code>config/index.js</code></a> to load environment variables. </p>\n<pre><code>import dotenv from 'dotenv';\n\nif (process.env.NODE_ENV == 'development') {\n    dotenv.config();\n}\n\nconst corsClient = {\n    domain: process.env.CORS_CLIENT_DOMAIN\n};\n\nconst sessionDB = {\n    host: process.env.SESSION_DB_HOST,\n    user: process.env.SESSION_DB_USER,\n    pass: process.env.SESSION_DB_PASS,\n    port: process.env.SESSION_DB_PORT,\n    name: process.env.SESSION_DB_NAME,\n    secret: process.env.SESSION_DB_SECRET\n};\n\nconst twilioConfig = {\n    accountSid: process.env.TWILIO_ACCOUNT_SID,\n    authToken: process.env.TWILIO_AUTH_TOKEN,\n    apiKey: process.env.TWILIO_API_KEY,\n    apiSecret: process.env.TWILIO_API_SECRET\n};\n\nconst port = process.env.PORT || '8000';\n\nexport { corsClient, port, sessionDB, twilioConfig };</code></pre>\n\n<p>The environment variables are grouped into categories based on what they do. Each of the configuration categories has its own object variable, and they are all exported for use in other parts of the app.</p>\n<h3>Getting Twilio Credentials From the Console</h3>\n<p>To build this project, you’ll need four different Twilio credentials: an <strong>Account SID</strong>, an <strong>Auth Token</strong>, an <strong>API key</strong>, and an <strong>API secret</strong>. In the console, on the <em><a href=\"https://console.twilio.com/us1/account/manage-account/general-settings\">General Settings page</a></em>, scroll down to the <strong>API Credentials</strong> section. This is where you will find your <strong>Account SID</strong> and <strong>Auth Token</strong>. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/dd939f57-e82b-4fb8-bf3f-fb886754803d/3-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<p>To get an <strong>API Key</strong> and <strong>Secret</strong>, go to the <a href=\"https://console.twilio.com/us1/account/keys-credentials/api-keys\"><strong>API Keys page</strong></a>. You can see it in the screenshot below. Click the + button to go to the <strong>New API Key page</strong>. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c4a13145-8b87-4f8d-8aa7-77c70ec69634/10-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<p>On this page, add a key name and leave the <code>KEY TYPE</code> as <code>Standard</code>, then click Create API Key. Copy the API key and secret. You will add all these credentials in a <code>.env</code> file as you shall see in subsequent steps.  </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ca88a2e6-d649-4599-9858-12c7a4f2d749/8-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<h3>Utils</h3>\n<p>The backend app needs two utility functions. One will create a token, and the other will wrap async controllers and handle errors for them.</p>\n<p>In <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/utils/token.js\"><code>utils/token.js</code></a>, add the following code to create a function called <code>createToken</code> that will generate Twilio access tokens:</p>\n<pre><code>import { twilioConfig } from '../config/index.js';\nimport twilio from 'twilio';\n\nfunction createToken(username, serviceSid) {\n    const AccessToken = twilio.jwt.AccessToken;\n    const ChatGrant = AccessToken.ChatGrant;\n\n    const token = new AccessToken(\n        twilioConfig.accountSid,\n        twilioConfig.apiKey,\n        twilioConfig.apiSecret,\n        { identity: username }\n    );\n\n    const chatGrant = new ChatGrant({\n        serviceSid: serviceSid,\n    });\n\n    token.addGrant(chatGrant);\n\n    return token.toJwt();\n}</code></pre>\n\n<p>In this function, you generate <a href=\"https://www.twilio.com/docs/libraries/reference/twilio-node/3.67.0/AccessToken.html\">access tokens</a> using your <strong>Account SID</strong>, <strong>API key</strong>, and <strong>API secret</strong>. You can optionally supply a unique identity which could be a username, email, etc. After creating a token, you have to add a <a href=\"https://www.twilio.com/docs/libraries/reference/twilio-node/3.67.0/ChatGrant.html\">chat grant</a> to it. The chat grant can take a conversation service ID among other optional values. Lastly, you’ll convert the token to a <a href=\"https://jwt.io/\">JWT</a> and return it. </p>\n<p>The <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/utils/controller.js\"><code>utils/controller.js</code></a> file contains an <code>asyncWrapper</code> function that wraps async controller functions and catches any errors they throw. Paste the following code into this file:</p>\n<div>\n<pre><code>function asyncWrapper(controller) {\n    return (req, res, next) =&gt; Promise.resolve(controller(req, res, next)).catch(next);\n}\n\nexport { asyncWrapper, createToken };</code></pre>\n</div>\n\n<h3>Controllers</h3>\n<p>The backend app has four controllers: two for authentication and two for handling conversations. The first auth controller creates a token, and the second deletes it. One of the conversations controllers creates new <a href=\"https://www.twilio.com/docs/libraries/reference/twilio-node/3.67.0/Twilio.Conversations.V1.ConversationInstance.html\">conversations</a>, while the other adds <a href=\"https://www.twilio.com/docs/libraries/reference/twilio-node/3.67.0/Twilio.Api.V2010.AccountContext.ConferenceContext.ParticipantInstance.html\">participants</a> to existing conversations. </p>\n<h4>Conversation Controllers</h4>\n<p>In the <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/controllers/conversations.js\"><code>controllers/conversations.js</code></a> file, add these imports and code for the <code>StartConversation</code> controller:</p>\n<div>\n<pre><code>import { twilioConfig } from '../config/index.js';\nimport { createToken } from '../utils/token.js';\nimport twilio from 'twilio';\n\nasync function StartConversation(req, res, next) {\n    const client = twilio(twilioConfig.accountSid, twilioConfig.authToken);\n\n    const { conversationTitle, username } = req.body;\n\n    try {\n        if (conversationTitle &amp;&amp; username) {\n            const conversation = await client.conversations.conversations\n                .create({ friendlyName: conversationTitle });\n\n            req.session.token = createToken(username, conversation.chatServiceSid);\n            req.session.username = username;\n\n            const participant = await client.conversations.conversations(conversation.sid)\n                .participants.create({ identity: username })\n\n            res.send({ conversation, participant });\n        } else {\n            next({ message: 'Missing conversation title or username' });\n        }\n    }\n    catch (error) {\n        next({ error, message: 'There was a problem creating your conversation' });\n    }\n}</code></pre>\n</div>\n\n<p>The <code>StartConversation</code> controller first creates a Twilio <code>client</code> using your <code>twilioConfig.accountSid</code> and <code>twilioConfig.authToken</code> which you get from <code>config/index.js</code>. </p>\n<p>Next, it creates a conversation. It needs a conversation title for this, which it gets from the request body. A user has to be added to a conversation before they can participate in it. A participant cannot send a message without an access token. So, it generates an access token using the username provided in the request body and the <code>conversation.chatServiceSid</code>. Then the user identified by the username is added to the conversation. The controller completes by responding with the newly created conversation and participant. </p>\n<p>Next, you need to create the <code>AddParticipant</code> controller. To do this, add the following code below what you just added in the <code>controllers/conversations.js</code> file above:</p>\n<div>\n<pre><code>async function AddParticipant(req, res, next) {\n    const client = twilio(twilioConfig.accountSid, twilioConfig.authToken);\n\n    const { username } = req.body;\n    const conversationSid = req.params.id;\n\n    try {\n        const conversation = await client.conversations.conversations\n            .get(conversationSid).fetch();\n\n        if (username &amp;&amp; conversationSid) {\n            req.session.token = createToken(username, conversation.chatServiceSid);\n            req.session.username = username;\n\n            const participant = await client.conversations.conversations(conversationSid)\n                .participants.create({ identity: username })\n\n            res.send({ conversation, participant });\n        } else {\n            next({ message: 'Missing username or conversation Sid' });\n        }\n    } catch (error) {\n        next({ error, message: 'There was a problem adding a participant' });\n    }\n}\n\nexport { AddParticipant, StartConversation };</code></pre>\n</div>\n\n<p>The <code>AddParticipant</code> controller adds new participants to already existing conversations. Using the <code>conversationSid</code> provided as a route parameter, it fetches the conversation. It then creates a token for the user and adds them to the conversation using their username from the request body. Lastly, it sends the conversation and participant as a response. </p>\n<h4>Auth Controllers</h4>\n<p>The two controllers in <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/controllers/auth.js\"><code>controllers/auth.js</code></a> are called <code>GetToken</code> and <code>DeleteToken</code>. Add them to the file by copying and pasting this code:</p>\n<div>\n<pre><code>function GetToken(req, res, next) {\n    if (req.session.token) {\n        res.send({ token: req.session.token, username: req.session.username });\n    } else {\n        next({ status: 404, message: 'Token not set' });\n    }\n}\n\nfunction DeleteToken(req, res, _next) {\n    delete req.session.token;\n    delete req.session.username;\n\n    res.send({ message: 'Session destroyed' });\n}\n\nexport { DeleteToken, GetToken };</code></pre>\n</div>\n\n<p>The <code>GetToken</code> controller retrieves the token and username from the session if they exist and returns them as a response. <code>DeleteToken</code> deletes the session.</p>\n<h3>Routes</h3>\n<p>The <code>routes</code> folder has three files: <code>index.js</code>, <code>conversations.js</code>, and <code>auth.js</code>.  </p>\n<p>Add these auth routes to the <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/routes/auth.js\"><code>routes/auth.js</code></a> file by adding this code:</p>\n<div>\n<pre><code>import { Router } from 'express';\n\nimport { DeleteToken, GetToken } from '../controllers/auth.js';\n\nvar router = Router();\n\nrouter.get('/', GetToken);\nrouter.delete('/', DeleteToken);\n\nexport default router;</code></pre>\n</div>\n\n<p>The <code>GET</code> route at the <code>/</code> path returns a token while the <code>DELETE</code> route deletes a token.</p>\n<p>Next, copy and paste the following code to the <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/routes/conversations.js\"><code>routes/conversations.js</code></a> file:</p>\n<div>\n<pre><code>import { Router } from 'express';\nimport { AddParticipant, StartConversation } from '../controllers/conversations.js';\nimport { asyncWrapper } from '../utils/controller.js';\n\nvar router = Router();\n\nrouter.post('/', asyncWrapper(StartConversation));\nrouter.post('/:id/participants', asyncWrapper(AddParticipant));\n\nexport default router;</code></pre>\n</div>\n\n<p>In this file, the conversations router is created. A <code>POST</code> route for creating conversations with the path <code>/</code> and another <code>POST</code> route for adding participants with the path <code>/:id/participants</code> are added to the router. </p>\n<p>Lastly, add the following code to your new <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/routes/index.js\"><code>routes/index.js</code></a> file. </p>\n<pre><code>import { Router } from 'express';\n\nimport authRouter from './auth.js';\nimport conversationRouter from './conversations.js';\n\nvar router = Router();\n\nrouter.use('/auth/token', authRouter);\nrouter.use('/api/conversations', conversationRouter);\n\nexport default router;</code></pre>\n\n<p>By adding the <code>conversation</code> and <code>auth</code> routers here, you are making them available at <code>/api/conversations</code> and <code>/auth/token</code> to the main router respectively. The router is then exported. </p>\n<h3>The Backend App</h3>\n<p>Now it’s time to put the backend pieces together. Open the <a href=\"https://github.com/zaracooper/twilio-chat-server/blob/main/index.js\"><code>index.js</code></a> file in your text editor and paste in the following code:</p>\n<div>\n<pre><code>import cors from 'cors';\nimport createError from 'http-errors';\nimport express, { json, urlencoded } from 'express';\nimport logger from 'morgan';\nimport session from 'express-session';\nimport store from 'connect-mongo';\n\nimport { corsClient, port, sessionDB } from './config/index.js';\n\nimport router from './routes/index.js';\n\nvar app = express();\n\napp.use(logger('dev'));\napp.use(json());\napp.use(urlencoded({ extended: false }));\n\napp.use(cors({\n    origin: corsClient.domain,\n    credentials: true,\n    methods: ['GET', 'POST', 'DELETE'],\n    maxAge: 3600 * 1000,\n    allowedHeaders: ['Content-Type', 'Range'],\n    exposedHeaders: ['Accept-Ranges', 'Content-Encoding', 'Content-Length', 'Content-Range']\n}));\napp.options('*', cors());\n\napp.use(session({\n    store: store.create({\n        mongoUrl: <code>mongodb://${sessionDB.user}:${sessionDB.pass}@${sessionDB.host}:${sessionDB.port}/${sessionDB.name}</code>,\n        mongoOptions: { useUnifiedTopology: true },\n        collectionName: 'sessions'\n    }),\n    secret: sessionDB.secret,\n    cookie: {\n        maxAge: 3600 * 1000,\n        sameSite: 'strict'\n    },\n    name: 'twilio.sid',\n    resave: false,\n    saveUninitialized: true\n}));\n\napp.use('/', router);\n\napp.use(function (_req, _res, next) {\n    next(createError(404, 'Route does not exist.'));\n});\n\napp.use(function (err, _req, res, _next) {\n    res.status(err.status || 500).send(err);\n});\n\napp.listen(port);</code></pre>\n</div>\n\n<p>This file starts off by creating the express app. It then sets up JSON and URL-encoded payload parsing and adds the logging middleware. Next, it sets up CORS and the session handling. As mentioned earlier, MongoDB is used as the session store.</p>\n<p>After all that is set up, it then adds the router created in the earlier step before configuring error handling. Lastly, it makes the app listen to and accept connections at the port specified in the <code>.env</code> file. If you haven’t set the port, the app will listen on port <code>8000</code>.</p>\n<p>Once you’re finished creating the backend app, make sure MongoDB is running and start it by running this command on the terminal:</p>\n<pre><code>NODE_ENV=development npm start</code></pre>\n\n<p>You pass the <code>NODE_ENV=development</code> variable, so that configuration is loaded from the local <code>.env</code> file. </p>\nThe Front-end\n<p>The front-end portion of this project serves a couple of functions. It allows users to create conversations, see the list of conversations they are a part of, invite others to conversations they created, and send messages within conversations. These roles are achieved by four pages: </p>\n<ul>\n<li>a <strong>conversations</strong> page,</li>\n<li>a <strong>chat</strong> page,</li>\n<li>an <strong>error</strong> page,</li>\n<li>a <strong>login</strong> page.</li>\n</ul>\n<p>You’ll call the front-end app <code>twilio-chat-app</code>. <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app\">A scaffolded starter exists for it on Github</a>. To clone the project and get the starter, run:</p>\n<div>\n<pre><code>git clone <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app.git\">https://github.com/zaracooper/twilio-vanilla-js-chat-app.git</a>\ncd twilio-vanilla-js-chat-app\ngit checkout starter</code></pre>\n</div>\n\n<p>The app takes this structure:</p>\n<pre><code>.\n├── index.html\n├── pages\n│   ├── chat.html\n│   ├── conversation.html\n│   ├── error.html\n│   └── login.html\n├── scripts\n│   ├── chat.js\n│   ├── conversation.js\n│   └── login.js\n└── styles\n    ├── chat.css\n    ├── main.css\n    └── simple-page.css\n</code></pre>\n\n<p>The styling and HTML markup have already been added for each of the pages in the starter. This section will only cover the scripts you have to add. </p>\n<h3>Dependencies</h3>\n<p>The app has two dependencies: <a href=\"https://www.npmjs.com/package/axios\"><code>axios</code></a> and <a href=\"http://media.twiliocdn.com/sdk/js/conversations/releases/1.2.3/docs/index.html\"><code>@twilio/conversations</code></a>. You’ll use <code>axios</code> to make requests to the backend app and <code>@twilio/conversations</code> to send and fetch messages and conversations in scripts. You can install them on the terminal by running: </p>\n<pre><code>npm i</code></pre>\n\n<h3>The Index Page</h3>\n<p>This page serves as a landing page for the app. You can <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/index.html\">find the markup for this page (<code>index.html</code>) here</a>. It uses two CSS stylesheets: <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/styles/main.css\"><code>styles/main.css</code></a> which all pages use and <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/styles/simple-page.css\"><code>styles/simple-page.css</code></a> which smaller, less complicated pages use.</p>\n<p>You can find the contents of these stylesheets linked in the earlier paragraph. Here is a screenshot of what this page will look like:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a602139c-a8fa-411b-a9bb-2e5cb3c8b09a/4-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<h3>The Error Page</h3>\n<p>This page is shown when an error occurs. <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/pages/error.html\">The contents of <code>pages/error.html</code> can be found here.</a> If an error occurs, a user can click the button to go to the home page. There, they can try what they were attempting again. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9f2598a3-bfaa-4e29-8477-0aa7c472e935/5-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<h3>The Conversations Page</h3>\n<p>On this page, a user provides the title of a conversation to be created and their username to a form. </p>\n<p><a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/pages/conversation.html\">The contents of <code>pages/conversation.html</code> can be found here.</a> Add the following code to the <code>scripts/conversation.js</code> file:</p>\n<pre><code>window.twilioChat = window.twilioChat || {};\n\nfunction createConversation() {\n    let convoForm = document.getElementById('convoForm');\n    let formData = new FormData(convoForm);\n\n    let body = Object.fromEntries(formData.entries()) || {};\n\n    let submitBtn = document.getElementById('submitConvo');\n    submitBtn.innerText = \"Creating...\"\n    submitBtn.disabled = true;\n    submitBtn.style.cursor = 'wait';\n\n    axios.request({\n        url: '/api/conversations',\n        baseURL: 'http://localhost:8000',\n        method: 'post',\n        withCredentials: true,\n        data: body\n    })\n        .then(() =&gt; {\n            window.twilioChat.username = body.username;\n            location.href = '/pages/chat.html';\n        })\n        .catch(() =&gt; {\n            location.href = '/pages/error.html';\n        });\n}</code></pre>\n\n<p>When a user clicks the Submit button, the <code>createConversation</code> function is called. In it, the contents of the form are collected and used in the body of a <code>POST</code> request made to <code>http://localhost:8000/api/conversations/</code> in the backend. </p>\n<p>You will use <code>axios</code> to make the request. If the request is successful, a conversation is created and the user is added to it. The user will then be redirected to the chat page where they can send messages in the conversation. </p>\n<p>Below is a screenshot of the conversations page:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/28017a81-6a1c-4a01-a673-87ce848045e1/7-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<h3>The Chat Page</h3>\n<p>On this page, a user will view a list of conversations they are part of and send messages to them. You can find <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/pages/chat.html\">the markup for <code>pages/chat.html</code> here</a> and <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/styles/chat.css\">the styling for <code>styles/chat.css</code> here</a>. </p>\n<p>The <code>scripts/chat.js</code> file starts out by defining a namespace <code>twilioDemo</code>. </p>\n<pre><code>window.twilioChat = window.twilioChat || {};</code></pre>\n\n<p>Add the <code>initClient</code> function below. It is responsible for initializing the Twilio client and loading conversations.</p>\n<div>\n<pre><code>async function initClient() {\n    try {\n        const response = await axios.request({\n            url: '/auth/token',\n            baseURL: '<a href=\"http://localhost:8000'\">http://localhost:8000'</a>,\n            method: 'GETget',\n            withCredentials: true\n        });\n\n        window.twilioChat.username = response.data.username;\n        window.twilioChat.client = await Twilio.Conversations.Client.create(response.data.token);\n\n        let conversations = await window.twilioChat.client.getSubscribedConversations();\n\n        let conversationCont, conversationName;\n\n        const sideNav = document.getElementById('side-nav');\n        sideNav.removeChild(document.getElementById('loading-msg'));\n\n        for (let conv of conversations.items) {\n            conversationCont = document.createElement('button');\n            conversationCont.classList.add('conversation');\n            conversationCont.id = conv.sid;\n            conversationCont.value = conv.sid;\n            conversationCont.onclick = async () =&gt; {\n                await setConversation(conv.sid, conv.channelState.friendlyName);\n            };\n\n            conversationName = document.createElement('h3');\n            conversationName.innerText = <code>💬 ${conv.channelState.friendlyName}</code>;\n\n            conversationCont.appendChild(conversationName);\n            sideNav.appendChild(conversationCont);\n        }\n    }\n    catch {\n        location.href = '/pages/error.html';\n    }\n};</code></pre>\n</div>\n\n<p>When the page loads, <code>initClient</code> fetches the user’s access token from the backend, then uses it to initialise the client. Once the client is initialised, it’s used to fetch all the conversations the user is subscribed to. After that, the conversations are loaded onto the <code>side-nav</code>. In case any error occurs, the user is sent to the error page.</p>\n<p>The <code>setConversion</code> function loads a single conversation. Copy and paste the code below in the file to add it:</p>\n<div>\n<pre><code>async function setConversation(sid, name) {\n    try {\n        window.twilioChat.selectedConvSid = sid;\n\n        document.getElementById('chat-title').innerText = '+ ' + name;\n\n        document.getElementById('loading-chat').style.display = 'flex';\n        document.getElementById('messages').style.display = 'none';\n\n        let submitButton = document.getElementById('submitMessage')\n        submitButton.disabled = true;\n\n        let inviteButton = document.getElementById('invite-button')\n        inviteButton.disabled = true;\n\n        window.twilioChat.selectedConversation = await window.twilioChat.client.getConversationBySid(window.twilioChat.selectedConvSid);\n\n        const messages = await window.twilioChat.selectedConversation.getMessages();\n\n        addMessagesToChatArea(messages.items, true);\n\n        window.twilioChat.selectedConversation.on('messageAdded', msg =&gt; addMessagesToChatArea([msg], false));\n\n        submitButton.disabled = false;\n        inviteButton.disabled = false;\n    } catch {\n        showError('loading the conversation you selected');\n    }\n};</code></pre>\n</div>\n\n<p>When a user clicks on a particular conversation, <code>setConversation</code> is called. This function receives the <strong>conversation SID</strong> and <strong>name</strong> and uses the <strong>SID</strong> to fetch the conversation and its messages. The messages are then added to the chat area. Lastly, a listener is added to watch for new messages added to the conversation. These new messages are appended to the chat area when they are received. In case any errors occur, an error message is displayed.</p>\n<p>This is a screenshot of the chat page:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/74fcb0d9-ee52-484d-9e2d-3d585cb2cd8f/6-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<p>Next, you’ll add the <code>addMessagedToChatArea</code> function which loads conversation messages.</p>\n<pre><code>function addMessagesToChatArea(messages, clearMessages) {\n    let cont, msgCont, msgAuthor, timestamp;\n\n    const chatArea = document.getElementById('messages');\n\n    if (clearMessages) {\n        document.getElementById('loading-chat').style.display = 'none';\n        chatArea.style.display = 'flex';\n        chatArea.replaceChildren();\n    }\n\n    for (const msg of messages) {\n        cont = document.createElement('div');\n        if (msg.state.author == window.twilioChat.username) {\n            cont.classList.add('right-message');\n        } else {\n            cont.classList.add('left-message');\n        }\n\n        msgCont = document.createElement('div');\n        msgCont.classList.add('message');\n\n        msgAuthor = document.createElement('p');\n        msgAuthor.classList.add('username');\n        msgAuthor.innerText = msg.state.author;\n\n        timestamp = document.createElement('p');\n        timestamp.classList.add('timestamp');\n        timestamp.innerText = msg.state.timestamp;\n\n        msgCont.appendChild(msgAuthor);\n        msgCont.innerText += msg.state.body;\n\n        cont.appendChild(msgCont);\n        cont.appendChild(timestamp);\n\n        chatArea.appendChild(cont);\n    }\n\n    chatArea.scrollTop = chatArea.scrollHeight;\n}</code></pre>\n\n<p>The function <code>addMessagesToChatArea</code> adds messages of the current conversation to the chat area when it is selected from the side nav. It is also called when new messages are added to the current conversation. A loading message is usually displayed as the messages are being fetched. Before the conversation messages are added, this loading message is removed. Messages from the current user are aligned to the right, while all other messages from group participants are aligned to the left.</p>\n<p>This is what the loading message looks like:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e9e6b5d4-bb08-4568-b233-73bbd5cc589c/9-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<p>Add the <code>sendMessage</code> function to send messages:</p>\n<div>\n<pre><code>function sendMessage() {\n    let submitBtn = document.getElementById('submitMessage');\n    submitBtn.disabled = true;\n\n    let messageForm = document.getElementById('message-input');\n    let messageData = new FormData(messageForm);\n\n    const msg = messageData.get('chat-message');\n\n    window.twilioChat.selectedConversation.sendMessage(msg)\n        .then(() =&gt; {\n            document.getElementById('chat-message').value = '';\n            submitBtn.disabled = false;\n        })\n        .catch(() =&gt; {\n            showError('sending your message');\n            submitBtn.disabled = false;\n        });\n};</code></pre>\n</div>\n\n<p>When the user sends a message, the <code>sendMessage</code> function is called. It gets the message text from the text area and disables the submit button. Then using the currently selected conversation, the message is sent using its <code>sendMessage</code> method. If successful, the text area is cleared and the submit button is re-enabled. If unsuccessful, an error message is displayed instead. </p>\n<p>The <code>showError</code> method displays an error message when it is called; <code>hideError</code> hides it.</p>\n<div>\n<pre><code>function showError(msg) {\n    document.getElementById('error-message').style.display = 'flex';\n    document.getElementById('error-text').innerText = <code>There was a problem ${msg ? msg : 'fulfilling your request'}.</code>;\n}\n\nfunction hideError() {\n    document.getElementById('error-message').style.display = 'none';\n}</code></pre>\n</div>\n\n<p>This is what this error message will look like:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/be1c9ad3-22cc-49a9-a710-b8e87ad624cc/1-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<p>The <code>logout</code> function logouts out the current user. It does this by making a request to the backend which clears their session. The user is then redirected to the conversation page, so they can create a new conversation if they’d like.</p>\n<pre><code>function logout(logoutButton) {\n    logoutButton.disabled = true;\n    logoutButton.style.cursor = 'wait';\n\n    axios.request({\n        url: '/auth/token',\n        baseURL: 'http://localhost:8000',\n        method: 'DELETEdelete',\n        withCredentials: true\n    })\n        .then(() =&gt; {\n            location.href = '/pages/conversation.html';\n        })\n        .catch(() =&gt; {\n            location.href = '/pages/error.html';\n        });\n}</code></pre>\n\n<p>Add the <code>inviteFriend</code> function to send conversation invites:</p>\n<div>\n<pre><code>async function inviteFriend() {\n    try {\n        const link = <code>http://localhost:3000/pages/login.html?sid=${window.twilioChat.selectedConvSid}</code>;\n\n        await navigator.clipboard.writeText(link);\n\n        alert(<code>The link below has been copied to your clipboard.\\n\\n${link}\\n\\nYou can invite a friend to chat by sending it to them.</code>);\n    } catch {\n        showError('preparing your chat invite');\n    }\n}</code></pre>\n</div>\n\n<p>To invite other people to participate in the conversation, the current user can send another person a link. This link is to the login page and contains the current <strong>conversation SID</strong> as a query parameter. When they click the invite button, the link is added to their clipboard. An alert is then displayed giving invite instructions. </p>\n<p>Here is a screenshot of the invite alert:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/715f67fa-ee72-4110-b712-9882693e27a6/11-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<h3>The Login Page</h3>\n<p>On this page, a user logs in when they are invited to a conversation. You can <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app/blob/main/pages/login.html\">find the markup for <code>pages/login.html</code> at this link</a>. </p>\n<p>In <code>scripts/login.js</code>, the <code>login</code> function is responsible for logging in conversation invitees. Copy its code below and add it to the aforementioned file:</p>\n<div>\n<pre><code>function login() {\n    const convParams = new URLSearchParams(window.location.search);\n    const conv = Object.fromEntries(convParams.entries());\n\n    if (conv.sid) {\n        let submitBtn = document.getElementById('login-button');\n        submitBtn.innerText = 'Logging in...';\n        submitBtn.disabled = true;\n        submitBtn.style.cursor = 'wait';\n\n        let loginForm = document.getElementById('loginForm');\n        let formData = new FormData(loginForm);\n        let body = Object.fromEntries(formData.entries());\n\n        axios.request({\n            url: <code>/api/conversations/${conv.sid}/participants</code>,\n            baseURL: '<a href=\"http://localhost:8000'\">http://localhost:8000'</a>,\n            method: 'POSTpost',\n            withCredentials: true,\n            data: body\n        })\n            .then(() =&gt; {\n                location.href = '/pages/chat.html';\n            })\n            .catch(() =&gt; {\n                location.href = '/pages/error.html';\n            });\n    } else {\n        location.href = '/pages/conversation.html';\n    }\n}</code></pre>\n</div>\n\n<p>The <code>login</code> function takes the conversation <code>sid</code> query parameter from the URL and the username from the form. It then makes a <code>POST</code> request to <code>api/conversations/{sid}/participants/</code> on the backend app. The backend app adds the user to the conversation and generates an access token for messaging. If successful, a session is started in the backend for the user. </p>\n<p>The user is then redirected to the <em>chat page</em>, but if the request returns an error, they are redirected to the <em>error page</em>. If there is no conversation <code>sid</code> query parameter in the URL, the user is redirected to the <em>conversation page</em>. </p>\n<p>Below is a screenshot of the login page:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/075a6d21-3f40-4e3d-a4b2-0f2485d194fb/2-build-group-chat-app-vanilla-js-twilio-nodejs.png\" /></p>\n<h3>Running the App</h3>\n<p>Before you can start the front-end app, make sure that the backend app is running. As mentioned earlier, you can start the backend app using this command on the terminal:</p>\n<pre><code>NODE_ENV=development npm start</code></pre>\n\n<p>To serve the front-end app, run this command in a different terminal window:</p>\n<pre><code>http-server -p 3000</code></pre>\n\n<p>This serves the app at <a href=\"http://localhost:3000\">http://localhost:3000</a>. Once it’s running, head on over to <a href=\"http://localhost:3000/pages/conversation.html\">http://localhost:3000/pages/conversation.html</a>; set a name for your conversation and add your username, then create it. When you get to the <em>chat page</em>, click on the <code>conversation</code>, then click the Invite button. </p>\n<p>In a separate incognito window, paste the invite link and put a different username. Once you’re on the chat page in the incognito window, you can begin chatting with yourself. You can send messages back and forth between the user in the first window and the second user in the incognito window in the same conversation. </p>\nConclusion\n<p>In this tutorial, you learned how to create a chat app using Twilio Conversations and Vanilla JS. You created a Node.js app that generates user access tokens, maintains a session for them, creates conversations, and adds users to them as participants. You also created a front-end app using HTML, CSS, and Vanilla JS. This app should allow users to create conversations, send messages, and invite other people to chat. It should get access tokens from the backend app and use them to perform these functions. I hope this tutorial gave you a better understanding of how Twilio Conversations works and how to use it for chat messaging.</p>\n<p><em>To find out more about Twilio Conversations and what else you could do with it, <a href=\"https://www.twilio.com/conversations-api\">check out its documentation linked here</a>. You can also find the <a href=\"https://github.com/zaracooper/twilio-chat-server\">source code for the backend app on Github here</a>, and the <a href=\"https://github.com/zaracooper/twilio-vanilla-js-chat-app\">code for the front-end app here</a>.</em></p>",
      "content_text": "Chat is becoming an increasingly popular communication medium in both business and social contexts. Businesses use chat for customer and employee intra-company communication like with Slack, Microsoft Teams, Chanty, HubSpot Live Chat, Help Scout, etc. Most social networks and communication apps also offer chat as an option by default, like on Instagram, Facebook, Reddit, and Twitter. Other apps like Discord, Whatsapp, and Telegram are mostly chat-based, with group chats being one of their main functionalities. \nWhile there exist numerous products to facilitate chat, you may need a custom-tailored solution for your site that fits your particular communication needs. For example, many of these products are stand-alone apps and may not be able to integrate within your own site. Having your users leave your website to chat may not be the greatest option as it can affect user experience and conversion. On the flip side, building a chat app from scratch can be a daunting and sometimes overwhelming task. However, by using APIs like Twilio Conversations you can simplify the process of creating them. These communication APIs handle group creation, adding participants, sending messages, notifications, among other important chat functions. Backend apps that use these APIs only have to handle authentication and make calls to these APIs. Front-end apps then display conversations, groups, and messages from the backend. \nIn this tutorial, you will learn how to create a group chat app using the Twilio Conversations API. The front end for this app will be built using HTML, CSS, and Vanilla JavaScript. It will allow users to create group chats, send invites, login, as well as send and receive messages. The backend will be a Node.js app. It will provide authentication tokens for chat invitees and manage chat creation. \nPrerequisites\nBefore you can start this tutorial, you need to have the following:\n\nNode.js installed. You’ll use it primarily for the backend app and to install dependencies in the front-end app.You can get it using a pre-built installer available on the Node.js downloads page.\nA Twilio account.You can create one on the Twilio website at this link.\nhttp-server to serve the front-end app.You can install it by running npm i -g http-server. You can also run it with npx http-server for one-off runs.\nMongoDB for session storage in the backend app.Its installation page has a detailed guide on how to get it running.\n\nThe Backend App\nTo send chat messages using Twilio API, you need a conversation. Chat messages are sent and received within a conversation. The people sending the messages are called participants. A participant can only send a message within a conversation if they are added to it. Both conversations and participants are created using the Twilio API. The backend app will perform this function.\nA participant needs an access token to send a message and get their subscribed conversations. The front-end portion of this project will use this access token. The backend app creates the token and sends it to the frontend. There it will be used to load conversations and messages. \nProject Starter\nYou’ll call the backend app twilio-chat-server. A scaffolded project starter for it is available on Github. To clone the project and get the starter, run:\ngit clone https://github.com/zaracooper/twilio-chat-server.git\ncd twilio-chat-server\ngit checkout starter\n\nThe backend app takes this structure:\n.\n├── app.js\n├── config/\n├── controllers/\n├── package.json\n├── routes/\n└── utils/\n\nTo run the app, you’ll use the node index.js command. \nDependencies\nThe backend app needs 8 dependencies. You can install them by running:\nnpm i \n\nHere’s a list of each of the dependencies:\n\nconnect-mongo connects to MongoDB, which you’ll use as a session store;\ncors handles CORS;\ndotenv loads environment variables from the .env file that you will create in a later step;\nexpress is the web framework you’ll use for the backend;\nexpress-session provides middleware to handle session data;\nhttp-errors helps create server errors;\nmorgan handles logging;\ntwilio creates the Twilio client, generates tokens, creates conversations, and adds participants.\n\nConfiguration\nThe config folder is responsible for loading configuration from environment variables. The configuration is grouped into three categories: configuration for CORS, Twilio, and the MongoDB session DB. When the environment is development, you will load config from the .env file using dotenv.\nStart by creating the .env file on the terminal. This file is already added to the .gitignore file to prevent the sensitive values it contains from being checked into the repository.\ntouch .env\n\nHere’s what your .env should look like:\n# Session DB Config\nSESSION_DB_HOST=XXXX\nSESSION_DB_USER=XXXX\nSESSION_DB_PASS=XXXX\nSESSION_DB_PORT=XXXX\nSESSION_DB_NAME=XXXX\nSESSION_DB_SECRET=XXXX\n\n# Twilio Config\nTWILIO_ACCOUNT_SID=XXXX\nTWILIO_AUTH_TOKEN=XXXX\nTWILIO_API_KEY=XXXX\nTWILIO_API_SECRET=XXXX\n\n# CORS Client Config\nCORS_CLIENT_DOMAIN=XXXX\n\nYou can learn how to create a user for your session DB from this MongoDB manual entry. Once you create a session database and a user who can write to it, you can fill the SESSION_DB_USER, SESSION_DB_PASS, and SESSION_DB_NAME values. If you’re running a local instance of MongoDB, the SESSION_DB_HOST would be localhost, and the SESSION_DB_PORT usually is 27017. The SESSION_DB_SECRET is used by express-session to sign the session ID cookie, and it can be any secret string you set. \nIn the next step, you will get credentials from the Twilio Console. The credentials should be assigned to the variables with the TWILIO_ prefix. During local development, the front-end client will run on http://localhost:3000. So, you can use this value for the CORS_CLIENT_DOMAIN environment variable.   \nAdd the following code to config/index.js to load environment variables. \nimport dotenv from 'dotenv';\n\nif (process.env.NODE_ENV == 'development') {\n    dotenv.config();\n}\n\nconst corsClient = {\n    domain: process.env.CORS_CLIENT_DOMAIN\n};\n\nconst sessionDB = {\n    host: process.env.SESSION_DB_HOST,\n    user: process.env.SESSION_DB_USER,\n    pass: process.env.SESSION_DB_PASS,\n    port: process.env.SESSION_DB_PORT,\n    name: process.env.SESSION_DB_NAME,\n    secret: process.env.SESSION_DB_SECRET\n};\n\nconst twilioConfig = {\n    accountSid: process.env.TWILIO_ACCOUNT_SID,\n    authToken: process.env.TWILIO_AUTH_TOKEN,\n    apiKey: process.env.TWILIO_API_KEY,\n    apiSecret: process.env.TWILIO_API_SECRET\n};\n\nconst port = process.env.PORT || '8000';\n\nexport { corsClient, port, sessionDB, twilioConfig };\n\nThe environment variables are grouped into categories based on what they do. Each of the configuration categories has its own object variable, and they are all exported for use in other parts of the app.\nGetting Twilio Credentials From the Console\nTo build this project, you’ll need four different Twilio credentials: an Account SID, an Auth Token, an API key, and an API secret. In the console, on the General Settings page, scroll down to the API Credentials section. This is where you will find your Account SID and Auth Token. \n\nTo get an API Key and Secret, go to the API Keys page. You can see it in the screenshot below. Click the + button to go to the New API Key page. \n\nOn this page, add a key name and leave the KEY TYPE as Standard, then click Create API Key. Copy the API key and secret. You will add all these credentials in a .env file as you shall see in subsequent steps.  \n\nUtils\nThe backend app needs two utility functions. One will create a token, and the other will wrap async controllers and handle errors for them.\nIn utils/token.js, add the following code to create a function called createToken that will generate Twilio access tokens:\nimport { twilioConfig } from '../config/index.js';\nimport twilio from 'twilio';\n\nfunction createToken(username, serviceSid) {\n    const AccessToken = twilio.jwt.AccessToken;\n    const ChatGrant = AccessToken.ChatGrant;\n\n    const token = new AccessToken(\n        twilioConfig.accountSid,\n        twilioConfig.apiKey,\n        twilioConfig.apiSecret,\n        { identity: username }\n    );\n\n    const chatGrant = new ChatGrant({\n        serviceSid: serviceSid,\n    });\n\n    token.addGrant(chatGrant);\n\n    return token.toJwt();\n}\n\nIn this function, you generate access tokens using your Account SID, API key, and API secret. You can optionally supply a unique identity which could be a username, email, etc. After creating a token, you have to add a chat grant to it. The chat grant can take a conversation service ID among other optional values. Lastly, you’ll convert the token to a JWT and return it. \nThe utils/controller.js file contains an asyncWrapper function that wraps async controller functions and catches any errors they throw. Paste the following code into this file:\n\nfunction asyncWrapper(controller) {\n    return (req, res, next) => Promise.resolve(controller(req, res, next)).catch(next);\n}\n\nexport { asyncWrapper, createToken };\n\n\nControllers\nThe backend app has four controllers: two for authentication and two for handling conversations. The first auth controller creates a token, and the second deletes it. One of the conversations controllers creates new conversations, while the other adds participants to existing conversations. \nConversation Controllers\nIn the controllers/conversations.js file, add these imports and code for the StartConversation controller:\n\nimport { twilioConfig } from '../config/index.js';\nimport { createToken } from '../utils/token.js';\nimport twilio from 'twilio';\n\nasync function StartConversation(req, res, next) {\n    const client = twilio(twilioConfig.accountSid, twilioConfig.authToken);\n\n    const { conversationTitle, username } = req.body;\n\n    try {\n        if (conversationTitle && username) {\n            const conversation = await client.conversations.conversations\n                .create({ friendlyName: conversationTitle });\n\n            req.session.token = createToken(username, conversation.chatServiceSid);\n            req.session.username = username;\n\n            const participant = await client.conversations.conversations(conversation.sid)\n                .participants.create({ identity: username })\n\n            res.send({ conversation, participant });\n        } else {\n            next({ message: 'Missing conversation title or username' });\n        }\n    }\n    catch (error) {\n        next({ error, message: 'There was a problem creating your conversation' });\n    }\n}\n\n\nThe StartConversation controller first creates a Twilio client using your twilioConfig.accountSid and twilioConfig.authToken which you get from config/index.js. \nNext, it creates a conversation. It needs a conversation title for this, which it gets from the request body. A user has to be added to a conversation before they can participate in it. A participant cannot send a message without an access token. So, it generates an access token using the username provided in the request body and the conversation.chatServiceSid. Then the user identified by the username is added to the conversation. The controller completes by responding with the newly created conversation and participant. \nNext, you need to create the AddParticipant controller. To do this, add the following code below what you just added in the controllers/conversations.js file above:\n\nasync function AddParticipant(req, res, next) {\n    const client = twilio(twilioConfig.accountSid, twilioConfig.authToken);\n\n    const { username } = req.body;\n    const conversationSid = req.params.id;\n\n    try {\n        const conversation = await client.conversations.conversations\n            .get(conversationSid).fetch();\n\n        if (username && conversationSid) {\n            req.session.token = createToken(username, conversation.chatServiceSid);\n            req.session.username = username;\n\n            const participant = await client.conversations.conversations(conversationSid)\n                .participants.create({ identity: username })\n\n            res.send({ conversation, participant });\n        } else {\n            next({ message: 'Missing username or conversation Sid' });\n        }\n    } catch (error) {\n        next({ error, message: 'There was a problem adding a participant' });\n    }\n}\n\nexport { AddParticipant, StartConversation };\n\n\nThe AddParticipant controller adds new participants to already existing conversations. Using the conversationSid provided as a route parameter, it fetches the conversation. It then creates a token for the user and adds them to the conversation using their username from the request body. Lastly, it sends the conversation and participant as a response. \nAuth Controllers\nThe two controllers in controllers/auth.js are called GetToken and DeleteToken. Add them to the file by copying and pasting this code:\n\nfunction GetToken(req, res, next) {\n    if (req.session.token) {\n        res.send({ token: req.session.token, username: req.session.username });\n    } else {\n        next({ status: 404, message: 'Token not set' });\n    }\n}\n\nfunction DeleteToken(req, res, _next) {\n    delete req.session.token;\n    delete req.session.username;\n\n    res.send({ message: 'Session destroyed' });\n}\n\nexport { DeleteToken, GetToken };\n\n\nThe GetToken controller retrieves the token and username from the session if they exist and returns them as a response. DeleteToken deletes the session.\nRoutes\nThe routes folder has three files: index.js, conversations.js, and auth.js.  \nAdd these auth routes to the routes/auth.js file by adding this code:\n\nimport { Router } from 'express';\n\nimport { DeleteToken, GetToken } from '../controllers/auth.js';\n\nvar router = Router();\n\nrouter.get('/', GetToken);\nrouter.delete('/', DeleteToken);\n\nexport default router;\n\n\nThe GET route at the / path returns a token while the DELETE route deletes a token.\nNext, copy and paste the following code to the routes/conversations.js file:\n\nimport { Router } from 'express';\nimport { AddParticipant, StartConversation } from '../controllers/conversations.js';\nimport { asyncWrapper } from '../utils/controller.js';\n\nvar router = Router();\n\nrouter.post('/', asyncWrapper(StartConversation));\nrouter.post('/:id/participants', asyncWrapper(AddParticipant));\n\nexport default router;\n\n\nIn this file, the conversations router is created. A POST route for creating conversations with the path / and another POST route for adding participants with the path /:id/participants are added to the router. \nLastly, add the following code to your new routes/index.js file. \nimport { Router } from 'express';\n\nimport authRouter from './auth.js';\nimport conversationRouter from './conversations.js';\n\nvar router = Router();\n\nrouter.use('/auth/token', authRouter);\nrouter.use('/api/conversations', conversationRouter);\n\nexport default router;\n\nBy adding the conversation and auth routers here, you are making them available at /api/conversations and /auth/token to the main router respectively. The router is then exported. \nThe Backend App\nNow it’s time to put the backend pieces together. Open the index.js file in your text editor and paste in the following code:\n\nimport cors from 'cors';\nimport createError from 'http-errors';\nimport express, { json, urlencoded } from 'express';\nimport logger from 'morgan';\nimport session from 'express-session';\nimport store from 'connect-mongo';\n\nimport { corsClient, port, sessionDB } from './config/index.js';\n\nimport router from './routes/index.js';\n\nvar app = express();\n\napp.use(logger('dev'));\napp.use(json());\napp.use(urlencoded({ extended: false }));\n\napp.use(cors({\n    origin: corsClient.domain,\n    credentials: true,\n    methods: ['GET', 'POST', 'DELETE'],\n    maxAge: 3600 * 1000,\n    allowedHeaders: ['Content-Type', 'Range'],\n    exposedHeaders: ['Accept-Ranges', 'Content-Encoding', 'Content-Length', 'Content-Range']\n}));\napp.options('*', cors());\n\napp.use(session({\n    store: store.create({\n        mongoUrl: mongodb://${sessionDB.user}:${sessionDB.pass}@${sessionDB.host}:${sessionDB.port}/${sessionDB.name},\n        mongoOptions: { useUnifiedTopology: true },\n        collectionName: 'sessions'\n    }),\n    secret: sessionDB.secret,\n    cookie: {\n        maxAge: 3600 * 1000,\n        sameSite: 'strict'\n    },\n    name: 'twilio.sid',\n    resave: false,\n    saveUninitialized: true\n}));\n\napp.use('/', router);\n\napp.use(function (_req, _res, next) {\n    next(createError(404, 'Route does not exist.'));\n});\n\napp.use(function (err, _req, res, _next) {\n    res.status(err.status || 500).send(err);\n});\n\napp.listen(port);\n\n\nThis file starts off by creating the express app. It then sets up JSON and URL-encoded payload parsing and adds the logging middleware. Next, it sets up CORS and the session handling. As mentioned earlier, MongoDB is used as the session store.\nAfter all that is set up, it then adds the router created in the earlier step before configuring error handling. Lastly, it makes the app listen to and accept connections at the port specified in the .env file. If you haven’t set the port, the app will listen on port 8000.\nOnce you’re finished creating the backend app, make sure MongoDB is running and start it by running this command on the terminal:\nNODE_ENV=development npm start\n\nYou pass the NODE_ENV=development variable, so that configuration is loaded from the local .env file. \nThe Front-end\nThe front-end portion of this project serves a couple of functions. It allows users to create conversations, see the list of conversations they are a part of, invite others to conversations they created, and send messages within conversations. These roles are achieved by four pages: \n\na conversations page,\na chat page,\nan error page,\na login page.\n\nYou’ll call the front-end app twilio-chat-app. A scaffolded starter exists for it on Github. To clone the project and get the starter, run:\n\ngit clone https://github.com/zaracooper/twilio-vanilla-js-chat-app.git\ncd twilio-vanilla-js-chat-app\ngit checkout starter\n\n\nThe app takes this structure:\n.\n├── index.html\n├── pages\n│   ├── chat.html\n│   ├── conversation.html\n│   ├── error.html\n│   └── login.html\n├── scripts\n│   ├── chat.js\n│   ├── conversation.js\n│   └── login.js\n└── styles\n    ├── chat.css\n    ├── main.css\n    └── simple-page.css\n\n\nThe styling and HTML markup have already been added for each of the pages in the starter. This section will only cover the scripts you have to add. \nDependencies\nThe app has two dependencies: axios and @twilio/conversations. You’ll use axios to make requests to the backend app and @twilio/conversations to send and fetch messages and conversations in scripts. You can install them on the terminal by running: \nnpm i\n\nThe Index Page\nThis page serves as a landing page for the app. You can find the markup for this page (index.html) here. It uses two CSS stylesheets: styles/main.css which all pages use and styles/simple-page.css which smaller, less complicated pages use.\nYou can find the contents of these stylesheets linked in the earlier paragraph. Here is a screenshot of what this page will look like:\n\nThe Error Page\nThis page is shown when an error occurs. The contents of pages/error.html can be found here. If an error occurs, a user can click the button to go to the home page. There, they can try what they were attempting again. \n\nThe Conversations Page\nOn this page, a user provides the title of a conversation to be created and their username to a form. \nThe contents of pages/conversation.html can be found here. Add the following code to the scripts/conversation.js file:\nwindow.twilioChat = window.twilioChat || {};\n\nfunction createConversation() {\n    let convoForm = document.getElementById('convoForm');\n    let formData = new FormData(convoForm);\n\n    let body = Object.fromEntries(formData.entries()) || {};\n\n    let submitBtn = document.getElementById('submitConvo');\n    submitBtn.innerText = \"Creating...\"\n    submitBtn.disabled = true;\n    submitBtn.style.cursor = 'wait';\n\n    axios.request({\n        url: '/api/conversations',\n        baseURL: 'http://localhost:8000',\n        method: 'post',\n        withCredentials: true,\n        data: body\n    })\n        .then(() => {\n            window.twilioChat.username = body.username;\n            location.href = '/pages/chat.html';\n        })\n        .catch(() => {\n            location.href = '/pages/error.html';\n        });\n}\n\nWhen a user clicks the Submit button, the createConversation function is called. In it, the contents of the form are collected and used in the body of a POST request made to http://localhost:8000/api/conversations/ in the backend. \nYou will use axios to make the request. If the request is successful, a conversation is created and the user is added to it. The user will then be redirected to the chat page where they can send messages in the conversation. \nBelow is a screenshot of the conversations page:\n\nThe Chat Page\nOn this page, a user will view a list of conversations they are part of and send messages to them. You can find the markup for pages/chat.html here and the styling for styles/chat.css here. \nThe scripts/chat.js file starts out by defining a namespace twilioDemo. \nwindow.twilioChat = window.twilioChat || {};\n\nAdd the initClient function below. It is responsible for initializing the Twilio client and loading conversations.\n\nasync function initClient() {\n    try {\n        const response = await axios.request({\n            url: '/auth/token',\n            baseURL: 'http://localhost:8000',\n            method: 'GETget',\n            withCredentials: true\n        });\n\n        window.twilioChat.username = response.data.username;\n        window.twilioChat.client = await Twilio.Conversations.Client.create(response.data.token);\n\n        let conversations = await window.twilioChat.client.getSubscribedConversations();\n\n        let conversationCont, conversationName;\n\n        const sideNav = document.getElementById('side-nav');\n        sideNav.removeChild(document.getElementById('loading-msg'));\n\n        for (let conv of conversations.items) {\n            conversationCont = document.createElement('button');\n            conversationCont.classList.add('conversation');\n            conversationCont.id = conv.sid;\n            conversationCont.value = conv.sid;\n            conversationCont.onclick = async () => {\n                await setConversation(conv.sid, conv.channelState.friendlyName);\n            };\n\n            conversationName = document.createElement('h3');\n            conversationName.innerText = 💬 ${conv.channelState.friendlyName};\n\n            conversationCont.appendChild(conversationName);\n            sideNav.appendChild(conversationCont);\n        }\n    }\n    catch {\n        location.href = '/pages/error.html';\n    }\n};\n\n\nWhen the page loads, initClient fetches the user’s access token from the backend, then uses it to initialise the client. Once the client is initialised, it’s used to fetch all the conversations the user is subscribed to. After that, the conversations are loaded onto the side-nav. In case any error occurs, the user is sent to the error page.\nThe setConversion function loads a single conversation. Copy and paste the code below in the file to add it:\n\nasync function setConversation(sid, name) {\n    try {\n        window.twilioChat.selectedConvSid = sid;\n\n        document.getElementById('chat-title').innerText = '+ ' + name;\n\n        document.getElementById('loading-chat').style.display = 'flex';\n        document.getElementById('messages').style.display = 'none';\n\n        let submitButton = document.getElementById('submitMessage')\n        submitButton.disabled = true;\n\n        let inviteButton = document.getElementById('invite-button')\n        inviteButton.disabled = true;\n\n        window.twilioChat.selectedConversation = await window.twilioChat.client.getConversationBySid(window.twilioChat.selectedConvSid);\n\n        const messages = await window.twilioChat.selectedConversation.getMessages();\n\n        addMessagesToChatArea(messages.items, true);\n\n        window.twilioChat.selectedConversation.on('messageAdded', msg => addMessagesToChatArea([msg], false));\n\n        submitButton.disabled = false;\n        inviteButton.disabled = false;\n    } catch {\n        showError('loading the conversation you selected');\n    }\n};\n\n\nWhen a user clicks on a particular conversation, setConversation is called. This function receives the conversation SID and name and uses the SID to fetch the conversation and its messages. The messages are then added to the chat area. Lastly, a listener is added to watch for new messages added to the conversation. These new messages are appended to the chat area when they are received. In case any errors occur, an error message is displayed.\nThis is a screenshot of the chat page:\n\nNext, you’ll add the addMessagedToChatArea function which loads conversation messages.\nfunction addMessagesToChatArea(messages, clearMessages) {\n    let cont, msgCont, msgAuthor, timestamp;\n\n    const chatArea = document.getElementById('messages');\n\n    if (clearMessages) {\n        document.getElementById('loading-chat').style.display = 'none';\n        chatArea.style.display = 'flex';\n        chatArea.replaceChildren();\n    }\n\n    for (const msg of messages) {\n        cont = document.createElement('div');\n        if (msg.state.author == window.twilioChat.username) {\n            cont.classList.add('right-message');\n        } else {\n            cont.classList.add('left-message');\n        }\n\n        msgCont = document.createElement('div');\n        msgCont.classList.add('message');\n\n        msgAuthor = document.createElement('p');\n        msgAuthor.classList.add('username');\n        msgAuthor.innerText = msg.state.author;\n\n        timestamp = document.createElement('p');\n        timestamp.classList.add('timestamp');\n        timestamp.innerText = msg.state.timestamp;\n\n        msgCont.appendChild(msgAuthor);\n        msgCont.innerText += msg.state.body;\n\n        cont.appendChild(msgCont);\n        cont.appendChild(timestamp);\n\n        chatArea.appendChild(cont);\n    }\n\n    chatArea.scrollTop = chatArea.scrollHeight;\n}\n\nThe function addMessagesToChatArea adds messages of the current conversation to the chat area when it is selected from the side nav. It is also called when new messages are added to the current conversation. A loading message is usually displayed as the messages are being fetched. Before the conversation messages are added, this loading message is removed. Messages from the current user are aligned to the right, while all other messages from group participants are aligned to the left.\nThis is what the loading message looks like:\n\nAdd the sendMessage function to send messages:\n\nfunction sendMessage() {\n    let submitBtn = document.getElementById('submitMessage');\n    submitBtn.disabled = true;\n\n    let messageForm = document.getElementById('message-input');\n    let messageData = new FormData(messageForm);\n\n    const msg = messageData.get('chat-message');\n\n    window.twilioChat.selectedConversation.sendMessage(msg)\n        .then(() => {\n            document.getElementById('chat-message').value = '';\n            submitBtn.disabled = false;\n        })\n        .catch(() => {\n            showError('sending your message');\n            submitBtn.disabled = false;\n        });\n};\n\n\nWhen the user sends a message, the sendMessage function is called. It gets the message text from the text area and disables the submit button. Then using the currently selected conversation, the message is sent using its sendMessage method. If successful, the text area is cleared and the submit button is re-enabled. If unsuccessful, an error message is displayed instead. \nThe showError method displays an error message when it is called; hideError hides it.\n\nfunction showError(msg) {\n    document.getElementById('error-message').style.display = 'flex';\n    document.getElementById('error-text').innerText = There was a problem ${msg ? msg : 'fulfilling your request'}.;\n}\n\nfunction hideError() {\n    document.getElementById('error-message').style.display = 'none';\n}\n\n\nThis is what this error message will look like:\n\nThe logout function logouts out the current user. It does this by making a request to the backend which clears their session. The user is then redirected to the conversation page, so they can create a new conversation if they’d like.\nfunction logout(logoutButton) {\n    logoutButton.disabled = true;\n    logoutButton.style.cursor = 'wait';\n\n    axios.request({\n        url: '/auth/token',\n        baseURL: 'http://localhost:8000',\n        method: 'DELETEdelete',\n        withCredentials: true\n    })\n        .then(() => {\n            location.href = '/pages/conversation.html';\n        })\n        .catch(() => {\n            location.href = '/pages/error.html';\n        });\n}\n\nAdd the inviteFriend function to send conversation invites:\n\nasync function inviteFriend() {\n    try {\n        const link = http://localhost:3000/pages/login.html?sid=${window.twilioChat.selectedConvSid};\n\n        await navigator.clipboard.writeText(link);\n\n        alert(The link below has been copied to your clipboard.\\n\\n${link}\\n\\nYou can invite a friend to chat by sending it to them.);\n    } catch {\n        showError('preparing your chat invite');\n    }\n}\n\n\nTo invite other people to participate in the conversation, the current user can send another person a link. This link is to the login page and contains the current conversation SID as a query parameter. When they click the invite button, the link is added to their clipboard. An alert is then displayed giving invite instructions. \nHere is a screenshot of the invite alert:\n\nThe Login Page\nOn this page, a user logs in when they are invited to a conversation. You can find the markup for pages/login.html at this link. \nIn scripts/login.js, the login function is responsible for logging in conversation invitees. Copy its code below and add it to the aforementioned file:\n\nfunction login() {\n    const convParams = new URLSearchParams(window.location.search);\n    const conv = Object.fromEntries(convParams.entries());\n\n    if (conv.sid) {\n        let submitBtn = document.getElementById('login-button');\n        submitBtn.innerText = 'Logging in...';\n        submitBtn.disabled = true;\n        submitBtn.style.cursor = 'wait';\n\n        let loginForm = document.getElementById('loginForm');\n        let formData = new FormData(loginForm);\n        let body = Object.fromEntries(formData.entries());\n\n        axios.request({\n            url: /api/conversations/${conv.sid}/participants,\n            baseURL: 'http://localhost:8000',\n            method: 'POSTpost',\n            withCredentials: true,\n            data: body\n        })\n            .then(() => {\n                location.href = '/pages/chat.html';\n            })\n            .catch(() => {\n                location.href = '/pages/error.html';\n            });\n    } else {\n        location.href = '/pages/conversation.html';\n    }\n}\n\n\nThe login function takes the conversation sid query parameter from the URL and the username from the form. It then makes a POST request to api/conversations/{sid}/participants/ on the backend app. The backend app adds the user to the conversation and generates an access token for messaging. If successful, a session is started in the backend for the user. \nThe user is then redirected to the chat page, but if the request returns an error, they are redirected to the error page. If there is no conversation sid query parameter in the URL, the user is redirected to the conversation page. \nBelow is a screenshot of the login page:\n\nRunning the App\nBefore you can start the front-end app, make sure that the backend app is running. As mentioned earlier, you can start the backend app using this command on the terminal:\nNODE_ENV=development npm start\n\nTo serve the front-end app, run this command in a different terminal window:\nhttp-server -p 3000\n\nThis serves the app at http://localhost:3000. Once it’s running, head on over to http://localhost:3000/pages/conversation.html; set a name for your conversation and add your username, then create it. When you get to the chat page, click on the conversation, then click the Invite button. \nIn a separate incognito window, paste the invite link and put a different username. Once you’re on the chat page in the incognito window, you can begin chatting with yourself. You can send messages back and forth between the user in the first window and the second user in the incognito window in the same conversation. \nConclusion\nIn this tutorial, you learned how to create a chat app using Twilio Conversations and Vanilla JS. You created a Node.js app that generates user access tokens, maintains a session for them, creates conversations, and adds users to them as participants. You also created a front-end app using HTML, CSS, and Vanilla JS. This app should allow users to create conversations, send messages, and invite other people to chat. It should get access tokens from the backend app and use them to perform these functions. I hope this tutorial gave you a better understanding of how Twilio Conversations works and how to use it for chat messaging.\nTo find out more about Twilio Conversations and what else you could do with it, check out its documentation linked here. You can also find the source code for the backend app on Github here, and the code for the front-end app here.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fd5325c3-f376-4565-9ce4-a3798d7d33b3/build-group-chat-app-vanillajs-twilio-nodejs.jpg",
      "date_published": "2022-06-02T09:30:00.000Z",
      "date_modified": "2022-06-02T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/06/dont-sink-website-third-parties/",
      "url": "https://smashingmagazine.com/2022/06/dont-sink-website-third-parties/",
      "title": "Don’t Sink Your Website With Third Parties",
      "summary": "In this article, Ken Harker explains what third-party resource requests really are and which common optimization strategies can help reduce the impact on the user experience. By carefully considering how third-party requests will fit into your website during the design stage, you’ll be able to avoid the most significant negative impacts.",
      "content_html": "<p>You’ve spent months putting together a great website design, crowd-pleasing content, and a business plan to bring it all together. You’ve focused on making the web design responsive to ensure that the widest audience of visitors can access your content. You’ve agonized over design patterns and usability. You’ve tested and retested the site for errors. Your operations team is ready to go. In short, you’ve done your due diligence in the areas of site design and delivery that you directly control. You’ve thought of everything… or have you?</p>\n<p><strong>Your website may be using more third-party services than you realize</strong>. These services use requests to external hosts (not servers you control) to deliver JavaScript framework libraries, custom fonts, advertising content, marketing analytics trackers, and more. </p>\n<p>You may have a lean, agile, responsive site design only to find it gradually loaded down with more and more “extras” that are often put onto the site by marketing departments or business leaders who are not always thinking about website performance. You cannot always anticipate what you cannot control.</p>\n<p>There are two big questions:</p>\n<ol>\n<li>How do you quantify the impact that these third-party requests have on website performance?</li>\n<li>How do you manage or even mitigate that impact? </li>\n</ol>\n<p>Even if you cannot prevent all third-party requests, web designers can make choices that will have an impact. In this article, we will review what third-party resource requests are, consider how impactful they can be to the user experience, and discuss common optimization strategies to reduce the impact on the user experience. By carefully considering how third-party requests will fit into your website during the design stage, you can avoid the most significant negative impacts.</p>\nWhat Are Third-Party Services?\n<p>In order to understand third-party services, it may be easier to start with your own website content. Any resource (HTML, CSS, JavaScript, image, font, etc.) that you host and serve from your own domain(s) is called a “first-party” resource. You have control over what these resources are. All other requests that happen when visitors load your pages can be attributed to other parties.</p>\n<p>Every major website on the Internet today relies — to some degree — on third-party services. The third-party in this case is someone (usually another commercial enterprise) other than you and your site visitors. In this case, we are not going to be talking about infrastructure services, such as a cloud computing platform like Microsoft Azure or a content distribution network like Akamai. Many websites use these services to deploy and run their businesses and understanding how they impact the user experience is important. </p>\n<p>In this article, however, we are going to focus on the <strong>third-party services that work their way into the design of your web pages</strong>. These third-party resource requests load in your visitor’s browser while your web page is loading, even if your visitors don’t realize it. They may be critical to site functionality, or they have been added as an afterthought, but all of them can potentially affect how fast users perceive your page load times.</p>\n<p>The HTTP Archive tracks third-party usage across a large swath of all active websites on the Internet today. According to the <a href=\"https://almanac.httparchive.org/en/2021/third-parties\">Third Parties chapter</a> of their <a href=\"https://almanac.httparchive.org/en/2021/\">2021 Web Almanac report</a>, “a staggering 94.4% of mobile sites and 94.1% of desktop sites use at least one third-party resource.” They also found out that “45.9% of requests on mobile and 45.1% of requests on desktop are third-party requests.”</p>\n<p>As it was noted in the report, third-party services share a few characteristics, such as:</p>\n<ul>\n<li>hosted on a shared and public origin,</li>\n<li>widely used by a variety of sites,</li>\n<li>uninfluenced by an individual site owner.</li>\n</ul>\n<p>In other words, third-party services on your site are outsourced and operated by another party other than you. You have no direct control over where and how the requests are being hosted online. Many other websites may be using the same service, and the company that provides it must balance how to run their services to benefit all of their customers, not just you.</p>\n<p>The upside to using third-party services on your site is that you do not need to develop everything you want to do yourself. In many cases, they can be super convenient to add or remove without having to push code changes to the site. The downside is that <strong>third-party requests can impact website visitors</strong>. Pages loaded up with dozens or hundreds of third-party calls can take longer to render or longer to become interactive.  </p>\n<h3>What About Fourth-party Or Second-Party Services?</h3>\n<p>While the earliest, simplest third-party services were simple 1x1 pixel images used for tracking visitors, almost all third-party requests today load JavaScript into the browser. And JavaScript can certainly make requests for additional network resources. If these follow-on requests are to a different host or service, you might think of them as <strong>“fourth-party services”</strong>. If the fourth-party service, in turn, makes a request to yet another domain, then you get “fifth-party service” requests, and so forth. Technically, all of them might be “third parties” in the sense that they are neither you (the “first party”) nor your site visitor (the “second party”), but I think it helps to understand that these services are even more removed from your direct control than the ones you work directly with.</p>\n<p>The most common scenario I see where fourth-party requests come into play is in advertising services. If you serve ads on your website through an ad broker, you may not even know what service will finally deliver the ad image that gets displayed in the browser.  </p>\n<p>Feeling like this is a little bit out of control? There’s at least one other way that resource requests you have no direct control over can impact your visitors’ experience. Sometimes, the visitor’s browser itself can be the origin of network activity. </p>\n<p>For example, users can install browser plugins to suggest coupon codes when they are shopping, to scan web pages for malware, to play games or message friends, or do any number of other things. These plugins can fire off <strong>“second-party”</strong> requests in the middle of your page load, and there is nothing you can do about it. Unlike third-party services, the best you can do is be aware of what these second-party services are, so you know what to ignore when troubleshooting problems.</p>\n<h3>Create Your Own Request Map</h3>\n<p>As a discovery tool, request maps are great for identifying the source of third-party, fourth-party, fifth-party, etc., requests. They can also highlight very long redirection chains in your third-party traffic. <a href=\"https://twitter.com/simonhearne\">Simon Hearne</a>, an independent web performance consultant and one of the co-organizers of the <a href=\"https://ldnwebperf.org/\">London Web Performance Group</a>, maintains an <a href=\"https://requestmap.webperf.tools\">online Request Map tool</a> that uses <a href=\"https://www.webpagetest.org/\">WebPageTest</a> to get the data and Ghostery to visualize it.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/207d6340-d617-45fe-bd50-f24dea9e8022/5-dont-sink-site-with-third-parties.png\" /></p>\n<h3>Ad Blockers Makes Sites Faster</h3>\n<p>In addition to the browser plugins mentioned above, users love to install ad blockers. While many are motivated simply by a desire to see fewer ads, ad blockers also often make web pages load faster. <a href=\"https://blogs.opera.com/news/2017/05/ads-eat-half-page-loading-time/\">Maciej Kocemba published research findings from Opera</a> that showed that a typical website with ads could be rendered 51% faster if the ads were blocked.</p>\n<p>This is obviously <strong>a concern for any website owner that monetizes page impressions with ads</strong>. They may not realize it, but users may be motivated to block ads partly to deal with slow third-party and fourth-party resource requests that lead to frustrating experiences. Faster page loads may reduce the motivation to use ad blockers.</p>\n<h3>The Revenue Trade-off You Need To Think About</h3>\n<p>Poor performance of third-party services can have other business impacts even if your website does not use advertising. Researchers and major companies have been <a href=\"https://wpostats.com/\">publishing case studies for years</a>, proving that slower page load experiences impact business metrics, including conversion rate, revenue, bounce rate, and more. </p>\n<p>No matter how valuable you think a particular third-party service is to your business, that benefit needs to be compared to the cost of lost visitor engagement. Can a fancy third-party custom font give your site a new look and feel? Yes. Will the conversion rate or session length go down slightly as users see slower page loads? Or will visitors find the new look and feel worth the wait?  </p>\nHow To Identify Problematic Third-Party Services On Your Website\n<p>If you are like most websites, about half of the resource requests that load in your customers’ browsers — when they load a page from your website — are third-party requests. Identifying them should be straightforward.  </p>\n<h3>Measuring Performance Impact</h3>\n<p>To quantify the performance impact of third-party resource requests on the user experience, we need to start by measuring page load performance. Many web performance measurement tools can measure the network load times of individual resource requests, and others can measure the client-side impacts of JavaScript resource requests. You may find that no single tool will answer every performance question you have about third parties. These tools fall into several categories.</p>\n<p>Some tools that can be helpful in evaluating the impact of third-party resource requests are what you might describe as auditing tools. The most popular, by far, is the Google Lighthouse report (available in Chrome Developer Tools) and Google’s Page Speed Insights. These tools generally work with data from a single page load but go into some greater depth on impact than the tools designed for ongoing monitoring.</p>\n<p>Synthetic web performance measurements use scripts to visit one or more pages on your website from one or more probe locations. Much like a laboratory environment (and depending to some degree on the features offered by the particular tool), <strong>you have control over the variables of the measurement</strong>. You can adjust what browser is used, the kind of network connection to employ, the locations to test from, whether or not the browser’s cache is empty or full, how frequently to take the measurements, and more. </p>\n<p>Because most of the variables remain fixed from one test run to the next, synthetic measurements are great for measuring the impact of change but less capable of accurately or comprehensively identifying real visitor experience. They are more of a benchmark than a true measurement of real user experience. Some of the popular synthetic measurement tools are <a href=\"https://www.webpagetest.org/\">WebPageTest</a>, <a href=\"https://www.sitespeed.io/\">SiteSpeed.io</a>, <a href=\"https://www.splunk.com/en_us/observability/synthetic-monitoring.html\">Splunk Synthetic Monitoring</a>, and <a href=\"https://www.dynatrace.com/\">Dynatrace</a>.</p>\n<p>For a more comprehensive measurement of visitor experience, you need <strong>R</strong>eal <strong>U</strong>ser <strong>M</strong>easurements (<strong>RUM</strong>). RUM systems embed a small JavaScript payload onto every page of your site. The code interacts with industry-standard APIs implemented by modern browsers to collect performance data, augments it with additional custom data collection, and transmits this very high-resolution data about the page as a whole and every resource request. </p>\n<p>The data may have some limitations, though — the only data that can be collected is what the APIs support, and <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\"><strong>C</strong>ross <strong>O</strong>rigin <strong>R</strong>esource <strong>S</strong>haring</a> (<strong>CORS</strong>) restrictions in the browsers limit some details, especially around third-party resource requests. Some of the more popular RUM services are offered by <a href=\"https://developer.akamai.com/akamai-mpulse-real-user-monitoring-solution\">Akamai</a>, <a href=\"https://newrelic.com/products/browser-monitoring\">New Relic</a>, <a href=\"https://www.dynatrace.com/platform/real-user-monitoring/\">Dynatrace</a>, and <a href=\"https://www.appdynamics.com/product/end-user-monitoring/browser-real-user-monitoring\">AppDynamics</a>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d328f52c-997b-4ee7-8bb7-1100711b0c63/3-dont-sink-site-with-third-parties.png\" /></p>\n<h3>What To Measure</h3>\n<p>Third-party resource requests can impact the user experience in several different ways, depending on whether they load early in the page load process or after the page is mostly complete. The risk you should be looking for with the measurement data you are collecting include:</p>\n<ul>\n<li><strong>Delaying initial render</strong><br />Resources that load prior to the initial page render (or First Contentful Paint) can be the most impactful overall. Many studies have shown that site visitors are more sensitive to delays at this point in the page load experience than any point after some visual progress has been achieved. Look for third-party requests that force new DNS lookups, require establishing connections to new origins, introduce redirection chains, include substantial client-side processing delay, or take a long time to download.</li>\n<li><strong>Other blocking effects</strong><br />Any JavaScript resource that blocks other resources from being requested until its processing is completed is a concern. A third-party font request could cause render-blocking. Look for third-party JavaScript resources that block other JavaScript resources that are not being loaded asynchronously from being requested in a timely manner. Avoid third-party requests that introduce contention for scarce resources like bandwidth or CPU utilization. If a third-party resource request is blocking, consider alternatives or approaches to mitigate the risk if the third party is slower than normal or fails.</li>\n<li><strong>Single Points of Failure (SPOFs)</strong><br />A resource request can be considered a SPOF if the web page fails to load or the load time is disastrously longer should the resource itself fail to load. For example, if a third-party host is down and your request takes 60 seconds to time out, if the initial render of the page is delayed 60 seconds as a result, then this is a SPOF.</li>\n</ul>\n<h3>Testing The Impact Of Specific Requests</h3>\n<p>Once you have identified potentially impactful third-party resource requests, measuring the specific performance impact of those requests can be challenging. Trying to separate the impact of a single request from all the others can be akin to trying to break down an alloy into its constituent metals because third-party requests are often made in parallel with first-party requests or third-party requests to other hosts, and they are competing with each other for the limited network, CPU, and memory resources of the client. Even with highly-detailed RUM or synthetic measurement data, it may not be practical.</p>\n<p>The best way to approach the problem is through applied testing. Specifically, deliver pages with the third-party request or service as normal, and compare the performance to pages delivered without that particular third-party service but which are otherwise identical.</p>\n<p>This is easiest to do with <strong>synthetic measurement tools</strong>. You can blackhole a particular domain so that the synthetic browser will never make the requests in the first place, simulating a page loading without that service on it. This can inform you about the performance (load times) impact of that third-party service. <a href=\"https://www.webpagetest.org/\">WebPageTest</a> — a free synthetic measurement service (see the following three figures below for an example) — makes this easy.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0780c82f-ee9d-431d-a817-07e055b6ca1b/1-dont-sink-site-with-third-parties.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/95e9726a-ef0e-42ce-bc36-b02f33beddc8/6-dont-sink-site-with-third-parties.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/621b65d7-7876-4895-a40e-d6540e0e1ecb/4-dont-sink-site-with-third-parties.png\" /></p>\n<p>A more sophisticated approach is to <strong>perform multivariate testing</strong> on your production site. In a multivariate test, you serve a version of the page with the third-party tag on it to one segment of your visitor population, and the other segment gets a version of the page without the third-party tag.</p>\n<p>By using RUM tools, you can directly measure the real-world performance differences between the two test segments as well as the effects on business metrics (such as bounce rate, conversion or session length). Managing multivariate testing is a significant undertaking, but it can pay off in the long run.</p>\nDesign Optimizations\n<p>Once you have a baseline of your site performance and some tools to test the basic performance impact of key third-party resource requests, it is time to implement some strategies to mitigate the impact that third-party services can have on performance.</p>\n<h3>Consider Removing Unneeded Services</h3>\n<p>By far, the most impactful change you can make is to remove any obsolete, unused, or unnecessary third-party tags from your site. After all, no resource loads faster than not making a resource request at all. Ironically, this may also be the most challenging optimization to put into practice. In many organizations, third-party tags or services “belong” to a variety of stakeholders, and finding a way to manage them is as much a cultural challenge as a technical one. Some basic steps to take include:</p>\n<ol>\n<li><strong>Audit all third-party requests appearing on your pages on a periodic basis</strong> (for example, quarterly).<br />To make sure you capture all third-party requests, use a RUM service that collects data about every page view. If a third-party domain is showing up in more than a small fraction of page views and you do not already know what it is, find out immediately. New third-party tags may have been added by some stakeholders within your organization, or you may be finding a fourth-party tag because a third-party service changed its behavior. Either way, you need to understand what the third-party tags are and who in your organization is using them.</li>\n<li><strong>Keep records on third-party services.</strong><br />Specifically, you want to know who the internal stakeholder is that “owns” that service and how it gets on the site. Is it hard-coded into the page HTML source? Is there JavaScript injected on the page by a CDN configuration? Are you using one (or more than one) tag manager? When does the contract with that service expire? The important thing is to have all the information on hand to know how to suspend or remove every third-party service if it becomes a performance issue or suddenly stops working, and who in your organization that is going to need to know.</li>\n<li><strong>Consider a periodic stakeholders meeting</strong> that includes a discussion of all third-party services to review the cost/benefit they introduce to the business. Even if it is still under contract, consider removing third-party services that stakeholders no longer use.</li>\n</ol>\n<h3>Geographically Align Your Third-Party Services With Your Visitors</h3>\n<p>If most of your visitors are in Europe, but a third-party service you are using is serving its resource content from the United States, those requests will likely have very slow load times as the traffic must cross an ocean each way. Some third-party services use a CDN of their own to ensure that they are serving requests from locations close to your visitors, but not all will do so. You may need to ensure that you are using appropriate hostnames or parameters in your requests. <a href=\"https://www.cdnplanet.com/tools/cdnfinder/\">CDN Finder</a> is a convenient tool to investigate which CDNs (if any) a third-party tag is using. </p>\n<h3>Loading Scripts Asynchronously</h3>\n<p>Blocking other resource requests from being made by the browser (often called “parser blocking”) is one of the most impactful (in a negative way) things a third-party resource can do. Historically, browsers have blocked while loading scripts to <strong>ensure that the page load experience is predictable</strong>. If scripts always load and evaluate in the same order, there are no surprises. The downside to this is that it takes longer to load the page.</p>\n<p>Fortunately, identifying and blocking third-party script resources is relatively easy. Both <a href=\"https://www.webpagetest.org/\">WebPageTest</a> and <a href=\"https://pagespeed.web.dev/\">PageSpeed Insights</a> (free-to-use tools) highlight resource requests that block other resource requests from being made. These tools work on one page (URL) at a time, so you will need to use them on a representative set of URLs to pick up all the blocking tags on your site.  </p>\n<p>Depending on how the third-party tag gets onto the page, you may be able to change a blocking script into a non-blocking script. Modern browsers support attributes to the script tag that gives the browser flexibility to load resources in a non-blocking manner. These are your basic options:</p>\n<ul>\n<li><code>&lt;script&gt;</code><br />Without an additional attribute, many browsers will block the loading of subsequent scripts until after the script in question is loaded and evaluated. With third-party scripts, this is not only a performance concern but also a potential for a single point of failure (SPOF).</li>\n<li><code>&lt;script async&gt;</code><br />With async, the browser can download the script resource in parallel with other HTML parsing and downloading activity, but it will evaluate the JavaScript immediately once it is done downloading and pause HTML parsing while the script evaluation happens. If the script evaluation needs to happen early in the page load, this is the best choice.</li>\n<li><code>&lt;script defer&gt;</code><br />With defer, the script load will happen in parallel with HTML parsing and the fetching of other resources, and the script will only be evaluated after the HTML is fully parsed. This is the best choice for any third-party tag whose evaluation is less important than a fast render experience for your visitor.</li>\n</ul>\n<h3>Cascading StyleSheets</h3>\n<p>Another kind of blocking that can be impactful to the user experience is render-blocking. Cascading StyleSheets almost always block page render while they are being downloaded and evaluated because the browsers do not want to render content on the screen only to have to change how it looks partway through the page load. For this reason, best practice advice is to <strong>load CSS resources as early as you can in the page load</strong>, so the browser has all the information to render the page as soon as possible. </p>\n<p>Third-party CSS requests are uncommon (mostly limited to custom font support), but if for some reason they are part of your site design, consider loading them directly through script tags in the base page HTML or through your CDN. Using a tag manager will just introduce additional delay in getting a critical resource into the browser as quickly as possible.   </p>\n<h3>Some Further Thoughts On Fonts</h3>\n<p>Like CSS, custom fonts are also render-blocking. Fonts can radically change the visual appearance of text, so browsers do not want to render text on the screen only to have a visually disruptive change mid-page load. Unlike CSS, I see far more sites using third-party resources for their custom fonts, with Google Fonts and Adobe Typekit being the most popular.</p>\n<p>Some implementations of custom fonts also involve loading third-party CSS, which introduces additional render-blocking. The resource requests for these fonts (<code>.woff</code>, <code>woff2</code>, or <code>.ttf</code> files, usually) are also not always done early in the page load. This is a problem for performance and a potential single point of failure.</p>\n<p>Here are some ideas for managing third-party custom fonts on your site:</p>\n<ul>\n<li><strong>Give serious consideration to whether you need custom fonts at all.</strong><br />Page load times will be faster without them, and if the custom font is almost visually identical to some of the fantastic pre-installed <a href=\"https://www.smashingmagazine.com/2015/11/using-system-ui-fonts-practical-guide/\">system fonts</a> now available in modern browsers, the brand impression benefit may be outweighed by the cost of slightly slower page loads frustrating your visitors.</li>\n<li><strong>If custom fonts are a requirement, consider how to deliver them as first-party resources.</strong><br />You may be limited by font licensing restrictions in this respect, and serving fonts from your own domains will result in delivering more bytes to visitors from your CDN or ISP, which can increase costs. On the other hand, you no longer have a SPOF vulnerability, you gain control over caching headers, and your visitors can avoid making connections to yet another third-party host and all the delays that it introduces.</li>\n<li><strong>If you cannot avoid having third-party fonts on your site, consider using font-display properties in your CSS.</strong><br />Setting the font-display property to swap (instead of block), for example, allows the browser to use system fonts until the custom fonts can be swapped in. If the visual change of the custom font is not too disruptive, this could be the best choice to give your visitors the content as early as possible while giving them the brand experience when the fonts do load. The fallback value is another choice that can incorporate a shorter blocking period and otherwise before behaving as a swap. The <a href=\"https://css-tricks.com/almanac/properties/f/font-display/\">CSS-Tricks website</a> has good documentation on font-display.</li>\n</ul>\n<h3>Two Script Management Solutions</h3>\n<p>One interesting approach to managing the performance impact of third parties is to <strong>move as many of them as possible</strong> to load via Web Workers. The core idea is to reserve the main thread in the browser for your first-party core scripts and let the browser manage and optimize your resource-intensive third-party scripts using Web Workers. Doing this is not trivial since Web Workers are limited to asynchronous communications with the main thread and many third-party scripts except synchronous access to browser resources, such as documents and windows. </p>\n<p>A new <a href=\"https://www.smashingmagazine.com/2022/04/partytown-eliminates-website-bloat-third-party-apps/\">open-source project called Partytown</a> provides a library that implements a communications layer to make this work. It is still in the early stages of development, and you would want to test extensively for potential weird side effects. <a href=\"https://dev.to/adamdbradley/how-partytown-s-sync-communication-works-4244\">It might also not work well with a tag manager system</a> if that’s a part of your architecture.</p>\n<p>Akamai Script Management is a solution that uses Service Workers. This service essentially <strong>acts as a proxy inside the browser</strong> that has knowledge about the third-party services on the site and a policy about how to handle specific third-party requests. The policy can block requests for specific third parties, defer their request to later in the page load, or change the waiting time before throwing a timeout error for a request. If a third-party request is render blocking but that third-party service is down, for example, <a href=\"https://developer.akamai.com/script-management-webinar\">Script Management can mitigate the impact</a> by reducing the length of time that the browser waits before deciding that the response is never going to arrive.</p>\nConclusion\n<p>Third-party resource requests have become an integral part of the web. These services can provide value to your business, but they do come at a potential cost to the user experience.</p>\n<p> You need the right tools for detection and measurement and knowledge of the best practices that help reduce the negative impacts of third-party requests.</p>\n<p>A great way to start managing the impacts of third-party requests on your site’s user experience is to audit your site to see which and how many third-party domains and requests are being used. Next, use performance measurement tools to identify those that have the potential to degrade the user experience through render-blocking, resource contention, or single points of failure. </p>\n<p>As you apply changes to mitigate the impact of third parties, <strong>develop a plan to use ongoing testing</strong> (such as <em>Real User Measurement Services</em>) to keep on top of site changes and unexpected changes to your third-party services.</p>\n<p>By carefully considering how third-party requests will fit into your site during the design stage, you can avoid the most significant negative impacts. With ongoing performance monitoring, you can ensure that new problems with third-party requests are identified early. Don’t sink your website with third parties!</p>",
      "content_text": "You’ve spent months putting together a great website design, crowd-pleasing content, and a business plan to bring it all together. You’ve focused on making the web design responsive to ensure that the widest audience of visitors can access your content. You’ve agonized over design patterns and usability. You’ve tested and retested the site for errors. Your operations team is ready to go. In short, you’ve done your due diligence in the areas of site design and delivery that you directly control. You’ve thought of everything… or have you?\nYour website may be using more third-party services than you realize. These services use requests to external hosts (not servers you control) to deliver JavaScript framework libraries, custom fonts, advertising content, marketing analytics trackers, and more. \nYou may have a lean, agile, responsive site design only to find it gradually loaded down with more and more “extras” that are often put onto the site by marketing departments or business leaders who are not always thinking about website performance. You cannot always anticipate what you cannot control.\nThere are two big questions:\n\nHow do you quantify the impact that these third-party requests have on website performance?\nHow do you manage or even mitigate that impact? \n\nEven if you cannot prevent all third-party requests, web designers can make choices that will have an impact. In this article, we will review what third-party resource requests are, consider how impactful they can be to the user experience, and discuss common optimization strategies to reduce the impact on the user experience. By carefully considering how third-party requests will fit into your website during the design stage, you can avoid the most significant negative impacts.\nWhat Are Third-Party Services?\nIn order to understand third-party services, it may be easier to start with your own website content. Any resource (HTML, CSS, JavaScript, image, font, etc.) that you host and serve from your own domain(s) is called a “first-party” resource. You have control over what these resources are. All other requests that happen when visitors load your pages can be attributed to other parties.\nEvery major website on the Internet today relies — to some degree — on third-party services. The third-party in this case is someone (usually another commercial enterprise) other than you and your site visitors. In this case, we are not going to be talking about infrastructure services, such as a cloud computing platform like Microsoft Azure or a content distribution network like Akamai. Many websites use these services to deploy and run their businesses and understanding how they impact the user experience is important. \nIn this article, however, we are going to focus on the third-party services that work their way into the design of your web pages. These third-party resource requests load in your visitor’s browser while your web page is loading, even if your visitors don’t realize it. They may be critical to site functionality, or they have been added as an afterthought, but all of them can potentially affect how fast users perceive your page load times.\nThe HTTP Archive tracks third-party usage across a large swath of all active websites on the Internet today. According to the Third Parties chapter of their 2021 Web Almanac report, “a staggering 94.4% of mobile sites and 94.1% of desktop sites use at least one third-party resource.” They also found out that “45.9% of requests on mobile and 45.1% of requests on desktop are third-party requests.”\nAs it was noted in the report, third-party services share a few characteristics, such as:\n\nhosted on a shared and public origin,\nwidely used by a variety of sites,\nuninfluenced by an individual site owner.\n\nIn other words, third-party services on your site are outsourced and operated by another party other than you. You have no direct control over where and how the requests are being hosted online. Many other websites may be using the same service, and the company that provides it must balance how to run their services to benefit all of their customers, not just you.\nThe upside to using third-party services on your site is that you do not need to develop everything you want to do yourself. In many cases, they can be super convenient to add or remove without having to push code changes to the site. The downside is that third-party requests can impact website visitors. Pages loaded up with dozens or hundreds of third-party calls can take longer to render or longer to become interactive.  \nWhat About Fourth-party Or Second-Party Services?\nWhile the earliest, simplest third-party services were simple 1x1 pixel images used for tracking visitors, almost all third-party requests today load JavaScript into the browser. And JavaScript can certainly make requests for additional network resources. If these follow-on requests are to a different host or service, you might think of them as “fourth-party services”. If the fourth-party service, in turn, makes a request to yet another domain, then you get “fifth-party service” requests, and so forth. Technically, all of them might be “third parties” in the sense that they are neither you (the “first party”) nor your site visitor (the “second party”), but I think it helps to understand that these services are even more removed from your direct control than the ones you work directly with.\nThe most common scenario I see where fourth-party requests come into play is in advertising services. If you serve ads on your website through an ad broker, you may not even know what service will finally deliver the ad image that gets displayed in the browser.  \nFeeling like this is a little bit out of control? There’s at least one other way that resource requests you have no direct control over can impact your visitors’ experience. Sometimes, the visitor’s browser itself can be the origin of network activity. \nFor example, users can install browser plugins to suggest coupon codes when they are shopping, to scan web pages for malware, to play games or message friends, or do any number of other things. These plugins can fire off “second-party” requests in the middle of your page load, and there is nothing you can do about it. Unlike third-party services, the best you can do is be aware of what these second-party services are, so you know what to ignore when troubleshooting problems.\nCreate Your Own Request Map\nAs a discovery tool, request maps are great for identifying the source of third-party, fourth-party, fifth-party, etc., requests. They can also highlight very long redirection chains in your third-party traffic. Simon Hearne, an independent web performance consultant and one of the co-organizers of the London Web Performance Group, maintains an online Request Map tool that uses WebPageTest to get the data and Ghostery to visualize it.\n\nAd Blockers Makes Sites Faster\nIn addition to the browser plugins mentioned above, users love to install ad blockers. While many are motivated simply by a desire to see fewer ads, ad blockers also often make web pages load faster. Maciej Kocemba published research findings from Opera that showed that a typical website with ads could be rendered 51% faster if the ads were blocked.\nThis is obviously a concern for any website owner that monetizes page impressions with ads. They may not realize it, but users may be motivated to block ads partly to deal with slow third-party and fourth-party resource requests that lead to frustrating experiences. Faster page loads may reduce the motivation to use ad blockers.\nThe Revenue Trade-off You Need To Think About\nPoor performance of third-party services can have other business impacts even if your website does not use advertising. Researchers and major companies have been publishing case studies for years, proving that slower page load experiences impact business metrics, including conversion rate, revenue, bounce rate, and more. \nNo matter how valuable you think a particular third-party service is to your business, that benefit needs to be compared to the cost of lost visitor engagement. Can a fancy third-party custom font give your site a new look and feel? Yes. Will the conversion rate or session length go down slightly as users see slower page loads? Or will visitors find the new look and feel worth the wait?  \nHow To Identify Problematic Third-Party Services On Your Website\nIf you are like most websites, about half of the resource requests that load in your customers’ browsers — when they load a page from your website — are third-party requests. Identifying them should be straightforward.  \nMeasuring Performance Impact\nTo quantify the performance impact of third-party resource requests on the user experience, we need to start by measuring page load performance. Many web performance measurement tools can measure the network load times of individual resource requests, and others can measure the client-side impacts of JavaScript resource requests. You may find that no single tool will answer every performance question you have about third parties. These tools fall into several categories.\nSome tools that can be helpful in evaluating the impact of third-party resource requests are what you might describe as auditing tools. The most popular, by far, is the Google Lighthouse report (available in Chrome Developer Tools) and Google’s Page Speed Insights. These tools generally work with data from a single page load but go into some greater depth on impact than the tools designed for ongoing monitoring.\nSynthetic web performance measurements use scripts to visit one or more pages on your website from one or more probe locations. Much like a laboratory environment (and depending to some degree on the features offered by the particular tool), you have control over the variables of the measurement. You can adjust what browser is used, the kind of network connection to employ, the locations to test from, whether or not the browser’s cache is empty or full, how frequently to take the measurements, and more. \nBecause most of the variables remain fixed from one test run to the next, synthetic measurements are great for measuring the impact of change but less capable of accurately or comprehensively identifying real visitor experience. They are more of a benchmark than a true measurement of real user experience. Some of the popular synthetic measurement tools are WebPageTest, SiteSpeed.io, Splunk Synthetic Monitoring, and Dynatrace.\nFor a more comprehensive measurement of visitor experience, you need Real User Measurements (RUM). RUM systems embed a small JavaScript payload onto every page of your site. The code interacts with industry-standard APIs implemented by modern browsers to collect performance data, augments it with additional custom data collection, and transmits this very high-resolution data about the page as a whole and every resource request. \nThe data may have some limitations, though — the only data that can be collected is what the APIs support, and Cross Origin Resource Sharing (CORS) restrictions in the browsers limit some details, especially around third-party resource requests. Some of the more popular RUM services are offered by Akamai, New Relic, Dynatrace, and AppDynamics.\n\nWhat To Measure\nThird-party resource requests can impact the user experience in several different ways, depending on whether they load early in the page load process or after the page is mostly complete. The risk you should be looking for with the measurement data you are collecting include:\n\nDelaying initial renderResources that load prior to the initial page render (or First Contentful Paint) can be the most impactful overall. Many studies have shown that site visitors are more sensitive to delays at this point in the page load experience than any point after some visual progress has been achieved. Look for third-party requests that force new DNS lookups, require establishing connections to new origins, introduce redirection chains, include substantial client-side processing delay, or take a long time to download.\nOther blocking effectsAny JavaScript resource that blocks other resources from being requested until its processing is completed is a concern. A third-party font request could cause render-blocking. Look for third-party JavaScript resources that block other JavaScript resources that are not being loaded asynchronously from being requested in a timely manner. Avoid third-party requests that introduce contention for scarce resources like bandwidth or CPU utilization. If a third-party resource request is blocking, consider alternatives or approaches to mitigate the risk if the third party is slower than normal or fails.\nSingle Points of Failure (SPOFs)A resource request can be considered a SPOF if the web page fails to load or the load time is disastrously longer should the resource itself fail to load. For example, if a third-party host is down and your request takes 60 seconds to time out, if the initial render of the page is delayed 60 seconds as a result, then this is a SPOF.\n\nTesting The Impact Of Specific Requests\nOnce you have identified potentially impactful third-party resource requests, measuring the specific performance impact of those requests can be challenging. Trying to separate the impact of a single request from all the others can be akin to trying to break down an alloy into its constituent metals because third-party requests are often made in parallel with first-party requests or third-party requests to other hosts, and they are competing with each other for the limited network, CPU, and memory resources of the client. Even with highly-detailed RUM or synthetic measurement data, it may not be practical.\nThe best way to approach the problem is through applied testing. Specifically, deliver pages with the third-party request or service as normal, and compare the performance to pages delivered without that particular third-party service but which are otherwise identical.\nThis is easiest to do with synthetic measurement tools. You can blackhole a particular domain so that the synthetic browser will never make the requests in the first place, simulating a page loading without that service on it. This can inform you about the performance (load times) impact of that third-party service. WebPageTest — a free synthetic measurement service (see the following three figures below for an example) — makes this easy.\n\n\n\nA more sophisticated approach is to perform multivariate testing on your production site. In a multivariate test, you serve a version of the page with the third-party tag on it to one segment of your visitor population, and the other segment gets a version of the page without the third-party tag.\nBy using RUM tools, you can directly measure the real-world performance differences between the two test segments as well as the effects on business metrics (such as bounce rate, conversion or session length). Managing multivariate testing is a significant undertaking, but it can pay off in the long run.\nDesign Optimizations\nOnce you have a baseline of your site performance and some tools to test the basic performance impact of key third-party resource requests, it is time to implement some strategies to mitigate the impact that third-party services can have on performance.\nConsider Removing Unneeded Services\nBy far, the most impactful change you can make is to remove any obsolete, unused, or unnecessary third-party tags from your site. After all, no resource loads faster than not making a resource request at all. Ironically, this may also be the most challenging optimization to put into practice. In many organizations, third-party tags or services “belong” to a variety of stakeholders, and finding a way to manage them is as much a cultural challenge as a technical one. Some basic steps to take include:\n\nAudit all third-party requests appearing on your pages on a periodic basis (for example, quarterly).To make sure you capture all third-party requests, use a RUM service that collects data about every page view. If a third-party domain is showing up in more than a small fraction of page views and you do not already know what it is, find out immediately. New third-party tags may have been added by some stakeholders within your organization, or you may be finding a fourth-party tag because a third-party service changed its behavior. Either way, you need to understand what the third-party tags are and who in your organization is using them.\nKeep records on third-party services.Specifically, you want to know who the internal stakeholder is that “owns” that service and how it gets on the site. Is it hard-coded into the page HTML source? Is there JavaScript injected on the page by a CDN configuration? Are you using one (or more than one) tag manager? When does the contract with that service expire? The important thing is to have all the information on hand to know how to suspend or remove every third-party service if it becomes a performance issue or suddenly stops working, and who in your organization that is going to need to know.\nConsider a periodic stakeholders meeting that includes a discussion of all third-party services to review the cost/benefit they introduce to the business. Even if it is still under contract, consider removing third-party services that stakeholders no longer use.\n\nGeographically Align Your Third-Party Services With Your Visitors\nIf most of your visitors are in Europe, but a third-party service you are using is serving its resource content from the United States, those requests will likely have very slow load times as the traffic must cross an ocean each way. Some third-party services use a CDN of their own to ensure that they are serving requests from locations close to your visitors, but not all will do so. You may need to ensure that you are using appropriate hostnames or parameters in your requests. CDN Finder is a convenient tool to investigate which CDNs (if any) a third-party tag is using. \nLoading Scripts Asynchronously\nBlocking other resource requests from being made by the browser (often called “parser blocking”) is one of the most impactful (in a negative way) things a third-party resource can do. Historically, browsers have blocked while loading scripts to ensure that the page load experience is predictable. If scripts always load and evaluate in the same order, there are no surprises. The downside to this is that it takes longer to load the page.\nFortunately, identifying and blocking third-party script resources is relatively easy. Both WebPageTest and PageSpeed Insights (free-to-use tools) highlight resource requests that block other resource requests from being made. These tools work on one page (URL) at a time, so you will need to use them on a representative set of URLs to pick up all the blocking tags on your site.  \nDepending on how the third-party tag gets onto the page, you may be able to change a blocking script into a non-blocking script. Modern browsers support attributes to the script tag that gives the browser flexibility to load resources in a non-blocking manner. These are your basic options:\n\n<script>Without an additional attribute, many browsers will block the loading of subsequent scripts until after the script in question is loaded and evaluated. With third-party scripts, this is not only a performance concern but also a potential for a single point of failure (SPOF).\n<script async>With async, the browser can download the script resource in parallel with other HTML parsing and downloading activity, but it will evaluate the JavaScript immediately once it is done downloading and pause HTML parsing while the script evaluation happens. If the script evaluation needs to happen early in the page load, this is the best choice.\n<script defer>With defer, the script load will happen in parallel with HTML parsing and the fetching of other resources, and the script will only be evaluated after the HTML is fully parsed. This is the best choice for any third-party tag whose evaluation is less important than a fast render experience for your visitor.\n\nCascading StyleSheets\nAnother kind of blocking that can be impactful to the user experience is render-blocking. Cascading StyleSheets almost always block page render while they are being downloaded and evaluated because the browsers do not want to render content on the screen only to have to change how it looks partway through the page load. For this reason, best practice advice is to load CSS resources as early as you can in the page load, so the browser has all the information to render the page as soon as possible. \nThird-party CSS requests are uncommon (mostly limited to custom font support), but if for some reason they are part of your site design, consider loading them directly through script tags in the base page HTML or through your CDN. Using a tag manager will just introduce additional delay in getting a critical resource into the browser as quickly as possible.   \nSome Further Thoughts On Fonts\nLike CSS, custom fonts are also render-blocking. Fonts can radically change the visual appearance of text, so browsers do not want to render text on the screen only to have a visually disruptive change mid-page load. Unlike CSS, I see far more sites using third-party resources for their custom fonts, with Google Fonts and Adobe Typekit being the most popular.\nSome implementations of custom fonts also involve loading third-party CSS, which introduces additional render-blocking. The resource requests for these fonts (.woff, woff2, or .ttf files, usually) are also not always done early in the page load. This is a problem for performance and a potential single point of failure.\nHere are some ideas for managing third-party custom fonts on your site:\n\nGive serious consideration to whether you need custom fonts at all.Page load times will be faster without them, and if the custom font is almost visually identical to some of the fantastic pre-installed system fonts now available in modern browsers, the brand impression benefit may be outweighed by the cost of slightly slower page loads frustrating your visitors.\nIf custom fonts are a requirement, consider how to deliver them as first-party resources.You may be limited by font licensing restrictions in this respect, and serving fonts from your own domains will result in delivering more bytes to visitors from your CDN or ISP, which can increase costs. On the other hand, you no longer have a SPOF vulnerability, you gain control over caching headers, and your visitors can avoid making connections to yet another third-party host and all the delays that it introduces.\nIf you cannot avoid having third-party fonts on your site, consider using font-display properties in your CSS.Setting the font-display property to swap (instead of block), for example, allows the browser to use system fonts until the custom fonts can be swapped in. If the visual change of the custom font is not too disruptive, this could be the best choice to give your visitors the content as early as possible while giving them the brand experience when the fonts do load. The fallback value is another choice that can incorporate a shorter blocking period and otherwise before behaving as a swap. The CSS-Tricks website has good documentation on font-display.\n\nTwo Script Management Solutions\nOne interesting approach to managing the performance impact of third parties is to move as many of them as possible to load via Web Workers. The core idea is to reserve the main thread in the browser for your first-party core scripts and let the browser manage and optimize your resource-intensive third-party scripts using Web Workers. Doing this is not trivial since Web Workers are limited to asynchronous communications with the main thread and many third-party scripts except synchronous access to browser resources, such as documents and windows. \nA new open-source project called Partytown provides a library that implements a communications layer to make this work. It is still in the early stages of development, and you would want to test extensively for potential weird side effects. It might also not work well with a tag manager system if that’s a part of your architecture.\nAkamai Script Management is a solution that uses Service Workers. This service essentially acts as a proxy inside the browser that has knowledge about the third-party services on the site and a policy about how to handle specific third-party requests. The policy can block requests for specific third parties, defer their request to later in the page load, or change the waiting time before throwing a timeout error for a request. If a third-party request is render blocking but that third-party service is down, for example, Script Management can mitigate the impact by reducing the length of time that the browser waits before deciding that the response is never going to arrive.\nConclusion\nThird-party resource requests have become an integral part of the web. These services can provide value to your business, but they do come at a potential cost to the user experience.\n You need the right tools for detection and measurement and knowledge of the best practices that help reduce the negative impacts of third-party requests.\nA great way to start managing the impacts of third-party requests on your site’s user experience is to audit your site to see which and how many third-party domains and requests are being used. Next, use performance measurement tools to identify those that have the potential to degrade the user experience through render-blocking, resource contention, or single points of failure. \nAs you apply changes to mitigate the impact of third parties, develop a plan to use ongoing testing (such as Real User Measurement Services) to keep on top of site changes and unexpected changes to your third-party services.\nBy carefully considering how third-party requests will fit into your site during the design stage, you can avoid the most significant negative impacts. With ongoing performance monitoring, you can ensure that new problems with third-party requests are identified early. Don’t sink your website with third parties!",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/65099ffa-f954-430f-992a-8078a8331802/dont-sink-website-third-parties.jpg",
      "date_published": "2022-06-01T10:00:00.000Z",
      "date_modified": "2022-06-01T10:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/desktop-wallpaper-calendars-june-2022/",
      "url": "https://smashingmagazine.com/2022/05/desktop-wallpaper-calendars-june-2022/",
      "title": "Expand Your Horizons (June 2022 Desktop Wallpapers Edition)",
      "summary": "What could be a better way to welcome June than with some colorful inspiration? Well, we might have something for you: wallpapers created with love by artists and designers from across the globe.",
      "content_html": "<p>There’s an artist in everyone. Some bring their creative ideas to life with digital tools, others <strong>capture the perfect moment</strong> with a camera or love to grab pen and paper to create little doodles or pieces of lettering. And even if you think you’re far from being an artist, well, it might just be hidden somewhere deep inside of you. So why not explore it?</p>\n\n<p>For more than eleven years, our <a href=\"https://www.smashingmagazine.com/category/wallpapers\">monthly wallpapers series</a> has been the perfect opportunity to do just that: to break out of your daily routine and put your creative skills to the test. And, well, creative folks from across the globe once again took on the challenge this month and created unique and inspiring wallpapers for <strong>June 2022</strong>.</p>\n\n<p>The wallpapers in this collection come in versions with and without a calendar and can be downloaded for free. As a little bonus goodie, we also compiled some designs from our wallpapers archives at the end of this post. Maybe you’ll spot one of <em>your</em> almost-forgotten June favorites, too? A big thank-you to everyone who shared their designs with us — this post wouldn’t exist without you!</p>\n\n<ul>\n<li>You can <strong>click on every image to see a larger preview</strong>,</li>\n<li>We respect and carefully consider the ideas and motivation behind each and every artist’s work. This is why we give all artists the <strong>full freedom to explore their creativity</strong> and express emotions and experience through their works. This is also why the themes of the wallpapers weren’t anyhow influenced by us but rather designed from scratch by the artists themselves.</li>\n<li><strong><a href=\"https://www.smashingmagazine.com/desktop-wallpaper-calendars-join-in/\">Submit a wallpaper!</a></strong><br />Did you know that <em>you</em> could get featured in our next wallpapers post, too? We are always <strong>looking for creative talent</strong>.</li>\n</ul>\n\n<div>\n<h3>Editor’s Note</h3>\n<p><em>In this month’s post, you will notice that some of the wallpapers are dedicated to Ukraine and its traditional embroidery patterns found in different regions of the country. As a design community, we can’t be silent in these times. It’s our obligation to help as much as we can, and so we are donating all proceeds of the “<a href=\"https://www.smashingmagazine.com/printed-books/checklist-cards/\">Interface Design Checklists PDF</a>” to support Ukraine.</em><br /><br /><em>We have already donated 16,944.73 EUR (US$ 18,663.86) to <a href=\"https://www.aktion-deutschland-hilft.de/de/hilfseinsaetze/nothilfe-ukraine/\">Aktion Deutschland Hilft e.V.</a> and will continue to donate to other organizations as well. A heartfelt THANK YOU to our wonderful community for all of their help and support!</em> 💞</p>\n</div>\n\nCreate Your Own Path\n<p>“Nice weather has arrived! Clean the dust off your bike and explore your hometown from a different angle! Invite a friend or loved one and share the joy of cycling. Whether you decide to go for a city ride or a ride in nature, the time spent on a bicycle will make you feel free and happy. So don’t wait, take your bike and call your loved one because happiness is greater only when it is shared. Happy World Bike Day!” — Designed by <a href=\"https://www.popwebdesign.net/ux-design.html\">PopArt Studio </a> from Serbia.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/june-22-create-your-own-path-full.jpg\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1c6a9a31-4619-4c93-b9ea-65b5f50082cd/june-22-create-your-own-path-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/june-22-create-your-own-path-preview.jpg\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-320x480.jpg\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-640x480.jpg\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1024x1024.jpg\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/cal/june-22-create-your-own-path-cal-2560x1440.jpg\">2560x1440</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-320x480.jpg\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-640x480.jpg\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1024x1024.jpg\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/create-your-own-path/nocal/june-22-create-your-own-path-nocal-2560x1440.jpg\">2560x1440</a></li>\n</ul>\n\nOld Kyiv\n<p>“This picture is dedicated to Kiev (Kyiv), the capital of Ukraine. It is loosely based on a 13th century map — this is what the center of Kyiv looked like ca. 900 years ago! The original map also included the city wall — however, I decided not to wrap the buildings into the wall, since in my dream world, a city would not need walls.” — Designed by <a href=\"https://vlad.studio/\">Vlad Gerasimov</a> from Georgia.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/june-22-old-kiyv-full.jpg\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a5f5b308-75f0-4c28-9a98-1c5d7099d8cd/june-22-old-kiyv-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/june-22-old-kiyv-preview.jpg\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/cal/june-22-old-kiyv-cal-5120x2880.jpg\">5120x2880</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/old-kiyv/nocal/june-22-old-kiyv-nocal-5120x2880.jpg\">5120x2880</a></li>\n</ul>\n\nWorld Environment Day\n<p>“On June 5th we celebrate World Environment Day — a moment to pause and reflect on how we impact Earth’s health. A few activities represented in this visual include conserving energy and water, shopping and growing local, planting flowers and trees, and building a sustainable infrastructure.” — Designed by <a href=\"https://www.madfishdigital.com/\">Mad Fish Digital</a> from Portland, OR.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/june-22-world-environment-day-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a1642a17-7fd3-4a75-b017-b64558b967f9/june-22-world-environment-day-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/june-22-world-environment-day-preview.png\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/cal/june-22-world-environment-day-cal-320x480.png\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/cal/june-22-world-environment-day-cal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/cal/june-22-world-environment-day-cal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/cal/june-22-world-environment-day-cal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/cal/june-22-world-environment-day-cal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/cal/june-22-world-environment-day-cal-2560x1440.png\">2560x1440</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/nocal/june-22-world-environment-day-nocal-320x480.png\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/nocal/june-22-world-environment-day-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/nocal/june-22-world-environment-day-nocal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/nocal/june-22-world-environment-day-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/nocal/june-22-world-environment-day-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/world-environment-day/nocal/june-22-world-environment-day-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\nSummer Chamomile\n<p>“Our designers were inspired by the lightness and innocence of June, as well as the desire to use bright colors. More calendars are <a href=\"https://masterbundles.com/amazing-june-calendars/\">here</a>.” — Designed by <a href=\"https://masterbundles.com/amazing-june-calendars/\">MasterBundles</a> from Ukraine.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/june-22-summer-chamomile-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d4e4afee-6f89-4679-9663-a999a250da37/june-22-summer-chamomile-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/june-22-summer-chamomile-preview.png\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-320x480.png\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/cal/june-22-summer-chamomile-cal-2560x1440.png\">2560x1440</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-320x480.png\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summer-chamomile/nocal/june-22-summer-chamomile-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\nUkrainian Embroidery\n\n<p><a href=\"https://vlad.studio/\">Vlad Gerasimov</a> from Georgia designed a series of wallpapers in which he explores traditional embroidery patterns found in different regions in Ukraine and the stories behind them.</p>\n\n<p></p><h3>Kherson</h3><p></p>\n<p>“This picture is dedicated to the Kherson region. Forms of fruits, flowers, leaves close to nature are typical of Kherson region. Viburnum motifs are usually found on women’s shirts, it is a symbol of beauty. Oak motifs are most often seen on boys’ shirts, they are a symbol of strength, development, and life. So, the boys wore a miraculous amulet of life-giving power of some kind.” — Designed by <a href=\"https://vlad.studio/\">Vlad Gerasimov</a> from Georgia.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/june-22-ukrainian-embroidery-kherson-full.jpg\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b02bee47-42f6-41f9-a33c-5ca7df105134/june-22-ukrainian-embroidery-kherson-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/june-22-ukrainian-embroidery-kherson-preview.jpg\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/cal/june-22-ukrainian-embroidery-kherson-cal-5120x2880.jpg\">5120x2880</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kherson/nocal/june-22-ukrainian-embroidery-kherson-nocal-5120x2880.jpg\">5120x2880</a></li>\n</ul>\n\n<h3>Mykolaiv</h3>\n<p>“This picture is dedicated to the Mykolaiv region. A large number of embroidered products of Mykolaiv region is characterized by floral ornaments. The symbol of the triangle, which is found on embroidered shirts, has long been associated with the element of fire, where fire represents the striving for freedom. The main colors were mostly red, blue, black, and yellow.” — Designed by <a href=\"https://vlad.studio/\">Vlad Gerasimov</a> from Georgia.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/june-22-ukrainian-embroidery-mykolaiv-full.jpg\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/65e3bcbf-cf0f-429c-8825-582ccbe7349b/june-22-ukrainian-embroidery-mykolaiv-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/june-22-ukrainian-embroidery-mykolaiv-preview.jpg\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/cal/june-22-ukrainian-embroidery-mykolaiv-cal-5120x2880.jpg\">5120x2880</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-mykolaiv/nocal/june-22-ukrainian-embroidery-mykolaiv-nocal-5120x2880.jpg\">5120x2880</a></li>\n</ul>\n\n<h3>Kirovohrad</h3>\n<p>“This picture is dedicated to the Kirovohrad region. From ancient times in Ukraine poppies were consecrated. People and cattle were sown with them. People believed that the poppy has a magical power that protects against all evil. Poppy motifs can be seen on the shirts of the Kirovohrad region.” — Designed by <a href=\"https://vlad.studio/\">Vlad Gerasimov</a> from Georgia.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/june-22-ukrainian-embroidery-kirovohrad-full.jpg\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ef8fa80c-0c1e-41ff-a9d6-2f62e51040d5/june-22-ukrainian-embroidery-kirovohrad-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/june-22-ukrainian-embroidery-kirovohrad-preview.jpg\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/cal/june-22-ukrainian-embroidery-kirovohrad-cal-5120x2880.jpg\">5120x2880</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-kirovohrad/nocal/june-22-ukrainian-embroidery-kirovohrad-nocal-5120x2880.jpg\">5120x2880</a></li>\n</ul>\n\n<h3>Ternopil</h3>\n<p>“This picture is dedicated to the Ternopil region. Embroidery of Ternopil region is characterized by rich, dark, up to black, colors. Made of wool, thick, almost without gaps, the ornaments completely cover the sleeves of women’s shirts. Floral motifs are often found on the shirts of Ternopil region, in particular marigold flowers, sunflowers, mustard.” — Designed by <a href=\"https://vlad.studio/\">Vlad Gerasimov</a> from Georgia.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/june-22-ukrainian-embroidery-ternopil-full.jpg\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9d809e5e-68e1-402f-89a0-5d44321dcd88/june-22-ukrainian-embroidery-ternopil-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/june-22-ukrainian-embroidery-ternopil-preview.jpg\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/cal/june-22-ukrainian-embroidery-ternopil-cal-5120x2880.jpg\">5120x2880</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-ternopil/nocal/june-22-ukrainian-embroidery-ternopil-nocal-5120x2880.jpg\">5120x2880</a></li>\n</ul>\n\n<h3>Sumy</h3>\n<p>“This picture is dedicated to the Sumy region. Geometric and plant-geometrized patterns were embroidered on the shirt from Sumy region. Most often there is an embroidered pattern called broken branch. This pattern has its ancient and deep meaning and depicts the creation of our Galaxy.” — Designed by <a href=\"https://vlad.studio/\">Vlad Gerasimov</a> from Georgia.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/june-22-ukrainian-embroidery-sumy-full.jpg\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d57fdf26-d1e5-490b-a09e-b430a02da899/june-22-ukrainian-embroidery-sumy-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/june-22-ukrainian-embroidery-sumy-preview.jpg\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/cal/june-22-ukrainian-embroidery-sumy-cal-5120x2880.jpg\">5120x2880</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-800x480.jpg\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-800x600.jpg\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1024x600.jpg\">1024x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1440x960.jpg\">1440x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1600x900.jpg\">1600x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-2560x1440.jpg\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-2560x1600.jpg\">2560x1600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-2880x1800.jpg\">2880x1800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-3072x1920.jpg\">3072x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-3840x2160.jpg\">3840x2160</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/ukrainian-embroidery-sumy/nocal/june-22-ukrainian-embroidery-sumy-nocal-5120x2880.jpg\">5120x2880</a></li>\n</ul>\n\nLooking At The Stars\n<p>“This month we travel to the stars. We find a planet and we sit down to observe the universe.” — Designed by <a href=\"https://www.silocreativo.com/en\">Veronica Valenzuela</a> from Spain.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/june-22-looking-at-the-stars-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9525d457-b30d-43b3-932c-f32053d55a3d/june-22-looking-at-the-stars-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/june-22-looking-at-the-stars-preview.png\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/cal/june-22-looking-at-the-stars-cal-2560x1440.png\">2560x1440</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/looking-at-the-stars/nocal/june-22-looking-at-the-stars-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\nI’m So Good\n<p>Designed by <a href=\"https://www.ricardogimenes.com/\">Ricardo Gimenes</a> from Sweden.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/june-22-im-so-good-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c29ab095-f4d9-4a33-9405-1c60c1b86432/june-22-im-so-good-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/june-22-im-so-good-preview.png\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-2560x1440.png\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/cal/june-22-im-so-good-cal-3840x2160.png\">3840x2160</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-2560x1440.png\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/im-so-good/nocal/june-22-im-so-good-nocal-3840x2160.png\">3840x2160</a></li>\n</ul>\n\nAwesome Summer Sunflowers\n<p>“Sunflowers are one of the symbols of Ukraine. There is especially a lot of them in the south, where the fighting is now taking place. Our designers were inspired by our nature and belief in our victory and therefore created this calendar. More calendars are available at <a href=\"https://masterbundles.com/\">https://masterbundles.com/</a>. Welcome!” — Designed by <a href=\"https://masterbundles.com/\">MasterBundles</a> from Ukraine.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/june-22-awesome-summer-sunflowers-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8cf079a9-1b5e-40bd-b8df-12dc991c95cf/june-22-awesome-summer-sunflowers-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/june-22-awesome-summer-sunflowers-preview.png\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-320x480.png\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/cal/june-22-awesome-summer-sunflowers-cal-2560x1440.png\">2560x1440</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-320x480.png\">320x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/awesome-summer-sunflowers/nocal/june-22-awesome-summer-sunflowers-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\nMr Broccoli Doesn’t Like You Either\n<p>Designed by <a href=\"https://www.ricardogimenes.com/\">Ricardo Gimenes</a> from Sweden.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/june-22-mr-broccoli-doesnt-like-you-either-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a2775e0d-0fe2-4755-862f-0b5acdaa7cbc/june-22-mr-broccoli-doesnt-like-you-either-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/june-22-mr-broccoli-doesnt-like-you-either-preview.png\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-2560x1440.png\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/cal/june-22-mr-broccoli-doesnt-like-you-either-cal-3840x2160.png\">3840x2160</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-640x480.png\">640x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-800x480.png\">800x480</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-800x600.png\">800x600</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1024x768.png\">1024x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1152x864.png\">1152x864</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1280x720.png\">1280x720</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1280x800.png\">1280x800</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1280x960.png\">1280x960</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-2560x1440.png\">2560x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/mr-broccoli-doesnt-like-you-either/nocal/june-22-mr-broccoli-doesnt-like-you-either-nocal-3840x2160.png\">3840x2160</a></li>\n</ul>\n\nSummertime\n<p>Designed by <a href=\"https://activecollab.com\">ActiveCollab</a> from the United States.</p>\n<a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/june-22-summertime-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1d1cb50c-9a37-41c4-9d2c-485bc2bc9989/june-22-summertime-preview-opt.png\" /></a>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/june-22-summertime-preview.png\">preview</a></li>\n<li>with calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1080x1920.png\">1080x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/cal/june-22-summertime-cal-2560x1440.png\">2560x1440</a></li>\n<li>without calendar: <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1080x1920.png\">1080x1920</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1366x768.png\">1366x768</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1440x900.png\">1440x900</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://www.smashingmagazine.com/files/wallpapers/june-22/summertime/nocal/june-22-summertime-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\n\n\nOldies But Goodies\n\n<p>Ready for more? Below you’ll find a little <strong>best-of</strong> from past June editions. Please note that these wallpapers don’t come with a calendar. Enjoy!</p>\n\n<p></p><h3>Travel Time</h3><p></p>\n<p></p><p>“June is our favorite time of the year because the keenly anticipated sunny weather inspires us to travel. Stuck at the airport, waiting for our flight but still excited about wayfaring, we often start dreaming about the new places we are going to visit. Where will you travel to this summer? Wherever you go, we wish you a pleasant journey!” — Designed by <a href=\"https://www.popwebdesign.net/index_eng.html\">PopArt Studio</a> from Serbia.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1fa14b29-e470-4b7d-b73d-1dd94d32bdf8/june-18-travel-time-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d57d2cfe-3f0d-48ac-9c26-df7e43cbd76b/june-18-travel-time-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d57d2cfe-3f0d-48ac-9c26-df7e43cbd76b/june-18-travel-time-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-320x480.jpg\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-640x480.jpg\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-800x480.jpg\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-800x600.jpg\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1024x1024.jpg\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/travel-time/nocal/june-18-travel-time-nocal-2560x1440.jpg\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Summer Party</h3><p></p>\n<p></p><p>Designed by <a href=\"https://www.ricardogimenes.com/\">Ricardo Gimenes</a> from Sweden.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6d0cb175-acd5-400c-b34d-9ffb094261ab/june-21-summer-party-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/db056d09-00a6-4aef-b237-64f081d6aec2/june-21-summer-party-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/db056d09-00a6-4aef-b237-64f081d6aec2/june-21-summer-party-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-640x480.png\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-800x480.png\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-800x600.png\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1024x768.png\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1152x864.png\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1280x720.png\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1280x800.png\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1280x960.png\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1366x768.png\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-2560x1440.png\">2560x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/summer-party/nocal/june-21-summer-party-nocal-3840x2160.png\">3840x2160</a></li>\n</ul>\n\n<p></p><h3>Dancing In The Summer Moonlight</h3><p></p>\n<p></p><p>“If you’re happy and you know it, show some dance moves, because summer is finally here!” — Designed by <a href=\"https://activecollab.com/\">ActiveCollab</a> from the United States.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/79aca550-08b4-479f-a905-6c7e26fed3f6/june-21-dancing-in-the-summer-moonlight-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/de1f5e31-f1e6-4e44-a852-49ffe601e9f2/june-21-dancing-in-the-summer-moonlight-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/de1f5e31-f1e6-4e44-a852-49ffe601e9f2/june-21-dancing-in-the-summer-moonlight-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1080x1920.png\">1080x1920</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1366x768.png\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/dancing-in-the-summer-moonlight/nocal/june-21-dancing-in-the-summer-moonlight-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Summer Coziness</h3><p></p>\n<p></p><p>“I’ve waited for this summer more than I waited for any other summer since I was a kid. I dream of watermelon, strawberries, and lots of colors.” — Designed by <a href=\"https://cozystream.com/\">Kate Jameson</a> from the United States.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/aa7facf5-395f-44a4-a0da-05a2b1a5bd23/june-20-summer-coziness-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/374464b5-093e-4ca2-9397-6f26c83756d4/june-20-summer-coziness-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/374464b5-093e-4ca2-9397-6f26c83756d4/june-20-summer-coziness-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-20/summer-coziness/nocal/june-20-summer-coziness-nocal-320x480.png\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-20/summer-coziness/nocal/june-20-summer-coziness-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-20/summer-coziness/nocal/june-20-summer-coziness-nocal-1280x720.png\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-20/summer-coziness/nocal/june-20-summer-coziness-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-20/summer-coziness/nocal/june-20-summer-coziness-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-20/summer-coziness/nocal/june-20-summer-coziness-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Solstice Sunset</h3><p></p>\n<p></p><p>“June 21 marks the longest day of the year for the Northern Hemisphere — and sunsets like these will be getting earlier and earlier after that!” — Designed by <a href=\"https://www.behance.net/jamesmitchell23\">James Mitchell</a> from the United Kingdom.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/492124f6-1b46-441b-a52b-2bbcf4372536/june-17-solstice-sunset-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2c0f6baa-5eda-4741-aa4c-bb92a50c16cb/june-17-solstice-sunset-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2c0f6baa-5eda-4741-aa4c-bb92a50c16cb/june-17-solstice-sunset-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-1280x720.png\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-1280x800.png\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-1366x768.png\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-2560x1440.png\">2560x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/solstice-sunset/nocal/june-17-solstice-sunset-nocal-2880x1800.png\">2880x1800</a></li>\n</ul>\n\n<p></p><h3>Oh, The Places You Will Go!</h3><p></p>\n<p></p><p>“In celebration of high school and college graduates ready to make their way in the world!” — Designed by <a href=\"https://bloeschcreative.etsy.com\">Bri Loesch</a> from the United States.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/46f6cae6-a2aa-468c-ba2f-ecf40e375055/june-14-oh-the-places-you-will-go-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5f1235cf-2e90-4379-9126-fb1afcc0338c/june-14-oh-the-places-you-will-go-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5f1235cf-2e90-4379-9126-fb1afcc0338c/june-14-oh-the-places-you-will-go-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-320x480.png\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-1024x768.png\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-14/oh-the-places-you-will-go/nocal/june-14-oh-the-places-you-will-go-nocal-2560x1440.png\">2560x1440</a></li></ul>\n\n<p></p><h3>Deep Dive</h3><p></p>\n<p></p><p>“Summer rains, sunny days, and a whole month to enjoy. Dive deep inside your passions and let them guide you.” — Designed by <a href=\"https://www.creitive.com/\">Ana Masnikosa</a> from Belgrade, Serbia.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fc6e8288-e0fc-4db9-8193-a75d34cf964b/june-17-deep-dive-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/565f3237-80f3-46a3-b86a-2c62b5be1213/june-17-deep-dive-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/565f3237-80f3-46a3-b86a-2c62b5be1213/june-17-deep-dive-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-320x480.png\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-640x480.png\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-800x480.png\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-800x600.png\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1024x768.png\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1152x864.png\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1280x720.png\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1280x800.png\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1280x960.png\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/deep-dive/nocal/june-17-deep-dive-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\n\n\n<p></p><h3>Ice Creams Away!</h3><p></p>\n<p></p><p>“Summer is taking off with some magical ice cream hot air balloons.” — Designed by <a href=\"https://www.sashaendoh.com\">Sasha Endoh</a> from Canada.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/269afd2b-4458-4abd-8ebe-c37011f98fbc/jun-13-ice-creams-away-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/544e8fbe-c670-4db5-a842-6243cbf84d9e/jun-13-ice-creams-away-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/544e8fbe-c670-4db5-a842-6243cbf84d9e/jun-13-ice-creams-away-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-320x480.jpg\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-13/ice-creams-away!/jun-13-Ice_creams_away-nocal-2560x1440.jpg\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Strawberry Fields</h3><p></p>\n<p></p><p>Designed by <a href=\"https://www.nathalieouederni.com/\">Nathalie Ouederni</a> from France.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d1977205-14df-4712-9049-a03ba427a678/june-15-strawberry-fields-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c5ed64c5-aacb-424d-a996-6b72be2e5339/june-15-strawberry-fields-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c5ed64c5-aacb-424d-a996-6b72be2e5339/june-15-strawberry-fields-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/strawberry-fields/nocal/june-15-strawberry-fields-nocal-320x480.jpg\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/strawberry-fields/nocal/june-15-strawberry-fields-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/strawberry-fields/nocal/june-15-strawberry-fields-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/strawberry-fields/nocal/june-15-strawberry-fields-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/strawberry-fields/nocal/june-15-strawberry-fields-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/strawberry-fields/nocal/june-15-strawberry-fields-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/strawberry-fields/nocal/june-15-strawberry-fields-nocal-2560x1440.jpg\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Bauhaus</h3><p></p>\n<p></p><p>“I created a screenprint of one of the most famous buildings from the Bauhaus architect Mies van der Rohe for you. So, enjoy the Barcelona Pavillon for your June wallpaper.” — Designed by <a href=\"https://glasshousestudio.de\">Anne Korfmacher</a> from Germany.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/008e5306-b83d-4216-9d40-b10a3713b9b9/june-19-its-bauhaus-year-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9046bec0-51bb-4aea-b312-c960e3c5894d/june-19-its-bauhaus-year-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9046bec0-51bb-4aea-b312-c960e3c5894d/june-19-its-bauhaus-year-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-640x480.jpeg\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-800x480.jpeg\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-800x600.jpeg\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1024x768.jpeg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1024x1024.jpeg\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1152x864.jpeg\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1280x800.jpeg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1280x960.jpeg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1280x1024.jpeg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1366x768.jpeg\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1400x1050.jpeg\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1440x900.jpeg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1600x1200.jpeg\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1680x1050.jpeg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1680x1200.jpeg\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1920x1080.jpeg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1920x1200.jpeg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-1920x1440.jpeg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/its-bauhaus-year/nocal/june-19-its-bauhaus-year-nocal-2560x1440.jpeg\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Merry-Go-Round</h3><p></p>\n<p></p><p>Designed by <a href=\"https://www.behance.com/xenialatii\">Xenia Latii</a> from Germany.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6ad15efe-32d0-4a13-9f98-0fbc19ad0e30/june-17-merry-go-round-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3567d518-b622-410d-86d3-9f844cba1cad/june-17-merry-go-round-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3567d518-b622-410d-86d3-9f844cba1cad/june-17-merry-go-round-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-320x480.jpg\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-640x480.jpg\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-800x480.jpg\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-800x600.jpg\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/merry-go-round/nocal/june-17-merry-go-round-nocal-2560x1440.jpg\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Summer Surf</h3><p></p>\n<p></p><p>“Summer vibes…” — Designed by <a href=\"https://www.facebook.com/Hirs-Design-148950788515251/?timeline_context_item_type=intro_card_work&amp;timeline_context_item_source=100002085435433\">Antun Hirsman</a> from Croatia.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/718103fa-7136-4f8c-a4d7-9cd1d2866c88/june-18-summer-surf-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/50f03ba5-c76f-497a-8948-934b504c0a9e/june-18-summer-surf-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/50f03ba5-c76f-497a-8948-934b504c0a9e/june-18-summer-surf-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-640x480.jpg\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-18/summer-surf/nocal/june-18-summer-surf-nocal-2650x1440.jpg\">2650x1440</a></li>\n</ul>\n\n<p></p><h3>Melting Away</h3><p></p>\n<p></p><p>Designed by <a href=\"https://www.ricardogimenes.com/\">Ricardo Gimenes</a> from Sweden.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/01f70092-8fa6-41c9-a5b0-4d2d441bfd2c/june-19-melting-away-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/68c2d3c0-1f39-4edf-a88d-f1869066901d/june-19-melting-away-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/68c2d3c0-1f39-4edf-a88d-f1869066901d/june-19-melting-away-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-320x480.png\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-640x480.png\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-800x480.png\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-800x600.png\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1024x768.png\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1152x864.png\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1280x720.png\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1280x800.png\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1280x960.png\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1366x768.png\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-19/melting-away/nocal/june-19-melting-away-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Pineapple Summer Pop</h3><p></p>\n<p></p><p>“I love creating fun and feminine illustrations and designs. I was inspired by juicy tropical pineapples to celebrate the start of summer.” — Designed by <a href=\"https://www.paperplaygrounds.com\">Brooke Glaser</a> from Honolulu, Hawaii.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e2d050c6-791c-4043-af11-3624e87054fe/june-16-pineapple-summer-pop-full-opt.png\">&lt;img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/16db22ee-c7f8-47a3-856c-992c82cd61f9/june-16-pineapple-summer-pop-preview-opt.png\" alt=\"Pineapple Summer Pop\"<p></p>\n<blockquote>\n<p></p></blockquote></a><p></p>\n\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/16db22ee-c7f8-47a3-856c-992c82cd61f9/june-16-pineapple-summer-pop-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-640x480.jpg\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-800x600.jpg\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1152x720.jpg\">1152x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/pineapple-summer-pop/nocal/june-16-pineapple-summer-pop-nocal-2560x1440.jpg\">2560x1440</a></li></ul>\n\n\n\n<p></p><h3>Fishing Is My Passion!</h3><p></p>\n<p></p><p>“The month of June is a wonderful time to go fishing, the most soothing and peaceful activity.” — Designed by <a href=\"https://izhik.com\">Igor Izhik</a> from Canada.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/90ce52e5-9da1-4bcd-99a0-997663458d1b/june-15-fishing-is-my-passion-full.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/add8ae80-3475-473f-9595-0c4a68a228a4/june-15-fishing-is-my-passion-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/add8ae80-3475-473f-9595-0c4a68a228a4/june-15-fishing-is-my-passion-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-320x480.jpg\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-640x480.jpg\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-800x480.jpg\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-800x600.jpg\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1024x1024.jpg\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-15/fishing-is-my-passion/nocal/june-15-fishing-is-my-passion-nocal-2560x1440.jpg\">2560x1440</a></li></ul>\n\n<p></p><h3>Getting Better Everyday</h3><p></p>\n<p></p><p>“The eternal forward motion to get better and excel.” — Designed by <a href=\"https://zjmdesigns.myportfolio.com/\">Zachary Johnson-Medland</a> from the United States.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e64cde11-f306-4d57-b1b6-1d6965a1550e/june-17-getting-better-everyday-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4973fc78-d798-46c8-bb9d-ea639712a70a/june-17-getting-better-everyday-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4973fc78-d798-46c8-bb9d-ea639712a70a/june-17-getting-better-everyday-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-320x480.png\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-640x480.png\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-800x480.png\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-800x600.png\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1024x768.png\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1152x864.png\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1280x720.png\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1280x800.png\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1280x960.png\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1366x768.png\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/getting-better-everyday/nocal/june-17-getting-better-everyday-nocal-2560x1440.png\">2560x1440</a></li></ul>\n\n<p></p><h3>Expand Your Horizons</h3><p></p>\n<p></p><p>“It’s summer! Go out, explore, expand your horizons!” — Designed by <a href=\"https://dorvandavoudi.com\">Dorvan Davoudi</a> from Canada.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/03f98df0-bf1a-43b1-8058-a4ca522ab709/june-16-expand-your-horizons-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bb46c0af-2c1f-49ab-94f0-79dcd7d32668/june-16-expand-your-horizons-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bb46c0af-2c1f-49ab-94f0-79dcd7d32668/june-16-expand-your-horizons-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-800x480.jpg\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-800x600.jpg\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1024x1024.jpg\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1152x864.jpg\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1280x720.jpg\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1400x1050.jpg\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-16/expand-your-horizons/nocal/june-16-expand-your-horizons-nocal-2560x1440.jpg\">2560x1440</a></li></ul>\n\n<p></p><h3>Happy Squatch</h3><p></p>\n<p></p><p>“I just wanted to capture the atmosphere of late spring/early summer in a fun, quirky way that may be reflective of an adventurous person during this time of year.” — Designed by <a href=\"https://artarcarese.car.blog/\">Nick Arcarese</a> from the United States.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b4c3b932-ce0a-4418-af0b-c6fc4059208d/june-21-happy-squatch-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ce69ee5f-0bf7-441e-83cd-bc50c0f4691f/june-21-happy-squatch-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ce69ee5f-0bf7-441e-83cd-bc50c0f4691f/june-21-happy-squatch-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-320x480.png\">320x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-640x480.png\">640x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-800x480.png\">800x480</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-800x600.png\">800x600</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1024x768.png\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1024x1024.png\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1152x864.png\">1152x864</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1280x720.png\">1280x720</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1280x800.png\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1280x960.png\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1280x1024.png\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1366x768.png\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1400x1050.png\">1400x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1440x900.png\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1600x1200.png\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1680x1050.png\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1680x1200.png\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1920x1080.png\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1920x1200.png\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-1920x1440.png\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-21/happy-squatch/nocal/june-21-happy-squatch-nocal-2560x1440.png\">2560x1440</a></li>\n</ul>\n\n<p></p><h3>Nine Lives</h3><p></p>\n<p></p><p>“I grew up with cats around (and drawing them all the time). They are so funny… one moment they are being funny, the next they are reserved. If you have place in your life for a pet, adopt one today!” — Designed by <a href=\"https://www.codesign.cc/\">Karen Frolo</a> from the United States.</p><p></p>\n<p></p><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/82f48517-5119-41a9-8073-83773719dd23/june-17-nine-lives-full-opt.png\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1c067d70-8504-476c-9730-b1d110917563/june-17-nine-lives-preview-opt.png\" /></a><p></p>\n<ul>\n<li><a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1c067d70-8504-476c-9730-b1d110917563/june-17-nine-lives-preview-opt.png\">preview</a></li>\n<li>without calendar: <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1024x768.jpg\">1024x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1024x1024.jpg\">1024x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1280x800.jpg\">1280x800</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1280x960.jpg\">1280x960</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1280x1024.jpg\">1280x1024</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1366x768.jpg\">1366x768</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1440x900.jpg\">1440x900</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1600x1200.jpg\">1600x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1680x1050.jpg\">1680x1050</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1680x1200.jpg\">1680x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1920x1080.jpg\">1920x1080</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1920x1200.jpg\">1920x1200</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-1920x1440.jpg\">1920x1440</a>, <a href=\"https://smashingmagazine.com/files/wallpapers/june-17/nine-lives/nocal/june-17-nine-lives-nocal-2560x1440.jpg\">2560x1440</a></li></ul>",
      "content_text": "There’s an artist in everyone. Some bring their creative ideas to life with digital tools, others capture the perfect moment with a camera or love to grab pen and paper to create little doodles or pieces of lettering. And even if you think you’re far from being an artist, well, it might just be hidden somewhere deep inside of you. So why not explore it?\n\nFor more than eleven years, our monthly wallpapers series has been the perfect opportunity to do just that: to break out of your daily routine and put your creative skills to the test. And, well, creative folks from across the globe once again took on the challenge this month and created unique and inspiring wallpapers for June 2022.\n\nThe wallpapers in this collection come in versions with and without a calendar and can be downloaded for free. As a little bonus goodie, we also compiled some designs from our wallpapers archives at the end of this post. Maybe you’ll spot one of your almost-forgotten June favorites, too? A big thank-you to everyone who shared their designs with us — this post wouldn’t exist without you!\n\n\nYou can click on every image to see a larger preview,\nWe respect and carefully consider the ideas and motivation behind each and every artist’s work. This is why we give all artists the full freedom to explore their creativity and express emotions and experience through their works. This is also why the themes of the wallpapers weren’t anyhow influenced by us but rather designed from scratch by the artists themselves.\nSubmit a wallpaper!Did you know that you could get featured in our next wallpapers post, too? We are always looking for creative talent.\n\n\n\nEditor’s Note\nIn this month’s post, you will notice that some of the wallpapers are dedicated to Ukraine and its traditional embroidery patterns found in different regions of the country. As a design community, we can’t be silent in these times. It’s our obligation to help as much as we can, and so we are donating all proceeds of the “Interface Design Checklists PDF” to support Ukraine.We have already donated 16,944.73 EUR (US$ 18,663.86) to Aktion Deutschland Hilft e.V. and will continue to donate to other organizations as well. A heartfelt THANK YOU to our wonderful community for all of their help and support! 💞\n\n\nCreate Your Own Path\n“Nice weather has arrived! Clean the dust off your bike and explore your hometown from a different angle! Invite a friend or loved one and share the joy of cycling. Whether you decide to go for a city ride or a ride in nature, the time spent on a bicycle will make you feel free and happy. So don’t wait, take your bike and call your loved one because happiness is greater only when it is shared. Happy World Bike Day!” — Designed by PopArt Studio  from Serbia.\n\n\npreview\nwith calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nOld Kyiv\n“This picture is dedicated to Kiev (Kyiv), the capital of Ukraine. It is loosely based on a 13th century map — this is what the center of Kyiv looked like ca. 900 years ago! The original map also included the city wall — however, I decided not to wrap the buildings into the wall, since in my dream world, a city would not need walls.” — Designed by Vlad Gerasimov from Georgia.\n\n\npreview\nwith calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1440x900, 1440x960, 1400x1050, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\nwithout calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1440x900, 1440x960, 1400x1050, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\n\n\nWorld Environment Day\n“On June 5th we celebrate World Environment Day — a moment to pause and reflect on how we impact Earth’s health. A few activities represented in this visual include conserving energy and water, shopping and growing local, planting flowers and trees, and building a sustainable infrastructure.” — Designed by Mad Fish Digital from Portland, OR.\n\n\npreview\nwith calendar: 320x480, 1024x1024, 1280x720, 1680x1200, 1920x1080, 2560x1440\nwithout calendar: 320x480, 1024x1024, 1280x720, 1680x1200, 1920x1080, 2560x1440\n\n\nSummer Chamomile\n“Our designers were inspired by the lightness and innocence of June, as well as the desire to use bright colors. More calendars are here.” — Designed by MasterBundles from Ukraine.\n\n\npreview\nwith calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nUkrainian Embroidery\n\nVlad Gerasimov from Georgia designed a series of wallpapers in which he explores traditional embroidery patterns found in different regions in Ukraine and the stories behind them.\n\nKherson\n“This picture is dedicated to the Kherson region. Forms of fruits, flowers, leaves close to nature are typical of Kherson region. Viburnum motifs are usually found on women’s shirts, it is a symbol of beauty. Oak motifs are most often seen on boys’ shirts, they are a symbol of strength, development, and life. So, the boys wore a miraculous amulet of life-giving power of some kind.” — Designed by Vlad Gerasimov from Georgia.\n\n\npreview\nwith calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\nwithout calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\n\n\nMykolaiv\n“This picture is dedicated to the Mykolaiv region. A large number of embroidered products of Mykolaiv region is characterized by floral ornaments. The symbol of the triangle, which is found on embroidered shirts, has long been associated with the element of fire, where fire represents the striving for freedom. The main colors were mostly red, blue, black, and yellow.” — Designed by Vlad Gerasimov from Georgia.\n\n\npreview\nwith calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\nwithout calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\n\n\nKirovohrad\n“This picture is dedicated to the Kirovohrad region. From ancient times in Ukraine poppies were consecrated. People and cattle were sown with them. People believed that the poppy has a magical power that protects against all evil. Poppy motifs can be seen on the shirts of the Kirovohrad region.” — Designed by Vlad Gerasimov from Georgia.\n\n\npreview\nwith calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\nwithout calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\n\n\nTernopil\n“This picture is dedicated to the Ternopil region. Embroidery of Ternopil region is characterized by rich, dark, up to black, colors. Made of wool, thick, almost without gaps, the ornaments completely cover the sleeves of women’s shirts. Floral motifs are often found on the shirts of Ternopil region, in particular marigold flowers, sunflowers, mustard.” — Designed by Vlad Gerasimov from Georgia.\n\n\npreview\nwith calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\nwithout calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\n\n\nSumy\n“This picture is dedicated to the Sumy region. Geometric and plant-geometrized patterns were embroidered on the shirt from Sumy region. Most often there is an embroidered pattern called broken branch. This pattern has its ancient and deep meaning and depicts the creation of our Galaxy.” — Designed by Vlad Gerasimov from Georgia.\n\n\npreview\nwith calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\nwithout calendar: 800x480, 800x600, 1024x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1440x960, 1600x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 2560x1600, 2880x1800, 3072x1920, 3840x2160, 5120x2880\n\n\nLooking At The Stars\n“This month we travel to the stars. We find a planet and we sit down to observe the universe.” — Designed by Veronica Valenzuela from Spain.\n\n\npreview\nwith calendar: 640x480, 800x480, 1024x768, 1280x720, 1280x800, 1440x900, 1600x1200, 1920x1080, 1920x1440, 2560x1440\nwithout calendar: 640x480, 800x480, 1024x768, 1280x720, 1280x800, 1440x900, 1600x1200, 1920x1080, 1920x1440, 2560x1440\n\n\nI’m So Good\nDesigned by Ricardo Gimenes from Sweden.\n\n\npreview\nwith calendar: 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 3840x2160\nwithout calendar: 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 3840x2160\n\n\nAwesome Summer Sunflowers\n“Sunflowers are one of the symbols of Ukraine. There is especially a lot of them in the south, where the fighting is now taking place. Our designers were inspired by our nature and belief in our victory and therefore created this calendar. More calendars are available at https://masterbundles.com/. Welcome!” — Designed by MasterBundles from Ukraine.\n\n\npreview\nwith calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nMr Broccoli Doesn’t Like You Either\nDesigned by Ricardo Gimenes from Sweden.\n\n\npreview\nwith calendar: 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 3840x2160\nwithout calendar: 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 3840x2160\n\n\nSummertime\nDesigned by ActiveCollab from the United States.\n\n\npreview\nwith calendar: 1080x1920, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1920x1080, 1920x1200, 1920x1440, 2560x1440\nwithout calendar: 1080x1920, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\n\n\nOldies But Goodies\n\nReady for more? Below you’ll find a little best-of from past June editions. Please note that these wallpapers don’t come with a calendar. Enjoy!\n\nTravel Time\n“June is our favorite time of the year because the keenly anticipated sunny weather inspires us to travel. Stuck at the airport, waiting for our flight but still excited about wayfaring, we often start dreaming about the new places we are going to visit. Where will you travel to this summer? Wherever you go, we wish you a pleasant journey!” — Designed by PopArt Studio from Serbia.\n\n\npreview\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nSummer Party\nDesigned by Ricardo Gimenes from Sweden.\n\n\npreview\nwithout calendar: 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440, 3840x2160\n\n\nDancing In The Summer Moonlight\n“If you’re happy and you know it, show some dance moves, because summer is finally here!” — Designed by ActiveCollab from the United States.\n\n\npreview\nwithout calendar: 1080x1920, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nSummer Coziness\n“I’ve waited for this summer more than I waited for any other summer since I was a kid. I dream of watermelon, strawberries, and lots of colors.” — Designed by Kate Jameson from the United States.\n\n\npreview\nwithout calendar: 320x480, 1024x1024, 1280x720, 1680x1200, 1920x1080, 2560x1440\n\n\nSolstice Sunset\n“June 21 marks the longest day of the year for the Northern Hemisphere — and sunsets like these will be getting earlier and earlier after that!” — Designed by James Mitchell from the United Kingdom.\n\n\npreview\nwithout calendar: 1280x720, 1280x800, 1366x768, 1440x900, 1680x1050, 1920x1080, 1920x1200, 2560x1440, 2880x1800\n\n\nOh, The Places You Will Go!\n“In celebration of high school and college graduates ready to make their way in the world!” — Designed by Bri Loesch from the United States.\n\n\npreview\nwithout calendar: 320x480, 1024x768, 1280x1024, 1440x900, 1680x1050, 1680x1200, 1920x1440, 2560x1440\n\nDeep Dive\n“Summer rains, sunny days, and a whole month to enjoy. Dive deep inside your passions and let them guide you.” — Designed by Ana Masnikosa from Belgrade, Serbia.\n\n\npreview\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\n\n\nIce Creams Away!\n“Summer is taking off with some magical ice cream hot air balloons.” — Designed by Sasha Endoh from Canada.\n\n\npreview\nwithout calendar: 320x480, 1024x768, 1152x864, 1280x800, 1280x960, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1920x1080, 1920x1200, 2560x1440\n\n\nStrawberry Fields\nDesigned by Nathalie Ouederni from France.\n\n\npreview\nwithout calendar: 320x480, 1024x768, 1280x1024, 1440x900, 1680x1200, 1920x1200, 2560x1440\n\n\nBauhaus\n“I created a screenprint of one of the most famous buildings from the Bauhaus architect Mies van der Rohe for you. So, enjoy the Barcelona Pavillon for your June wallpaper.” — Designed by Anne Korfmacher from Germany.\n\n\npreview\nwithout calendar: 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nMerry-Go-Round\nDesigned by Xenia Latii from Germany.\n\n\npreview\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nSummer Surf\n“Summer vibes…” — Designed by Antun Hirsman from Croatia.\n\n\npreview\nwithout calendar: 640x480, 1152x864, 1280x1024, 1440x900, 1680x1050, 1920x1080, 1920x1440, 2650x1440\n\n\nMelting Away\nDesigned by Ricardo Gimenes from Sweden.\n\n\npreview\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1400x1050, 1440x900, 1366x768, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nPineapple Summer Pop\n“I love creating fun and feminine illustrations and designs. I was inspired by juicy tropical pineapples to celebrate the start of summer.” — Designed by Brooke Glaser from Honolulu, Hawaii.\n<img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/16db22ee-c7f8-47a3-856c-992c82cd61f9/june-16-pineapple-summer-pop-preview-opt.png\" alt=\"Pineapple Summer Pop\"\n\n\n\n\npreview\nwithout calendar: 640x480, 800x600, 1024x768, 1152x720, 1280x720, 1280x800, 1280x960, 1366x768, 1440x900, 1680x1050, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\n\nFishing Is My Passion!\n“The month of June is a wonderful time to go fishing, the most soothing and peaceful activity.” — Designed by Igor Izhik from Canada.\n\n\npreview\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1400x1050, 1440x900, 1600x1200, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\nGetting Better Everyday\n“The eternal forward motion to get better and excel.” — Designed by Zachary Johnson-Medland from the United States.\n\n\npreview\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\nExpand Your Horizons\n“It’s summer! Go out, explore, expand your horizons!” — Designed by Dorvan Davoudi from Canada.\n\n\npreview\nwithout calendar: 800x480, 800x600, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\nHappy Squatch\n“I just wanted to capture the atmosphere of late spring/early summer in a fun, quirky way that may be reflective of an adventurous person during this time of year.” — Designed by Nick Arcarese from the United States.\n\n\npreview\nwithout calendar: 320x480, 640x480, 800x480, 800x600, 1024x768, 1024x1024, 1152x864, 1280x720, 1280x800, 1280x960, 1280x1024, 1366x768, 1400x1050, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440\n\n\nNine Lives\n“I grew up with cats around (and drawing them all the time). They are so funny… one moment they are being funny, the next they are reserved. If you have place in your life for a pet, adopt one today!” — Designed by Karen Frolo from the United States.\n\n\npreview\nwithout calendar: 1024x768, 1024x1024, 1280x800, 1280x960, 1280x1024, 1366x768, 1440x900, 1600x1200, 1680x1050, 1680x1200, 1920x1080, 1920x1200, 1920x1440, 2560x1440",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1c6a9a31-4619-4c93-b9ea-65b5f50082cd/june-22-create-your-own-path-preview-opt.png",
      "date_published": "2022-05-31T12:30:00.000Z",
      "date_modified": "2022-05-31T12:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/smashing-podcast-episode-47/",
      "url": "https://smashingmagazine.com/2022/05/smashing-podcast-episode-47/",
      "title": "Smashing Podcast Episode 47 With Sara Soueidan: Why Does Accessibility Matter?",
      "summary": "In this episode of the Smashing Podcast, we ask why accessibility really matters and why it is so important to get it right. Smashing’s Vitaly Friedman talks in-depth to Sara Soueidan to find out.",
      "content_html": "<p>This article is a sponsored by <a href=\"https://www.storyblok.com/\">Storyblok</a></p>\n<p>In this episode of the Smashing Podcast, we ask why accessibility really matters and why it is so important to get it right. Smashing’s Vitaly Friedman talks in-depth to Sara Soueidan to find out.</p>\n\n\n<h3>Show Notes</h3>\n<ul>\n<li>Sara’s <a href=\"https://www.sarasoueidan.com/\">personal website</a></li>\n<li>Sara on <a href=\"https://twitter.com/SaraSoueidan\">Twitter</a></li>\n<li><a href=\"https://practical-accessibility.today/\">Practical Accessibility Online Course</a> (coming soon)</li>\n</ul>\n<h4>Weekly Update</h4>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/kubernetes-front-end-developers/\">Kubernetes For Frontend Developers</a>” <em>written by Benjamin Ajibade</em></li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/ultimate-free-solo-blog-setup-ghost-gatsby/\">The Ultimate Free Solo Blog Setup With Ghost And Gatsby</a>” <em>written by Greg Dickens</em></li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/lesser-known-underused-css-features-2022/\">Lesser-Known And Underused CSS Features In 2022</a>” <em>written by Adrian Bece</em></li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/understanding-weak-reference-javascript/\">Understanding Weak Reference In JavaScript</a>” <em>written by Frank Joseph</em></li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/05/accessible-design-system-themes-css-color-contrast/\">Manage Accessible Design System Themes With CSS Color-Contrast()</a>” <em>written by Daniel Yuschik</em></li>\n</ul>\n<h3>Transcript</h3>\n<p></p><p><a href=\"https://twitter.com/SaraSoueidan\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e0009b96-9568-4c6e-bf4f-9896906b336d/sara-soueidan-250px-opt.png\" /></a> Vitaly: She’s an independent web user interface and design systems engineer, author, speaker, and trainer based in Lebanon. She worked with companies and agencies all around the world from Netflix, and Telus, and the Royal Schiphol Group at Amsterdam airport, just to name a few, where she built digital products with focus on accessibility performance and of course cutting edge tech.</p>\n<p>Vitaly: Now, she also writes beautiful and very comprehensive, very, very comprehensive articles all around front-end SVG accessibility on her wonderful blog. And she’s also working, which might be a rumor; we’ll find out on her very own video course on web accessibility. So, in all, she’s an expert in creating accessible and beautiful interfaces.</p>\n<p>Vitaly: But did you know that she loves tea, drawings, and birds and has raised more than a dozen of them throughout her life? So, I shouldn’t be surprised to hear the birds chirping when we have a call just now. My smashing friends, please welcome Sara Soueidan. Hello, Sara, how are you?</p>\n<p>Sara: I am smashing. How are you?</p>\n<p>Vitaly: That’s wonderful. I don’t know. I feel like coffee today. I had already three, and I feel like I should get forth, but you’re not big on coffee, are you?</p>\n<p>Sara: No. I have my matcha sitting right next to me right now.</p>\n<p>Vitaly: Okay. That would be a very surprising start to the conversation. But what is your favorite tea, if I may ask?</p>\n<p>Sara: My favorite tea, if we’re not counting matcha as tea, even though it is actually tea, but if... okay. So, I’d say it’s either a matcha or ginger tea. I love ginger.</p>\n<p>Vitaly: Okay. Now, dear friends, if you ever want to ship any gifts to Sara, you know what to ship. Now, staying on the topic of food and drinks, and beverages, it’s interesting, Sara, because I know we’ve known each other for, I don’t know how many years now. And we even shared pizzas on very different occasions in various parts of the world, that surely counts for something.</p>\n<p>Vitaly: And one thing that really astonishes me when I think about our conversations and I think about you as a personality and just the incredible work that you put on the web, it’s just incredibly difficult for me to find many people who are more passionate about accessibility as you are.</p>\n<p>Vitaly: So, maybe you could give us a bit of a background of where this genuine empathy and excitement about accessibility comes from. Where did it all start, Sara? Where?</p>\n<p>Sara: Do you want the long version answer or the short version answer?</p>\n<p>Vitaly: The very long answer, if I can.</p>\n<p>Sara: Are you sure?</p>\n<p>Vitaly: No.</p>\n<p>Sara: Yes.</p>\n<p>Vitaly: Okay. But make a choice, whatever works for you works for me.</p>\n<p>Sara: Okay. So, if you want some background, I’ve always been the kind of person who loves helping people, even if they don’t directly ask for it. So, I’m just going to give you a quick example. Back when I was in college, I think it was my second year in college or in university, and it was the start of the year, and everyone was in the university, and we were registering and doing all the necessary paperwork that we needed to do to start going to class.</p>\n<p>Sara: And there were a lot of people, basically. And there was this one old man, he was standing in the middle of the crowd, and he was carrying a few papers in his hand and a pen. And he looked absolutely clueless. I could tell from his facial expressions that he was lost. He had no idea what he was supposed to do.</p>\n<p>Sara: So, I approached him and I asked him... I always do this, by the way. I’m not sure if this is a good thing or a bad thing, but I tend to do this with strangers a lot. So, I said, “Is there anything I can help you with?” He looked at me, and he said, “I have no idea basically how to fill the paperwork in.”</p>\n<p>Sara: He was there to register his son, who couldn’t be there. So, he was registering him instead, and he didn’t know how to do it. And I know how difficult it can be the first time. Because my first time, when I went to college for the first time, in the first year, it took me four days to register because there was no one there to help you.</p>\n<p>Sara: You can either find your way on your own, or you would just have to ask people. And if you don’t ask anyone, you’re just kind of stand there like that old man did. So, I asked him if I could help him, and he welcomed my help. I took the paperwork. I took the pen. I started asking him questions and filling in the paperwork for him.</p>\n<p>Sara: And then, when I finished, I told him exactly where to go next, exactly what to do. And I basically just helped him as much as I could. I do this with a lot of people. I don’t know; I think it’s just part of who I am. Helping people makes me feel amazing.</p>\n<p>Sara: Even the smallest acts of anything that you do in your daily life makes them meaningful and gives them purpose. So, to know that I have contributed a positive thing, no matter how small, into someone else’s life is wonderful. And I want my work to have a purpose, as well.</p>\n<p>Sara: So, when I started my career as a developer, I think it was in 2013, and this is something that I’m sharing for the first time, I went through a few years where I felt like what I was doing wasn’t very meaningful, to be honest. So, I was just doing what I was doing just to make some money, make a living, and that was it.</p>\n<p>Sara: But I would get designs someone made and turn them into something that worked, which is nice because I love doing that. But as always, I kept asking myself for years like, “What good is this contributing to the world?” I wanted to feel like the code that I’m writing can make a difference. And it took some time for me to finally get there.</p>\n<p>Sara: So, I started changing my path, so to speak, by choosing the clients that I wanted to work with. I started choosing clients that did meaningful things in the world. That way, if I help them create a website to expand the reach, it meant that I was contributing to something good in this world, as well.</p>\n<p>Sara: And I even expressed that on my Hire Me page, where I’m explicitly clear that I’m looking to do something meaningful in the world. So, there is that. And on the other hand, I’ve always been fascinated with design, in general. I’ve never taken a design class in my life, not in university, not outside of university, but I’ve always been interested in design because of how it directly impacted people’s lives.</p>\n<p>Sara: You can maybe start to see connection here. So, I’m going to give an example from the adjacent design field. Many people who have been following me for years know that I’m fascinated and very passionate towards interior design. And the best thing I’ve ever read about interior design is that interiors should be designed around how we live.</p>\n<p>Sara: So, how do you decide what you put in the kitchen, for example? How do you decide how much space you give a certain feature or piece of furniture in the house? The answer is based on how often it is needed by the people who will live in this house.</p>\n<p>Sara: A great interior designer will sit down with their client and ask them questions like, “How do you start your day? What does your typical day look like? What do you do when you wake up in the morning? Do you work from home? Do you like having people over? Do you like entertaining? What are your hobbies?”</p>\n<p>Sara: And the answers to all these questions they asked creates the framework and guides the interior design decisions of the house that the client will live in. The house is designed and built around the client’s lives, not the other way around.</p>\n<p>Sara: And I love that because if design isn’t about people, then it is selfish, right? Then, you’re not really designing for people anymore. And accessibility and inclusive design in general, but accessibility is not the same as inclusive design. Accessibility design is all about people.</p>\n<p>Sara: There is no room for selfishness, in my opinion. So, what you design and build either works for the user or it doesn’t. And if it doesn’t, then it needs to change because what good is anything that you built for people if they can’t use it?</p>\n<p>Sara: So, connecting these two things, I love design, and I love designing for people, and I love helping people. So, when I first learned about accessibility, and I found out that some of the work that I was building prior to that was possibly creating barriers to access for people.</p>\n<p>Sara: I felt horrible. And I started feeling more responsibility, and I started digging more into accessibility and learning more about it. And what I love the most about it is it makes me feel more like a designer. Why? Because, well, I do believe that all of us, we are designers, one way or another.</p>\n<p>Sara: And the work that we do and the decisions that I make as a design engineer when I write code, these decisions have a direct impact on the user experience, and that makes me a designer. So, every decision that I make has a direct impact on the experience and the inclusivity and accessibility of the interfaces I built.</p>\n<p>Sara: A decision such as, for example, what HDML element I choose to use, how do I apply the styles because CSS affects semantics, which affect accessibility, which development strategy I follow, which is a progressive enhancement or something else. Whether I use platform features or a third-party library, which library do I choose?</p>\n<p>Sara: How does it perform? All of these things, they impact your work, and eventually, the user experience. And design should be about people. Accessibility is about people, which means that it gives code purpose. It gives the work that I do purpose, which brings me back... the first thing that I mentioned, I want to feel like what I’m doing has a purpose and is actually beneficial for people.</p>\n<p>Sara: And this is why I love accessibility, in general, because it is a concrete, practical type of design, something either works or it doesn’t. And there is no room for bad decisions because it’s about the user, not about you. So yeah, I’m passionate about accessibility because-</p>\n<p>Vitaly: I could tell. Yeah, that’s incredible to hear. And actually, a few things that have really connected the dots for me, as well, because when I think about the work that I’m doing, as well, I feel like... we don’t even notice that sometimes, but all these minor decisions about the labeling of navigation and the way we design navigation, and the way we make buttons to look like buttons.</p>\n<p>Vitaly: All those things can have tremendous impact. We might feel like, “Okay, we’re just moving pixels around.” And we’re just making things a little bit more nice, right? But I think that the right significant decisions that we end up, that we use to really help somebody in different situations, complete the task, to find information that they need, and so on.</p>\n<p>Vitaly: And one thing that really comes up in my mind every time we have this conversation is that you often identify yourself with a design engineering role. And I see that some teams are moving towards that role now. Where in the past, it was just a developer, and then it was just a designer, and then it was a front-end developer and backend developer.</p>\n<p>Vitaly: And if you have an interface designer, you have to use the experience designer. So, maybe you could share a little bit of light on how you see design engineering as a role. And maybe many of our listeners now actually are design engineers without even knowing that. So, how would you define it? And do you think that companies actually understand what it means?</p>\n<p>Sara: I have actually an essay, not just an article, an essay that is all about just defining the role of a design engineer. And from my point of view, I even have a domain name that I purchased just to put that on it. If I try to describe it with just a few words because I already gave a super long answer to the previous question-</p>\n<p>Vitaly: That was a wonderful answer. It wasn’t long at all.</p>\n<p>Sara: Thank you. Okay. So, as design engineers, we specialize in implementing designs. That is the general description, right? We specialize in implementing designs, but then, of course, there is how you implement it. So, I like to label myself as an inclusive design engineer, which is something that I’m doing on my new website, which is not public yet.</p>\n<p>Sara: So, an inclusive design engineer is someone who, in my opinion, uses accessibility and progressive enhancement as a framework to build inclusive interfaces. But, as a design engineer, in general, is someone who works directly with designers, hopefully, because this is what I think the role should be.</p>\n<p>Sara: We should be working directly with designers, helping them make decisions and informing design decisions with our accessibility and code knowledge, basically, because they complement each other. We write HDML. We write CSS. We write presentational JavaScript, mostly.</p>\n<p>Sara: And with a strong focus on accessibility, hopefully, because that should be part of every design engineer’s job. And then, of course, the strategy that you choose and the frameworks that you use, and I’m not talking about CSS frameworks or JavaScript frameworks here, but like I said, this... let me just call it the strategy.</p>\n<p>Sara: Strategies that you use and what exactly you focus on, and how you do your job as a design engineer probably differs between people because like I said, I’m a progressive enhancement advocate, others are maybe not. So, we would differ in these small details.</p>\n<p>Sara: But a design engineer is someone who works with designers, helps inform design decisions and makes sure that designs are implemented in a way that hopefully works for as many users as possible.</p>\n<p>Vitaly: Right. So then, as a design engineer, at this point, how would you then actually work? So, what would your process be like? So, when you think about implementing a particular design, do you break it down into components? Do you think about navigation landmarks first?</p>\n<p>Vitaly: How do you actually start building things? What is your maybe mindset in that framework of getting accessible results? Maybe you could describe it a little bit.</p>\n<p>Sara: Okay. So, when you say that you divide the... you not divide, basically looked at the design and then start thinking in components, that very much depends on the process that you work with the designer. So, if I’m working with someone who has handed over a design, like an entire page, the process is different from when I’m working with the designer, like I did with Yan Persy.</p>\n<p>Sara: I’ve mentioned him multiple times on Smashing Hour, by the way, because working with him was one of my favorite ways of working with the designers because he didn’t have like a full finished design for me to implement. We worked in tandem. We worked together. And he changed some of the things in the design.</p>\n<p>Sara: So, for example, he wasn’t using a responsive type scale like we do in front-end development now using CSS variables and viewport units, et cetera. So, we had this discussion, and then he shifted the way the design process went. It was different.</p>\n<p>Sara: So, we both started building the site in terms of components, and then assembling those components into what we called slices back then, and then assembling the slices into the entire website. So, how I start from whether it’s components or not, depends on the process that I work with the designer.</p>\n<p>Sara: But then, if I get a little bit more technical, like if I have a component that I want to build, how do I go about doing that in layers, I would say? Again, progressive enhancement, the first thing that I think about is how does this work? How does this look like?</p>\n<p>Sara: How does someone perceive this if JavaScript is disabled? And what happens if there is no style? So, I just start with the bare minimum, HTML, because HTML defines the semantics. The semantics give meaning to the content that I’m creating.</p>\n<p>Sara: So, which HTML elements do I need to tell the user what this thing is to give semantics? If HDML already contains an element that represents this component or this element that I’m building, I use that. If not, then I start to thinking about ARIA attributes; which ARIA attributes do I need?</p>\n<p>Sara: How much ARIA do I need? ARIA is... it’s not an enhancement; it’s necessary for a lot of dynamic and interactive components. But I always try to think of it as a last resort, not a first one, so always semantic HTML first. How much can I get done with just semantic HTML?</p>\n<p>Sara: How accessible is it? Do I need something? Do I need to polyfill some semantics using ARIA? If I do, then I start thinking about that. And then applying CSS, and how does CSS affect these semantics? Does it? Does it not?</p>\n<p>Sara: Do I have to do something extra to make sure that something remains accessible after I style it? Like, for example, if you stripped away the default list styles on list elements, which is something you probably... and many people probably already know by now, if you set list style to none, for example, on an unordered list, then Safari or WebKit, WebKit, in general, is going to remove the semantics of the list.</p>\n<p>Sara: And VoiceOver is not going to announce that anymore. So, what do I do in that case? Do I need those semantics? Do I go into the HTML and add them again using a role attribute or not? So, I think about this stuff in layers. Start with HTML semantics. Do I need ARIA? How do I style this? And then, interactivity is always the last layer that I think about and that I build into components.</p>\n<p>Vitaly: Right. Makes sense. It’s interesting what you’re saying that it’s a process. It doesn’t seem like a simple process, especially when you think about like literally implementing quite a complex interface, which may also have all kinds of different views and maybe single page application in the back and so on.</p>\n<p>Vitaly: And one thing that I’m struggling with when I’m doing work with clients and trying to make things more inclusive and interfaces maybe a bit more usable is that very often web accessibility is still seen as this little thing. Like, “Okay, that’s just semantics.” “Okay, so we’re going to use buttons for buttons.”</p>\n<p>Vitaly: But it’s actually much, much, much more than that. And I’m wondering, what do you think... like, where do we actually stand in terms of accessibility today? It’s very hard for me, personally, for example, to imagine a new project being released without even considering accessibility.</p>\n<p>Vitaly: I think that might have been possible maybe a decade ago. I think today, it would be very difficult to imagine a brand new project that’s going to be advertised everywhere on posters that is not accessible at all, some parts accessible, but maybe not everything.</p>\n<p>Vitaly: So, what do you think, has accessibility not become just the natural part of every design implementation process, or are we way, way, way, far away from this yet?</p>\n<p>Sara: I think we are not too far, but we’re still far. So, there is definitely a lot more awareness on accessibility. I hope so, at least, because I only follow like less than 250 people on Twitter. And most of the people in my circle are people who either work with accessibility or care about accessibility.</p>\n<p>Sara: So, if I were to judge the current situation based on my little circle, I would say that accessibility is doing great, and people care about it a lot. And they work to make their content more accessible. But I can’t speak for everyone because I know that this isn’t the case for everyone.</p>\n<p>Sara: I know that there are still many developers who just simply don’t care. Because with accessibility, you either care or you don’t care; this is it. If you don’t care, then you are basically not doing any accessibility work at all.</p>\n<p>Sara: And then, on the other hand, those that do care about accessibility and try to implement it in their work, some of them are finding difficulty because they get lost in all of the resources out there, and where should they go? Where do they start? This is why I’m creating the accessibility course now, to hopefully help with that a little bit.</p>\n<p>Sara: So, we are definitely doing much better than we did like five years ago, let me say, five. But I don’t think we’re just exactly there yet. No. I think it’s going to take more time.</p>\n<p>Vitaly: Yeah. But then, I also hear developers telling me all the time, “Well, hold on. But the platform is evolving so beautifully at this point. We have not only the wonderful CSS feature coming along, but also we have these incredible things that common UI components, like input type date for a date picker, the dialogue for models, details, and summary for accordions.”</p>\n<p>Vitaly: And very often, what I find is that they just use those things, and they think that, “Okay, well, since these are native components available on the platform, they surely are accessible.” And then, come eye along, and then there is trouble. I’m wondering, at this point, what would you say in this position?</p>\n<p>Vitaly: Like, those things, would you recommend to use them ever? Or where are there? Ideally, it would be a very nice idea and situation where we ended up with all those native components just available out of the box, beautiful, accessible, inclusive, and all of that. Are we there yet?</p>\n<p>Sara: No.</p>\n<p>Vitaly: Are we again, far away from it?</p>\n<p>Sara: No. No. We’re definitely not there yet. I know that the dialogue element, for example, has been pretty... I don’t want to say completely inaccessible, but it has had a lot of accessibility issues for years now. And I think it only started getting better this year. And then, input type equal date, I rarely ever used it because, to be honest, I don’t think that it offers the best usability anyway, even if it is accessible, which I think it’s... I don’t know.</p>\n<p>Sara: I haven’t used it in a very long time, so I can’t even tell if it’s fully accessible or not. But I think the last I heard was that it wasn’t and that it was a usability nightmare. So, even if something is technically accessible, that doesn’t mean that it’s going to be usable. Definitely a lot of tests.</p>\n<p>Sara: And I like this quote by my friend, Scott O’Hara, that he said in one of his talks. He said, “Technology and user expectations change rapidly. And we should always test to ensure not only emerging patterns work correctly but try untrue patterns continue to work as we expect.”</p>\n<p>Sara: This is me, now, continuing. Sometimes even something that you know works may stop working as you expect. Browsers may create new heuristics, for example. And the way they... not interpret, the way they present something because the user may change on any day.</p>\n<p>Sara: Also, a note about details and summary, which is something that I had a discussion about today, details and summary are not the best choice for an accordion. They can be used for an accordion, but even they... like, when you choose any component, the first thing you have to think about is the semantics.</p>\n<p>Sara: What are the semantics that are going to be conveyed? Because the semantics determine the non-visual interface for a non-sighted user, for a screen reader, for a user, for example, assuming they’re a non-sighted screen reader, the user.</p>\n<p>Sara: Details in summary, they have their own quirks when it comes to semantics. So, the summary has a button roll, which means that it is conveyed as a button to assistive technologies. And buttons eat up the semantics of the elements inside of them.</p>\n<p>Sara: So, if you have a heading, which is what you would normally have in an accordion, and if you put that inside of a summary, then the heading is not going to be conveyed as a heading anymore. Of course, there are exceptions because sometimes browsers try to quote, fix our misuse of ARIA or our misuse of semantics.</p>\n<p>Sara: And they try to help stream users by conveying things that we may have broken as developers, but it doesn’t mean that all browsers do that. So, definitely, always, you need to test. And if details in summary, for example, if you use that, and if the headings are not exposed as headings, and then the user cannot use those headings to navigate, for example, anymore.</p>\n<p>Sara: So, even if something is technically accessible, yes, they can access the contents of summary. Yes, they can access the contents of the details. But you have to think about what semantics you are conveying and how they affect the usability of the interface and sometimes maybe navigation, so there are a lot of things to keep in mind.</p>\n<p>Vitaly: Yeah. So, it’s interesting that you brought up the testing for accessibility at this point. Because when we run our workshops, and every now and then, we... in my workshop, I tend to just explain to people how security works. And I always ask the same question. And for the last, I don’t know, two, three, four years, maybe now, I’ve been asking the same question.</p>\n<p>Vitaly: So, who is hearing this VoiceOver for the very first time? And these are usually designers or developers coming to those workshops. And very often, you would see a vast majority of people hearing things for the very first time. So, maybe you could also share a bit of light in how do you actually test accessibility?</p>\n<p>Vitaly: Do you always have screen reader or VoiceOver on or maybe any other tools? Could you also, maybe, run us through the process of testing your components for accessibility?</p>\n<p>Sara: Okay. So, there are quite a few things that I like to use, and I’m going to mention them in no particular order; definitely browser DevTools to inspect the accessibility tree because you can get a lot of insight on the accessibility of the elements and components that you’re building from the accessibility tree.</p>\n<p>Sara: Because basically, the accessibility tree is the accessibility... contains the accessibility information that the browser has created for assistive technologies to announce. So, when you look at the accessibility tree, you can get an idea of how an element is going to be announced by a screen reader that accesses and gets that information from the browser via the accessibility API, of course.</p>\n<p>Sara: So, the dev tools for accessibility tree. There are a lot of extensions that I like to use, for example, to see the document outline on a page or to see the landmarks on a page. If I’m doing an accessibility audit, I would definitely use an automated testing tool such as asking DevTools, for example.</p>\n<p>Sara: As far as screen reader go, definitely like... you cannot just test on one screen reader. And I have been guilty of this. I mean, I’m not like preaching something that I don’t practice now, but I know that I didn’t practice this before. I don’t have access to a windows machine.</p>\n<p>Sara: So, I recently... not recently, like a few months ago, I started using Nvidia A on my windows virtual machine. And I also recently got a license for JAWS because JAWS is not free, but Nvidia is free. So, I used VoiceOver with Safari on iOS. Sometimes I test on other browsers, as well, just because sometimes, maybe a VoiceOver using may be using another browser.</p>\n<p>Sara: But generally speaking, VoiceOver and Safari are the best combination, and users typically know that. And on windows, I test Nvidia A with Firefox, Nvidia A with Chrome. And the narrator is also built into Windows, so I use that for testing as well.</p>\n<p>Sara: And JAWS is the most popular screen meter according to the WebAIM screen reader, user survey. So yes, you have to test using multiple screen readers and browser combinations because just like you cannot test your website only on one browser.</p>\n<p>Sara: Like say, you’ve built a website, and you want to test, if everything is working as expected, all your CSS and stuff, you don’t just test it on one browser, right? You test it on most modern browsers and possibly even on IE if you still have to support that. Just like you test on multiple browsers, you also have to test on multiple screen readers, if you can. So, this is what I do, in general.</p>\n<p>Vitaly: Yeah. So, you also mentioned in one of the Smashing Hours that tool.</p>\n<p>Sara: Assistive labs.</p>\n<p>Vitaly: Assistive labs, which is like browsers tech for screen readers, which is really need to see, as well. And I think, for me, it’s really this really interesting world of other browsers, I would say because we tend to focus a lot on what are some of the fancy new features we get in Firefox and in Chrome, and in Safari.</p>\n<p>Vitaly: Just in general, would you say that the development of screen readers is... the frequency of updates, is it similar or is it something like maybe there is a new version coming up every six months or only just once a year, because we have this comparability, right, stuff happening across browsers.</p>\n<p>Vitaly: So, as much as it used to where you’re using Firefox or Chrome, or Safari, or Edge, at this point, do you see that it’s also moving in the world of screen readers towards this comparability mode... not mode, compatibility across different screens readers? Or is it... maybe you could share just a bit of light about that world and that universe of screen readers?</p>\n<p>Sara: To be honest, I’ve never dug that deep into it. So, I haven’t been monitoring, for example, screen reader updates, like how often Nvidia is updated and how often JAWS is updated. But I do know that even if JAWS or Nvidia is updated, not all screen reader users are going to update their software because they’re aware of... a lot of things may break for them.</p>\n<p>Sara: And if they already have an environment that works, nobody wants to break something that works for them. So, I know that many screen reader users do not update their software as often as we may think that they do.</p>\n<p>Vitaly: Right. Well, of course, talking about browsers, at this point, I do have to bring out the wonderful notion of wonderful CSS. And obviously, I do have some questions about CSS, as well. And one thing that I definitely have to ask, and I know what your answer is going to be, but I still like hearing it every single time.</p>\n<p>Vitaly: So, I am going to bring this up. I have a feeling... well, I know that you have or maybe don’t have strong feelings about CSS methodologies or frameworks, or JavaScript frameworks for that matter. Do you have any favorites, or do you not? Do you always just work with what the project requires?</p>\n<p>Vitaly: How do you pick your battles? Would you ever use any framework or CSS framework library Tailwind, CSS and JS; I don’t know. I mean, a short, no would suffice.</p>\n<p>Sara: I can’t just say no, because it depends on the project. If I’m working with a team and everyone on the team is using Tailwind, then I will definitely be using Tailwind with them. But I’ve never had to do that yet. And I’ve been super lucky with... actually, I would even say privileged with the projects that I’ve worked on so far.</p>\n<p>Sara: So, no, I don’t use any CSS frameworks. I prefer not to use them because they come with a lot of... and I’m not, not talking specifically about any particular framework here. Most of them come with a lot of overhead. And for me personally, I feel that trying to remove all the unnecessary CSS or learn something or learn it from... it’s just so much faster for me to build something from scratch, literary.</p>\n<p>Sara: Like, I have some CSS that I’ve created over the years that I moved from one project to the other, and of course, I constantly update that, and I used that. It’s like a mini, tiny framework that I used. Like, there are some utility classes that I used in there.</p>\n<p>Sara: Some settings, I called them these settings files for setting up the type scale and the tokens for theming and all that stuff. But I would definitely rather not use a CSS framework. I don’t have super strong feelings about them. I personally used a combination of BEM ITCSS and utility classes in my work.</p>\n<p>Sara: And I only add as much CSS as I need. So, if I need a utility class, I add it to the utility class list that I have. If not, I don’t just add it just in case I’m going to need it. I’m super minimal when it comes to writing CSS.</p>\n<p>Vitaly: Right. Sorry, can you hear the voices of the wonderful people on the remote corners of the internet asking for that little framework that you have created to be open source, maybe?</p>\n<p>Sara: I will. I do plan on doing that. Yes. The course has taken up most of my time. My website has been neglected. My blog has literally been abandoned for months, and I’m going to do... like, even the website that I’m using, I built the course website from scratch using 11T.</p>\n<p>Sara: I’m even considering sharing that as a framework, if anyone wants to use it someday. So, a lot of stuff that I have on my to-do list, but I’m postponing all of it until after the course is released because I need to get this done.</p>\n<p>Vitaly: Right. So, maybe let’s just jump into the course. I think that we’ve been speaking about it a couple of times already, but I could not be more excited to actually get this course finally released. Well, do you think you could actually share a bit of insight about what’s going to be about, when it’s going to be released, and where wonderful people listening to this show can subscribe to updates to actually get it when it does get released?</p>\n<p>Sara: Okay. Updates, subscription, e-mail, newsletter on practical-accessibility.today, that is the website for where the course is going to be hosted currently. It just includes an overview of what the course is about and a link to subscribe to the newsletter.</p>\n<p>Sara: But hopefully next month, when the backend is finally ready... because we’re doing everything from scratch, and I hired a friend of mine to build the backend and all the payment stuff into it. Once that is finished, the website is going to be updated with more details about the course. So, I’m going to introduce the course in a short video.</p>\n<p>Sara: There’s going to be a more detailed table of contents. I haven’t shared a table of contents yet because it keeps changing a lot. Like, even yesterday I added a new section or a new chapter in between two other chapters. So, if I had shared the table of contents before, it wouldn’t have been super accurate.</p>\n<p>Sara: So hopefully, in a month... I think during the next Smashing Hour, I’m going to be making an important update on the course.</p>\n<p>Vitaly: Oh, that’s cool. That’s nice. That’s nice. Can I ask you just on that point? I find it so difficult to record videos. I always see like, “Oh, no, no, no. I shouldn’t have said that.” I should brief rewind back, and then I should re-edit and then I should change.</p>\n<p>Vitaly: And then, I keep going all the time, and it takes me, I don’t know, hours to just record 10 or 15 minutes of stuff. Is it the same for you? Or do you just go?</p>\n<p>Sara: I’m already worried about this because I haven’t recorded anything final yet. I’ve only done a few, so like some testing and editing stuff. I’m starting with a course in reverse, actually. I’m not recording first. I’m going to give more details about the process and everything later, once it’s finished.</p>\n<p>Sara: But I’ve decided to do things in a different way so that when it’s time to do the recordings and the editings, I hope will hopefully have eased things for myself, so that they don’t take as much time. And something that I need to keep reminding myself of is because I’m a perfectionist, and that sometimes is a bad thing.</p>\n<p>Sara: I’m just going to assume that I’m on stage in a conference and just like, I can’t edit every single word I say on stage. I’m going to try to just ignore some things in the videos. That’s going to be super difficult, especially because I know that I can edit them, but it’s definitely going to take some self-discipline to do that.</p>\n<p>Vitaly: Yeah. So, it’s impossible for me. I always say like, “Oh, no, no, no, of course, I can go back,” and surely I can come back. So, in the end, it just takes hours. But I think that we all cannot wait for the video course to be finally released and get our hands on the videos.</p>\n<p>Vitaly: This is very, very exciting. Maybe talking about excitement, I know that there are so many wonderful new features coming to the web. I don’t know when it’s coming. Is it like Chrome 103 something, where we should be expecting the :has() pseudo-class coming in, container queries coming in? It’s like Christmas is coming early.</p>\n<p>Sara: The year of CSS.</p>\n<p>Vitaly: Yeah, the year of CSS. So, maybe you could just share a bit of light about what are you excited about at this point? What is the thing that keeps you awake at night where you think, “Oh, if it only was available today, I would use it all over in my projects.” What would that be? Or what are you most excited about these days in CSS?</p>\n<p>Sara: Well, CSS doesn’t keep me up at night, but I do look forward to things like definitely subgrid. I know that I was one of the people who started requesting container queries years ago, and then we finally got them. But then, at this point, we were already doing a lot of intrinsic responsive design already and using flexbox and CSS grid to create responsive components that don’t require container queries anymore.</p>\n<p>Sara: Although, I mean, they are still important, and I will definitely still be using them. But probably what I’m personally more excited about is cascade layers and subgrid because almost every single project that I’ve used, especially since I worked on the Prismic Slices Project in 2019, that project changed the way I started building websites, at least for me.</p>\n<p>Sara: It influenced the work that we did on the ?? website with Yan. And it also influences now, my own work on my website, for example. Instead of thinking of either pages or small components, there is this middle ground, which is slices.</p>\n<p>Sara: And layout within slices always... like I’ve always wanted the ability to inherit the grit on the parent container of the parent container into the child. And so, subgrid is going to be one of the things that I will probably need even more than container queries in my work.</p>\n<p>Sara: Cascade layers, I wouldn’t say that I need it, but the way it allows me to organize my CSS, the same way the CSS is organized inside of my head, so to speak, that is one of the reasons why I’m excited about it as well.</p>\n<p>Vitaly: Okay. And then, maybe just a few final questions to finally wrap up, just because I’m very, very curious, so I’m sure you have a couple of books lying around at this point; how do you organize your books? Are they organized by topic? Are they organized by color? I met some people doing that. How do you organize them?</p>\n<p>Sara: By color, but not like the rainbow style color that other people do.</p>\n<p>Vitaly: Okay. How many pencils or pens do you have on your table most of the time?</p>\n<p>Sara: Probably two, like one or two.</p>\n<p>Vitaly: And how many screens?</p>\n<p>Sara: You mean for work?</p>\n<p>Vitaly: Yes.</p>\n<p>Sara: Right now, just two, the laptop and an external display, 32-inch.</p>\n<p>Vitaly: Okay. Because for me, moving to a secondary display was really a deal-breaker, so it’s just incredible. And then finally, one thing that I do want to ask, and it’s totally unrelated, is, do you happen to have a printer?</p>\n<p>Sara: No, I haven’t had one in more than two decades, I think.</p>\n<p>Vitaly: Yeah. Now, I feel just lonely because every time I bring this up, because I just got a printer, like what, two months ago. And I’m very proud of this because this is like me having a printer like the first time in two decades, seems like I’m the only person who’s buying printers at this point. That makes me very, very sad.</p>\n<p>Sara: I mean, you’ve lived in Germany, right, and you still do a lot of printed paperwork there, so you need it.</p>\n<p>Vitaly: Yes, indeed. You’re absolutely right. Well, okay, now we know that. All right. So, we’ve been learning a little bit about what it means to design and create more accessible interfaces today; what have you been learning about lately, Sara? Maybe one interesting insight or one unusual thing that you’ve learned recently, which really changed your views, maybe it’s just something that somebody said to you, which has influenced your work or just the way you’re thinking about design or about development, anything in that department?</p>\n<p>Sara: Nothing that big, but a lot of small detail.</p>\n<p>Vitaly: Like what?</p>\n<p>Sara: There is super technical thing.</p>\n<p>Vitaly: Okay. So, when it comes to implementation of accessible components, and things like that.</p>\n<p>Sara: Yeah. There are a lot of things that I learned from digging really deep into specifications. And I love that because my go-to resource to learn about almost anything starting with CSS and other things, is to go to the specifications first. And there’s so much I’ve learned from that recently.</p>\n<p>Vitaly: All right. Excellent. Well, so, if you, dear listener, would like to hear more from Sara, you can follow her on Twitter, which is @SaraSoueidan. And also, find all her work on her website at <a href=\"https://www.sarasoueidan.com/\">sarasoueidan.com/</a>.</p>\n<p>Vitaly: And also, don’t forget to subscribe to <a href=\"https://practical-accessibility.today/\">practical-accessibility.today</a>, which as we’ve heard today will be released soon. So, this is something I’m very, very much looking forward to.</p>\n<p>Sara: In the summer, hopefully. That’s what I’m aiming for.</p>\n<p>Vitaly: Well, that’s fantastic news one way or the other. Well, thanks so much for joining us today, Sara. Do we have any parts in words?</p>\n<p>Sara: Thank you for having me. Today is Global Accessibility Awareness Day. So, if there is something or one thing that you can do today, I would say go either learn something new about accessibility. Or, if you already have the knowledge, fix something on your own website or on somebody else’s website, like open a PR, or fix an issue that exists somewhere out there. Spread the word on accessibility, and subscribe to my newsletter.</p>",
      "content_text": "This article is a sponsored by Storyblok\nIn this episode of the Smashing Podcast, we ask why accessibility really matters and why it is so important to get it right. Smashing’s Vitaly Friedman talks in-depth to Sara Soueidan to find out.\n\n\nShow Notes\n\nSara’s personal website\nSara on Twitter\nPractical Accessibility Online Course (coming soon)\n\nWeekly Update\n\n“Kubernetes For Frontend Developers” written by Benjamin Ajibade\n“The Ultimate Free Solo Blog Setup With Ghost And Gatsby” written by Greg Dickens\n“Lesser-Known And Underused CSS Features In 2022” written by Adrian Bece\n“Understanding Weak Reference In JavaScript” written by Frank Joseph\n“Manage Accessible Design System Themes With CSS Color-Contrast()” written by Daniel Yuschik\n\nTranscript\n Vitaly: She’s an independent web user interface and design systems engineer, author, speaker, and trainer based in Lebanon. She worked with companies and agencies all around the world from Netflix, and Telus, and the Royal Schiphol Group at Amsterdam airport, just to name a few, where she built digital products with focus on accessibility performance and of course cutting edge tech.\nVitaly: Now, she also writes beautiful and very comprehensive, very, very comprehensive articles all around front-end SVG accessibility on her wonderful blog. And she’s also working, which might be a rumor; we’ll find out on her very own video course on web accessibility. So, in all, she’s an expert in creating accessible and beautiful interfaces.\nVitaly: But did you know that she loves tea, drawings, and birds and has raised more than a dozen of them throughout her life? So, I shouldn’t be surprised to hear the birds chirping when we have a call just now. My smashing friends, please welcome Sara Soueidan. Hello, Sara, how are you?\nSara: I am smashing. How are you?\nVitaly: That’s wonderful. I don’t know. I feel like coffee today. I had already three, and I feel like I should get forth, but you’re not big on coffee, are you?\nSara: No. I have my matcha sitting right next to me right now.\nVitaly: Okay. That would be a very surprising start to the conversation. But what is your favorite tea, if I may ask?\nSara: My favorite tea, if we’re not counting matcha as tea, even though it is actually tea, but if... okay. So, I’d say it’s either a matcha or ginger tea. I love ginger.\nVitaly: Okay. Now, dear friends, if you ever want to ship any gifts to Sara, you know what to ship. Now, staying on the topic of food and drinks, and beverages, it’s interesting, Sara, because I know we’ve known each other for, I don’t know how many years now. And we even shared pizzas on very different occasions in various parts of the world, that surely counts for something.\nVitaly: And one thing that really astonishes me when I think about our conversations and I think about you as a personality and just the incredible work that you put on the web, it’s just incredibly difficult for me to find many people who are more passionate about accessibility as you are.\nVitaly: So, maybe you could give us a bit of a background of where this genuine empathy and excitement about accessibility comes from. Where did it all start, Sara? Where?\nSara: Do you want the long version answer or the short version answer?\nVitaly: The very long answer, if I can.\nSara: Are you sure?\nVitaly: No.\nSara: Yes.\nVitaly: Okay. But make a choice, whatever works for you works for me.\nSara: Okay. So, if you want some background, I’ve always been the kind of person who loves helping people, even if they don’t directly ask for it. So, I’m just going to give you a quick example. Back when I was in college, I think it was my second year in college or in university, and it was the start of the year, and everyone was in the university, and we were registering and doing all the necessary paperwork that we needed to do to start going to class.\nSara: And there were a lot of people, basically. And there was this one old man, he was standing in the middle of the crowd, and he was carrying a few papers in his hand and a pen. And he looked absolutely clueless. I could tell from his facial expressions that he was lost. He had no idea what he was supposed to do.\nSara: So, I approached him and I asked him... I always do this, by the way. I’m not sure if this is a good thing or a bad thing, but I tend to do this with strangers a lot. So, I said, “Is there anything I can help you with?” He looked at me, and he said, “I have no idea basically how to fill the paperwork in.”\nSara: He was there to register his son, who couldn’t be there. So, he was registering him instead, and he didn’t know how to do it. And I know how difficult it can be the first time. Because my first time, when I went to college for the first time, in the first year, it took me four days to register because there was no one there to help you.\nSara: You can either find your way on your own, or you would just have to ask people. And if you don’t ask anyone, you’re just kind of stand there like that old man did. So, I asked him if I could help him, and he welcomed my help. I took the paperwork. I took the pen. I started asking him questions and filling in the paperwork for him.\nSara: And then, when I finished, I told him exactly where to go next, exactly what to do. And I basically just helped him as much as I could. I do this with a lot of people. I don’t know; I think it’s just part of who I am. Helping people makes me feel amazing.\nSara: Even the smallest acts of anything that you do in your daily life makes them meaningful and gives them purpose. So, to know that I have contributed a positive thing, no matter how small, into someone else’s life is wonderful. And I want my work to have a purpose, as well.\nSara: So, when I started my career as a developer, I think it was in 2013, and this is something that I’m sharing for the first time, I went through a few years where I felt like what I was doing wasn’t very meaningful, to be honest. So, I was just doing what I was doing just to make some money, make a living, and that was it.\nSara: But I would get designs someone made and turn them into something that worked, which is nice because I love doing that. But as always, I kept asking myself for years like, “What good is this contributing to the world?” I wanted to feel like the code that I’m writing can make a difference. And it took some time for me to finally get there.\nSara: So, I started changing my path, so to speak, by choosing the clients that I wanted to work with. I started choosing clients that did meaningful things in the world. That way, if I help them create a website to expand the reach, it meant that I was contributing to something good in this world, as well.\nSara: And I even expressed that on my Hire Me page, where I’m explicitly clear that I’m looking to do something meaningful in the world. So, there is that. And on the other hand, I’ve always been fascinated with design, in general. I’ve never taken a design class in my life, not in university, not outside of university, but I’ve always been interested in design because of how it directly impacted people’s lives.\nSara: You can maybe start to see connection here. So, I’m going to give an example from the adjacent design field. Many people who have been following me for years know that I’m fascinated and very passionate towards interior design. And the best thing I’ve ever read about interior design is that interiors should be designed around how we live.\nSara: So, how do you decide what you put in the kitchen, for example? How do you decide how much space you give a certain feature or piece of furniture in the house? The answer is based on how often it is needed by the people who will live in this house.\nSara: A great interior designer will sit down with their client and ask them questions like, “How do you start your day? What does your typical day look like? What do you do when you wake up in the morning? Do you work from home? Do you like having people over? Do you like entertaining? What are your hobbies?”\nSara: And the answers to all these questions they asked creates the framework and guides the interior design decisions of the house that the client will live in. The house is designed and built around the client’s lives, not the other way around.\nSara: And I love that because if design isn’t about people, then it is selfish, right? Then, you’re not really designing for people anymore. And accessibility and inclusive design in general, but accessibility is not the same as inclusive design. Accessibility design is all about people.\nSara: There is no room for selfishness, in my opinion. So, what you design and build either works for the user or it doesn’t. And if it doesn’t, then it needs to change because what good is anything that you built for people if they can’t use it?\nSara: So, connecting these two things, I love design, and I love designing for people, and I love helping people. So, when I first learned about accessibility, and I found out that some of the work that I was building prior to that was possibly creating barriers to access for people.\nSara: I felt horrible. And I started feeling more responsibility, and I started digging more into accessibility and learning more about it. And what I love the most about it is it makes me feel more like a designer. Why? Because, well, I do believe that all of us, we are designers, one way or another.\nSara: And the work that we do and the decisions that I make as a design engineer when I write code, these decisions have a direct impact on the user experience, and that makes me a designer. So, every decision that I make has a direct impact on the experience and the inclusivity and accessibility of the interfaces I built.\nSara: A decision such as, for example, what HDML element I choose to use, how do I apply the styles because CSS affects semantics, which affect accessibility, which development strategy I follow, which is a progressive enhancement or something else. Whether I use platform features or a third-party library, which library do I choose?\nSara: How does it perform? All of these things, they impact your work, and eventually, the user experience. And design should be about people. Accessibility is about people, which means that it gives code purpose. It gives the work that I do purpose, which brings me back... the first thing that I mentioned, I want to feel like what I’m doing has a purpose and is actually beneficial for people.\nSara: And this is why I love accessibility, in general, because it is a concrete, practical type of design, something either works or it doesn’t. And there is no room for bad decisions because it’s about the user, not about you. So yeah, I’m passionate about accessibility because-\nVitaly: I could tell. Yeah, that’s incredible to hear. And actually, a few things that have really connected the dots for me, as well, because when I think about the work that I’m doing, as well, I feel like... we don’t even notice that sometimes, but all these minor decisions about the labeling of navigation and the way we design navigation, and the way we make buttons to look like buttons.\nVitaly: All those things can have tremendous impact. We might feel like, “Okay, we’re just moving pixels around.” And we’re just making things a little bit more nice, right? But I think that the right significant decisions that we end up, that we use to really help somebody in different situations, complete the task, to find information that they need, and so on.\nVitaly: And one thing that really comes up in my mind every time we have this conversation is that you often identify yourself with a design engineering role. And I see that some teams are moving towards that role now. Where in the past, it was just a developer, and then it was just a designer, and then it was a front-end developer and backend developer.\nVitaly: And if you have an interface designer, you have to use the experience designer. So, maybe you could share a little bit of light on how you see design engineering as a role. And maybe many of our listeners now actually are design engineers without even knowing that. So, how would you define it? And do you think that companies actually understand what it means?\nSara: I have actually an essay, not just an article, an essay that is all about just defining the role of a design engineer. And from my point of view, I even have a domain name that I purchased just to put that on it. If I try to describe it with just a few words because I already gave a super long answer to the previous question-\nVitaly: That was a wonderful answer. It wasn’t long at all.\nSara: Thank you. Okay. So, as design engineers, we specialize in implementing designs. That is the general description, right? We specialize in implementing designs, but then, of course, there is how you implement it. So, I like to label myself as an inclusive design engineer, which is something that I’m doing on my new website, which is not public yet.\nSara: So, an inclusive design engineer is someone who, in my opinion, uses accessibility and progressive enhancement as a framework to build inclusive interfaces. But, as a design engineer, in general, is someone who works directly with designers, hopefully, because this is what I think the role should be.\nSara: We should be working directly with designers, helping them make decisions and informing design decisions with our accessibility and code knowledge, basically, because they complement each other. We write HDML. We write CSS. We write presentational JavaScript, mostly.\nSara: And with a strong focus on accessibility, hopefully, because that should be part of every design engineer’s job. And then, of course, the strategy that you choose and the frameworks that you use, and I’m not talking about CSS frameworks or JavaScript frameworks here, but like I said, this... let me just call it the strategy.\nSara: Strategies that you use and what exactly you focus on, and how you do your job as a design engineer probably differs between people because like I said, I’m a progressive enhancement advocate, others are maybe not. So, we would differ in these small details.\nSara: But a design engineer is someone who works with designers, helps inform design decisions and makes sure that designs are implemented in a way that hopefully works for as many users as possible.\nVitaly: Right. So then, as a design engineer, at this point, how would you then actually work? So, what would your process be like? So, when you think about implementing a particular design, do you break it down into components? Do you think about navigation landmarks first?\nVitaly: How do you actually start building things? What is your maybe mindset in that framework of getting accessible results? Maybe you could describe it a little bit.\nSara: Okay. So, when you say that you divide the... you not divide, basically looked at the design and then start thinking in components, that very much depends on the process that you work with the designer. So, if I’m working with someone who has handed over a design, like an entire page, the process is different from when I’m working with the designer, like I did with Yan Persy.\nSara: I’ve mentioned him multiple times on Smashing Hour, by the way, because working with him was one of my favorite ways of working with the designers because he didn’t have like a full finished design for me to implement. We worked in tandem. We worked together. And he changed some of the things in the design.\nSara: So, for example, he wasn’t using a responsive type scale like we do in front-end development now using CSS variables and viewport units, et cetera. So, we had this discussion, and then he shifted the way the design process went. It was different.\nSara: So, we both started building the site in terms of components, and then assembling those components into what we called slices back then, and then assembling the slices into the entire website. So, how I start from whether it’s components or not, depends on the process that I work with the designer.\nSara: But then, if I get a little bit more technical, like if I have a component that I want to build, how do I go about doing that in layers, I would say? Again, progressive enhancement, the first thing that I think about is how does this work? How does this look like?\nSara: How does someone perceive this if JavaScript is disabled? And what happens if there is no style? So, I just start with the bare minimum, HTML, because HTML defines the semantics. The semantics give meaning to the content that I’m creating.\nSara: So, which HTML elements do I need to tell the user what this thing is to give semantics? If HDML already contains an element that represents this component or this element that I’m building, I use that. If not, then I start to thinking about ARIA attributes; which ARIA attributes do I need?\nSara: How much ARIA do I need? ARIA is... it’s not an enhancement; it’s necessary for a lot of dynamic and interactive components. But I always try to think of it as a last resort, not a first one, so always semantic HTML first. How much can I get done with just semantic HTML?\nSara: How accessible is it? Do I need something? Do I need to polyfill some semantics using ARIA? If I do, then I start thinking about that. And then applying CSS, and how does CSS affect these semantics? Does it? Does it not?\nSara: Do I have to do something extra to make sure that something remains accessible after I style it? Like, for example, if you stripped away the default list styles on list elements, which is something you probably... and many people probably already know by now, if you set list style to none, for example, on an unordered list, then Safari or WebKit, WebKit, in general, is going to remove the semantics of the list.\nSara: And VoiceOver is not going to announce that anymore. So, what do I do in that case? Do I need those semantics? Do I go into the HTML and add them again using a role attribute or not? So, I think about this stuff in layers. Start with HTML semantics. Do I need ARIA? How do I style this? And then, interactivity is always the last layer that I think about and that I build into components.\nVitaly: Right. Makes sense. It’s interesting what you’re saying that it’s a process. It doesn’t seem like a simple process, especially when you think about like literally implementing quite a complex interface, which may also have all kinds of different views and maybe single page application in the back and so on.\nVitaly: And one thing that I’m struggling with when I’m doing work with clients and trying to make things more inclusive and interfaces maybe a bit more usable is that very often web accessibility is still seen as this little thing. Like, “Okay, that’s just semantics.” “Okay, so we’re going to use buttons for buttons.”\nVitaly: But it’s actually much, much, much more than that. And I’m wondering, what do you think... like, where do we actually stand in terms of accessibility today? It’s very hard for me, personally, for example, to imagine a new project being released without even considering accessibility.\nVitaly: I think that might have been possible maybe a decade ago. I think today, it would be very difficult to imagine a brand new project that’s going to be advertised everywhere on posters that is not accessible at all, some parts accessible, but maybe not everything.\nVitaly: So, what do you think, has accessibility not become just the natural part of every design implementation process, or are we way, way, way, far away from this yet?\nSara: I think we are not too far, but we’re still far. So, there is definitely a lot more awareness on accessibility. I hope so, at least, because I only follow like less than 250 people on Twitter. And most of the people in my circle are people who either work with accessibility or care about accessibility.\nSara: So, if I were to judge the current situation based on my little circle, I would say that accessibility is doing great, and people care about it a lot. And they work to make their content more accessible. But I can’t speak for everyone because I know that this isn’t the case for everyone.\nSara: I know that there are still many developers who just simply don’t care. Because with accessibility, you either care or you don’t care; this is it. If you don’t care, then you are basically not doing any accessibility work at all.\nSara: And then, on the other hand, those that do care about accessibility and try to implement it in their work, some of them are finding difficulty because they get lost in all of the resources out there, and where should they go? Where do they start? This is why I’m creating the accessibility course now, to hopefully help with that a little bit.\nSara: So, we are definitely doing much better than we did like five years ago, let me say, five. But I don’t think we’re just exactly there yet. No. I think it’s going to take more time.\nVitaly: Yeah. But then, I also hear developers telling me all the time, “Well, hold on. But the platform is evolving so beautifully at this point. We have not only the wonderful CSS feature coming along, but also we have these incredible things that common UI components, like input type date for a date picker, the dialogue for models, details, and summary for accordions.”\nVitaly: And very often, what I find is that they just use those things, and they think that, “Okay, well, since these are native components available on the platform, they surely are accessible.” And then, come eye along, and then there is trouble. I’m wondering, at this point, what would you say in this position?\nVitaly: Like, those things, would you recommend to use them ever? Or where are there? Ideally, it would be a very nice idea and situation where we ended up with all those native components just available out of the box, beautiful, accessible, inclusive, and all of that. Are we there yet?\nSara: No.\nVitaly: Are we again, far away from it?\nSara: No. No. We’re definitely not there yet. I know that the dialogue element, for example, has been pretty... I don’t want to say completely inaccessible, but it has had a lot of accessibility issues for years now. And I think it only started getting better this year. And then, input type equal date, I rarely ever used it because, to be honest, I don’t think that it offers the best usability anyway, even if it is accessible, which I think it’s... I don’t know.\nSara: I haven’t used it in a very long time, so I can’t even tell if it’s fully accessible or not. But I think the last I heard was that it wasn’t and that it was a usability nightmare. So, even if something is technically accessible, that doesn’t mean that it’s going to be usable. Definitely a lot of tests.\nSara: And I like this quote by my friend, Scott O’Hara, that he said in one of his talks. He said, “Technology and user expectations change rapidly. And we should always test to ensure not only emerging patterns work correctly but try untrue patterns continue to work as we expect.”\nSara: This is me, now, continuing. Sometimes even something that you know works may stop working as you expect. Browsers may create new heuristics, for example. And the way they... not interpret, the way they present something because the user may change on any day.\nSara: Also, a note about details and summary, which is something that I had a discussion about today, details and summary are not the best choice for an accordion. They can be used for an accordion, but even they... like, when you choose any component, the first thing you have to think about is the semantics.\nSara: What are the semantics that are going to be conveyed? Because the semantics determine the non-visual interface for a non-sighted user, for a screen reader, for a user, for example, assuming they’re a non-sighted screen reader, the user.\nSara: Details in summary, they have their own quirks when it comes to semantics. So, the summary has a button roll, which means that it is conveyed as a button to assistive technologies. And buttons eat up the semantics of the elements inside of them.\nSara: So, if you have a heading, which is what you would normally have in an accordion, and if you put that inside of a summary, then the heading is not going to be conveyed as a heading anymore. Of course, there are exceptions because sometimes browsers try to quote, fix our misuse of ARIA or our misuse of semantics.\nSara: And they try to help stream users by conveying things that we may have broken as developers, but it doesn’t mean that all browsers do that. So, definitely, always, you need to test. And if details in summary, for example, if you use that, and if the headings are not exposed as headings, and then the user cannot use those headings to navigate, for example, anymore.\nSara: So, even if something is technically accessible, yes, they can access the contents of summary. Yes, they can access the contents of the details. But you have to think about what semantics you are conveying and how they affect the usability of the interface and sometimes maybe navigation, so there are a lot of things to keep in mind.\nVitaly: Yeah. So, it’s interesting that you brought up the testing for accessibility at this point. Because when we run our workshops, and every now and then, we... in my workshop, I tend to just explain to people how security works. And I always ask the same question. And for the last, I don’t know, two, three, four years, maybe now, I’ve been asking the same question.\nVitaly: So, who is hearing this VoiceOver for the very first time? And these are usually designers or developers coming to those workshops. And very often, you would see a vast majority of people hearing things for the very first time. So, maybe you could also share a bit of light in how do you actually test accessibility?\nVitaly: Do you always have screen reader or VoiceOver on or maybe any other tools? Could you also, maybe, run us through the process of testing your components for accessibility?\nSara: Okay. So, there are quite a few things that I like to use, and I’m going to mention them in no particular order; definitely browser DevTools to inspect the accessibility tree because you can get a lot of insight on the accessibility of the elements and components that you’re building from the accessibility tree.\nSara: Because basically, the accessibility tree is the accessibility... contains the accessibility information that the browser has created for assistive technologies to announce. So, when you look at the accessibility tree, you can get an idea of how an element is going to be announced by a screen reader that accesses and gets that information from the browser via the accessibility API, of course.\nSara: So, the dev tools for accessibility tree. There are a lot of extensions that I like to use, for example, to see the document outline on a page or to see the landmarks on a page. If I’m doing an accessibility audit, I would definitely use an automated testing tool such as asking DevTools, for example.\nSara: As far as screen reader go, definitely like... you cannot just test on one screen reader. And I have been guilty of this. I mean, I’m not like preaching something that I don’t practice now, but I know that I didn’t practice this before. I don’t have access to a windows machine.\nSara: So, I recently... not recently, like a few months ago, I started using Nvidia A on my windows virtual machine. And I also recently got a license for JAWS because JAWS is not free, but Nvidia is free. So, I used VoiceOver with Safari on iOS. Sometimes I test on other browsers, as well, just because sometimes, maybe a VoiceOver using may be using another browser.\nSara: But generally speaking, VoiceOver and Safari are the best combination, and users typically know that. And on windows, I test Nvidia A with Firefox, Nvidia A with Chrome. And the narrator is also built into Windows, so I use that for testing as well.\nSara: And JAWS is the most popular screen meter according to the WebAIM screen reader, user survey. So yes, you have to test using multiple screen readers and browser combinations because just like you cannot test your website only on one browser.\nSara: Like say, you’ve built a website, and you want to test, if everything is working as expected, all your CSS and stuff, you don’t just test it on one browser, right? You test it on most modern browsers and possibly even on IE if you still have to support that. Just like you test on multiple browsers, you also have to test on multiple screen readers, if you can. So, this is what I do, in general.\nVitaly: Yeah. So, you also mentioned in one of the Smashing Hours that tool.\nSara: Assistive labs.\nVitaly: Assistive labs, which is like browsers tech for screen readers, which is really need to see, as well. And I think, for me, it’s really this really interesting world of other browsers, I would say because we tend to focus a lot on what are some of the fancy new features we get in Firefox and in Chrome, and in Safari.\nVitaly: Just in general, would you say that the development of screen readers is... the frequency of updates, is it similar or is it something like maybe there is a new version coming up every six months or only just once a year, because we have this comparability, right, stuff happening across browsers.\nVitaly: So, as much as it used to where you’re using Firefox or Chrome, or Safari, or Edge, at this point, do you see that it’s also moving in the world of screen readers towards this comparability mode... not mode, compatibility across different screens readers? Or is it... maybe you could share just a bit of light about that world and that universe of screen readers?\nSara: To be honest, I’ve never dug that deep into it. So, I haven’t been monitoring, for example, screen reader updates, like how often Nvidia is updated and how often JAWS is updated. But I do know that even if JAWS or Nvidia is updated, not all screen reader users are going to update their software because they’re aware of... a lot of things may break for them.\nSara: And if they already have an environment that works, nobody wants to break something that works for them. So, I know that many screen reader users do not update their software as often as we may think that they do.\nVitaly: Right. Well, of course, talking about browsers, at this point, I do have to bring out the wonderful notion of wonderful CSS. And obviously, I do have some questions about CSS, as well. And one thing that I definitely have to ask, and I know what your answer is going to be, but I still like hearing it every single time.\nVitaly: So, I am going to bring this up. I have a feeling... well, I know that you have or maybe don’t have strong feelings about CSS methodologies or frameworks, or JavaScript frameworks for that matter. Do you have any favorites, or do you not? Do you always just work with what the project requires?\nVitaly: How do you pick your battles? Would you ever use any framework or CSS framework library Tailwind, CSS and JS; I don’t know. I mean, a short, no would suffice.\nSara: I can’t just say no, because it depends on the project. If I’m working with a team and everyone on the team is using Tailwind, then I will definitely be using Tailwind with them. But I’ve never had to do that yet. And I’ve been super lucky with... actually, I would even say privileged with the projects that I’ve worked on so far.\nSara: So, no, I don’t use any CSS frameworks. I prefer not to use them because they come with a lot of... and I’m not, not talking specifically about any particular framework here. Most of them come with a lot of overhead. And for me personally, I feel that trying to remove all the unnecessary CSS or learn something or learn it from... it’s just so much faster for me to build something from scratch, literary.\nSara: Like, I have some CSS that I’ve created over the years that I moved from one project to the other, and of course, I constantly update that, and I used that. It’s like a mini, tiny framework that I used. Like, there are some utility classes that I used in there.\nSara: Some settings, I called them these settings files for setting up the type scale and the tokens for theming and all that stuff. But I would definitely rather not use a CSS framework. I don’t have super strong feelings about them. I personally used a combination of BEM ITCSS and utility classes in my work.\nSara: And I only add as much CSS as I need. So, if I need a utility class, I add it to the utility class list that I have. If not, I don’t just add it just in case I’m going to need it. I’m super minimal when it comes to writing CSS.\nVitaly: Right. Sorry, can you hear the voices of the wonderful people on the remote corners of the internet asking for that little framework that you have created to be open source, maybe?\nSara: I will. I do plan on doing that. Yes. The course has taken up most of my time. My website has been neglected. My blog has literally been abandoned for months, and I’m going to do... like, even the website that I’m using, I built the course website from scratch using 11T.\nSara: I’m even considering sharing that as a framework, if anyone wants to use it someday. So, a lot of stuff that I have on my to-do list, but I’m postponing all of it until after the course is released because I need to get this done.\nVitaly: Right. So, maybe let’s just jump into the course. I think that we’ve been speaking about it a couple of times already, but I could not be more excited to actually get this course finally released. Well, do you think you could actually share a bit of insight about what’s going to be about, when it’s going to be released, and where wonderful people listening to this show can subscribe to updates to actually get it when it does get released?\nSara: Okay. Updates, subscription, e-mail, newsletter on practical-accessibility.today, that is the website for where the course is going to be hosted currently. It just includes an overview of what the course is about and a link to subscribe to the newsletter.\nSara: But hopefully next month, when the backend is finally ready... because we’re doing everything from scratch, and I hired a friend of mine to build the backend and all the payment stuff into it. Once that is finished, the website is going to be updated with more details about the course. So, I’m going to introduce the course in a short video.\nSara: There’s going to be a more detailed table of contents. I haven’t shared a table of contents yet because it keeps changing a lot. Like, even yesterday I added a new section or a new chapter in between two other chapters. So, if I had shared the table of contents before, it wouldn’t have been super accurate.\nSara: So hopefully, in a month... I think during the next Smashing Hour, I’m going to be making an important update on the course.\nVitaly: Oh, that’s cool. That’s nice. That’s nice. Can I ask you just on that point? I find it so difficult to record videos. I always see like, “Oh, no, no, no. I shouldn’t have said that.” I should brief rewind back, and then I should re-edit and then I should change.\nVitaly: And then, I keep going all the time, and it takes me, I don’t know, hours to just record 10 or 15 minutes of stuff. Is it the same for you? Or do you just go?\nSara: I’m already worried about this because I haven’t recorded anything final yet. I’ve only done a few, so like some testing and editing stuff. I’m starting with a course in reverse, actually. I’m not recording first. I’m going to give more details about the process and everything later, once it’s finished.\nSara: But I’ve decided to do things in a different way so that when it’s time to do the recordings and the editings, I hope will hopefully have eased things for myself, so that they don’t take as much time. And something that I need to keep reminding myself of is because I’m a perfectionist, and that sometimes is a bad thing.\nSara: I’m just going to assume that I’m on stage in a conference and just like, I can’t edit every single word I say on stage. I’m going to try to just ignore some things in the videos. That’s going to be super difficult, especially because I know that I can edit them, but it’s definitely going to take some self-discipline to do that.\nVitaly: Yeah. So, it’s impossible for me. I always say like, “Oh, no, no, no, of course, I can go back,” and surely I can come back. So, in the end, it just takes hours. But I think that we all cannot wait for the video course to be finally released and get our hands on the videos.\nVitaly: This is very, very exciting. Maybe talking about excitement, I know that there are so many wonderful new features coming to the web. I don’t know when it’s coming. Is it like Chrome 103 something, where we should be expecting the :has() pseudo-class coming in, container queries coming in? It’s like Christmas is coming early.\nSara: The year of CSS.\nVitaly: Yeah, the year of CSS. So, maybe you could just share a bit of light about what are you excited about at this point? What is the thing that keeps you awake at night where you think, “Oh, if it only was available today, I would use it all over in my projects.” What would that be? Or what are you most excited about these days in CSS?\nSara: Well, CSS doesn’t keep me up at night, but I do look forward to things like definitely subgrid. I know that I was one of the people who started requesting container queries years ago, and then we finally got them. But then, at this point, we were already doing a lot of intrinsic responsive design already and using flexbox and CSS grid to create responsive components that don’t require container queries anymore.\nSara: Although, I mean, they are still important, and I will definitely still be using them. But probably what I’m personally more excited about is cascade layers and subgrid because almost every single project that I’ve used, especially since I worked on the Prismic Slices Project in 2019, that project changed the way I started building websites, at least for me.\nSara: It influenced the work that we did on the ?? website with Yan. And it also influences now, my own work on my website, for example. Instead of thinking of either pages or small components, there is this middle ground, which is slices.\nSara: And layout within slices always... like I’ve always wanted the ability to inherit the grit on the parent container of the parent container into the child. And so, subgrid is going to be one of the things that I will probably need even more than container queries in my work.\nSara: Cascade layers, I wouldn’t say that I need it, but the way it allows me to organize my CSS, the same way the CSS is organized inside of my head, so to speak, that is one of the reasons why I’m excited about it as well.\nVitaly: Okay. And then, maybe just a few final questions to finally wrap up, just because I’m very, very curious, so I’m sure you have a couple of books lying around at this point; how do you organize your books? Are they organized by topic? Are they organized by color? I met some people doing that. How do you organize them?\nSara: By color, but not like the rainbow style color that other people do.\nVitaly: Okay. How many pencils or pens do you have on your table most of the time?\nSara: Probably two, like one or two.\nVitaly: And how many screens?\nSara: You mean for work?\nVitaly: Yes.\nSara: Right now, just two, the laptop and an external display, 32-inch.\nVitaly: Okay. Because for me, moving to a secondary display was really a deal-breaker, so it’s just incredible. And then finally, one thing that I do want to ask, and it’s totally unrelated, is, do you happen to have a printer?\nSara: No, I haven’t had one in more than two decades, I think.\nVitaly: Yeah. Now, I feel just lonely because every time I bring this up, because I just got a printer, like what, two months ago. And I’m very proud of this because this is like me having a printer like the first time in two decades, seems like I’m the only person who’s buying printers at this point. That makes me very, very sad.\nSara: I mean, you’ve lived in Germany, right, and you still do a lot of printed paperwork there, so you need it.\nVitaly: Yes, indeed. You’re absolutely right. Well, okay, now we know that. All right. So, we’ve been learning a little bit about what it means to design and create more accessible interfaces today; what have you been learning about lately, Sara? Maybe one interesting insight or one unusual thing that you’ve learned recently, which really changed your views, maybe it’s just something that somebody said to you, which has influenced your work or just the way you’re thinking about design or about development, anything in that department?\nSara: Nothing that big, but a lot of small detail.\nVitaly: Like what?\nSara: There is super technical thing.\nVitaly: Okay. So, when it comes to implementation of accessible components, and things like that.\nSara: Yeah. There are a lot of things that I learned from digging really deep into specifications. And I love that because my go-to resource to learn about almost anything starting with CSS and other things, is to go to the specifications first. And there’s so much I’ve learned from that recently.\nVitaly: All right. Excellent. Well, so, if you, dear listener, would like to hear more from Sara, you can follow her on Twitter, which is @SaraSoueidan. And also, find all her work on her website at sarasoueidan.com/.\nVitaly: And also, don’t forget to subscribe to practical-accessibility.today, which as we’ve heard today will be released soon. So, this is something I’m very, very much looking forward to.\nSara: In the summer, hopefully. That’s what I’m aiming for.\nVitaly: Well, that’s fantastic news one way or the other. Well, thanks so much for joining us today, Sara. Do we have any parts in words?\nSara: Thank you for having me. Today is Global Accessibility Awareness Day. So, if there is something or one thing that you can do today, I would say go either learn something new about accessibility. Or, if you already have the knowledge, fix something on your own website or on somebody else’s website, like open a PR, or fix an issue that exists somewhere out there. Spread the word on accessibility, and subscribe to my newsletter.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/81bf4897-467c-4f52-a253-ed207834c9a1/smashing-podcast-episode-47.png",
      "date_published": "2022-05-31T05:00:00.000Z",
      "date_modified": "2022-05-31T05:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/whats-that-dev-tool/",
      "url": "https://smashingmagazine.com/2022/05/whats-that-dev-tool/",
      "title": "What’s That (Dev) Tool?",
      "summary": "How many browser DevTools panels do you commonly use in your day-to-day web development? One? Three? Probably not that many more. In this article, Patrick Brosset shines the spotlight on a number of tools that people don’t use or even know about. Let’s dive in!",
      "content_html": "<p>Have you ever looked to see what other tools were available to you within the DevTools toolbox? You’re probably using the same few panels over and over again — I know I am!</p>\n<p>It turns out there are more than thirty (30!) individual panels in Chrome DevTools (as well as other Chromium-based browsers, such as Edge). Safari and Firefox have fewer panels but still probably more than you use on any given day.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/79db772f-6021-4b63-b12c-f9edc04a57bf/3-whats-that-dev-tool.png\" /></p>\n<p>When I realized this, it gave me an idea for a silly game where you’d try to name as many panels as you could in under one minute. Play it here and try your luck (no cheating, OK?): <a href=\"https://patrickbrosset.com/lab/2022-05-13-whats-that-tool/\">What’s That Tool?</a></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d927b3ff-e7da-4af3-8795-4e0828063e86/11-whats-that-dev-tool.jpg\" /></p>\n<p>This game is silly, of course. As a web developer, remembering the exact names of each and every tool in DevTools isn’t important. It’s more important to know how to use these tools when needed.</p>\n<p>But the game does prove a point: there are many more tools than what people use or even know about! The whole goal of this game is — by the time the minute is gone and the full list is displayed — to realize, “oh wow, that’s a lot of tools I had no idea even existed.”</p>\n<p>So, why are there so many? Let’s face it, DevTools is crammed with buttons, tabs, and features. How did we get here, and is there a way out?</p>\nThe Story Of An Explosion\n<p>In the early 2000s, web development was very different than it is now. Back then, most of the complexity lay in generating the right HTML code from your server. The browsers’ ability to “view source” was enough to debug the odd table <code>colspan</code> problems. JavaScript was only getting started on the web, and CSS was nowhere near the feature-full language it is now.</p>\n<p>So, on top of the old <code>alert()</code> debugging trick, the very few tools we used for front-end code debugging were very specialized; they only did one thing. <a href=\"https://www-archive.mozilla.org/projects/venkman/\">Venkman</a> only did JavaScript debugging, <a href=\"https://www.karmatics.com/aardvark/\">Aardvark</a> was focused on inspecting elements, and <a href=\"https://addons.thunderbird.net/en-us/firefox/addon/console%C2%B2/\">Console2</a> displayed nice JavaScript log messages.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Joe_Hewitt_(programmer\">Joe Hewitt</a>) brought it all together under one tool called <a href=\"https://getfirebug.com/\">Firebug</a> which was a Firefox extension. It was an absolute revolution for web developers throughout the world! Around 2010, Firebug was probably the most used front-end debugging tool, and Firefox was a dominant browser. Crazy! Right?</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b6d46824-0aae-45a6-af97-9527017aaa1c/2-whats-that-dev-tool.png\" /></p>\n<p>Even if you have never used Firebug and started your web development journey in more recent times, I’m willing to bet this user interface feels familiar.</p>\n<p>Though the DevTools we use now aren’t very different from what Firebug used to look like, it felt like we had fewer things to worry about back then and, therefore, fewer tools to help them with.</p>\n<p>As the screenshot above shows, there weren’t many tools at all:</p>\n<ul>\n<li><strong>Console</strong> to view logs and execute JavaScript,</li>\n<li><strong>HTML tab</strong> to view and edit the page’s <strong>DOM</strong> and the applied <strong>CSS styles</strong>,</li>\n<li><strong>JavaScript debugger</strong>,</li>\n<li><strong>Network tab</strong> to check the downloaded resources and HTTP requests.</li>\n</ul>\n<p>Fast forward to 15 years in the future, to now. The user interface of the browser tools we use hasn’t changed much, but the sheer number of panels skyrocketed! Here’s a quick and incomplete (and very approximative) history of when new panels got introduced in Chrome DevTools:</p>\n<table>\n  <thead>\n        <tr>\n            <th>Year</th>\n            <th>Panels</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>2008</td>\n            <td>Console, Elements, Sources, Network, JavaScript profiler</td>\n        </tr>\n        <tr>\n            <td>2010</td>\n            <td>Performance (called Timeline at the time)</td>\n        </tr>\n    <tr>\n            <td>2013</td>\n            <td>Rendering, Layers</td>\n        </tr>\n    <tr>\n            <td>2014</td>\n            <td>CSS Overview, Network Conditions</td>\n        </tr>\n    <tr>\n            <td>2015</td>\n            <td>Security, Memory</td>\n        </tr>\n    <tr>\n            <td>2016</td>\n            <td>Animations</td>\n        </tr>\n    <tr>\n            <td>2017</td>\n            <td>Coverage, Lighthouse (called Audits at the time), Performance Monitor, Network Request Blocking</td>\n        </tr>\n    <tr>\n            <td>2018</td>\n            <td>Changes, Accessibility</td>\n        </tr>\n    <tr>\n            <td>2020</td>\n            <td>Media, WebAuthn, WebAudio, Issues</td>\n        </tr>\n    <tr>\n            <td>2021</td>\n            <td>Memory Inspector, Recorder</td>\n        </tr>\n        <tr>\n            <td>2022</td>\n            <td>Performance Insights</td>\n        </tr>\n    </tbody>\n</table>\n\n<p>There are many reasons why the number of new panels keeps growing. Some of them are good, while others are more questionable:</p>\n<ul>\n<li><strong>The number of features and APIs available to the Web platform is constantly and quickly increasing.</strong> Now, there are many more things a web developer can do on the web than 15 years ago. Some of those things can’t easily be debugged with the 4 or 5 tools we had back then, thus it required new panels in DevTools.</li>\n<li><strong>Our discipline is way more developed than it used to be.</strong> Front-end web development was maybe regarded as a little less interesting or important 15 years ago. It has now proven itself as a much deeper field of computer engineering that requires knowledge of not only programming but also performance optimization, accessibility, user experience, progressive enhancements, and more.<br />These things tend to sometimes require specialized tools too.</li>\n<li><strong>People who write the code for the browsers and DevTools also need tools themselves, and sometimes they end up as new panels.</strong> The <a href=\"https://developer.chrome.com/blog/new-in-devtools-92/#protocol-monitor\">Protocol Monitor</a> panel in Chromium is a great example of this.</li>\n<li><strong>Deleting things is really hard!</strong> You’re bound to break people’s workflows if you do it. So, things tend to accumulate over time. Chrome, for example, has three tools to do performance optimizations: Performance, Performance Insights, and JavaScript profiler.</li>\n<li>Finally, there seems to be a general <strong>tendency to add new things rather than improve what’s already in place</strong>. I get it; it’s more exciting to most people to build new things rather than fix bugs. But it tends to make the software more complicated over a long period of time. And this has most probably been at play in DevTools, too.</li>\n</ul>\n<p>In any case, we’re here now with probably what’s one of the most advanced tooling suites any application platform could dream of. But it’s also one of the most complex that no one uses to its full potential.</p>\nIs This A Problem?\n<p>Yes! Put simply, DevTools is a very complicated product, and its user interface can be scary.</p>\n<p>Where other products have five main user scenarios, DevTools has dozens, if not hundreds. Do you need to simulate a mobile screen? Detect color contrast? Convert between font units? See JSON responses? DevTools can do it all! And these are just a few random examples.</p>\n<p>So, with that many options and features, it isn’t a surprise that the user interface is complex so much that new users can feel very overwhelmed in their first-run experience. But even experienced users don’t necessarily know what’s available outside of the same few panels they’re used to.</p>\n<p>This is starting to become a serious usability problem, in my opinion, one that may sometimes discourage new people in their learning journey. People coming to DevTools today are likely to be used to newer development products that are much easier to use. The digital tool space is undergoing a big change in this direction, and the browser DevTools haven’t started moving yet.</p>\n<p>This isn’t a simple problem to solve either. As I said before, there are some really good reasons why we need a lot of specialized tooling. So, the complexity is needed, but I believe it should be opt-in rather than opt-out!</p>\n<p>Indeed, the DevTools learning curve is getting very steep because so much information is presented to users right from the start, and people have to learn to ignore the parts they don’t know about or think they don’t need.</p>\nWhy Don’t We Just Clean It All Up?\n<p>Well, it’s complicated. There are many user scenarios built in DevTools, and there are probably as many workflows as there are people using DevTools out there. Even the most rarely used tools are here for a reason, and the few people who use them may depend on them.</p>\n<p>In my experience working on DevTools, removing old/un-maintained/rarely used panels for the sake of making the codebase easier to work with always proved to be a bad idea, especially when done without enough customer research.</p>\n<p>In fact, while I worked on Firefox, we tried <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1247723\">removing the Fonts panel</a> at some point in Firefox DevTools, and the response was pretty instant and strong — so much that we put it back in! We lacked the necessary customer understanding of how this tool was being used and what unique scenarios it supported.</p>\n<p>In 2016, the 3D view panel <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=937166#c16\">had to be removed</a> because it wasn’t supported anymore by the new (back then) Firefox architecture. To this day, more than six years later, people still complain that it’s gone (note that you can still use it <a href=\"https://docs.microsoft.com/en-us/microsoft-edge/devtools-guide-chromium/3d-view/\">in Edge</a>)!</p>\n<p>As a final example, the Chrome team <a href=\"https://developer.chrome.com/blog/new-in-devtools-84/#properties\">removed the Properties sidebar pane</a> in 2020 but later added it again after seeing how much people needed it.</p>\n<p><strong>Usage numbers alone aren’t a good measure of a tool’s worth.</strong> Some tools may be used by a few people only, but they may depend on them to do their jobs. Proper user research and understanding of the various user roles and scenarios (and DevTools has a lot of them!) are needed to be able to simplify the product.</p>\nA Way Out?\n<p>I want to propose two directions that I think have a lot of potential when it comes to improving the situation with DevTools: </p>\n<ol>\n<li><strong>simplifying the DevTools core and opening it up to more powerful extensions</strong>, so that users make their own tools;</li>\n<li>being bold and taking risks with a <strong>radically user-friendly user interface</strong>.</li>\n</ol>\n<h3>A Powerful But Simple Core, Boosted With Extensions</h3>\n<p><a href=\"https://code.visualstudio.com/\"><strong>Visual Studio Code</strong></a> is such an amazing product! Many people use it and not only web developers. It’s built on a very strong core that can be extended tremendously.</p>\n<p>This way, the people who work on VS Code don’t have to worry about all of the features that people might need. VS Code is a bit like DevTools in the sense that no two people have the same needs and workflows, and there are hundreds of ways to use the product.</p>\n<p>So, the team’s job is to build a <strong>solid foundation</strong> that allows basic editing and top that up with an <strong>extension API</strong> that lets other people dig deep into the platform and add extra features.</p>\n<p>There are many advantages to this, but one that is of particular interest to me here is that <strong>complexity is opt-in</strong>. When you install VS Code the first time, it’s not overwhelming. It’s a text editor, and you can use it to edit text right off the bat. But if your project has special needs, like checking code quality or doing some custom syntax highlighting, then you can install all the fancy extensions you want and get the extra functionality you need.</p>\n<p>The VS Code extension API goes really deep into how much you can customize the editor, and I believe this is largely responsible for its success.</p>\n<p>DevTools, however, is built differently. You can also install extensions in the browser to add new panels to DevTools, but there aren’t very many useful extensions available outside of the major framework ones (<a href=\"https://github.com/facebook/react/tree/main/packages/react-devtools-extensions\">React</a>, for example). The teams who work on DevTools are the ones who pretty much do all the tools that a web developer might need.</p>\n<p>By using the <a href=\"https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions\">browser extensions API</a>, creating a new panel in DevTools isn’t too hard, but the API isn’t as advanced as in VS Code. In particular, there is <strong>no way to extend the existing tools to augment their functionality</strong>. This is a serious limitation that I think is responsible for the low number of useful extensions we have at our disposal.</p>\n<p>As an example, the amazing <a href=\"https://motion.dev/tools\">Motions DevTools extension</a> allows you to view and edit animations on the web. But it’s limited to its own panel container, and it can’t integrate with the <em>Elements</em> panel right next to it, which would have been useful to simplify user workflows and re-use existing components, such as the color picker.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a72fe548-da9e-491f-8638-b519cf161145/7-whats-that-dev-tool.png\" /></p>\n<p>Although they have now gone back to a more traditional tabbed navigation which seems to work better with developers, I appreciate this early attempt to make a more user-friendly interface that’s also more consistent with what people knew at the time.</p>\n<p>This also goes to show that very special care needs to be taken to bring developers along a journey of user interface change in DevTools.</p>\n<p>This brings me to the team working on the Edge DevTools now (which, full disclosure, I am part of). I believe this is currently the only team doing something in this area.</p>\n<p>Our current experiment is called <a href=\"https://docs.microsoft.com/microsoft-edge/devtools-guide-chromium/experimental-features/focus-mode\"><strong>Focus Mode</strong></a>, and it is effectively the first attempt at redesigning the entire DevTools product UI.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/20f41746-f7c3-4656-b367-dcc7c9522e1a/9-whats-that-dev-tool.png\" /></p>\n<p>Focus Mode is available to users of DevTools on the Canary and Dev pre-release channels of Microsoft Edge by <a href=\"https://docs.microsoft.com/en-us/microsoft-edge/devtools-guide-chromium/experimental-features/focus-mode#enable-focus-mode\">enabling the “Focus Mode” experiment from the DevTools Settings</a>. Most users of these channels should in fact already have it on, as our team is gradually rolling out the feature and listening to user feedback in order to ensure this is not disruptive to existing workflows and a welcome change.</p>\n<p>Based on this feedback, we will continue rolling out Focus Mode to users of the Beta channel and eventually to the normal release version of Edge.</p>\n<p>Now, it might not seem like a big change at first, but this is only a first step in an iterative approach to creating a more approachable user interface. Again, changing things in this product is complicated, so our team is taking things slow.</p>\n<p>But if you look closely, there are a few major changes to the UI that try to make things less cluttered and more streamlined.</p>\n<p>The most visible changes are located in the top toolbar. Here is an animation showing a comparison of what the toolbar looks like with and without Focus Mode:</p>\n<a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a6c8ee1f-a3b6-4340-b102-813b26b54118/06-focus-mode-toolbar-transition.gif\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/683cb013-32b2-42cc-a2b2-adaccc512716/06-focus-mode-toolbar-transition-800w.gif\" /></a>(<a href=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a6c8ee1f-a3b6-4340-b102-813b26b54118/06-focus-mode-toolbar-transition.gif\">Large preview</a>)\n\n<ul>\n<li>The list of warnings, errors, and infos is now gone from the toolbar, and instead, it appears as colored badges on the Console and Issues panel tabs, removing some clutter.</li>\n<li>The Settings, Feedback, and main menu icons have been grouped under just one menu button in the top-right corner, further reducing clutter.</li>\n<li>Tabs now have icons, so they’re easier to see and tell apart.</li>\n</ul>\n<p>Here are a few more things coming with Focus Mode.</p>\n<p>The + button in the toolbar shows all available tools with their icons making it easier to re-open a tool you’ve closed before and maybe more inviting to try tools you haven’t tried yet.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f62e44a9-a7f1-43b7-bfc2-9b3c6861d09e/4-whats-that-dev-tool.png\" /></p>\n<p>It’s also possible to switch the tabs to a vertical orientation. Being positioned to the left and hiding the labels further reduces the noise in the central part of the window, letting you focus on the code. Additionally, it matches UI patterns that people are growing used to in other tools (for example, the Activity bar in VS Code or vertical tabs in Edge).</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d8e96113-4c2f-4b6d-bdb9-9b4dd9fc49d9/5-whats-that-dev-tool.png\" /></p>\n<p>And finally, the drawer in DevTools was re-designed. The drawer is this area of the user interface that appears at the bottom when you press the Esc key on the keyboard, and that normally contains the Console.</p>\n<p>It was introduced as a way to have access to the Console at the same time as other tools, and all browser DevTools have this now. But over the years, the Chrome team added more and more things to the drawer, in particular secondary tools that were useful but not quite popular enough for a spot on the main tab bar (e.g., the Rendering panel was added there).</p>\n<p>I think it’s come to a point where it’s hard to know for sure which tool is available in which area. Edge — with Focus Mode — is taking a different approach. The drawer is now called Quick View, which is always visible at the bottom of the toolbox (so you don’t even have to know to press <code>Escape</code>) and can be used to display any tool you want.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f06ba56e-cd2d-493f-9bbe-159c278758e4/6-whats-that-dev-tool.png\" /></p>\n<p>I’m very excited about where Focus Mode is going, and I can’t wait for our team to start exploring what’s next in this area.</p>\n<p>If you want to try Focus Mode out, make sure you have a copy of <a href=\"https://www.microsoft.com/edge\">Edge</a> (you can also get a <a href=\"https://www.microsoftedgeinsider.com/en-us/download\">pre-release version</a> if you prefer to have the latest changes), open DevTools, and if you don’t already have it ON, press <code>F1</code>, then go to Experiments and check the Focus Mode box.</p>\n<p>Let the team know what you think about it — and if you have other ideas — by filing new issues on <a href=\"https://github.com/MicrosoftEdge/DevTools\">our DevTools GitHub repository</a>.</p>\n<p>I believe that a user-friendly DevTools that is both more welcoming to learners and inclusive of everyone’s needs is possible, and together, we can make it happen. As a community, let’s demand more from our friendly DevTools teams!</p>\n<p>There are full-time dedicated DevTools product engineering teams working for each browser vendor. They keep adding new features and fixing bugs, but they can only do a good job with our collective help. </p>\n<p>Tell them if the UI doesn’t work for you. Let them know about your most common workflows. How many clicks did you need? Do you often forget where things are? Do you wish things were named differently? Input like this can lead to changes that make a big difference for millions of users.</p>\n<p>As mentioned, we’re actively seeking feedback on this experiment and other DevTools features. You can leave comments on our <a href=\"https://github.com/MicrosoftEdge/DevTools/\">GitHub repository</a>. Other browsers also like to hear feedback on their DevTools which you can do at the <a href=\"https://bugzilla.mozilla.org/\">Mozilla bugzilla tracker</a> for Firefox, on the <a href=\"https://bugs.chromium.org/p/chromium/issues/list\">Chromium bug tracker</a> for Chrome, and on the <a href=\"https://bugs.webkit.org/\">WebKit bugzilla tracker</a> for Safari.</p>\n<p>Thanks for reading! And see you next time.</p>",
      "content_text": "Have you ever looked to see what other tools were available to you within the DevTools toolbox? You’re probably using the same few panels over and over again — I know I am!\nIt turns out there are more than thirty (30!) individual panels in Chrome DevTools (as well as other Chromium-based browsers, such as Edge). Safari and Firefox have fewer panels but still probably more than you use on any given day.\n\nWhen I realized this, it gave me an idea for a silly game where you’d try to name as many panels as you could in under one minute. Play it here and try your luck (no cheating, OK?): What’s That Tool?\n\nThis game is silly, of course. As a web developer, remembering the exact names of each and every tool in DevTools isn’t important. It’s more important to know how to use these tools when needed.\nBut the game does prove a point: there are many more tools than what people use or even know about! The whole goal of this game is — by the time the minute is gone and the full list is displayed — to realize, “oh wow, that’s a lot of tools I had no idea even existed.”\nSo, why are there so many? Let’s face it, DevTools is crammed with buttons, tabs, and features. How did we get here, and is there a way out?\nThe Story Of An Explosion\nIn the early 2000s, web development was very different than it is now. Back then, most of the complexity lay in generating the right HTML code from your server. The browsers’ ability to “view source” was enough to debug the odd table colspan problems. JavaScript was only getting started on the web, and CSS was nowhere near the feature-full language it is now.\nSo, on top of the old alert() debugging trick, the very few tools we used for front-end code debugging were very specialized; they only did one thing. Venkman only did JavaScript debugging, Aardvark was focused on inspecting elements, and Console2 displayed nice JavaScript log messages.\nJoe Hewitt) brought it all together under one tool called Firebug which was a Firefox extension. It was an absolute revolution for web developers throughout the world! Around 2010, Firebug was probably the most used front-end debugging tool, and Firefox was a dominant browser. Crazy! Right?\n\nEven if you have never used Firebug and started your web development journey in more recent times, I’m willing to bet this user interface feels familiar.\nThough the DevTools we use now aren’t very different from what Firebug used to look like, it felt like we had fewer things to worry about back then and, therefore, fewer tools to help them with.\nAs the screenshot above shows, there weren’t many tools at all:\n\nConsole to view logs and execute JavaScript,\nHTML tab to view and edit the page’s DOM and the applied CSS styles,\nJavaScript debugger,\nNetwork tab to check the downloaded resources and HTTP requests.\n\nFast forward to 15 years in the future, to now. The user interface of the browser tools we use hasn’t changed much, but the sheer number of panels skyrocketed! Here’s a quick and incomplete (and very approximative) history of when new panels got introduced in Chrome DevTools:\n\n  \n        \n            Year\n            Panels\n        \n    \n    \n        \n            2008\n            Console, Elements, Sources, Network, JavaScript profiler\n        \n        \n            2010\n            Performance (called Timeline at the time)\n        \n    \n            2013\n            Rendering, Layers\n        \n    \n            2014\n            CSS Overview, Network Conditions\n        \n    \n            2015\n            Security, Memory\n        \n    \n            2016\n            Animations\n        \n    \n            2017\n            Coverage, Lighthouse (called Audits at the time), Performance Monitor, Network Request Blocking\n        \n    \n            2018\n            Changes, Accessibility\n        \n    \n            2020\n            Media, WebAuthn, WebAudio, Issues\n        \n    \n            2021\n            Memory Inspector, Recorder\n        \n        \n            2022\n            Performance Insights\n        \n    \n\n\nThere are many reasons why the number of new panels keeps growing. Some of them are good, while others are more questionable:\n\nThe number of features and APIs available to the Web platform is constantly and quickly increasing. Now, there are many more things a web developer can do on the web than 15 years ago. Some of those things can’t easily be debugged with the 4 or 5 tools we had back then, thus it required new panels in DevTools.\nOur discipline is way more developed than it used to be. Front-end web development was maybe regarded as a little less interesting or important 15 years ago. It has now proven itself as a much deeper field of computer engineering that requires knowledge of not only programming but also performance optimization, accessibility, user experience, progressive enhancements, and more.These things tend to sometimes require specialized tools too.\nPeople who write the code for the browsers and DevTools also need tools themselves, and sometimes they end up as new panels. The Protocol Monitor panel in Chromium is a great example of this.\nDeleting things is really hard! You’re bound to break people’s workflows if you do it. So, things tend to accumulate over time. Chrome, for example, has three tools to do performance optimizations: Performance, Performance Insights, and JavaScript profiler.\nFinally, there seems to be a general tendency to add new things rather than improve what’s already in place. I get it; it’s more exciting to most people to build new things rather than fix bugs. But it tends to make the software more complicated over a long period of time. And this has most probably been at play in DevTools, too.\n\nIn any case, we’re here now with probably what’s one of the most advanced tooling suites any application platform could dream of. But it’s also one of the most complex that no one uses to its full potential.\nIs This A Problem?\nYes! Put simply, DevTools is a very complicated product, and its user interface can be scary.\nWhere other products have five main user scenarios, DevTools has dozens, if not hundreds. Do you need to simulate a mobile screen? Detect color contrast? Convert between font units? See JSON responses? DevTools can do it all! And these are just a few random examples.\nSo, with that many options and features, it isn’t a surprise that the user interface is complex so much that new users can feel very overwhelmed in their first-run experience. But even experienced users don’t necessarily know what’s available outside of the same few panels they’re used to.\nThis is starting to become a serious usability problem, in my opinion, one that may sometimes discourage new people in their learning journey. People coming to DevTools today are likely to be used to newer development products that are much easier to use. The digital tool space is undergoing a big change in this direction, and the browser DevTools haven’t started moving yet.\nThis isn’t a simple problem to solve either. As I said before, there are some really good reasons why we need a lot of specialized tooling. So, the complexity is needed, but I believe it should be opt-in rather than opt-out!\nIndeed, the DevTools learning curve is getting very steep because so much information is presented to users right from the start, and people have to learn to ignore the parts they don’t know about or think they don’t need.\nWhy Don’t We Just Clean It All Up?\nWell, it’s complicated. There are many user scenarios built in DevTools, and there are probably as many workflows as there are people using DevTools out there. Even the most rarely used tools are here for a reason, and the few people who use them may depend on them.\nIn my experience working on DevTools, removing old/un-maintained/rarely used panels for the sake of making the codebase easier to work with always proved to be a bad idea, especially when done without enough customer research.\nIn fact, while I worked on Firefox, we tried removing the Fonts panel at some point in Firefox DevTools, and the response was pretty instant and strong — so much that we put it back in! We lacked the necessary customer understanding of how this tool was being used and what unique scenarios it supported.\nIn 2016, the 3D view panel had to be removed because it wasn’t supported anymore by the new (back then) Firefox architecture. To this day, more than six years later, people still complain that it’s gone (note that you can still use it in Edge)!\nAs a final example, the Chrome team removed the Properties sidebar pane in 2020 but later added it again after seeing how much people needed it.\nUsage numbers alone aren’t a good measure of a tool’s worth. Some tools may be used by a few people only, but they may depend on them to do their jobs. Proper user research and understanding of the various user roles and scenarios (and DevTools has a lot of them!) are needed to be able to simplify the product.\nA Way Out?\nI want to propose two directions that I think have a lot of potential when it comes to improving the situation with DevTools: \n\nsimplifying the DevTools core and opening it up to more powerful extensions, so that users make their own tools;\nbeing bold and taking risks with a radically user-friendly user interface.\n\nA Powerful But Simple Core, Boosted With Extensions\nVisual Studio Code is such an amazing product! Many people use it and not only web developers. It’s built on a very strong core that can be extended tremendously.\nThis way, the people who work on VS Code don’t have to worry about all of the features that people might need. VS Code is a bit like DevTools in the sense that no two people have the same needs and workflows, and there are hundreds of ways to use the product.\nSo, the team’s job is to build a solid foundation that allows basic editing and top that up with an extension API that lets other people dig deep into the platform and add extra features.\nThere are many advantages to this, but one that is of particular interest to me here is that complexity is opt-in. When you install VS Code the first time, it’s not overwhelming. It’s a text editor, and you can use it to edit text right off the bat. But if your project has special needs, like checking code quality or doing some custom syntax highlighting, then you can install all the fancy extensions you want and get the extra functionality you need.\nThe VS Code extension API goes really deep into how much you can customize the editor, and I believe this is largely responsible for its success.\nDevTools, however, is built differently. You can also install extensions in the browser to add new panels to DevTools, but there aren’t very many useful extensions available outside of the major framework ones (React, for example). The teams who work on DevTools are the ones who pretty much do all the tools that a web developer might need.\nBy using the browser extensions API, creating a new panel in DevTools isn’t too hard, but the API isn’t as advanced as in VS Code. In particular, there is no way to extend the existing tools to augment their functionality. This is a serious limitation that I think is responsible for the low number of useful extensions we have at our disposal.\nAs an example, the amazing Motions DevTools extension allows you to view and edit animations on the web. But it’s limited to its own panel container, and it can’t integrate with the Elements panel right next to it, which would have been useful to simplify user workflows and re-use existing components, such as the color picker.\n\nAlthough they have now gone back to a more traditional tabbed navigation which seems to work better with developers, I appreciate this early attempt to make a more user-friendly interface that’s also more consistent with what people knew at the time.\nThis also goes to show that very special care needs to be taken to bring developers along a journey of user interface change in DevTools.\nThis brings me to the team working on the Edge DevTools now (which, full disclosure, I am part of). I believe this is currently the only team doing something in this area.\nOur current experiment is called Focus Mode, and it is effectively the first attempt at redesigning the entire DevTools product UI.\n\nFocus Mode is available to users of DevTools on the Canary and Dev pre-release channels of Microsoft Edge by enabling the “Focus Mode” experiment from the DevTools Settings. Most users of these channels should in fact already have it on, as our team is gradually rolling out the feature and listening to user feedback in order to ensure this is not disruptive to existing workflows and a welcome change.\nBased on this feedback, we will continue rolling out Focus Mode to users of the Beta channel and eventually to the normal release version of Edge.\nNow, it might not seem like a big change at first, but this is only a first step in an iterative approach to creating a more approachable user interface. Again, changing things in this product is complicated, so our team is taking things slow.\nBut if you look closely, there are a few major changes to the UI that try to make things less cluttered and more streamlined.\nThe most visible changes are located in the top toolbar. Here is an animation showing a comparison of what the toolbar looks like with and without Focus Mode:\n(Large preview)\n\n\nThe list of warnings, errors, and infos is now gone from the toolbar, and instead, it appears as colored badges on the Console and Issues panel tabs, removing some clutter.\nThe Settings, Feedback, and main menu icons have been grouped under just one menu button in the top-right corner, further reducing clutter.\nTabs now have icons, so they’re easier to see and tell apart.\n\nHere are a few more things coming with Focus Mode.\nThe + button in the toolbar shows all available tools with their icons making it easier to re-open a tool you’ve closed before and maybe more inviting to try tools you haven’t tried yet.\n\nIt’s also possible to switch the tabs to a vertical orientation. Being positioned to the left and hiding the labels further reduces the noise in the central part of the window, letting you focus on the code. Additionally, it matches UI patterns that people are growing used to in other tools (for example, the Activity bar in VS Code or vertical tabs in Edge).\n\nAnd finally, the drawer in DevTools was re-designed. The drawer is this area of the user interface that appears at the bottom when you press the Esc key on the keyboard, and that normally contains the Console.\nIt was introduced as a way to have access to the Console at the same time as other tools, and all browser DevTools have this now. But over the years, the Chrome team added more and more things to the drawer, in particular secondary tools that were useful but not quite popular enough for a spot on the main tab bar (e.g., the Rendering panel was added there).\nI think it’s come to a point where it’s hard to know for sure which tool is available in which area. Edge — with Focus Mode — is taking a different approach. The drawer is now called Quick View, which is always visible at the bottom of the toolbox (so you don’t even have to know to press Escape) and can be used to display any tool you want.\n\nI’m very excited about where Focus Mode is going, and I can’t wait for our team to start exploring what’s next in this area.\nIf you want to try Focus Mode out, make sure you have a copy of Edge (you can also get a pre-release version if you prefer to have the latest changes), open DevTools, and if you don’t already have it ON, press F1, then go to Experiments and check the Focus Mode box.\nLet the team know what you think about it — and if you have other ideas — by filing new issues on our DevTools GitHub repository.\nI believe that a user-friendly DevTools that is both more welcoming to learners and inclusive of everyone’s needs is possible, and together, we can make it happen. As a community, let’s demand more from our friendly DevTools teams!\nThere are full-time dedicated DevTools product engineering teams working for each browser vendor. They keep adding new features and fixing bugs, but they can only do a good job with our collective help. \nTell them if the UI doesn’t work for you. Let them know about your most common workflows. How many clicks did you need? Do you often forget where things are? Do you wish things were named differently? Input like this can lead to changes that make a big difference for millions of users.\nAs mentioned, we’re actively seeking feedback on this experiment and other DevTools features. You can leave comments on our GitHub repository. Other browsers also like to hear feedback on their DevTools which you can do at the Mozilla bugzilla tracker for Firefox, on the Chromium bug tracker for Chrome, and on the WebKit bugzilla tracker for Safari.\nThanks for reading! And see you next time.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6a1e15f7-a8bd-4593-b880-c9857e673516/whats-that-dev-tool.jpg",
      "date_published": "2022-05-30T13:30:00.000Z",
      "date_modified": "2022-05-30T13:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/3dicons-open-source-library-case-study-download/",
      "url": "https://smashingmagazine.com/2022/05/3dicons-open-source-library-case-study-download/",
      "title": "Open-Source 3dicons Library: Case Study And Free Downloads",
      "summary": "In this article, Vijay describes his learning experiences during the design stages of creating his 3dicons image library (a free library for product screens, social media posts and marketing campaigns), which you can download and use for free.",
      "content_html": "<p>In February 2021, I began studying 3D illustration using <a href=\"https://www.blender.org/\">Blender</a>. Like most beginners in the field of 3D design, I also <a href=\"https://www.youtube.com/playlist?list=PLjEaoINr3zgEq0u2MzVgAaHEBt--xLB6U\">created my first donut</a> by following <a href=\"https://www.youtube.com/user/AndrewPPrice\">BlenderGuru</a>’s (Andrew Price) tutorials. I firmly believe that <em>learning by doing</em> is the best way to learn. Picking an icon and following the steps on how to construct it in the 3D space was a great challenge for me, as each icon required a different approach to modeling.</p>\n<p>While learning, I noticed that the number of icons in my project had grown to almost 30, and at this moment, I decided to release them under an open-source license. I started preparing more icons for the most commonly used cases, and in the end, I created exactly 120 icons.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3c370405-baa3-4280-8c2f-af11a964add3/1-3dicons-open-source-library-case-study-download.png\" /></p>\n<p>Then the main objective evolved into creating a set of icons that could be used on product screens, presentations, and social media posts. These icons should be rendered as product-ready assets, but I also wanted to share the editable source files with the optimized and exported icons.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1f62010b-32a0-4b65-ab0e-95049fdbd561/2-3dicons-open-source-library-case-study-download.png\" /></p>\n<p>In this article, I will share my experience of learning and managing to release this large set, where the images alone take up 3.8 GB in size! I have divided it into five parts:</p>\n<ul>\n<li><a href=\"#why-open-source\">Why Open Source?</a></li>\n<li><a href=\"#tools-used\">Tools Used</a></li>\n<li><a href=\"#process-and-learning\">Process and Learning</a></li>\n<li><a href=\"#release\">Release</a></li>\n<li><a href=\"#conclusion-and-download\">Conclusion and Download</a></li>\n</ul>\n<p><strong>Note:</strong> <em>If you just want to download the</em> <strong><em>3dicons library,</em></strong> <em>you can jump straight to the “<a href=\"#download\">Conclusion and Download</a>” section at the end of the article.</em></p>\nWhy Open Source?\n<p>Firstly, I believe in <a href=\"https://en.wikipedia.org/wiki/Open_source\">open-source</a> design. Often, a project starts with the intent of learning and practice, when we redesign existing websites and apps like Facebook and Netflix, or various design screens, objects, or icons of interest, and then we post the results on <a href=\"https://dribbble.com/\">Dribbble</a>, <a href=\"https://www.behance.net/\">Behance</a>, and many other social platforms. We do this to improve our own skills, but when someone works on a concept, why not also share the source files with the community so that people can learn and benefit from <em>how</em> the design was crafted?</p>\n<p>By sharing our source files and best practices, we uplift the community and make the Design world better. After realizing this (and also drawing inspiration from <a href=\"https://twitter.com/pablostanley\">Pablo Stanley’s work</a>), I decided to do something similar.</p>\n<p>In 2019, I shared my first source file, which had 100+ illustrations. I had these illustrations sitting on my hard drive for years, but they were only taking up storage space. I wanted to make this resource available to the community and share it under an open-source license. Then I thought the same about the 100+ 3dicons, which I next created with the sole purpose of learning 3D design.</p>\n<p><strong>Important:</strong> <em>Releasing my icons for free does not mean that I want to diminish the value of other artists’ work.</em></p>\n<p>Secondly, there are a lot of 3D illustrations and icons available online for free or for a small fee. Unfortunately, most of the free resources out there do not allow you to modify them as you see fit — these freebies are often nothing more than a link to purchasing the final product. At the same time, many designers in the community are just starting out and need low-cost resources to learn from and use in their projects. These 3dicons should help them to get started, and when they are ready, they can either create their own 3D icons and art or buy and then build upon some existing ones. </p>\n<p><strong>Update:</strong> <em><a href=\"https://www.figma.com/community/file/1030350068466019692\">3dicons</a> has just been <a href=\"https://twitter.com/realvjy/status/1521176158263386113\">nominated</a> as one of the finalist projects in the Figma Community Awards! (Editor’s Note in the last minute)</em></p>\nTools Used\n<p>As a designer, I’m a huge fan of Apple products! But learning 3D on a 16\" MacBook was not good enough for me, so I decided to build my own PC specifically for learning 3D design. The following are some of the hardware and software tools that I used to craft the project’s files: </p>\n<ul>\n<li>Windows machine (<a href=\"https://www.amd.com/en/products/cpu/amd-ryzen-7-3800x\">AMD Ryzen 7 3800X</a>, <a href=\"https://www.nvidia.com/en-eu/geforce/graphics-cards/rtx-2080/\">nvidia GeForce RTX 2080</a>);</li>\n<li><a href=\"https://www.blender.org/\">Blender</a>: for all modeling, rendering, and compositing;</li>\n<li><a href=\"https://www.pureref.com/index.php\">PureRef</a>: helping me collect references for icons, colors, and other things;</li>\n<li><a href=\"https://www.smashingmagazine.com/category/figma/\">Figma</a>: using it for arranging the icons and for designing the web page;</li>\n<li>iPad with the <a href=\"https://apps.apple.com/us/app/procreate/id425073498\">Procreate app</a>: for sketching, doodling, and ideation;</li>\n<li><a href=\"https://www.notion.so/\">Notion</a>: it’s a tool for managing everything, and after Figma, it’s my next favorite tool on the list! :-)</li>\n</ul>\nProcess And Learning\n<p>I created all these icons in Blender. Some of them were first doodled on an iPad using <a href=\"https://apps.apple.com/us/app/procreate/id425073498\">Procreate</a> and then modeled in 3D. After modeling, all icons were rendered in different angles and styles for multipurpose use. I was considering releasing to the public both the rough master file and all the production-ready assets, and for this, I needed some sort of a plan.</p>\n<h3>Planning Stage</h3>\n<p>To manage all my projects, I use Notion. First, I created a board and listed all the initial requirements there. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/91729d0c-b1da-47bc-bba6-7ddf74c5fcf2/3-3dicons-open-source-library-case-study-download.png\" /></p>\n<h3>Modeling</h3>\n<p>Some icons are easy to make and can be directly created from a reference. Some of them were conceived as doodles on my iPad using Procreate and then imported via Google Photos to my Windows machine. I created a basic guide window, and then all the icons were put together as a single file. This initial stage was quick, but then properly rendering all those models one by one was quite a challenging bit of work.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6ac850e0-b6e1-44d8-b6ed-2ef4673d5b08/13-v4-3dicons-open-source-library-case-study-download.jpg\" /></p>\n<h3>Challenges</h3>\n<p>Creating stuff for yourself is easy — nobody will see what’s <em>inside</em> your files. However, when you prepare to share a source file with someone else, you have to spend a lot of time managing and arranging all the layers and elements inside it.</p>\n<h3>Modeling</h3>\n<p>There is no doubt that modeling in Blender is very smooth. Learning was a trial and error process for me when I started. I figured it might be necessary to have a guide to make sure that all icons were the same size and positioned well. So, I made a basic guide with two cubes, one for the icon’s maximum boundaries and one for just the end edge of the area. Next, I modeled all the icons and stored them all in one file. I was looking for quality icons instead of low-poly ones, so I added <a href=\"https://docs.blender.org/manual/en/latest/modeling/modifiers/generate/subdivision_surface.html\">surface modifiers to smooth them out</a>.</p>\n\n<p>If you’re new to modeling, check “<a href=\"https://www.youtube.com/watch?v=ICBP-7x7Chc\">Modeling for Absolute Beginners</a>” — a Blender tutorial by <a href=\"https://www.youtube.com/channel/UC12jzVACGeiHDCj_1wZ2tog\">Surfaced Studio</a>.</p>\n\n<blockquote><strong>Key point:</strong><br /><br />When you apply the subdivision surface modifier, it increases the file size. I want to share <code>.obj</code> or <code>.fbx</code> files as well, so I need to apply all modifiers. Otherwise, it will mostly be low-poly icons, since modifiers will be removed.</blockquote>\n\n<h3>Lighting</h3>\n<p>A perfectly lighted model looks good. If you don’t light up your model properly, no matter how much effort you put into modeling, the result won’t look right. Every object has a different shape and needs different levels of light intensity. Since I decided to render icons from three different angles, each angle required a different light position and light intensity. It is time-consuming and complicated to change the same lights for different models.</p>\n\n<p>If you’re new to lighting, check “<a href=\"https://www.youtube.com/watch?v=Ys4793edotw\">Lighting for Beginners (Intro)</a>” — a Blender tutorial series by <a href=\"https://www.youtube.com/channel/UCOKHwx1VCdgnxwbjyb9Iu1g\">Blender Guru</a>.</p>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6661a3b4-ca06-4128-819e-16642ad00991/5-3dicons-open-source-library-case-study-download.png\" /></p>\n<blockquote><strong>Key point:</strong><br /><br />As a result, I created three sets of the same lights with similar three-point light settings: ISO, Dynamic, and Front. The lights’ positions were adjusted accordingly.</blockquote>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/75dda367-acaa-45b5-a121-9d90a31c2725/7-3dicons-open-source-library-case-study-download.png\" /></p>\n<p>I did not have a problem when choosing colors, but in the 3D world, color intensity is affected by the light source, so this is an important thing to keep in mind. Additionally, I used to add gradients with light shades or complementary colors of the primary color rather than a direct “flat” color.</p>\n<blockquote><strong>Key point:</strong><br /><br />Managing the same color for all angles is a challenge. I tried and failed a few times before finally fixing the colors and gradients for all icons. Also, I found that high contrast is a better option in Blender when you work with vibrant colors.</blockquote>\n\n\n\n<h3>Rendering</h3>\n<p>It is quite challenging to render so many icons in four styles and at three different angles. <a href=\"https://www.blender.org/features/scripting/\">Blender supports scripting</a>, but it was difficult for me to learn too many things at the same time. Also, automatic rendering with the help of a script might not work for all icons due to their shape and angle — different icons will require different light amounts and intensity before being rendered. Therefore, the project was released later than expected.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/28e68c72-c3aa-4862-86b3-017401defb10/8-3dicons-open-source-library-case-study-download.png\" /></p>\n<blockquote><strong>Key points:</strong><ul><li>In the end, I created two cameras: one <strong>Normal</strong> camera and the second <strong>TrueISO</strong> camera. I used the Normal camera to render the front and dynamic angles, while the TrueISO camera was used to shoot the icon in its isometric form.</li><li>Rather than creating multiple cameras for the different angles, I used <strong>timelines</strong> and controlled the rotation and position of the objects.</li><li>I used 800 samples to render all these icons. By increasing the icon sample size, the rendering times will also increase. Rendering a single image with a resolution of 2400 × 2400 pixels took 2-4 minutes.</li></ul></blockquote>\n\n<p><strong>Note:</strong> <em><a href=\"https://docs.blender.org/manual/en/latest/render/cycles/render_settings/sampling.html\">Samples are the noise</a> that appears as your scene is rendering. In the Render panel, you define the number of samples, and then Blender stops once it reaches it. The more samples, the clearer the render will be, but it will also take a longer time to complete.</em></p>\n<h3>Compression and Post-processing</h3>\n<p>I tried to calculate the render times for the 120 icons in 12 variations (4 styles × 3 angles). When doing the first tests, at first, I was satisfied with the rendering at 3000x3000 px with 16-bit color depth. However, I discovered that one image file was about 15 MB in size. When I calculated the time and space needed for 1,200+ images rendered from different angles, I was shocked — I would need more than 8 GB in the storage space (including the source file), and also Figma couldn’t handle all those images in a single file either.</p>\n<blockquote><strong>Key points:</strong><ul><li>I could further optimize the images using Photoshop, but wouldn’t it be too time-consuming to add another step to the post-processing? Instead, I decided to change the resolution to 2400x2400 px, which is still quite large for an icon. Lastly, I changed the color depth to 8-bit and used 100% compression straight from Blender. And then, the single file size was reduced to 4 MB or less. The final icon library now was around 4 GB in size, which was manageable.</li><li>At first, I planned to render each icon separately with different channels and arrange them all in Figma with the help of components; this would allow me to easily change colors, lighting, and shadows right in Figma. Unfortunately, Figma files became very heavy, and I had to abandon the idea.</li></ul></blockquote>\n\n\n\nRelease\n<p>In total, more than two months of hard work (mostly done during the night) were needed to complete this project, from crafting the icons to rendering them and finally to hosting and building the project’s website.</p>\n<h3>Figma Community</h3>\n<p>I had trouble creating more flexible versions of the Figma files as this icon set grew to more than 4 GB in size. Figma stopped responding as soon as I uploaded 300+ images, which is a lot of data! How did I solve this issue? I used <a href=\"https://imageoptim.com/mac\">ImageOptim</a> to compress the images and then added them to Figma again. In addition, I dropped the idea of creating variations as the file size became excessively large. After that, I organized all the compressed 1000 × 1000 px images and shared them with the Figma community. (Eventually, I will create a customizable variant for Figma specifically, or maybe a plugin that will allow the icons to be easily imported and edited within Figma.)</p>\n<p><strong>ImageOptim:</strong> <em>It is a powerful image lossless compression tool software that provides “lossless” compression services for PNG images, reducing file size by 60%–90%.</em></p>\n<p>Here are the settings that I used to compress icons:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5c913dcc-a2ce-4f05-9a9a-da7f107d8b58/11-3dicons-open-source-library-case-study-download.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/31c61766-ede3-40f0-95f2-d3d8d3798004/12-3dicons-open-source-library-case-study-download.png\" /></p>\n<h3>Hosting</h3>\n<p>I host all of my projects directly on GitHub pages, although I occasionally use other hosting services. The main question was where to host over 3 GB of data, so people can easily download the icons. </p>\n<ul>\n<li><strong>Gumroad</strong><br />As the first example, <a href=\"https://gumroad.com/\">Gumroad</a> doesn’t offer a free option for downloading files over 200 MB in size — if I hosted the project on Gumroad, I would need to charge for it at least 1$. So, I tried to explore a few other solutions.</li>\n<li><strong>Google Drive</strong><br />It should work, but there are bandwidth limitations after some time.</li>\n<li><strong>Dropbox</strong><br />Same, after a certain point, the bandwidth issue will come up.</li>\n<li><strong>AWS</strong><br />I have used Amazon AWS in my experiential projects. Although usually a good solution, it’s quite complicated to set up.</li>\n<li><strong>Webflow</strong><br />I tried it once, as I’m not a big fan of no-code solutions (at the moment).</li>\n<li><strong>Digital Ocean</strong><br />After exploring a bit, I decided to store all my icons on the Digital Ocean hosting. It’s quite affordable at only 5$/month starting price. However, after running 3dicons for months, I discovered Digital Ocean is not an affordable solution after a certain bandwidth limit has been reached. I am charged 60-80 USD per month for the download bandwidth over 7 TB.</li>\n</ul>\n<p>Hopefully, I will be able to find a better solution than the Digital Ocean hosting so that 3dicons may continue to provide frictionless downloads with an affordable maintenance/download fee. If you have any suggestions or you think you could help, <a href=\"https://twitter.com/realvjy\">message me on Twitter</a>!</p>\n<h3>Website Domain</h3>\n<p>Honestly, I bought the 3dicons.co domain without any reason in 2020. Luckily for me, it was perfect for my new project!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/cbb35d8f-e4e0-4664-a18f-2ee7f479bc00/14-3dicons-open-source-library-case-study-download.png\" /></p>\n<h3>Frontend</h3>\n<ul>\n<li><strong><a href=\"https://webflow.com/\">Webflow</a></strong><br />No doubt, a great no-code web solution. However, it limits my freedom to customize things, so I’m not a big fan, even though I have used it for clients.</li>\n<li><strong><a href=\"https://www.wix.com/\">Wix</a></strong><br />Good for beginners. You can easily create sites by dragging and dropping.</li>\n<li><strong>Writing the code myself</strong><br />I love coding all my projects. Most of my projects use the following stack:<ul>\n<li><strong><a href=\"https://www.gatsbyjs.com/\">Gatsby Framework</a></strong><br />An easy and lightweight way to create static pages that can be directly hosted on GitHub pages. Gatsby is an open-source framework that combines functionality from React, GraphQL, and Webpack into a single tool.</li>\n<li><strong><a href=\"https://pages.github.com/\">GitHub pages</a></strong><br />GitHub allows you to host static pages directly as well as add custom domains with SSL security without any additional cost.</li>\n</ul>\n</li>\n</ul>\n<h3>Assets Creation</h3>\n<p>I use <a href=\"https://www.figma.com/\">Figma Design</a> for all my design needs, and the 3dicons project was no exception — I used Figma to help me create all the social media posts and Designs.</p>\nConclusion and Download\n<p>Now, I do know quite a few things about 3D design, but it wasn’t so when I was only beginning to learn. At the start of the journey, I wasn’t familiar with how to handle 3D files and how to render them in such a way that there would be very few hiccups. Fast-forward a few months of learning and experiments, and I think that the most important thing is that the final outcome looks good and that I have hope that the community will like and support this project. As an example, <a href=\"https://twitter.com/realvjy/status/1483837245279051779\">recently, Morflax integrated 3dicons</a> into their mesh project.</p>\n<p><strong>Note:</strong> <em>The Morflax mesh lets you customize the colors of the icons and add scenes on the web without requiring the use of any complex 3D software. You can <a href=\"https://morflax.com/mesh\">try the project for yourself</a>.</em></p>\n<h3>Download</h3>\n<p>You can get the latest version of the icons from <a href=\"https://3dicons.co/\">https://3dicons.co/</a>, and as I have more plans for 3dicons (including adding a few more icons to the existing set), make sure to check the project’s website for updates.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/cbcad802-8c29-48c9-87f6-edababb0e5b9/9-3dicons-open-source-library-case-study-download.png\" /></p>\n<blockquote>You can also download the icons set here:<br /><ul>\n <li><a href=\"https://www.figma.com/community/file/1030350068466019692/3dicons---Open-source-3D-icon-library\">Figma (Compressed)</a></li>\n <li><a href=\"https://www.smashingmagazine.com/provide/3dicons-set/3dicons-png-dynamic-1.0.0.zip\">PNG Dynamic</a></li>\n <li><a href=\"https://smashingmagazine.com/provide/3dicons-set/3dicons-png-iso-1.0.0.zip\">PNG ISO</a></li>\n <li><a href=\"https://www.smashingmagazine.com/provide/3dicons-set/3dicons-png-front-1.0.0.zip\">PNG Front</a></li>\n <li><a href=\"https://www.smashingmagazine.com/provide/3dicons-set/3dicons-blender-1.0.0.zip \">Blender File</a></li>\n <li><a href=\"https://www.smashingmagazine.com/provide/3dicons-set/3dicons-fbx-1.0.0.zip\">Fbx File</a></li>\n <li><a href=\"https://www.smashingmagazine.com/provide/3dicons-set/3dicons-set-full.zip\">Download all versions</a></li>\n </ul>\n\n<em>Last updated in May 2022. For the latest versions, please check the <a href=\"https://3dicons.co/\">3dicons</a> official webpage</em></blockquote>\n\n<h3>License</h3>\n<p>There are no restrictions on how you can use the 3dicons since they were released under a <strong><a href=\"https://creativecommons.org/publicdomain/zero/1.0/\">CC0 license</a></strong> (“<a href=\"https://creativecommons.org/share-your-work/public-domain/cc0/\">No Rights Reserved</a>”).</p>\n<h3>Need help?</h3>\n<p>There is a little <a href=\"https://realvjy.notion.site/3dicons-FAQ-be562c619cf04f2daa04a10c2684575d\">FAQ Notion board</a> that should help you when you want to change the icons and colors using Blender. You can also reach out to me on Twitter (<a href=\"https://twitter.com/realvjy\">@realvjy</a>) for feedback and suggestions, and you can leave a comment here — I’d be happy to reply. </p>",
      "content_text": "In February 2021, I began studying 3D illustration using Blender. Like most beginners in the field of 3D design, I also created my first donut by following BlenderGuru’s (Andrew Price) tutorials. I firmly believe that learning by doing is the best way to learn. Picking an icon and following the steps on how to construct it in the 3D space was a great challenge for me, as each icon required a different approach to modeling.\nWhile learning, I noticed that the number of icons in my project had grown to almost 30, and at this moment, I decided to release them under an open-source license. I started preparing more icons for the most commonly used cases, and in the end, I created exactly 120 icons.\n\nThen the main objective evolved into creating a set of icons that could be used on product screens, presentations, and social media posts. These icons should be rendered as product-ready assets, but I also wanted to share the editable source files with the optimized and exported icons.\n\nIn this article, I will share my experience of learning and managing to release this large set, where the images alone take up 3.8 GB in size! I have divided it into five parts:\n\nWhy Open Source?\nTools Used\nProcess and Learning\nRelease\nConclusion and Download\n\nNote: If you just want to download the 3dicons library, you can jump straight to the “Conclusion and Download” section at the end of the article.\nWhy Open Source?\nFirstly, I believe in open-source design. Often, a project starts with the intent of learning and practice, when we redesign existing websites and apps like Facebook and Netflix, or various design screens, objects, or icons of interest, and then we post the results on Dribbble, Behance, and many other social platforms. We do this to improve our own skills, but when someone works on a concept, why not also share the source files with the community so that people can learn and benefit from how the design was crafted?\nBy sharing our source files and best practices, we uplift the community and make the Design world better. After realizing this (and also drawing inspiration from Pablo Stanley’s work), I decided to do something similar.\nIn 2019, I shared my first source file, which had 100+ illustrations. I had these illustrations sitting on my hard drive for years, but they were only taking up storage space. I wanted to make this resource available to the community and share it under an open-source license. Then I thought the same about the 100+ 3dicons, which I next created with the sole purpose of learning 3D design.\nImportant: Releasing my icons for free does not mean that I want to diminish the value of other artists’ work.\nSecondly, there are a lot of 3D illustrations and icons available online for free or for a small fee. Unfortunately, most of the free resources out there do not allow you to modify them as you see fit — these freebies are often nothing more than a link to purchasing the final product. At the same time, many designers in the community are just starting out and need low-cost resources to learn from and use in their projects. These 3dicons should help them to get started, and when they are ready, they can either create their own 3D icons and art or buy and then build upon some existing ones. \nUpdate: 3dicons has just been nominated as one of the finalist projects in the Figma Community Awards! (Editor’s Note in the last minute)\nTools Used\nAs a designer, I’m a huge fan of Apple products! But learning 3D on a 16\" MacBook was not good enough for me, so I decided to build my own PC specifically for learning 3D design. The following are some of the hardware and software tools that I used to craft the project’s files: \n\nWindows machine (AMD Ryzen 7 3800X, nvidia GeForce RTX 2080);\nBlender: for all modeling, rendering, and compositing;\nPureRef: helping me collect references for icons, colors, and other things;\nFigma: using it for arranging the icons and for designing the web page;\niPad with the Procreate app: for sketching, doodling, and ideation;\nNotion: it’s a tool for managing everything, and after Figma, it’s my next favorite tool on the list! :-)\n\nProcess And Learning\nI created all these icons in Blender. Some of them were first doodled on an iPad using Procreate and then modeled in 3D. After modeling, all icons were rendered in different angles and styles for multipurpose use. I was considering releasing to the public both the rough master file and all the production-ready assets, and for this, I needed some sort of a plan.\nPlanning Stage\nTo manage all my projects, I use Notion. First, I created a board and listed all the initial requirements there. \n\nModeling\nSome icons are easy to make and can be directly created from a reference. Some of them were conceived as doodles on my iPad using Procreate and then imported via Google Photos to my Windows machine. I created a basic guide window, and then all the icons were put together as a single file. This initial stage was quick, but then properly rendering all those models one by one was quite a challenging bit of work.\n\nChallenges\nCreating stuff for yourself is easy — nobody will see what’s inside your files. However, when you prepare to share a source file with someone else, you have to spend a lot of time managing and arranging all the layers and elements inside it.\nModeling\nThere is no doubt that modeling in Blender is very smooth. Learning was a trial and error process for me when I started. I figured it might be necessary to have a guide to make sure that all icons were the same size and positioned well. So, I made a basic guide with two cubes, one for the icon’s maximum boundaries and one for just the end edge of the area. Next, I modeled all the icons and stored them all in one file. I was looking for quality icons instead of low-poly ones, so I added surface modifiers to smooth them out.\n\nIf you’re new to modeling, check “Modeling for Absolute Beginners” — a Blender tutorial by Surfaced Studio.\n\nKey point:When you apply the subdivision surface modifier, it increases the file size. I want to share .obj or .fbx files as well, so I need to apply all modifiers. Otherwise, it will mostly be low-poly icons, since modifiers will be removed.\n\nLighting\nA perfectly lighted model looks good. If you don’t light up your model properly, no matter how much effort you put into modeling, the result won’t look right. Every object has a different shape and needs different levels of light intensity. Since I decided to render icons from three different angles, each angle required a different light position and light intensity. It is time-consuming and complicated to change the same lights for different models.\n\nIf you’re new to lighting, check “Lighting for Beginners (Intro)” — a Blender tutorial series by Blender Guru.\n\n\nKey point:As a result, I created three sets of the same lights with similar three-point light settings: ISO, Dynamic, and Front. The lights’ positions were adjusted accordingly.\n\n\nI did not have a problem when choosing colors, but in the 3D world, color intensity is affected by the light source, so this is an important thing to keep in mind. Additionally, I used to add gradients with light shades or complementary colors of the primary color rather than a direct “flat” color.\nKey point:Managing the same color for all angles is a challenge. I tried and failed a few times before finally fixing the colors and gradients for all icons. Also, I found that high contrast is a better option in Blender when you work with vibrant colors.\n\n\n\nRendering\nIt is quite challenging to render so many icons in four styles and at three different angles. Blender supports scripting, but it was difficult for me to learn too many things at the same time. Also, automatic rendering with the help of a script might not work for all icons due to their shape and angle — different icons will require different light amounts and intensity before being rendered. Therefore, the project was released later than expected.\n\nKey points:In the end, I created two cameras: one Normal camera and the second TrueISO camera. I used the Normal camera to render the front and dynamic angles, while the TrueISO camera was used to shoot the icon in its isometric form.Rather than creating multiple cameras for the different angles, I used timelines and controlled the rotation and position of the objects.I used 800 samples to render all these icons. By increasing the icon sample size, the rendering times will also increase. Rendering a single image with a resolution of 2400 × 2400 pixels took 2-4 minutes.\n\nNote: Samples are the noise that appears as your scene is rendering. In the Render panel, you define the number of samples, and then Blender stops once it reaches it. The more samples, the clearer the render will be, but it will also take a longer time to complete.\nCompression and Post-processing\nI tried to calculate the render times for the 120 icons in 12 variations (4 styles × 3 angles). When doing the first tests, at first, I was satisfied with the rendering at 3000x3000 px with 16-bit color depth. However, I discovered that one image file was about 15 MB in size. When I calculated the time and space needed for 1,200+ images rendered from different angles, I was shocked — I would need more than 8 GB in the storage space (including the source file), and also Figma couldn’t handle all those images in a single file either.\nKey points:I could further optimize the images using Photoshop, but wouldn’t it be too time-consuming to add another step to the post-processing? Instead, I decided to change the resolution to 2400x2400 px, which is still quite large for an icon. Lastly, I changed the color depth to 8-bit and used 100% compression straight from Blender. And then, the single file size was reduced to 4 MB or less. The final icon library now was around 4 GB in size, which was manageable.At first, I planned to render each icon separately with different channels and arrange them all in Figma with the help of components; this would allow me to easily change colors, lighting, and shadows right in Figma. Unfortunately, Figma files became very heavy, and I had to abandon the idea.\n\n\n\nRelease\nIn total, more than two months of hard work (mostly done during the night) were needed to complete this project, from crafting the icons to rendering them and finally to hosting and building the project’s website.\nFigma Community\nI had trouble creating more flexible versions of the Figma files as this icon set grew to more than 4 GB in size. Figma stopped responding as soon as I uploaded 300+ images, which is a lot of data! How did I solve this issue? I used ImageOptim to compress the images and then added them to Figma again. In addition, I dropped the idea of creating variations as the file size became excessively large. After that, I organized all the compressed 1000 × 1000 px images and shared them with the Figma community. (Eventually, I will create a customizable variant for Figma specifically, or maybe a plugin that will allow the icons to be easily imported and edited within Figma.)\nImageOptim: It is a powerful image lossless compression tool software that provides “lossless” compression services for PNG images, reducing file size by 60%–90%.\nHere are the settings that I used to compress icons:\n\n\nHosting\nI host all of my projects directly on GitHub pages, although I occasionally use other hosting services. The main question was where to host over 3 GB of data, so people can easily download the icons. \n\nGumroadAs the first example, Gumroad doesn’t offer a free option for downloading files over 200 MB in size — if I hosted the project on Gumroad, I would need to charge for it at least 1$. So, I tried to explore a few other solutions.\nGoogle DriveIt should work, but there are bandwidth limitations after some time.\nDropboxSame, after a certain point, the bandwidth issue will come up.\nAWSI have used Amazon AWS in my experiential projects. Although usually a good solution, it’s quite complicated to set up.\nWebflowI tried it once, as I’m not a big fan of no-code solutions (at the moment).\nDigital OceanAfter exploring a bit, I decided to store all my icons on the Digital Ocean hosting. It’s quite affordable at only 5$/month starting price. However, after running 3dicons for months, I discovered Digital Ocean is not an affordable solution after a certain bandwidth limit has been reached. I am charged 60-80 USD per month for the download bandwidth over 7 TB.\n\nHopefully, I will be able to find a better solution than the Digital Ocean hosting so that 3dicons may continue to provide frictionless downloads with an affordable maintenance/download fee. If you have any suggestions or you think you could help, message me on Twitter!\nWebsite Domain\nHonestly, I bought the 3dicons.co domain without any reason in 2020. Luckily for me, it was perfect for my new project!\n\nFrontend\n\nWebflowNo doubt, a great no-code web solution. However, it limits my freedom to customize things, so I’m not a big fan, even though I have used it for clients.\nWixGood for beginners. You can easily create sites by dragging and dropping.\nWriting the code myselfI love coding all my projects. Most of my projects use the following stack:\nGatsby FrameworkAn easy and lightweight way to create static pages that can be directly hosted on GitHub pages. Gatsby is an open-source framework that combines functionality from React, GraphQL, and Webpack into a single tool.\nGitHub pagesGitHub allows you to host static pages directly as well as add custom domains with SSL security without any additional cost.\n\n\n\nAssets Creation\nI use Figma Design for all my design needs, and the 3dicons project was no exception — I used Figma to help me create all the social media posts and Designs.\nConclusion and Download\nNow, I do know quite a few things about 3D design, but it wasn’t so when I was only beginning to learn. At the start of the journey, I wasn’t familiar with how to handle 3D files and how to render them in such a way that there would be very few hiccups. Fast-forward a few months of learning and experiments, and I think that the most important thing is that the final outcome looks good and that I have hope that the community will like and support this project. As an example, recently, Morflax integrated 3dicons into their mesh project.\nNote: The Morflax mesh lets you customize the colors of the icons and add scenes on the web without requiring the use of any complex 3D software. You can try the project for yourself.\nDownload\nYou can get the latest version of the icons from https://3dicons.co/, and as I have more plans for 3dicons (including adding a few more icons to the existing set), make sure to check the project’s website for updates.\n\nYou can also download the icons set here:\n Figma (Compressed)\n PNG Dynamic\n PNG ISO\n PNG Front\n Blender File\n Fbx File\n Download all versions\n \n\nLast updated in May 2022. For the latest versions, please check the 3dicons official webpage\n\nLicense\nThere are no restrictions on how you can use the 3dicons since they were released under a CC0 license (“No Rights Reserved”).\nNeed help?\nThere is a little FAQ Notion board that should help you when you want to change the icons and colors using Blender. You can also reach out to me on Twitter (@realvjy) for feedback and suggestions, and you can leave a comment here — I’d be happy to reply. ",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/af9b67f7-433c-421a-8fe6-14878b3f884d/3dicons-open-source-library-case-study-download.jpg",
      "date_published": "2022-05-27T09:00:00.000Z",
      "date_modified": "2022-05-27T09:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/accessible-design-system-themes-css-color-contrast/",
      "url": "https://smashingmagazine.com/2022/05/accessible-design-system-themes-css-color-contrast/",
      "title": "Manage Accessible Design System Themes With CSS Color-Contrast()",
      "summary": "From working with design handoffs to supporting custom themes in a design system, the CSS `color-contrast()` function can become a cornerstone for developers by enforcing accessible UIs.",
      "content_html": "<p>There’s certainly no shortage of design systems available to use when building your next project. Between IBM’s <a href=\"https://carbondesignsystem.com/\">Carbon</a>, <a href=\"https://design.wonderflow.ai/\">Wanda</a> and <a href=\"https://nordhealth.design/\">Nord</a>, there are plenty of terrific design systems to choose from. Yet, while each one contains its own nuances and opinions, most share a similar goal — simplifying the development process of creating beautifully accessible user interfaces.</p>\n<p>It’s an admirable goal and, honestly, one that has led me to shift my own career into design systems. But a core feature at the foundation of many design systems is the extensibility for theming. And why wouldn’t it be? Without some flexibility for branding, every product using a particular system would look the same, <em>à la Bootstrap around 2012</em>.</p>\n<p>While providing support for custom themes is vital, it also leaves the most well-intentioned system’s accessibility at the mercy of the implementation. Some teams may spend weeks, if not months, defining their ideal color palette for a rebranding. They’ll labor over each shade and color combination to ensure everything is reliable, informative, and accessible.</p>\n<p>Others simply can’t and/or won’t do that.</p>\n<p>It’s one thing to require <code>alt</code> text on an <code>img</code> element or a <code>label</code> for an <code>input</code> element, but enforcing accessible color palettes is an entirely different beast. It’s a beast with jagged yellow teeth, fiery-red eyes, and green scales covering its body like sheets of crocodile armor.</p>\n<p>At least you <em>think</em> it is. For all you know, it could be a beast of nothing more than indistinct shades of black and slightly darker black.</p>\n<p>And therein lies the problem.</p>\nThe CSS <code>Color-Contrast()</code> Function\n<blockquote>Building inclusive products doesn’t mean supporting devices but supporting the people using them.</blockquote>\n\n<p>The CSS <code>color-contrast()</code> function is an experimental feature which is currently a part of <a href=\"https://www.w3.org/TR/css-color-5/#colorcontrast\">Color Module 5</a>. Its purpose — and the reason for the excitement of this article — is to select the greatest contrasting color from a list when compared against a base color.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c0ffced8-be80-4145-a326-943c6800ea58/color-contrast-syntax-1.jpg\" /></p>\n<p>For the sake of this article, we will refer to the first parameter as the “base color” and the second as the “color list.” These parameters can accept any combination of browser-supported CSS color formats, but be weary of opacities. There’s an optional third parameter, but let’s look at that later. First, let’s define what we mean by this being an <em>experimental feature</em>.</p>\n<p>At the time of writing, the <code>color-contrast()</code> feature is only available in the <a href=\"https://developer.apple.com/safari/technology-preview\">Safari Technology Preview browser</a>. The feature can be toggled through the <code>Develop</code> and <code>Experimental Features</code> menus. The following demos will only work if the feature is enabled in that browser. So, if you’d like to switch, now wouldn’t be the worst time to do so.</p>\n<p>Now, with the base syntax, terminology, and support out of the way, let’s dive in. 🤿 </p>\nColor Me Intrigued\n<p>It was Rachel Andrew’s talk at AxeCon 2022, “<a href=\"https://www.deque.com/axe-con/sessions/new-css-with-accessibility-in-mind/\">New CSS With Accessibility in Mind</a>”, where I was introduced to <code>color-contrast()</code>. I scribbled the function down into my notebook and circled it multiple times to <em>make it pop</em>. Because my mind has been entirely in the world of design systems as of late, I wondered how big of an impact this little CSS feature could have in that context.</p>\n<p>In her presentation, Rachel <a href=\"https://codepen.io/rachelandrew/pen/XWzapXJ\">demoed the new feature</a> by dynamically defining text colors based on a background. So, let’s start there as well, by setting background and text colors on an <code>article</code>.</p>\n<pre><code>article {\n  --article-bg: #222;\n\n  background: var(--article-bg);\n  color: color-contrast(var(--article-bg) vs #FFF, #000);\n}</code></pre>\n\n<p>We start by defining the <code>--article-bg</code> custom property as a dark grey, <code>#222</code>. That property is then used as the base color in the <code>color-contrast()</code> function and compared against each item in the color list to find the highest contrasting value.</p>\n<table>\n    <thead>\n        <tr>\n            <th>Base Color</th>\n            <th>Color List</th>\n      <th>Contrast Ratio</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n      <td><code>#222</code></td>\n      <td><a href=\"https://paper.dropbox.com/?q=%23FFF\"><code>#FFF</code></a></td>\n      <td><code>15.9</code></td>\n        </tr>\n        <tr>\n            <td><code>#222</code></td>\n            <td><code>#000</code></td>\n      <td><code>1.31</code></td>\n        </tr>\n    </tbody>\n</table>\n\n<p>As a result, the article’s <code>color</code> will be set to white, <code>#FFF</code>.</p>\n<p>But this can be taken further.</p>\n<p>We can effectively chain <code>color-contrast()</code> functions by using the result of one as the base color of another. Let’s extend the <code>article</code> example by defining the <code>::selection</code> color relative to its text.</p>\n<pre><code>article {\n  --article-bg: #222;\n  --article-color: color-contrast(var(--article-bg) vs #FFF, #000);\n\n  background: var(--article-bg);\n  color: var(--article-color);\n\n  ::selection {\n    background: color-contrast(var(--article-color) vs #FFF, #000);\n  }\n}</code></pre>\n\n<p>Now, as the text color is defined, so will its selection background.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/99c566d1-f83c-4fa2-8ce4-7f69871ebe4d/color-contrast-syntax-2.jpg\" /></p>\n<p>The optional third parameter for <code>color-contrast()</code> defines a target contrast ratio. The parameter accepts either a keyword — <code>AA</code>, <code>AA-large</code>, <code>AAA</code>, and <code>AAA-large</code> — or a number. When a target contrast is defined, the first color from the color list that meets or exceeds it is selected.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8eafbd32-845e-499e-b333-c13d026f3043/color-contrast-demo-4.jpeg\" /></p>\n<p>This is where <code>color-contrast()</code> could really empower design systems to enforce a specific level of accessibility.</p>\n<p>Let’s break this down.</p>\n<pre><code>.dark-mode {\n  --bg: #000;\n  --color-list: #111, #222;\n}\n\n.dark-mode {\n  background: var(--bg);\n  color: color-contrast(var(--bg) vs var(--color-list));\n\n  &amp;.with-target {\n    color: color-contrast(var(--bg) vs var(--color-list) to AA);\n  }\n}</code></pre>\n\n<p>The magic here happens when the two <code>color</code> declarations are compared.</p>\n<p>The base <code>.dark-mode</code> class does not use a target contrast. This results in the <code>color</code> being defined as <code>#222</code>, the highest contrasting value from the color list relative to its base color of black. Needless to say, the contrast ratio of <code>1.35</code> may be the highest, but it’s far from accessible.</p>\n<p>Compare this to when the <code>.dark-mode</code> and <code>.with-target</code> classes are combined, and a target contrast is specified. Despite using the same base color and color list, the result is much different. When no value in the color list meets the <code>AA (4.5)</code> target contrast, the function selects a value that does. In this case, white.</p>\n<p>This is where the potential of <code>color-contrast()</code> is the brightest.</p>\n<p>In the context of design systems, this would allow a system to enforce a level of color accessibility with very granular control. That level could also be a <code>:root</code>-scoped custom property allowing the target contrast to be dynamic yet global. There’s a real feeling of control on the product side, but that comes at a cost during the implementation.</p>\n<p>There’s a logical disconnect between the code and the result. The code doesn’t communicate that the color white will be the result. And, of course, that control on the product side translates to uncertainty with the implementation. If a person is using a design system and passes specific colors into their theme, why are black and white being used instead?</p>\n<p>The first concern could be remedied by understanding the <code>color-contrast()</code> feature more deeply, and the second could be alleviated by clear, communicative documentation. However, in both cases, this shifts the burden of expectation onto the implementation side, which is not ideal.</p>\n<p>In some cases, the explicit control will justify the costs. However, there are other drawbacks to <code>color-contrast()</code> that will need to be considered in all cases.</p>\nNot All That Glitters Is Gold\n<p>There are inevitable drawbacks to consider, as with any experimental or new feature, and <code>color-contrast()</code> is no different.</p>\n<h3>Color And Visual Contrasts Are Different Things</h3>\n<p>When using <code>color-contrast()</code> to determine text color based on its background, the function is comparing exactly that — the colors. What <code>color-contrast()</code> <em>does not</em> take into consideration are other styles that may affect visual contrast, such as font size, weight, and opacity.</p>\n<p>This means it’s possible to have a color pairing that technically meets a specific contrast threshold but still results in an inaccessible text because its size is too small, weight is too light, or its opacity is too transparent.</p>\n<p>To learn more about accessible typography, I highly recommend Carie Fisher’s talk, “<a href=\"https://www.deque.com/axe-con/sessions/accessible-typography-essentials/\">Accessible Typography Essentials</a>.”</p>\n<h3>Custom Properties And Fallbacks</h3>\n<p>Since CSS custom properties support fallback values for when the property is not defined, it seemed like a good approach to use <code>color-contrast()</code> as a progressive enhancement.</p>\n<pre><code>--article-color: color-contrast(#000 vs #333, #FFF);\ncolor: var(--article-color, var(--fallback-color));</code></pre>\n\n<p>If <code>color-contrast()</code> is not supported, the <code>--article-color</code> property would not be defined, and therefore the <code>--fallback-color</code> would be used. Unfortunately, that’s not how this works.</p>\n<p>An interesting thing happens in unsupported browsers — the custom property would be defined with the function itself. Here’s an example of this from Chrome DevTools:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fd99763c-d569-4a74-b69a-26e86de3ee88/color-contrast-devtools-snippet.jpg\" /></p>\n<p>Because the <code>--article-color</code> property is technically defined, the fallback won’t trigger.</p>\n<p>However, that’s not to say <code>color-contrast()</code> can’t be used progressively, though. It can be paired with the <code>@supports()</code> function, but be mindful if you decide to do so. As exciting as it may be, with such limited support and potential for syntax and/or functionality changes, it may be best to hold off on sprinkling this little gem throughout an entire codebase.</p>\n<pre><code>@supports (color: color-contrast(#000 vs #fff, #eee)) {\n  --article-color: color-contrast(var(--article-color) vs #fff, #000);\n}</code></pre>\n\n<h3>The Highest Contrast Doesn’t Mean Accessible Contrast</h3>\n<p>Despite the control <code>color-contrast()</code> can offer with colors and themes, there are still limitations. When the function compares the base color against the list and no target contrast is specified, it will select the highest contrasting value. Just because the two colors offer the greatest contrast ratio, it doesn’t mean it’s an accessible one.</p>\n<pre><code>h1 {\n  background: #000;\n  color: color-contrast(#000 vs #111, #222);\n}</code></pre>\n\n<p>In this example, the background color of black. <code>#000</code> is compared against two shades of dark grey. While <code>#222</code> would be selected for having the “greatest” contrast ratio, pairing it with black would be anything but great.</p>\n<h3>No Gradient Support</h3>\n<p>In hindsight, it was maybe a touch ambitious trying gradients with <code>color-contrast()</code>. Nevertheless, through some testing, it seems gradients are not supported. Which, once I thought about it, makes sense.</p>\n<p>If a gradient transitioned from black to white, what would the base color be? And wouldn’t it need to be relative to the position of the content? It’s not like the function can interpret the UI. However, Michelle Barker has experimented with <a href=\"https://codepen.io/michellebarker/pen/LYQPYoq\">using CSS <code>color-mix()</code> and <code>color-contrast()</code> together</a> to support this exact use case.</p>\n<p>It’s not you, <code>color-contrast()</code>, it’s me. Well, it’s actually the gradients, but you know what I mean.</p>\nWrapping Up\n<p>That was a lot of code and demos, so let’s take a step back and review <code>color-contrast()</code>.</p>\n<p>The function compares a base color against a color list, then selects the highest contrasting value. Additionally, it can compare those values against a target contrast ratio and either select the first color to meet that threshold or use a dynamic color that does. Pair this with progressive enhancement, and we’ve got a feature that can drastically improve web accessibility.</p>\n<p>I believe there are still plenty of unexplored areas and use cases for <code>color-contrast()</code>, so I want to end this article with some additional thoughts and/or questions.</p>\n<p>How do you see this feature being leveraged when working with different color modes, like light, dark, and high contrast? Could a React-based design system expose an optional <code>targetContrast</code> prop on its <code>ThemeProvider</code> in order to enforce accessibility if the theme falls short? Would there be a use case for the function to return the lowest contrasting value instead? If there were two base colors, could the function be used to find the best contrasting value between them?</p>\n<p>What do you think? </p>\n<h3>Resources</h3>\n<ul>\n<li>“<a href=\"https://www.deque.com/axe-con/sessions/new-css-with-accessibility-in-mind/\">New CSS with Accessibility in Mind</a>”, Rachel Andrew</li>\n<li>“<a href=\"https://css-tricks.com/exploring-color-contrast-for-the-first-time/\">Exploring <code>color-contrast()</code> for the First Time</a>”, Chris Coyier</li>\n<li><a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/color-contrast%28%29\"><code>Color-Contrast()</code> on MDN</a> </li>\n<li><a href=\"https://caniuse.com/?search=color-contrast%28%29\">Support stats on caniuse.com</a></li>\n<li><a href=\"https://www.w3.org/TR/css-color-5/#colorcontrast\"><code>Color-Contrast()</code> on W3 Color Module Level 5</a></li>\n</ul>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/06/css-javascript-requirements-accessible-components/\">When CSS Isn’t Enough: JavaScript Requirements For Accessible Components</a>”, Stephanie Eckles</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/03/complete-guide-accessible-front-end-components/\">A Complete Guide To Accessible Front-End Components</a>”, Vitaly Friedman  </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/07/strong-case-for-accessibility/\">Making A Strong Case For Accessibility</a>”, Todd Libby</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/07/design-wireframes-accessible-html-css/\">Translating Design Wireframes Into Accessible HTML/CSS</a>”, Harris Schneiderman</li>\n</ul>",
      "content_text": "There’s certainly no shortage of design systems available to use when building your next project. Between IBM’s Carbon, Wanda and Nord, there are plenty of terrific design systems to choose from. Yet, while each one contains its own nuances and opinions, most share a similar goal — simplifying the development process of creating beautifully accessible user interfaces.\nIt’s an admirable goal and, honestly, one that has led me to shift my own career into design systems. But a core feature at the foundation of many design systems is the extensibility for theming. And why wouldn’t it be? Without some flexibility for branding, every product using a particular system would look the same, à la Bootstrap around 2012.\nWhile providing support for custom themes is vital, it also leaves the most well-intentioned system’s accessibility at the mercy of the implementation. Some teams may spend weeks, if not months, defining their ideal color palette for a rebranding. They’ll labor over each shade and color combination to ensure everything is reliable, informative, and accessible.\nOthers simply can’t and/or won’t do that.\nIt’s one thing to require alt text on an img element or a label for an input element, but enforcing accessible color palettes is an entirely different beast. It’s a beast with jagged yellow teeth, fiery-red eyes, and green scales covering its body like sheets of crocodile armor.\nAt least you think it is. For all you know, it could be a beast of nothing more than indistinct shades of black and slightly darker black.\nAnd therein lies the problem.\nThe CSS Color-Contrast() Function\nBuilding inclusive products doesn’t mean supporting devices but supporting the people using them.\n\nThe CSS color-contrast() function is an experimental feature which is currently a part of Color Module 5. Its purpose — and the reason for the excitement of this article — is to select the greatest contrasting color from a list when compared against a base color.\n\nFor the sake of this article, we will refer to the first parameter as the “base color” and the second as the “color list.” These parameters can accept any combination of browser-supported CSS color formats, but be weary of opacities. There’s an optional third parameter, but let’s look at that later. First, let’s define what we mean by this being an experimental feature.\nAt the time of writing, the color-contrast() feature is only available in the Safari Technology Preview browser. The feature can be toggled through the Develop and Experimental Features menus. The following demos will only work if the feature is enabled in that browser. So, if you’d like to switch, now wouldn’t be the worst time to do so.\nNow, with the base syntax, terminology, and support out of the way, let’s dive in. 🤿 \nColor Me Intrigued\nIt was Rachel Andrew’s talk at AxeCon 2022, “New CSS With Accessibility in Mind”, where I was introduced to color-contrast(). I scribbled the function down into my notebook and circled it multiple times to make it pop. Because my mind has been entirely in the world of design systems as of late, I wondered how big of an impact this little CSS feature could have in that context.\nIn her presentation, Rachel demoed the new feature by dynamically defining text colors based on a background. So, let’s start there as well, by setting background and text colors on an article.\narticle {\n  --article-bg: #222;\n\n  background: var(--article-bg);\n  color: color-contrast(var(--article-bg) vs #FFF, #000);\n}\n\nWe start by defining the --article-bg custom property as a dark grey, #222. That property is then used as the base color in the color-contrast() function and compared against each item in the color list to find the highest contrasting value.\n\n    \n        \n            Base Color\n            Color List\n      Contrast Ratio\n        \n    \n    \n        \n      #222\n      #FFF\n      15.9\n        \n        \n            #222\n            #000\n      1.31\n        \n    \n\n\nAs a result, the article’s color will be set to white, #FFF.\nBut this can be taken further.\nWe can effectively chain color-contrast() functions by using the result of one as the base color of another. Let’s extend the article example by defining the ::selection color relative to its text.\narticle {\n  --article-bg: #222;\n  --article-color: color-contrast(var(--article-bg) vs #FFF, #000);\n\n  background: var(--article-bg);\n  color: var(--article-color);\n\n  ::selection {\n    background: color-contrast(var(--article-color) vs #FFF, #000);\n  }\n}\n\nNow, as the text color is defined, so will its selection background.\n\nThe optional third parameter for color-contrast() defines a target contrast ratio. The parameter accepts either a keyword — AA, AA-large, AAA, and AAA-large — or a number. When a target contrast is defined, the first color from the color list that meets or exceeds it is selected.\n\nThis is where color-contrast() could really empower design systems to enforce a specific level of accessibility.\nLet’s break this down.\n.dark-mode {\n  --bg: #000;\n  --color-list: #111, #222;\n}\n\n.dark-mode {\n  background: var(--bg);\n  color: color-contrast(var(--bg) vs var(--color-list));\n\n  &.with-target {\n    color: color-contrast(var(--bg) vs var(--color-list) to AA);\n  }\n}\n\nThe magic here happens when the two color declarations are compared.\nThe base .dark-mode class does not use a target contrast. This results in the color being defined as #222, the highest contrasting value from the color list relative to its base color of black. Needless to say, the contrast ratio of 1.35 may be the highest, but it’s far from accessible.\nCompare this to when the .dark-mode and .with-target classes are combined, and a target contrast is specified. Despite using the same base color and color list, the result is much different. When no value in the color list meets the AA (4.5) target contrast, the function selects a value that does. In this case, white.\nThis is where the potential of color-contrast() is the brightest.\nIn the context of design systems, this would allow a system to enforce a level of color accessibility with very granular control. That level could also be a :root-scoped custom property allowing the target contrast to be dynamic yet global. There’s a real feeling of control on the product side, but that comes at a cost during the implementation.\nThere’s a logical disconnect between the code and the result. The code doesn’t communicate that the color white will be the result. And, of course, that control on the product side translates to uncertainty with the implementation. If a person is using a design system and passes specific colors into their theme, why are black and white being used instead?\nThe first concern could be remedied by understanding the color-contrast() feature more deeply, and the second could be alleviated by clear, communicative documentation. However, in both cases, this shifts the burden of expectation onto the implementation side, which is not ideal.\nIn some cases, the explicit control will justify the costs. However, there are other drawbacks to color-contrast() that will need to be considered in all cases.\nNot All That Glitters Is Gold\nThere are inevitable drawbacks to consider, as with any experimental or new feature, and color-contrast() is no different.\nColor And Visual Contrasts Are Different Things\nWhen using color-contrast() to determine text color based on its background, the function is comparing exactly that — the colors. What color-contrast() does not take into consideration are other styles that may affect visual contrast, such as font size, weight, and opacity.\nThis means it’s possible to have a color pairing that technically meets a specific contrast threshold but still results in an inaccessible text because its size is too small, weight is too light, or its opacity is too transparent.\nTo learn more about accessible typography, I highly recommend Carie Fisher’s talk, “Accessible Typography Essentials.”\nCustom Properties And Fallbacks\nSince CSS custom properties support fallback values for when the property is not defined, it seemed like a good approach to use color-contrast() as a progressive enhancement.\n--article-color: color-contrast(#000 vs #333, #FFF);\ncolor: var(--article-color, var(--fallback-color));\n\nIf color-contrast() is not supported, the --article-color property would not be defined, and therefore the --fallback-color would be used. Unfortunately, that’s not how this works.\nAn interesting thing happens in unsupported browsers — the custom property would be defined with the function itself. Here’s an example of this from Chrome DevTools:\n\nBecause the --article-color property is technically defined, the fallback won’t trigger.\nHowever, that’s not to say color-contrast() can’t be used progressively, though. It can be paired with the @supports() function, but be mindful if you decide to do so. As exciting as it may be, with such limited support and potential for syntax and/or functionality changes, it may be best to hold off on sprinkling this little gem throughout an entire codebase.\n@supports (color: color-contrast(#000 vs #fff, #eee)) {\n  --article-color: color-contrast(var(--article-color) vs #fff, #000);\n}\n\nThe Highest Contrast Doesn’t Mean Accessible Contrast\nDespite the control color-contrast() can offer with colors and themes, there are still limitations. When the function compares the base color against the list and no target contrast is specified, it will select the highest contrasting value. Just because the two colors offer the greatest contrast ratio, it doesn’t mean it’s an accessible one.\nh1 {\n  background: #000;\n  color: color-contrast(#000 vs #111, #222);\n}\n\nIn this example, the background color of black. #000 is compared against two shades of dark grey. While #222 would be selected for having the “greatest” contrast ratio, pairing it with black would be anything but great.\nNo Gradient Support\nIn hindsight, it was maybe a touch ambitious trying gradients with color-contrast(). Nevertheless, through some testing, it seems gradients are not supported. Which, once I thought about it, makes sense.\nIf a gradient transitioned from black to white, what would the base color be? And wouldn’t it need to be relative to the position of the content? It’s not like the function can interpret the UI. However, Michelle Barker has experimented with using CSS color-mix() and color-contrast() together to support this exact use case.\nIt’s not you, color-contrast(), it’s me. Well, it’s actually the gradients, but you know what I mean.\nWrapping Up\nThat was a lot of code and demos, so let’s take a step back and review color-contrast().\nThe function compares a base color against a color list, then selects the highest contrasting value. Additionally, it can compare those values against a target contrast ratio and either select the first color to meet that threshold or use a dynamic color that does. Pair this with progressive enhancement, and we’ve got a feature that can drastically improve web accessibility.\nI believe there are still plenty of unexplored areas and use cases for color-contrast(), so I want to end this article with some additional thoughts and/or questions.\nHow do you see this feature being leveraged when working with different color modes, like light, dark, and high contrast? Could a React-based design system expose an optional targetContrast prop on its ThemeProvider in order to enforce accessibility if the theme falls short? Would there be a use case for the function to return the lowest contrasting value instead? If there were two base colors, could the function be used to find the best contrasting value between them?\nWhat do you think? \nResources\n\n“New CSS with Accessibility in Mind”, Rachel Andrew\n“Exploring color-contrast() for the First Time”, Chris Coyier\nColor-Contrast() on MDN \nSupport stats on caniuse.com\nColor-Contrast() on W3 Color Module Level 5\n\nFurther Reading on Smashing Magazine\n\n“When CSS Isn’t Enough: JavaScript Requirements For Accessible Components”, Stephanie Eckles\n“A Complete Guide To Accessible Front-End Components”, Vitaly Friedman  \n“Making A Strong Case For Accessibility”, Todd Libby\n“Translating Design Wireframes Into Accessible HTML/CSS”, Harris Schneiderman\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1fd91360-3b48-4a72-9280-c778dc5dc53d/manage-accessible-design-system-themes-with-css-color-contrast-card-v2.jpg",
      "date_published": "2022-05-26T09:30:00.000Z",
      "date_modified": "2022-05-26T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/understanding-weak-reference-javascript/",
      "url": "https://smashingmagazine.com/2022/05/understanding-weak-reference-javascript/",
      "title": "Understanding Weak Reference In JavaScript",
      "summary": "In this article, Frank Joseph explains both weak and strong references in JavaScript, as well as the concept of reachability. Let’s dig in!",
      "content_html": "<p>Memory and performance management are important aspects of software development and ones that every software developer should pay attention to. Though useful, weak references are not often used in JavaScript. <code>WeakSet</code> and <code>WeakMap</code> were introduced to JavaScript in the ES6 version.</p>\nWeak Reference\n<p>To clarify, unlike strong reference, weak reference doesn’t prevent the referenced object from being reclaimed or collected by the garbage collector, even if it is the only reference to the object in memory.</p>\n<p>Before getting into strong reference, <code>WeakSet</code>, <code>Set</code>, <code>WeakMap</code>, and <code>Map</code>, let’s illustrate weak reference with the following snippet:</p>\n<pre><code>// Create an instance of the WeakMap object.\nlet human = new WeakMap():\n\n// Create an object, and assign it to a variable called man.\nlet man = { name: \"Joe Doe\" };\n\n// Call the set method on human, and pass two arguments (key and value) to it.\nhuman.set(man, \"done\")\n\nconsole.log(human)</code></pre>\n\n<p>The output of the code above would be the following:</p>\n<pre><code>WeakMap {{…} =&gt; 'done'}\n\nman = null;\nconsole.log(human)</code></pre>\n\n<p>The <code>man</code> argument is now set to the <code>WeakMap</code> object. At the point when we reassigned the <code>man</code> variable to <code>null</code>, the only reference to the original object in memory was the weak reference, and it came from the <code>WeakMap</code> that we created earlier. When the JavaScript engine runs a garbage-collection process, the <code>man</code> object will be removed from memory and from the <code>WeakMap</code> that we assigned it to. This is because it is a weak reference, and it doesn’t prevent garbage collection.</p>\n<p>It looks like we are making progress. Let’s talk about strong reference, and then we’ll tie everything together.</p>\nStrong Reference\n<p>A strong reference in JavaScript is a reference that prevents an object from being garbage-collected. It keeps the object in memory.</p>\n<p>The following code snippets illustrate the concept of strong reference:</p>\n<pre><code>let man = {name: \"Joe Doe\"};\n\nlet human = [man];\n\nman =  null;\nconsole.log(human);</code></pre>\n\n<p>The result of the code above would be this:</p>\n<pre><code>// An array of objects of length 1. \n[{…}]</code></pre>\n\n<p>The object cannot be accessed via the <code>dog</code> variable anymore due to the strong reference that exists between the <code>human</code> array and object. The object is retained in memory and can be accessed with the following code:</p>\n<pre><code>console.log(human[0])</code></pre>\n\n<p>The important point to note here is that a weak reference doesn’t prevent an object from being garbage-collected, whereas a strong reference does prevent an object from being garbage-collected.</p>\nGarbage Collection in JavaScript\n<p>As in every programming language, memory management is a key factor to consider when writing JavaScript. Unlike C, JavaScript is a high-level programming language that automatically allocates memory when objects are created and that clears memory automatically when the objects are no longer needed. The process of clearing memory when objects are no longer being used is referred to as garbage collection. It is almost impossible to talk about garbage collection in JavaScript without touching on the concept of reachability.</p>\n<h3>Reachability</h3>\n<p>All values that are within a specific scope or that are in use within a scope are said to be “reachable” within that scope and are referred to as “reachable values”. Reachable values are always stored in memory.</p>\n<p>Values are considered reachable if they are:</p>\n<ul>\n<li>values in the root of the program or referenced from the root, such as global variables or the currently executing function, its context, and callback;</li>\n<li>values accessible from the root by a reference or chain of references (for example, an object in the global variable referencing another object, which also references another object — these are all considered reachable values).</li>\n</ul>\n<p>The code snippets below illustrate the concept of reachability:</p>\n<pre><code>let languages = {name: “JavaScript”};</code></pre>\n\n<p>Here we have an object with a key-value pair (with the name <code>JavaScript</code>) referencing the global variable <code>languages</code>. If we overwrite the value of <code>languages</code> by assigning <code>null</code> to it…</p>\n<pre><code>languages = null;</code></pre>\n\n<p>… then the object will be garbage-collected, and the value <code>JavaScript</code> cannot be accessed again. Here is another example:</p>\n<pre><code>let languages = {name: “JavaScript”};\n\nlet programmer = languages;</code></pre>\n\n<p>From the code snippets above, we can access the object property from both the <code>languages</code> variable and the <code>programmer</code> variable. However, if we set <code>languages</code> to <code>null</code>…</p>\n<pre><code>languages = null;</code></pre>\n\n<p>… then the object will still be in memory because it can be accessed via the <code>programmer</code> variable. This is how garbage collection works in a nutshell.</p>\n<p><strong>Note:</strong> <em>By default, JavaScript uses strong reference for its references. To implement weak reference in JavaScript, you would use <code>WeakMap</code>, <code>WeakSet</code>, or <code>WeakRef</code>.</em></p>\nComparing Set and WeakSet\n<p>A set object is a collection of unique values with a single occurrence. A set, like an array, does not have a key-value pair. We can iterate through a set of arrays with the array methods <code>for… of</code> and <code>.forEach</code>.</p>\n<p>Let’s illustrate this with the following snippets:</p>\n<pre><code>let setArray = new Set([\"Joseph\", \"Frank\", \"John\", \"Davies\"]);\nfor (let names of setArray){\n  console.log(names)\n}// Joseph Frank John Davies\n</code></pre>\n\n<p>We can use the <code>.forEach</code> iterator as well:</p>\n<pre><code> setArray.forEach((name, nameAgain, setArray) =&gt;{\n   console.log(names);\n });</code></pre>\n\n<p>A <code>WeakSet</code> is a collection of unique objects. As the name applies, <code>WeakSet</code>s use weak reference. The following are properties of <code>WeakSet()</code>:</p>\n<ul>\n<li>It may only contain objects.</li>\n<li>Objects within the set can be reachable somewhere else.</li>\n<li>It cannot be looped through.</li>\n<li>Like <code>Set()</code>, <code>WeakSet()</code> has the methods <code>add</code>, <code>has</code>, and <code>delete</code>.</li>\n</ul>\n<p>The code below illustrates how to use <code>WeakSet()</code> and some of the methods available:</p>\n<pre><code>const human = new WeakSet();\n\nlet paul = {name: \"Paul\"};\nlet mary = {gender: \"Mary\"};\n\n// Add the human with the name paul to the classroom. \nconst classroom = human.add(paul);\n\nconsole.log(classroom.has(paul)); // true\n\npaul = null;\n\n// The classroom will be cleaned automatically of the human paul.\n\nconsole.log(classroom.has(paul)); // false</code></pre>\n\n<p>On line 1, we’ve created an instance of <code>WeakSet()</code>. On lines 3 and 4, we created objects and assigned them to their respective variables. On line 7, we added <code>paul</code> to the <code>WeakSet()</code> and assigned it to the <code>classroom</code> variable. On line 11, we made the <code>paul</code> reference <code>null</code>. The code on line 15 returns <code>false</code> because <code>WeakSet()</code> will be automatically cleaned; so, <code>WeakSet()</code> doesn’t prevent garbage collection.</p>\nComparing Map and WeakMap\n<p>As we know from the section on garbage collection above, the JavaScript engine keeps a value in memory as long as it is reachable. Let’s illustrate this with some snippets:</p>\n<pre><code>let smashing = {name: \"magazine\"};\n// The object can be accessed from the reference.\n\n// Overwrite the reference smashing.\nsmashing = null;\n// The object can no longer be accessed.</code></pre>\n\n<p>Properties of a data structure are considered reachable while the data structure is in memory, and they are usually kept in memory. If we store an object in an array, then as long as the array is in memory, the object can still be accessed even if it has no other references.</p>\n<pre><code>let smashing = {name: \"magazine\"};\n\nlet arr = [smashing];\n\n// Overwrite the reference.\nsmashing = null;\nconsole.log(array[0]) // {name: 'magazine'}</code></pre>\n\n<p>We’re still able to access this object even if the reference has been overwritten because the object was saved in the array; hence, it was saved in memory as long the array is still in memory. Therefore, it was not garbage-collected. As we’ve used an array in the example above, we can use <code>map</code> too. While the <code>map</code> still exists, the values stored in it won’t be garbage-collected.</p>\n<pre><code>let map = new Map();\n\nlet smashing {name: \"magazine\"};\n\nmap.set(smashing, \"blog\");\n\n// Overwrite the reference.\nsmashing = null;\n\n// To access the object.\nconsole.log(map.keys());</code></pre>\n\n<p>Like an object, <code>map</code>s can hold key-value pairs, and we can access the value through the key. But with <code>map</code>s, we must use the <code>.get()</code> method to access the values.</p>\n<p>According to Mozilla Developer Network, the <code>Map</code> object holds key-value pairs and remembers the original insertion order of the keys. Any value (both objects and <a href=\"https://developer.mozilla.org/en-US/docs/Glossary/Primitive\">primitive values</a>) may be used as either key or value.</p>\n<p>Unlike a <code>map</code>, <code>WeakMap</code> holds a weak reference; hence, it doesn’t prevent garbage collection from removing values that it references if those values are not strongly referenced elsewhere. Apart from this, <code>WeakMap</code> is the same as <code>map</code>. <code>WeakMap</code>s are not enumerable due to weak references.</p>\n<p>With <code>WeakMap</code>, the keys must be objects, and the values may be a number or a string.</p>\n<p>The snippets below illustrate how <code>WeakMap</code> works and the methods in it:</p>\n<pre><code>// Create a weakMap.\nlet weakMap = new WeakMap();\n\nlet weakMap2 = new WeakMap();\n\n// Create an object.\nlet ob = {};\n\n// Use the set method.\nweakMap.set(ob, \"Done\");\n\n// You can set the value to be an object or even a function.\nweakMap.set(ob, ob)\n\n// You can set the value to undefined.\nweakMap.set(ob, undefined);\n\n// WeakMap can also be the value and the key.\nweakMap.set(weakMap2, weakMap)\n\n// To get values, use the get method.\nweakMap.get(ob) // Done\n\n// Use the has method.\nweakMap.has(ob) // true\n\nweakMap.delete(ob)\n\nweakMap.has(ob) // false</code></pre>\n\n<p>One major side effect of using objects as keys in a <code>WeakMap</code> with no other references to it is that they will be automatically removed from memory during garbage collection.</p>\nAreas of Application of WeakMap\n<p><code>WeakMap</code> can be used in two areas of web development: caching and additional data storage.</p>\n<h3>Caching</h3>\n<p>This a <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching\">web technique that involves</a> saving (i.e. storing) a copy of a given resource and serving it back when requested. The result from a function can be cached so that whenever the function is called, the cached result can be reused.</p>\n<p>Let’s see this in action. Create a file, name it <code>cachedResult.js</code>, and write the following in it:</p>\n<div>\n<pre><code> let cachedResult = new WeakMap();\n // A function that stores a result.\nfunction keep(obj){\nif(!cachedResult.has(obj){\n  let result = obj;\n  cachedResult.set(obj, result);\n  }\nreturn cachedResult.get(obj);\n}\n\n\nlet obj = {name: \"Frank\"};\n\nlet resultSaved = keep(obj)\n\nobj = null;\n\n// console.log(cachedResult.size); Possible with map, not with WeakMap</code></pre>\n</div>\n\n<p>If we had used <code>Map()</code> instead of <code>WeakMap()</code> in the code above, and there were multiple invocations on the function <code>keep()</code>, then it would only calculate the result the first time it was called, and it would retrieve it from <code>cachedResult</code> the other times. The side effect is that we’ll need to clean <code>cachedResult</code> whenever the object is not needed. With <code>WeakMap()</code>, the cached result will be automatically removed from memory as soon as the object is garbage-collected. Caching is a great means of improving software performance — it could save the costs of database usage, third-party API calls, and server-to-server requests. With caching, a copy of the result from a request is saved locally.</p>\n<h3>Additional Data</h3>\n<p>Another important use of <code>WeakMap()</code> is additional data storage. Imagine we are building an e-commerce platform, and we have a program that counts visitors, and we want to be able to reduce the count when visitors leave. This task would be very demanding with Map, but quite easy to implement with <code>WeakMap()</code>:</p>\n<pre><code>let visitorCount = new WeakMap();\nfunction countCustomer(customer){\n   let count = visitorCount.get(customer) || 0;\n    visitorCount.set(customer, count + 1);\n}</code></pre>\n\n<p>Let’s create client code for this:</p>\n<pre><code>let person = {name: \"Frank\"};\n\n// Taking count of person visit.\ncountCustomer(person)\n\n// Person leaves.\nperson = null;</code></pre>\n\n<p>With <code>Map()</code>, we will have to clean <code>visitorCount</code> whenever a customer leaves; otherwise, it will grow in memory indefinitely, taking up space. But with <code>WeakMap()</code>, we do not need to clean <code>visitorCount</code>; as soon as a person (object) becomes unreachable, it will be garbage-collected automatically.</p>\nConclusion\n<p>In this article, we learned about weak reference, strong reference, and the concept of reachability, and we tried to connect them to memory management as best we could. I hope you found this article valuable. Feel free to drop a comment.</p>",
      "content_text": "Memory and performance management are important aspects of software development and ones that every software developer should pay attention to. Though useful, weak references are not often used in JavaScript. WeakSet and WeakMap were introduced to JavaScript in the ES6 version.\nWeak Reference\nTo clarify, unlike strong reference, weak reference doesn’t prevent the referenced object from being reclaimed or collected by the garbage collector, even if it is the only reference to the object in memory.\nBefore getting into strong reference, WeakSet, Set, WeakMap, and Map, let’s illustrate weak reference with the following snippet:\n// Create an instance of the WeakMap object.\nlet human = new WeakMap():\n\n// Create an object, and assign it to a variable called man.\nlet man = { name: \"Joe Doe\" };\n\n// Call the set method on human, and pass two arguments (key and value) to it.\nhuman.set(man, \"done\")\n\nconsole.log(human)\n\nThe output of the code above would be the following:\nWeakMap {{…} => 'done'}\n\nman = null;\nconsole.log(human)\n\nThe man argument is now set to the WeakMap object. At the point when we reassigned the man variable to null, the only reference to the original object in memory was the weak reference, and it came from the WeakMap that we created earlier. When the JavaScript engine runs a garbage-collection process, the man object will be removed from memory and from the WeakMap that we assigned it to. This is because it is a weak reference, and it doesn’t prevent garbage collection.\nIt looks like we are making progress. Let’s talk about strong reference, and then we’ll tie everything together.\nStrong Reference\nA strong reference in JavaScript is a reference that prevents an object from being garbage-collected. It keeps the object in memory.\nThe following code snippets illustrate the concept of strong reference:\nlet man = {name: \"Joe Doe\"};\n\nlet human = [man];\n\nman =  null;\nconsole.log(human);\n\nThe result of the code above would be this:\n// An array of objects of length 1. \n[{…}]\n\nThe object cannot be accessed via the dog variable anymore due to the strong reference that exists between the human array and object. The object is retained in memory and can be accessed with the following code:\nconsole.log(human[0])\n\nThe important point to note here is that a weak reference doesn’t prevent an object from being garbage-collected, whereas a strong reference does prevent an object from being garbage-collected.\nGarbage Collection in JavaScript\nAs in every programming language, memory management is a key factor to consider when writing JavaScript. Unlike C, JavaScript is a high-level programming language that automatically allocates memory when objects are created and that clears memory automatically when the objects are no longer needed. The process of clearing memory when objects are no longer being used is referred to as garbage collection. It is almost impossible to talk about garbage collection in JavaScript without touching on the concept of reachability.\nReachability\nAll values that are within a specific scope or that are in use within a scope are said to be “reachable” within that scope and are referred to as “reachable values”. Reachable values are always stored in memory.\nValues are considered reachable if they are:\n\nvalues in the root of the program or referenced from the root, such as global variables or the currently executing function, its context, and callback;\nvalues accessible from the root by a reference or chain of references (for example, an object in the global variable referencing another object, which also references another object — these are all considered reachable values).\n\nThe code snippets below illustrate the concept of reachability:\nlet languages = {name: “JavaScript”};\n\nHere we have an object with a key-value pair (with the name JavaScript) referencing the global variable languages. If we overwrite the value of languages by assigning null to it…\nlanguages = null;\n\n… then the object will be garbage-collected, and the value JavaScript cannot be accessed again. Here is another example:\nlet languages = {name: “JavaScript”};\n\nlet programmer = languages;\n\nFrom the code snippets above, we can access the object property from both the languages variable and the programmer variable. However, if we set languages to null…\nlanguages = null;\n\n… then the object will still be in memory because it can be accessed via the programmer variable. This is how garbage collection works in a nutshell.\nNote: By default, JavaScript uses strong reference for its references. To implement weak reference in JavaScript, you would use WeakMap, WeakSet, or WeakRef.\nComparing Set and WeakSet\nA set object is a collection of unique values with a single occurrence. A set, like an array, does not have a key-value pair. We can iterate through a set of arrays with the array methods for… of and .forEach.\nLet’s illustrate this with the following snippets:\nlet setArray = new Set([\"Joseph\", \"Frank\", \"John\", \"Davies\"]);\nfor (let names of setArray){\n  console.log(names)\n}// Joseph Frank John Davies\n\n\nWe can use the .forEach iterator as well:\n setArray.forEach((name, nameAgain, setArray) =>{\n   console.log(names);\n });\n\nA WeakSet is a collection of unique objects. As the name applies, WeakSets use weak reference. The following are properties of WeakSet():\n\nIt may only contain objects.\nObjects within the set can be reachable somewhere else.\nIt cannot be looped through.\nLike Set(), WeakSet() has the methods add, has, and delete.\n\nThe code below illustrates how to use WeakSet() and some of the methods available:\nconst human = new WeakSet();\n\nlet paul = {name: \"Paul\"};\nlet mary = {gender: \"Mary\"};\n\n// Add the human with the name paul to the classroom. \nconst classroom = human.add(paul);\n\nconsole.log(classroom.has(paul)); // true\n\npaul = null;\n\n// The classroom will be cleaned automatically of the human paul.\n\nconsole.log(classroom.has(paul)); // false\n\nOn line 1, we’ve created an instance of WeakSet(). On lines 3 and 4, we created objects and assigned them to their respective variables. On line 7, we added paul to the WeakSet() and assigned it to the classroom variable. On line 11, we made the paul reference null. The code on line 15 returns false because WeakSet() will be automatically cleaned; so, WeakSet() doesn’t prevent garbage collection.\nComparing Map and WeakMap\nAs we know from the section on garbage collection above, the JavaScript engine keeps a value in memory as long as it is reachable. Let’s illustrate this with some snippets:\nlet smashing = {name: \"magazine\"};\n// The object can be accessed from the reference.\n\n// Overwrite the reference smashing.\nsmashing = null;\n// The object can no longer be accessed.\n\nProperties of a data structure are considered reachable while the data structure is in memory, and they are usually kept in memory. If we store an object in an array, then as long as the array is in memory, the object can still be accessed even if it has no other references.\nlet smashing = {name: \"magazine\"};\n\nlet arr = [smashing];\n\n// Overwrite the reference.\nsmashing = null;\nconsole.log(array[0]) // {name: 'magazine'}\n\nWe’re still able to access this object even if the reference has been overwritten because the object was saved in the array; hence, it was saved in memory as long the array is still in memory. Therefore, it was not garbage-collected. As we’ve used an array in the example above, we can use map too. While the map still exists, the values stored in it won’t be garbage-collected.\nlet map = new Map();\n\nlet smashing {name: \"magazine\"};\n\nmap.set(smashing, \"blog\");\n\n// Overwrite the reference.\nsmashing = null;\n\n// To access the object.\nconsole.log(map.keys());\n\nLike an object, maps can hold key-value pairs, and we can access the value through the key. But with maps, we must use the .get() method to access the values.\nAccording to Mozilla Developer Network, the Map object holds key-value pairs and remembers the original insertion order of the keys. Any value (both objects and primitive values) may be used as either key or value.\nUnlike a map, WeakMap holds a weak reference; hence, it doesn’t prevent garbage collection from removing values that it references if those values are not strongly referenced elsewhere. Apart from this, WeakMap is the same as map. WeakMaps are not enumerable due to weak references.\nWith WeakMap, the keys must be objects, and the values may be a number or a string.\nThe snippets below illustrate how WeakMap works and the methods in it:\n// Create a weakMap.\nlet weakMap = new WeakMap();\n\nlet weakMap2 = new WeakMap();\n\n// Create an object.\nlet ob = {};\n\n// Use the set method.\nweakMap.set(ob, \"Done\");\n\n// You can set the value to be an object or even a function.\nweakMap.set(ob, ob)\n\n// You can set the value to undefined.\nweakMap.set(ob, undefined);\n\n// WeakMap can also be the value and the key.\nweakMap.set(weakMap2, weakMap)\n\n// To get values, use the get method.\nweakMap.get(ob) // Done\n\n// Use the has method.\nweakMap.has(ob) // true\n\nweakMap.delete(ob)\n\nweakMap.has(ob) // false\n\nOne major side effect of using objects as keys in a WeakMap with no other references to it is that they will be automatically removed from memory during garbage collection.\nAreas of Application of WeakMap\nWeakMap can be used in two areas of web development: caching and additional data storage.\nCaching\nThis a web technique that involves saving (i.e. storing) a copy of a given resource and serving it back when requested. The result from a function can be cached so that whenever the function is called, the cached result can be reused.\nLet’s see this in action. Create a file, name it cachedResult.js, and write the following in it:\n\n let cachedResult = new WeakMap();\n // A function that stores a result.\nfunction keep(obj){\nif(!cachedResult.has(obj){\n  let result = obj;\n  cachedResult.set(obj, result);\n  }\nreturn cachedResult.get(obj);\n}\n\n\nlet obj = {name: \"Frank\"};\n\nlet resultSaved = keep(obj)\n\nobj = null;\n\n// console.log(cachedResult.size); Possible with map, not with WeakMap\n\n\nIf we had used Map() instead of WeakMap() in the code above, and there were multiple invocations on the function keep(), then it would only calculate the result the first time it was called, and it would retrieve it from cachedResult the other times. The side effect is that we’ll need to clean cachedResult whenever the object is not needed. With WeakMap(), the cached result will be automatically removed from memory as soon as the object is garbage-collected. Caching is a great means of improving software performance — it could save the costs of database usage, third-party API calls, and server-to-server requests. With caching, a copy of the result from a request is saved locally.\nAdditional Data\nAnother important use of WeakMap() is additional data storage. Imagine we are building an e-commerce platform, and we have a program that counts visitors, and we want to be able to reduce the count when visitors leave. This task would be very demanding with Map, but quite easy to implement with WeakMap():\nlet visitorCount = new WeakMap();\nfunction countCustomer(customer){\n   let count = visitorCount.get(customer) || 0;\n    visitorCount.set(customer, count + 1);\n}\n\nLet’s create client code for this:\nlet person = {name: \"Frank\"};\n\n// Taking count of person visit.\ncountCustomer(person)\n\n// Person leaves.\nperson = null;\n\nWith Map(), we will have to clean visitorCount whenever a customer leaves; otherwise, it will grow in memory indefinitely, taking up space. But with WeakMap(), we do not need to clean visitorCount; as soon as a person (object) becomes unreachable, it will be garbage-collected automatically.\nConclusion\nIn this article, we learned about weak reference, strong reference, and the concept of reachability, and we tried to connect them to memory management as best we could. I hope you found this article valuable. Feel free to drop a comment.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/44544ece-23b3-48cb-b2bf-0183a32d2bee/understanding-weak-reference-javascript.jpg",
      "date_published": "2022-05-25T09:30:00.000Z",
      "date_modified": "2022-05-25T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/developing-award-winning-onboarding-process-case-study/",
      "url": "https://smashingmagazine.com/2022/05/developing-award-winning-onboarding-process-case-study/",
      "title": "Developing An Award-Winning Onboarding Process (Case Study)",
      "summary": "This article is a case study of how the platformOS team has researched, developed, and iteratively adjusted their onboarding processes over more than three years to eventually create the multiple award winning developer experience they provide today.",
      "content_html": "<p>The notion of onboarding is all about helping users quickly and easily find value in your offering. Speed and ease of use are equally important because users might lose interest if going through an onboarding takes more time or is more complicated than what they expected. Speed and ease of use are also relative to a person’s point of view: a salesperson can have vastly different expectations for an onboarding than a developer. </p>\n<p>A well-constructed onboarding process boosts engagement, improves product adoption, increases conversion rates, and educates users about a product. Optimizing the onboarding experience is a journey. You should have a plan but be agile, utilizing processes and tools to garner feedback from target users in a bid to constantly improve. </p>\n<p>In this article, we will walk you through how we developed the onboarding processes for platformOS from the very beginning. You will be able to follow how we carried out user experience research, how our onboarding has changed over time, what assumptions we made, and how we adjusted them. We will talk about all the tools we used as examples, but the same processes can be implemented with a wide variety of other tools. You will get practical examples and a complete overview of how we built our onboarding, with insights into UX research and the specifics of working with different audience segments. </p>\n<p>Our audience has always combined technical people with various levels of programming skills, and non-technical people who come to our docs to evaluate if platformOS would be a good fit for their projects like Project Owners, Business Analysts, and Project Managers. Because our main target audience is divided into different segments, you will also get a glimpse of the processes we developed for our documentation, developer education, and developer relations. </p>\nChallenge: Onboarding For Different Target Audiences\n<p><a href=\"https://www.platformos.com/\">platformOS</a> is a model-based application development platform aimed at front-end developers and site builders automating infrastructure provisioning and <a href=\"https://aws.amazon.com/devops/what-is-devops/\">DevOps</a>. </p>\n<blockquote> DevOps is a combination of development methodologies, practices, and tools that enable teams to evolve and improve products at a faster pace to better serve their customers and compete more effectively in the market. Under a DevOps model, development and operations teams are merged into a single team where the engineers work across the entire application lifecycle, from development and test to deployment to operations.</blockquote>\n\n<p>Our main target audience is developers, and the foundation for their onboarding, education, and support is our <a href=\"https://documentation.platformos.com/\">developer portal</a> — but our onboarding has to cater to other target audience segments as well. </p>\n<h3>Defining Our Target Audience Segments</h3>\n<p>We defined our target audience during the discovery phase of the Design Thinking process that we used to plan our developer portal. Since then, we have frequently revalidated the results to see if we are on the right track because we want to be sure that we understand the people who will be using our product, and what motivates them. We also know that in the lifecycle of a product this audience can change as a result of product positioning, and how well we can address their needs. </p>\n<p>Our target audience currently has four segments:</p>\n<ul>\n<li>Experienced developers,</li>\n<li>Junior developers,</li>\n<li>Agency Owner, Sales/Marketing,</li>\n<li>PM, Business Analyst.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/65904c10-2eb9-4962-83be-795bfed65ce9/6-developing-award-winning-onboarding-process-case-study.png\" /></p>\n<h3>User Base Shifts</h3>\n<p>We created the first target audience map when we started planning our developer portal. In the discovery phase, we mapped out four proto-personas that covered the following segments: Experienced Developers, Junior Developers, Site Builders, and Marketplace Owners.</p>\n<p>We revalidated these results a year later, and we realized that our audience had shifted a bit. </p>\n<ul>\n<li>The Experienced Developers and the Junior Developers stayed as the main target audiences. However, we collected new knowledge related to the needs of the junior devs. They needed more detail to be able to understand and start working with the product. This new information helped us specify their user journey.</li>\n<li>At this point, the Site Builders were the smallest group. We identified we needed to address the needs of the developers group first, creating a strong foundation to support site builders in the platform.</li>\n<li>The non-technical segment shifted on the way. The Marketplace Owners segment was divided into two separate audiences: the Agency Owners, who have a sales and marketing background, and the Business Analysts, who have an enterprise background in business management or transformation — a new audience who started to show interest in our product.</li>\n</ul>\n<p>Along the way, we were able to specify the needs of these audiences in more detail. These details helped with the prioritization of the onboarding tasks and kept our focus on the needs of the audience. </p>\n<h3>Defining Entry Points For Target Audience Segments</h3>\n<p>Getting to know the needs of the target audience segments provided guidance for identifying the entry points to the product.</p>\n<ul>\n<li>The <strong>Agency Owners’</strong> key goal is to work on multiple web projects that they host and manage on the platform. They won’t work on the platform themselves, but they would like to know the status and the progress of the platform without worrying about DevOps. They need to see the business perspective, the security, and that they are part of a reliable ecosystem with a helpful community around without diving deep into the technical part of the product.</li>\n<li>The <strong>Business Analysts’</strong> goal is to identify solution providers for their specific business problems. They need to find a long-term solution that fits with their use case, is scalable, and gives them the possibility for easy evaluation that shows the key business values in action.</li>\n<li>The <strong>Junior Developers’</strong> goal is to learn the basics without much hassle, under the guidance of experienced community members. They need clear technical communication on how to set up a dev environment and how to troubleshoot common errors.</li>\n<li>The <strong>Experienced Developers’</strong> goal is to find a solution that is reliable and flexible enough for all their project needs and at the same time provides good performance. They need to be able to evaluate quickly if it’s a good fit, then see how their project could work on the platform. They also need to see that the platform has a future with a solid community behind it.</li>\n</ul>\n<p>All segments needed an actionable onboarding where they can interact with the product (and engage with the community) based on their level of technical knowledge. </p>\n<ul>\n<li>In the <strong>non-technical</strong> journey, users can go from the <strong>1-click route</strong> that takes them through registering on the Partner Portal to creating a demo site and installing the blog module by clicking through a setup wizard.</li>\n<li>In the <strong>semi-technical</strong> journey, users can create a <strong>sandbox</strong> in which they can experiment by cloning a demo site from our GitHub repository, and they also have the option to go through our “Hello, World!” guide.</li>\n<li>In the <strong>technical</strong> journey, users can follow a more complex tutorial that walks them through the steps of <strong>creating an app</strong> on platformOS from setting up their development environment to deploying and testing their finished app. It explains basic concepts, the main building blocks, and the logic behind platformOS, while also giving some recommendations on the workflow.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/090f3fca-3619-46c5-87b9-1b81d9fc2c6a/onboarding-pathways.png\" /></p>\nHow We Approached The Challenge: Methods And Tools\n<p>We followed various methods to tackle different aspects of the main challenge. We selected a Design process to follow, used many different user research methods to collect insights and feedback from our users, chose a framework for our editorial workflow and technical implementation that could work well for our Agile, iterative process and our target audience, and went with an approach for content production that allowed community members to contribute early on. </p>\n<h3>Design Thinking</h3>\n<p>Because of the strategic role our developer portal plays in the adoption and use of our product, we wanted to use a creative design process that solves traditional business problems with an open mindset.</p>\n<p>Our goal was to:</p>\n<ul>\n<li>help our community to be able to use our documentation site for their needs as early as possible;</li>\n<li>measure user needs and iterate the product based on the feedback;</li>\n<li>keep the long-term user and business goals in mind and take a step closer with each iteration.</li>\n</ul>\n<p>We found the <strong>Design Thinking framework</strong> a perfect fit because it is a user-centric approach that focuses on problem-solving while fostering innovation. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/63b1e78f-4c28-4427-b45f-44170c458d5e/design-thinking.png\" /></p>\n<p>We followed the stages of the design thinking process:</p>\n<ul>\n<li><strong>Empathize</strong><br />In the beginning, we explored our audience, our documentation needs, and existing and missing content through in-depth interviews and workshops. </li>\n<li><strong>Define</strong><br />Then, we defined personas and our Content Inventory.</li>\n<li><strong>Ideate</strong><br />We shared our ideas for content and features through a Card Sorting exercise.</li>\n<li><strong>Prototype</strong><br />Based on our findings, we created a sitemap and prioritized content needs, and created layouts and wireframes. Content production started based on the results of our discovery phase.</li>\n<li><strong>Test</strong><br />We followed an iterative, Docs as Code approach: at each stage, we work with quick feedback rounds, deploy often, and improve features and content based on feedback from real users.</li>\n</ul>\n<h3>User Research</h3>\n<p>In the life of a product, each development stage has a fitting UX research method that we can use, depending on the business plans, time constraints, stage of product/feature, and the current concerns.</p>\n<p>In the last three years we used the following methods:</p>\n<ul>\n<li><strong>Interviews</strong><br />We met with users, sales, and support persons to discuss in-depth what the participant experienced about various topics.</li>\n<li><strong>Remote Usability Testing</strong><br />We asked potential or current users of the product to complete a set of tasks during this process, and we observed their behavior to define the usability of the product. We used two types of remote usability testing:<ul>\n<li><strong>Moderated:</strong> We conducted the research remotely via screen-sharing software, and the participants joined in from their usual work environment. This approach is advantageous when analyzing complex tasks — where real-time interaction and questioning with participants are essential.</li>\n<li><strong>Unmoderated:</strong> We sent tasks for users to complete in their own time. As moderators are not present, we measured less complex tasks and focused on the overall level of satisfaction they experienced when interfacing with the product.</li>\n</ul>\n</li>\n<li><strong>Card Sorting</strong><br />A quantitative or qualitative method, where we ask users to organize items into groups and assign categories to each group. This process makes it possible to reflect the users’ mental model on the architecture. </li>\n<li><strong>Tree tests</strong><br />We used tree tests to validate the logic of the used information architecture. We gave users a task to find certain elements in the navigation structure and asked them to talk about where they would go next to accomplish the task.</li>\n<li><strong>Surveys, Questionnaires</strong><br />We used questionnaires and surveys to gather a large amount of information about a topic. This quantitative data can help us have a better understanding of specific topics that we can further research to understand what motivates users.</li>\n<li><strong>Analytics review</strong><br />We used site analytics to gather quantitative data about usage patterns and identify possible flow breaks. Based on the data we either fixed the problem or if needed, we further tested with usability research.</li>\n</ul>\n<h3>Docs As Code And CI/CD</h3>\n<p>We engaged our users in an Agile and iterative process right from the beginning discovery phase. This ensured that we were able to test and validate all of our assumptions, and quickly make modifications if needed. As our internal team members and our community participants are distributed, we needed a workflow that made it possible to collaborate on changes, large or small, remotely. Consequently, we needed a robust approach to version control accommodating authors, reviewers, and editors all working on content concurrently. As we wanted to encourage developers to contribute, we needed a framework that they’re familiar with. We also wanted to make our documentation open-source, so that anyone could duplicate and reuse it for their own projects. Based on these requirements, we decided to follow the Docs as Code approach. </p>\n<p>Documentation as Code or Docs as Code refers to a philosophy of writing documentation with the same tools as software coding. This means following the same workflows as development teams, including being integrated into the product team. It enables a culture where writers and developers both feel they have ownership of the documentation and work together to aim for the best possible outcome. In our case, we didn’t only have writers and developers working on our onboarding but also UX researchers, account and project managers, and of course, a range of users in varying roles.  </p>\n<p>Our documentation is in a separate repository on GitHub. We have a central branch, and we work locally in a dedicated branch, then we send pull requests for review to be merged into the main branch. To preview docs, we use our own staging site which is an exact copy of the live documentation site. </p>\n<p>Once we accept changes, we take steps to push them live almost immediately. To maintain the integrity of the site during this process, we follow the practice of <strong>continuous integration and continuous deployment (CI/CD)</strong>. We run test scripts automatically and deploy the codebase to staging. If a test fails, an error report is generated. Alternatively, if everything goes well, our CI/CD of choice — GitHub Actions — deploys the codebase to production and sends us a notification. We release updates continuously, at times merging multiple changes in a single day, at other times only once or twice a week. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/983f6b64-62fc-41f4-bdb8-d87e94672818/4-developing-award-winning-onboarding-process-case-study.png\" /></p>\n<h3>Editorial Workflow</h3>\n<p>Docs as Code provides the foundation for our processes, but for the various users to work efficiently together, we needed to define a clear editorial workflow that worked for all participants (internal and external writer, developer, contributor, and so on) and for all stages of the process (writing, reviewing, editing); but that was also simple enough to involve new contributors. Following Docs as Code, each stage of our workflow is in git, including project management (contributors can also add tickets to report issues or requests). </p>\n<p>These are the steps of our editorial workflow:</p>\n<ol>\n<li><strong>Write</strong> new content in Markdown using the templates. You can use any editor that can produce Github Flavored Markdown. </li>\n<li><strong>Submit</strong> the new topic as a pull request on GitHub. </li>\n<li><strong>Review.</strong> We have a peer-review system in place for code and docs alike. Topics are reviewed by both technical reviewers (developers) and writers. </li>\n<li><strong>Edit</strong> as needed. Repeat steps 3-4 until approved. </li>\n<li><strong>Merge</strong> approved pull request. </li>\n<li><strong>Deploy</strong> to staging, then to production.</li>\n</ol>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c5bb9026-f352-41f1-a970-eedbbaaff6e1/editorial-workflow.png\" /></p>\n<p>Our editorial workflow ensures that contribution works the same way for everyone, and we support our contributors with guidelines and ready-to-use templates. </p>\n<h3>Content Production And Contribution</h3>\n<p>When we started developing our onboarding and documentation, we followed the <a href=\"https://balsamiq.com/learn/articles/content-first-design/\">Content First</a> approach. We planned to develop some initial content that we could work with, but even before that, we decided what types of content we would need and outlined the structure of each content type. These outlines became templates that ensure consistency and encourage contribution. </p>\n<p>We were inspired by topic-based authoring and <a href=\"https://en.wikipedia.org/wiki/Darwin_Information_Typing_Architecture\">DITA</a>, in the sense that we decided to have three main content types for our documentation, tutorials that describe how to accomplish a task, concepts that provide background information and context, and references like our API Reference. Our onboarding consists of tutorials that link to concepts and references when needed. </p>\n<blockquote> DITA, short for Darwin Information Typing Architecture, is an XML standard, an architectural approach, and a topic-based writing methodology where content is authored in topics rather than in larger documents or publications. A DITA topic must make sense in its own right.</blockquote>\n\n<p>Involving our users from the beginning ensured that we could test and validate all of our assumptions, and quickly modify anything if needed. This proved to be a time and cost-efficient approach: although we edit and rewrite our content, and change things on our documentation site all the time, we don’t run the risk of creating large chunks of work that have to be thrown away because they don’t correspond to the needs of our users.</p>\n<p>Constant collaboration also builds trust: as our process is completely transparent, our community continuously knows what we’re working on and how our docs evolve, and community members can be sure that their opinions are heard and acted upon. </p>\n<p>Involving the community from an early stage means that our users saw lots of stuff that was partially done, missing, or ended up totally rewritten. So, for all of this to work, our users had to be mature enough to give feedback on half-done content, and we had to be level-headed enough to utilize sometimes passionate criticism. </p>\n<h4>Encouraging Contribution</h4>\n<p>We wanted to make it very easy to get involved for all segments of our target audience, so we offer several ways to contribute, taking into consideration the time contributors have available, and their skill level. We describe ways for our community members to get involved in our <a href=\"https://documentation.platformos.com/community/contributor-guide\">Contributor Guide</a>. For some quick editing, like fixing typos or adding links, contributors can edit the content easily on the GitHub UI. For heavy editing, adding new content, or for developers who prefer to use git, we provide a complete Docs as Code workflow. This approach proved to be extremely valuable for our onboarding. We got direct feedback on where users struggled with a step or had too little or too much information, and we could immediately make adjustments and verify that we have fixed the issue. </p>\n<p>To help contributors write larger chunks of text or complete topics, we provide guidelines and templates to start from:</p>\n<ul>\n<li><a href=\"https://documentation.platformos.com/community/documentation-style-guide\">Style Guide</a><br />Our style guide contains guidelines for writing technical content (e.g. language, tone, etc.) and each content type in our documentation (e.g. tutorials, concept topics, etc.).</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/17aa994c-fa36-427e-9063-939c81a66fca/8-developing-award-winning-onboarding-process-case-study.png\" /></p>\n<ul>\n<li><a href=\"https://github.com/mdyd-dev/platformos-documentation/tree/master/app/views/pages/doc-templates\">Templates</a><br />Our site uses Liquid pages, but to make editing easier for contributors, we write documentation content in Markdown and use a Markdown converter to turn it into Liquid. Our templates include all non-changeable content and placeholders with explanations for the parts that are editable. Placeholders provide information on the recommended format (e.g. title) and any requirements or limitations (e.g. maximum number of characters). </li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2f1e74a3-c379-4303-a430-47d98fbe5fa0/9-developing-award-winning-onboarding-process-case-study.png\" /></p>\n<p>We thank all of our contributors by giving recognition to them on our <a href=\"https://documentation.platformos.com/community/contributors\">Contributors page</a> as well as on <a href=\"https://github.com/mdyd-dev/platformos-documentation#contributors\">our GitHub repository’s README page</a>.</p>\n<h4>Communication</h4>\n<p>Our team and community members are scattered across different time zones. Similarly to how we communicate among team members, we use mostly asynchronous and sometimes real-time communication tools to communicate with our community. We even leverage real-time communication tools, like a video conference, to become somewhat asynchronous. For example, video conferences and webinars are recorded, and community members can discuss them on various channels.</p>\n<ul>\n<li><a href=\"https://community.platformos.com/\"><strong>pOS Community site</strong></a><br />One of our main communication channels is our community site, where you can ask, answer, upvote, and downvote questions, and get to know other members of the platformOS Community. More features coming soon!</li>\n<li><strong>Slack support</strong><br />One of our main communication channels is dedicated Slack channels, where community members ask questions, share ideas, and get to know our team members and each other. Based on their feedback, community members have confirmed how helpful it is to be able to communicate directly with us and each other: they can share what they’ve learned, plan their module development in sync with our roadmap and each other’s projects, and allocate their resources according to what’s going on in the business and the wider community. This communication seeds the documentation site with the most sought-after topics.</li>\n<li><strong>Video conference</strong><br />We regularly have video conferences over Zoom called Town Halls, where community members and the platformOS team share news, demo features, and modules and have the opportunity to engage in real-time, face-to-face conversation. Our team and community members are distributed over different continents, so we try to accommodate participants in different time zones by rotating the time of this event so that everyone has the chance to participate. We also share the recording of each session. </li>\n<li><a href=\"https://documentation.platformos.com/community/user-research/user-research-platformos\"><strong>User experience research</strong></a><br />Besides getting constant feedback from the community through the channels described above, we plan regular checkpoints in our process to facilitate testing and course correction. During development, we tie these checkpoints to development phases. At the end of each larger release, we conduct user interviews and compile and share a short survey for community members to fill out. This helps us clarify the roadmap for the next development phase.</li>\n</ul>\n<p>We make sure to keep community members informed about what’s happening through different channels: </p>\n<ul>\n<li><strong>Status reports</strong><br />We regularly share status reports on our blog to keep our community updated on what we’ve achieved, what we are working on, and what we are planning for the near future. Our status reports also include calls for contribution and research participation and the results and analysis of UX research. Subscribers can also choose to receive the status reports via email newsletter.</li>\n<li><a href=\"https://documentation.platformos.com/release-notes\"><strong>Release notes</strong></a><br />We share updates regarding new features, improvements, and fixes in our release notes.</li>\n<li><a href=\"https://www.platformos.com/blog\"><strong>Blog</strong></a><br />We regularly share articles about best practices and general news on our blog.</li>\n</ul>\n<h3>Accessibility And Inclusiveness</h3>\n<p>We address accessibility right from the design phase, where we use <a href=\"https://www.figma.com/community/plugin/734693888346260052/Able-–-Friction-free-accessibility\">Figma’s Able accessibility plugin</a>. We regularly test for accessibility with various tools and ensure that the site complies with all accessibility requirements. </p>\n<p>From a technical writing perspective, we support Accessibility and Usability by providing well-structured, clear, concise, and easy-to-understand copy. All of our documentation topics follow a predefined structure (predefined headings, steps, sections, link collections, and so on) applicable to that topic type (tasks, concepts, references), inspired by the principles of topic-based authoring. </p>\n<p>Semantic HTML is important for Accessibility, and we make sure not to style text any other way than through Markdown which is then translated into HTML. This way, screen readers can properly navigate through the content, and it also helps overall consistency when, for example, we want to do a design update.</p>\n<p>We also review all content to ensure accessible and inclusive language as specified in our style guide. </p>\nHow We Developed Our Onboarding: Rounds And Lessons Learned\n<h3>Developing Our Onboarding Using Continuous Iteration Rounds</h3>\n<p>At the beginning of the project, we started with a focused effort around discovery to identify the main business goals and user needs. As a result of this research, we were able to articulate the <strong>big picture</strong>. After we had all the user journeys and a sitemap for the big picture plan, we were able to break it down to <strong>identify the first iteration</strong> that would become the first working MVP version of the site.  </p>\n<p>Moving forward, we continue to follow an <strong>iterative approach,</strong> moving fast with an agile mindset. Steps: gather user feedback, identify areas of improvement and possible new directions, define the solution based on resources, business goals, and user needs, and implement it. This circle repeats indefinitely. So, we have an overarching plan outlined for our documentation that we keep in mind, but we always focus on the next couple of action steps we’d like to take.</p>\n<p>We can highlight five distinctive rounds that had a great impact on the development of our developer portal.</p>\n<ol>\n<li>For our onboarding process, we started with exploring the requirements following the Design Thinking approach. Through a Card Sorting session, we explored the areas of interest for each target audience and that helped us define the topics that concern them the most. This worked as a persona-based content prioritization for the documentation site.</li>\n<li>We wanted to guide our users with actionable items that they can try out on our site as a next step. At this point, we were already aware that our target audience shifted. The interviews and the support feedback helped us understand their needs that pointed in two main directions. We needed an easy journey for non-technicals and another one for technicals who like to understand the logic of the platform. In this stage, we planned, tested, and developed the first version of the <em>1-click journey</em> and the <em>sandbox</em>.</li>\n<li>We already had experienced platform users who we wanted to see in action. Using remote field studies, we discovered how they use the tools, the documentation site, and the partner portal we provide. At the same time, we started to conduct continuous onboarding interviews with partners who joined the platform. The two research directions helped us to realize how users with a varying degrees of experience interpret the platform.</li>\n<li>By this point, our content grew a lot on the developer portal, and we wanted to discover if we needed a structural and content reorganization based on the user research. </li>\n<li>In this latest round, we wanted to dedicate some time to fine-tuning and adjustments, and to double down on the developer portal’s accessibility and inclusiveness.</li>\n</ol>\n<h3>Round 1: Identifying The Target Audience Segments, Defining Proto-Personas, Base Discovery</h3>\n<p>With the Design Thinking workshops, we first focused on understanding our users. Based on the user research results, we defined the proto-personas and created a detailed description of each to show their needs and expectations and help us identify who we were designing for. It provided a good foundation for guiding the ideation process and prioritizing features based on how well they address the needs of one or more personas.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6f9cd72b-c6fd-45cf-9d05-fef6fe3ec4e5/7-developing-award-winning-onboarding-process-case-study.png\" /></p>\n<p>On our documentation site, we are working with a large amount of data that we need to present clearly to all users. To define a Content Inventory:</p>\n<ul>\n<li>we created a list of our proto-personas’ needs based on the problems they needed to solve with the platform;</li>\n<li>we created a detailed list of content from our previous documentation site and identified missing, reusable, and non-reusable content for our future site;</li>\n<li>we analyzed the competitor sites to create a list of inspirations.</li>\n</ul>\n<p>We ideated with the workshop participant using a Card Sorting exercise. The task was to map out the Content Inventory elements and define connections between them. The result showed us the connected areas and the proto-persona’s preference through color coding.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0e92ccc4-1314-4136-a7ea-94124086fbe1/3-developing-award-winning-onboarding-process-case-study.png\" /></p>\n<p>Based on the Content Inventory and the results of the Card Sorting sessions, we outlined the Information Architecture by creating a sitemap and the navigation for our future site. This plan included all the needs that were discovered and offered a roadmap to keep track of site improvements, content needs, and project phases. </p>\n<p>During the Card Sorting sessions, we explored areas of interest for each user persona and, on the sitemaps, we highlighted these as user journeys. We also validated the importance of these areas to assign higher priorities to the ones that need more attention. This process kept our focus on the most important needs of the personas. </p>\n<p>The most important sections for the four segments:</p>\n<ul>\n<li><strong>Experienced Developers:</strong> Quickstart guide, How to guide, API docs;</li>\n<li><strong>Junior Developers:</strong> Quickstart guide, Tutorials, Conceptual documentation;</li>\n<li><strong>Site Builders:</strong> Quickstart guide, Tutorials, FAQ, Forum;</li>\n<li><strong>Marketplace Owners:</strong> About platformOS, Blog.</li>\n</ul>\n<p>This concluded our Information Architecture phase. We have discovered and organized all the information we needed to continue to the next phase, where we started creating templates for content types, building the wireframes for each page, producing content, and making Design decisions.</p>\n<h3>Round 2: Onboarding Strategy And Testing Of The Onboarding Process</h3>\n<h4>Strategy</h4>\n<p>Before we jumped into planning an onboarding strategy, we did a revalidation on proto-personas. At that point, we discovered that our audience shifted to Experienced developers, Junior developers, Agency Owner, Sales/Marketing, PM and Business Analyst, and we realized that we needed to cover a broader spectrum of needs than previously identified.</p>\n<p>We interviewed 20 platformOS users. We identified how long they have been using the system, how they use the platform, what the key ‘aha’ moments were, what struggles they faced, and how they solved them. Their needs pointed in two main directions: we needed an easy journey for non-technicals and another one for technicals, covering those with less experience as well as those more capable developers who wished to understand the deeper logic and nuances of platformOS.</p>\n<p>Our main goals with the new onboarding strategy were:</p>\n<ul>\n<li>to connect our systems (developer portal — partner portal — platform), so our users can go through their discovery experience in one flow during their first visit;</li>\n<li>to provide an actionable stepped process that the users can walk through;</li>\n<li>allow users/personas to quickly identify the most fitting journey.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f656bdd9-991b-4247-814e-37d493ca0d96/opening-onboarding-screen-before-usability-test.png\" /></p>\n<h4>Usability Test</h4>\n<p>We conducted remote Usability Test sessions in three rounds to validate the platformOS onboarding process. </p>\n<p>The onboarding section connects the Documentation site and the Partner Portal where users can select one of three journeys based on their programming experience. The goal was to learn how users with different levels of technical knowledge reacted to the three journeys. Are they able to quickly identify what is included in each journey? If yes, how do they engage from that time forward? Did they follow the pathway most appropriate for them?</p>\n<p>During the Usability study, we asked users to do several short tasks using a prototype of the planned features built with Figma. We used both moderated and unmoderated remote usability testing techniques and conducted extra tests with platformOS team members to verify the represented business, technical, and content goals.</p>\n<p>We conducted six moderated remote Usability Tests in two rounds and set up three unmoderated remote Usability Tests. These tests were separated into three rounds, and after each round, we updated the prototype with the test results.</p>\n<p>Based on the test results, we decided that instead of showing three options to the users, we show the two quickest options: 1-click install and Build a basic ‘Hello world’ app. This helps them to quickly decide which is the best fit for them, and at the same time they can immediately try out the platformOS basics. Then, if they want to, they can check out our third journey — the Get Started guide that explains how to build a to-do app.</p>\n<p>We redesigned the Instance welcome screen to help users identify the next steps. Based on the results, we had to optimize the UI copy to make it comfortable for non-technical users as well.</p>\n<p>As the flow connects two sites and shows the product, the main goal was to show that the user is on the right track and still on the selected journey. We achieved it by showing the steps of the journey upfront, using consistent wording, and allowing the user to step back and forth.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7db6eda6-ff3f-4565-9df1-afcbc379e4ca/opening-onboarding-screen-after-usability-test.png\" /></p>\n<h3>Round 3: Remote Field Study And Onboarding Interviews</h3>\n<p>In this round, the goal was to examine the overall journey of the experienced and prospective pOS users, focusing on both successes and challenges they are facing. We conducted an interview with a remote field study to get a better understanding of how they work and what processes they are using.</p>\n<p>We focused on four main topics:</p>\n<ol>\n<li><strong>Development with pOS</strong> (workflows, preferences on version control, tools),</li>\n<li><strong>Community and collaboration</strong> (support, discussions),</li>\n<li><strong>Developer Portal</strong> (overall experience, obstacles, suggestions for improvements),</li>\n<li><strong>Partner Portal</strong> (usage, dashboard preferences).</li>\n</ol>\n<p>Key insights from the user research results:</p>\n<ul>\n<li><p><strong>The development with platformOS has a flexible and limitless offering</strong> which is a great strength of the system, but it also means that learning the workings of the platform, especially in the very beginning, takes more effort and patience from developers.<br /><strong><em>Solution:</em></strong> <em>Templates might provide aid during the learning process.</em>  </p>\n</li>\n<li><p>As <strong>platformOS is new in the market, there’s not much information on Google or StackOverflow</strong> yet. On the positive side, the pOS team always provides great support via Slack and introduces new solutions in Town Hall meetings, status reports, and release notes.<br /><strong><em>Solution:</em></strong> <em>To further strengthen the community, a separate Community Site can be an efficient and quick platform for peer-to-peer support by having a search function, and users can follow useful topics.</em>  </p>\n</li>\n<li><p>Related to the Developer Portal, we saw that the user easily gets to the documentation and finds the solution for most of their use cases. However, the <strong>search results were not precise enough</strong> in some cases, and the <strong>naming of the tutorials caused uncertainty</strong> about where to find items.<br /><strong><em>Solution:</em></strong> <em>Run a content reorganization session for the tutorials and fix the search function.</em>  </p>\n</li>\n<li><p>We discovered that the Partner Portal was used mostly at the beginning of the projects by experienced devs. Junior developers preferred that they can find helping instructions on the instances page that supported their work on the new instances. Agency Owners/Business Analyst preferred to use the site to see the payments related information and the analytics of the instance use. We saw that they generally had <strong>problems handling the permissions related to the instances and identifying the hierarchy between their instances</strong>.<br /><strong><em>Solution:</em></strong> <em>Partner Portal design update with new information structure of the instances and permissions.</em></p>\n</li>\n</ul>\n<h3>Round 4: Structural And Content Reorganization, User Testing, Implementation</h3>\n<h4>Structural And Content Reorganization</h4>\n<p>In this round, we renamed the Tutorials section to Developer Guide. This was in line with our plan to extend our tutorials in this section with more concept topics, as requested. We planned to have a comprehensive Get Started section for beginners with the “Hello, World!” tutorial and the Build a To-do List App series, and the Developer Guide for everyone working with platformOS — from users who have just finished the Get Started guides to experienced platformOS developers. This separated and highlighted the onboarding area of the site, and this is when the current structure of our Get Started section came to be: a separate tutorial for when you start your journey with platformOS, that you can use as a first step to go through the more advanced onboarding tutorials. </p>\n<h4>Card Sorting</h4>\n<p>At this point, we had 136+ topics in our Tutorials section organized into 27 groups, and we knew that we wanted to add more. Based on user feedback, we could improve the usability of the Tutorials section by organizing the topics better. Our goal was to identify a structure that best fits users’ expectations. We used a Card Sorting exercise to reach our goal. </p>\n<p>We have analyzed the inputs, and based on the results, we concluded that seven categories can cover our 27 topics: Data management, Schema, Templates, Modules and Module examples, Partner Portal, Third-Party Systems, and Best Practices. We used the similarity matrix and the category namings to identify which topics are connected and what names users suggested for them.</p>\n<p>With this research, we managed to restructure the Tutorials section to become in line with the mental models of the users.</p>\n<h3>Round 5: Fine-Tuning, Content Production</h3>\n<p>In the latest round, we added the possibility, on our onboarding, to start from a template. Based on our discovery, the marketplace template is a good option for site builders who would like to have a marketplace up and running fast and don’t want to explore the development in detail. </p>\n<p>The <a href=\"https://documentation.platformos.com/get-started/marketplace-template/marketplace-template\">pOS marketplace template</a> is a fully functional marketplace built on platformOS with features like user onboarding, ad listings and ads, purchase and checkout process, and online payment. Following the tutorial we added, users can deploy this code within minutes to have a list of working features and start customizing the back- and front-end code.</p>\n<p>We also keep fine-tuning our content for clarity, brevity, readability, accessibility, and inclusive language. We have regular accessibility reviews where we pay attention to aspects, such as terminology, technical language, gender-neutral pronouns, and informative link text while avoiding ableist language, metaphors, and colloquialisms. We summarized our experience with fine-tuning accessibility in the article “<a href=\"https://www.platformos.com/blog/post/code-and-content-for-accessibility-on-the-platformos-developer-portal\">Code and Content for Accessibility on the platformOS Developer Portal</a>” which includes examples of what we changed and how. </p>\nFuture Plans\n<p>The platformOS Developer Portal was very positively received and even won a few peer-reviewed <a href=\"https://documentation.platformos.com/community/awards/dra_best_ongoing_developer_experience\">awards</a>. We are honored and grateful that our efforts have yielded such great recognition. We will keep revalidating and improving our onboarding just like we have been doing since the beginning. We are also working on a <strong>developer education program</strong> for our soon-to-be-launched community site that includes various learning pathways that will try to accommodate users’ different learning styles and also offer ways for them to get more involved with our developer community. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/04fcfc35-cc81-4553-a443-8962a74ea8a3/1-developing-award-winning-onboarding-process-case-study.png\" /></p>\nConclusions\n<p>So, after years of working on our onboarding, what are our key takeaways?</p>\n<ul>\n<li><strong>Don’t feel pressured to get everything right</strong> the first time around. Instead, become comfortable with change and consider each adjustment progress.</li>\n<li><strong>Get to know your target audience</strong> and be ready to revalidate and shift target audience segments based on your findings.</li>\n<li><strong>Get familiar with different user research methods</strong> to know when to use which approach. Carry out extensive user research and, in turn, listen to your users. To support feedback, allow users multiple different channels to give you feedback.</li>\n<li><strong>Choose a flexible workflow</strong>, so that the editorial process does not become an obstacle to continuous change. We love Docs as Code.</li>\n<li><strong>A product is never ready.</strong> Shaping and updating an already done flow is perfectly fine.</li>\n<li><strong>Iteration and prioritization are your best friends</strong> when it comes to delivering large amounts of work.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5e90069a-361d-4d51-8026-4c92ae0a10eb/2-developing-award-winning-onboarding-process-case-study.png\" /></p>\n<p>We hope that this case study helps and encourages you as you build an onboarding experience for your product.  </p>",
      "content_text": "The notion of onboarding is all about helping users quickly and easily find value in your offering. Speed and ease of use are equally important because users might lose interest if going through an onboarding takes more time or is more complicated than what they expected. Speed and ease of use are also relative to a person’s point of view: a salesperson can have vastly different expectations for an onboarding than a developer. \nA well-constructed onboarding process boosts engagement, improves product adoption, increases conversion rates, and educates users about a product. Optimizing the onboarding experience is a journey. You should have a plan but be agile, utilizing processes and tools to garner feedback from target users in a bid to constantly improve. \nIn this article, we will walk you through how we developed the onboarding processes for platformOS from the very beginning. You will be able to follow how we carried out user experience research, how our onboarding has changed over time, what assumptions we made, and how we adjusted them. We will talk about all the tools we used as examples, but the same processes can be implemented with a wide variety of other tools. You will get practical examples and a complete overview of how we built our onboarding, with insights into UX research and the specifics of working with different audience segments. \nOur audience has always combined technical people with various levels of programming skills, and non-technical people who come to our docs to evaluate if platformOS would be a good fit for their projects like Project Owners, Business Analysts, and Project Managers. Because our main target audience is divided into different segments, you will also get a glimpse of the processes we developed for our documentation, developer education, and developer relations. \nChallenge: Onboarding For Different Target Audiences\nplatformOS is a model-based application development platform aimed at front-end developers and site builders automating infrastructure provisioning and DevOps. \n DevOps is a combination of development methodologies, practices, and tools that enable teams to evolve and improve products at a faster pace to better serve their customers and compete more effectively in the market. Under a DevOps model, development and operations teams are merged into a single team where the engineers work across the entire application lifecycle, from development and test to deployment to operations.\n\nOur main target audience is developers, and the foundation for their onboarding, education, and support is our developer portal — but our onboarding has to cater to other target audience segments as well. \nDefining Our Target Audience Segments\nWe defined our target audience during the discovery phase of the Design Thinking process that we used to plan our developer portal. Since then, we have frequently revalidated the results to see if we are on the right track because we want to be sure that we understand the people who will be using our product, and what motivates them. We also know that in the lifecycle of a product this audience can change as a result of product positioning, and how well we can address their needs. \nOur target audience currently has four segments:\n\nExperienced developers,\nJunior developers,\nAgency Owner, Sales/Marketing,\nPM, Business Analyst.\n\n\nUser Base Shifts\nWe created the first target audience map when we started planning our developer portal. In the discovery phase, we mapped out four proto-personas that covered the following segments: Experienced Developers, Junior Developers, Site Builders, and Marketplace Owners.\nWe revalidated these results a year later, and we realized that our audience had shifted a bit. \n\nThe Experienced Developers and the Junior Developers stayed as the main target audiences. However, we collected new knowledge related to the needs of the junior devs. They needed more detail to be able to understand and start working with the product. This new information helped us specify their user journey.\nAt this point, the Site Builders were the smallest group. We identified we needed to address the needs of the developers group first, creating a strong foundation to support site builders in the platform.\nThe non-technical segment shifted on the way. The Marketplace Owners segment was divided into two separate audiences: the Agency Owners, who have a sales and marketing background, and the Business Analysts, who have an enterprise background in business management or transformation — a new audience who started to show interest in our product.\n\nAlong the way, we were able to specify the needs of these audiences in more detail. These details helped with the prioritization of the onboarding tasks and kept our focus on the needs of the audience. \nDefining Entry Points For Target Audience Segments\nGetting to know the needs of the target audience segments provided guidance for identifying the entry points to the product.\n\nThe Agency Owners’ key goal is to work on multiple web projects that they host and manage on the platform. They won’t work on the platform themselves, but they would like to know the status and the progress of the platform without worrying about DevOps. They need to see the business perspective, the security, and that they are part of a reliable ecosystem with a helpful community around without diving deep into the technical part of the product.\nThe Business Analysts’ goal is to identify solution providers for their specific business problems. They need to find a long-term solution that fits with their use case, is scalable, and gives them the possibility for easy evaluation that shows the key business values in action.\nThe Junior Developers’ goal is to learn the basics without much hassle, under the guidance of experienced community members. They need clear technical communication on how to set up a dev environment and how to troubleshoot common errors.\nThe Experienced Developers’ goal is to find a solution that is reliable and flexible enough for all their project needs and at the same time provides good performance. They need to be able to evaluate quickly if it’s a good fit, then see how their project could work on the platform. They also need to see that the platform has a future with a solid community behind it.\n\nAll segments needed an actionable onboarding where they can interact with the product (and engage with the community) based on their level of technical knowledge. \n\nIn the non-technical journey, users can go from the 1-click route that takes them through registering on the Partner Portal to creating a demo site and installing the blog module by clicking through a setup wizard.\nIn the semi-technical journey, users can create a sandbox in which they can experiment by cloning a demo site from our GitHub repository, and they also have the option to go through our “Hello, World!” guide.\nIn the technical journey, users can follow a more complex tutorial that walks them through the steps of creating an app on platformOS from setting up their development environment to deploying and testing their finished app. It explains basic concepts, the main building blocks, and the logic behind platformOS, while also giving some recommendations on the workflow.\n\n\nHow We Approached The Challenge: Methods And Tools\nWe followed various methods to tackle different aspects of the main challenge. We selected a Design process to follow, used many different user research methods to collect insights and feedback from our users, chose a framework for our editorial workflow and technical implementation that could work well for our Agile, iterative process and our target audience, and went with an approach for content production that allowed community members to contribute early on. \nDesign Thinking\nBecause of the strategic role our developer portal plays in the adoption and use of our product, we wanted to use a creative design process that solves traditional business problems with an open mindset.\nOur goal was to:\n\nhelp our community to be able to use our documentation site for their needs as early as possible;\nmeasure user needs and iterate the product based on the feedback;\nkeep the long-term user and business goals in mind and take a step closer with each iteration.\n\nWe found the Design Thinking framework a perfect fit because it is a user-centric approach that focuses on problem-solving while fostering innovation. \n\nWe followed the stages of the design thinking process:\n\nEmpathizeIn the beginning, we explored our audience, our documentation needs, and existing and missing content through in-depth interviews and workshops. \nDefineThen, we defined personas and our Content Inventory.\nIdeateWe shared our ideas for content and features through a Card Sorting exercise.\nPrototypeBased on our findings, we created a sitemap and prioritized content needs, and created layouts and wireframes. Content production started based on the results of our discovery phase.\nTestWe followed an iterative, Docs as Code approach: at each stage, we work with quick feedback rounds, deploy often, and improve features and content based on feedback from real users.\n\nUser Research\nIn the life of a product, each development stage has a fitting UX research method that we can use, depending on the business plans, time constraints, stage of product/feature, and the current concerns.\nIn the last three years we used the following methods:\n\nInterviewsWe met with users, sales, and support persons to discuss in-depth what the participant experienced about various topics.\nRemote Usability TestingWe asked potential or current users of the product to complete a set of tasks during this process, and we observed their behavior to define the usability of the product. We used two types of remote usability testing:\nModerated: We conducted the research remotely via screen-sharing software, and the participants joined in from their usual work environment. This approach is advantageous when analyzing complex tasks — where real-time interaction and questioning with participants are essential.\nUnmoderated: We sent tasks for users to complete in their own time. As moderators are not present, we measured less complex tasks and focused on the overall level of satisfaction they experienced when interfacing with the product.\n\n\nCard SortingA quantitative or qualitative method, where we ask users to organize items into groups and assign categories to each group. This process makes it possible to reflect the users’ mental model on the architecture. \nTree testsWe used tree tests to validate the logic of the used information architecture. We gave users a task to find certain elements in the navigation structure and asked them to talk about where they would go next to accomplish the task.\nSurveys, QuestionnairesWe used questionnaires and surveys to gather a large amount of information about a topic. This quantitative data can help us have a better understanding of specific topics that we can further research to understand what motivates users.\nAnalytics reviewWe used site analytics to gather quantitative data about usage patterns and identify possible flow breaks. Based on the data we either fixed the problem or if needed, we further tested with usability research.\n\nDocs As Code And CI/CD\nWe engaged our users in an Agile and iterative process right from the beginning discovery phase. This ensured that we were able to test and validate all of our assumptions, and quickly make modifications if needed. As our internal team members and our community participants are distributed, we needed a workflow that made it possible to collaborate on changes, large or small, remotely. Consequently, we needed a robust approach to version control accommodating authors, reviewers, and editors all working on content concurrently. As we wanted to encourage developers to contribute, we needed a framework that they’re familiar with. We also wanted to make our documentation open-source, so that anyone could duplicate and reuse it for their own projects. Based on these requirements, we decided to follow the Docs as Code approach. \nDocumentation as Code or Docs as Code refers to a philosophy of writing documentation with the same tools as software coding. This means following the same workflows as development teams, including being integrated into the product team. It enables a culture where writers and developers both feel they have ownership of the documentation and work together to aim for the best possible outcome. In our case, we didn’t only have writers and developers working on our onboarding but also UX researchers, account and project managers, and of course, a range of users in varying roles.  \nOur documentation is in a separate repository on GitHub. We have a central branch, and we work locally in a dedicated branch, then we send pull requests for review to be merged into the main branch. To preview docs, we use our own staging site which is an exact copy of the live documentation site. \nOnce we accept changes, we take steps to push them live almost immediately. To maintain the integrity of the site during this process, we follow the practice of continuous integration and continuous deployment (CI/CD). We run test scripts automatically and deploy the codebase to staging. If a test fails, an error report is generated. Alternatively, if everything goes well, our CI/CD of choice — GitHub Actions — deploys the codebase to production and sends us a notification. We release updates continuously, at times merging multiple changes in a single day, at other times only once or twice a week. \n\nEditorial Workflow\nDocs as Code provides the foundation for our processes, but for the various users to work efficiently together, we needed to define a clear editorial workflow that worked for all participants (internal and external writer, developer, contributor, and so on) and for all stages of the process (writing, reviewing, editing); but that was also simple enough to involve new contributors. Following Docs as Code, each stage of our workflow is in git, including project management (contributors can also add tickets to report issues or requests). \nThese are the steps of our editorial workflow:\n\nWrite new content in Markdown using the templates. You can use any editor that can produce Github Flavored Markdown. \nSubmit the new topic as a pull request on GitHub. \nReview. We have a peer-review system in place for code and docs alike. Topics are reviewed by both technical reviewers (developers) and writers. \nEdit as needed. Repeat steps 3-4 until approved. \nMerge approved pull request. \nDeploy to staging, then to production.\n\n\nOur editorial workflow ensures that contribution works the same way for everyone, and we support our contributors with guidelines and ready-to-use templates. \nContent Production And Contribution\nWhen we started developing our onboarding and documentation, we followed the Content First approach. We planned to develop some initial content that we could work with, but even before that, we decided what types of content we would need and outlined the structure of each content type. These outlines became templates that ensure consistency and encourage contribution. \nWe were inspired by topic-based authoring and DITA, in the sense that we decided to have three main content types for our documentation, tutorials that describe how to accomplish a task, concepts that provide background information and context, and references like our API Reference. Our onboarding consists of tutorials that link to concepts and references when needed. \n DITA, short for Darwin Information Typing Architecture, is an XML standard, an architectural approach, and a topic-based writing methodology where content is authored in topics rather than in larger documents or publications. A DITA topic must make sense in its own right.\n\nInvolving our users from the beginning ensured that we could test and validate all of our assumptions, and quickly modify anything if needed. This proved to be a time and cost-efficient approach: although we edit and rewrite our content, and change things on our documentation site all the time, we don’t run the risk of creating large chunks of work that have to be thrown away because they don’t correspond to the needs of our users.\nConstant collaboration also builds trust: as our process is completely transparent, our community continuously knows what we’re working on and how our docs evolve, and community members can be sure that their opinions are heard and acted upon. \nInvolving the community from an early stage means that our users saw lots of stuff that was partially done, missing, or ended up totally rewritten. So, for all of this to work, our users had to be mature enough to give feedback on half-done content, and we had to be level-headed enough to utilize sometimes passionate criticism. \nEncouraging Contribution\nWe wanted to make it very easy to get involved for all segments of our target audience, so we offer several ways to contribute, taking into consideration the time contributors have available, and their skill level. We describe ways for our community members to get involved in our Contributor Guide. For some quick editing, like fixing typos or adding links, contributors can edit the content easily on the GitHub UI. For heavy editing, adding new content, or for developers who prefer to use git, we provide a complete Docs as Code workflow. This approach proved to be extremely valuable for our onboarding. We got direct feedback on where users struggled with a step or had too little or too much information, and we could immediately make adjustments and verify that we have fixed the issue. \nTo help contributors write larger chunks of text or complete topics, we provide guidelines and templates to start from:\n\nStyle GuideOur style guide contains guidelines for writing technical content (e.g. language, tone, etc.) and each content type in our documentation (e.g. tutorials, concept topics, etc.).\n\n\n\nTemplatesOur site uses Liquid pages, but to make editing easier for contributors, we write documentation content in Markdown and use a Markdown converter to turn it into Liquid. Our templates include all non-changeable content and placeholders with explanations for the parts that are editable. Placeholders provide information on the recommended format (e.g. title) and any requirements or limitations (e.g. maximum number of characters). \n\n\nWe thank all of our contributors by giving recognition to them on our Contributors page as well as on our GitHub repository’s README page.\nCommunication\nOur team and community members are scattered across different time zones. Similarly to how we communicate among team members, we use mostly asynchronous and sometimes real-time communication tools to communicate with our community. We even leverage real-time communication tools, like a video conference, to become somewhat asynchronous. For example, video conferences and webinars are recorded, and community members can discuss them on various channels.\n\npOS Community siteOne of our main communication channels is our community site, where you can ask, answer, upvote, and downvote questions, and get to know other members of the platformOS Community. More features coming soon!\nSlack supportOne of our main communication channels is dedicated Slack channels, where community members ask questions, share ideas, and get to know our team members and each other. Based on their feedback, community members have confirmed how helpful it is to be able to communicate directly with us and each other: they can share what they’ve learned, plan their module development in sync with our roadmap and each other’s projects, and allocate their resources according to what’s going on in the business and the wider community. This communication seeds the documentation site with the most sought-after topics.\nVideo conferenceWe regularly have video conferences over Zoom called Town Halls, where community members and the platformOS team share news, demo features, and modules and have the opportunity to engage in real-time, face-to-face conversation. Our team and community members are distributed over different continents, so we try to accommodate participants in different time zones by rotating the time of this event so that everyone has the chance to participate. We also share the recording of each session. \nUser experience researchBesides getting constant feedback from the community through the channels described above, we plan regular checkpoints in our process to facilitate testing and course correction. During development, we tie these checkpoints to development phases. At the end of each larger release, we conduct user interviews and compile and share a short survey for community members to fill out. This helps us clarify the roadmap for the next development phase.\n\nWe make sure to keep community members informed about what’s happening through different channels: \n\nStatus reportsWe regularly share status reports on our blog to keep our community updated on what we’ve achieved, what we are working on, and what we are planning for the near future. Our status reports also include calls for contribution and research participation and the results and analysis of UX research. Subscribers can also choose to receive the status reports via email newsletter.\nRelease notesWe share updates regarding new features, improvements, and fixes in our release notes.\nBlogWe regularly share articles about best practices and general news on our blog.\n\nAccessibility And Inclusiveness\nWe address accessibility right from the design phase, where we use Figma’s Able accessibility plugin. We regularly test for accessibility with various tools and ensure that the site complies with all accessibility requirements. \nFrom a technical writing perspective, we support Accessibility and Usability by providing well-structured, clear, concise, and easy-to-understand copy. All of our documentation topics follow a predefined structure (predefined headings, steps, sections, link collections, and so on) applicable to that topic type (tasks, concepts, references), inspired by the principles of topic-based authoring. \nSemantic HTML is important for Accessibility, and we make sure not to style text any other way than through Markdown which is then translated into HTML. This way, screen readers can properly navigate through the content, and it also helps overall consistency when, for example, we want to do a design update.\nWe also review all content to ensure accessible and inclusive language as specified in our style guide. \nHow We Developed Our Onboarding: Rounds And Lessons Learned\nDeveloping Our Onboarding Using Continuous Iteration Rounds\nAt the beginning of the project, we started with a focused effort around discovery to identify the main business goals and user needs. As a result of this research, we were able to articulate the big picture. After we had all the user journeys and a sitemap for the big picture plan, we were able to break it down to identify the first iteration that would become the first working MVP version of the site.  \nMoving forward, we continue to follow an iterative approach, moving fast with an agile mindset. Steps: gather user feedback, identify areas of improvement and possible new directions, define the solution based on resources, business goals, and user needs, and implement it. This circle repeats indefinitely. So, we have an overarching plan outlined for our documentation that we keep in mind, but we always focus on the next couple of action steps we’d like to take.\nWe can highlight five distinctive rounds that had a great impact on the development of our developer portal.\n\nFor our onboarding process, we started with exploring the requirements following the Design Thinking approach. Through a Card Sorting session, we explored the areas of interest for each target audience and that helped us define the topics that concern them the most. This worked as a persona-based content prioritization for the documentation site.\nWe wanted to guide our users with actionable items that they can try out on our site as a next step. At this point, we were already aware that our target audience shifted. The interviews and the support feedback helped us understand their needs that pointed in two main directions. We needed an easy journey for non-technicals and another one for technicals who like to understand the logic of the platform. In this stage, we planned, tested, and developed the first version of the 1-click journey and the sandbox.\nWe already had experienced platform users who we wanted to see in action. Using remote field studies, we discovered how they use the tools, the documentation site, and the partner portal we provide. At the same time, we started to conduct continuous onboarding interviews with partners who joined the platform. The two research directions helped us to realize how users with a varying degrees of experience interpret the platform.\nBy this point, our content grew a lot on the developer portal, and we wanted to discover if we needed a structural and content reorganization based on the user research. \nIn this latest round, we wanted to dedicate some time to fine-tuning and adjustments, and to double down on the developer portal’s accessibility and inclusiveness.\n\nRound 1: Identifying The Target Audience Segments, Defining Proto-Personas, Base Discovery\nWith the Design Thinking workshops, we first focused on understanding our users. Based on the user research results, we defined the proto-personas and created a detailed description of each to show their needs and expectations and help us identify who we were designing for. It provided a good foundation for guiding the ideation process and prioritizing features based on how well they address the needs of one or more personas.\n\nOn our documentation site, we are working with a large amount of data that we need to present clearly to all users. To define a Content Inventory:\n\nwe created a list of our proto-personas’ needs based on the problems they needed to solve with the platform;\nwe created a detailed list of content from our previous documentation site and identified missing, reusable, and non-reusable content for our future site;\nwe analyzed the competitor sites to create a list of inspirations.\n\nWe ideated with the workshop participant using a Card Sorting exercise. The task was to map out the Content Inventory elements and define connections between them. The result showed us the connected areas and the proto-persona’s preference through color coding.\n\nBased on the Content Inventory and the results of the Card Sorting sessions, we outlined the Information Architecture by creating a sitemap and the navigation for our future site. This plan included all the needs that were discovered and offered a roadmap to keep track of site improvements, content needs, and project phases. \nDuring the Card Sorting sessions, we explored areas of interest for each user persona and, on the sitemaps, we highlighted these as user journeys. We also validated the importance of these areas to assign higher priorities to the ones that need more attention. This process kept our focus on the most important needs of the personas. \nThe most important sections for the four segments:\n\nExperienced Developers: Quickstart guide, How to guide, API docs;\nJunior Developers: Quickstart guide, Tutorials, Conceptual documentation;\nSite Builders: Quickstart guide, Tutorials, FAQ, Forum;\nMarketplace Owners: About platformOS, Blog.\n\nThis concluded our Information Architecture phase. We have discovered and organized all the information we needed to continue to the next phase, where we started creating templates for content types, building the wireframes for each page, producing content, and making Design decisions.\nRound 2: Onboarding Strategy And Testing Of The Onboarding Process\nStrategy\nBefore we jumped into planning an onboarding strategy, we did a revalidation on proto-personas. At that point, we discovered that our audience shifted to Experienced developers, Junior developers, Agency Owner, Sales/Marketing, PM and Business Analyst, and we realized that we needed to cover a broader spectrum of needs than previously identified.\nWe interviewed 20 platformOS users. We identified how long they have been using the system, how they use the platform, what the key ‘aha’ moments were, what struggles they faced, and how they solved them. Their needs pointed in two main directions: we needed an easy journey for non-technicals and another one for technicals, covering those with less experience as well as those more capable developers who wished to understand the deeper logic and nuances of platformOS.\nOur main goals with the new onboarding strategy were:\n\nto connect our systems (developer portal — partner portal — platform), so our users can go through their discovery experience in one flow during their first visit;\nto provide an actionable stepped process that the users can walk through;\nallow users/personas to quickly identify the most fitting journey.\n\n\nUsability Test\nWe conducted remote Usability Test sessions in three rounds to validate the platformOS onboarding process. \nThe onboarding section connects the Documentation site and the Partner Portal where users can select one of three journeys based on their programming experience. The goal was to learn how users with different levels of technical knowledge reacted to the three journeys. Are they able to quickly identify what is included in each journey? If yes, how do they engage from that time forward? Did they follow the pathway most appropriate for them?\nDuring the Usability study, we asked users to do several short tasks using a prototype of the planned features built with Figma. We used both moderated and unmoderated remote usability testing techniques and conducted extra tests with platformOS team members to verify the represented business, technical, and content goals.\nWe conducted six moderated remote Usability Tests in two rounds and set up three unmoderated remote Usability Tests. These tests were separated into three rounds, and after each round, we updated the prototype with the test results.\nBased on the test results, we decided that instead of showing three options to the users, we show the two quickest options: 1-click install and Build a basic ‘Hello world’ app. This helps them to quickly decide which is the best fit for them, and at the same time they can immediately try out the platformOS basics. Then, if they want to, they can check out our third journey — the Get Started guide that explains how to build a to-do app.\nWe redesigned the Instance welcome screen to help users identify the next steps. Based on the results, we had to optimize the UI copy to make it comfortable for non-technical users as well.\nAs the flow connects two sites and shows the product, the main goal was to show that the user is on the right track and still on the selected journey. We achieved it by showing the steps of the journey upfront, using consistent wording, and allowing the user to step back and forth.\n\nRound 3: Remote Field Study And Onboarding Interviews\nIn this round, the goal was to examine the overall journey of the experienced and prospective pOS users, focusing on both successes and challenges they are facing. We conducted an interview with a remote field study to get a better understanding of how they work and what processes they are using.\nWe focused on four main topics:\n\nDevelopment with pOS (workflows, preferences on version control, tools),\nCommunity and collaboration (support, discussions),\nDeveloper Portal (overall experience, obstacles, suggestions for improvements),\nPartner Portal (usage, dashboard preferences).\n\nKey insights from the user research results:\n\nThe development with platformOS has a flexible and limitless offering which is a great strength of the system, but it also means that learning the workings of the platform, especially in the very beginning, takes more effort and patience from developers.Solution: Templates might provide aid during the learning process.  \n\nAs platformOS is new in the market, there’s not much information on Google or StackOverflow yet. On the positive side, the pOS team always provides great support via Slack and introduces new solutions in Town Hall meetings, status reports, and release notes.Solution: To further strengthen the community, a separate Community Site can be an efficient and quick platform for peer-to-peer support by having a search function, and users can follow useful topics.  \n\nRelated to the Developer Portal, we saw that the user easily gets to the documentation and finds the solution for most of their use cases. However, the search results were not precise enough in some cases, and the naming of the tutorials caused uncertainty about where to find items.Solution: Run a content reorganization session for the tutorials and fix the search function.  \n\nWe discovered that the Partner Portal was used mostly at the beginning of the projects by experienced devs. Junior developers preferred that they can find helping instructions on the instances page that supported their work on the new instances. Agency Owners/Business Analyst preferred to use the site to see the payments related information and the analytics of the instance use. We saw that they generally had problems handling the permissions related to the instances and identifying the hierarchy between their instances.Solution: Partner Portal design update with new information structure of the instances and permissions.\n\n\nRound 4: Structural And Content Reorganization, User Testing, Implementation\nStructural And Content Reorganization\nIn this round, we renamed the Tutorials section to Developer Guide. This was in line with our plan to extend our tutorials in this section with more concept topics, as requested. We planned to have a comprehensive Get Started section for beginners with the “Hello, World!” tutorial and the Build a To-do List App series, and the Developer Guide for everyone working with platformOS — from users who have just finished the Get Started guides to experienced platformOS developers. This separated and highlighted the onboarding area of the site, and this is when the current structure of our Get Started section came to be: a separate tutorial for when you start your journey with platformOS, that you can use as a first step to go through the more advanced onboarding tutorials. \nCard Sorting\nAt this point, we had 136+ topics in our Tutorials section organized into 27 groups, and we knew that we wanted to add more. Based on user feedback, we could improve the usability of the Tutorials section by organizing the topics better. Our goal was to identify a structure that best fits users’ expectations. We used a Card Sorting exercise to reach our goal. \nWe have analyzed the inputs, and based on the results, we concluded that seven categories can cover our 27 topics: Data management, Schema, Templates, Modules and Module examples, Partner Portal, Third-Party Systems, and Best Practices. We used the similarity matrix and the category namings to identify which topics are connected and what names users suggested for them.\nWith this research, we managed to restructure the Tutorials section to become in line with the mental models of the users.\nRound 5: Fine-Tuning, Content Production\nIn the latest round, we added the possibility, on our onboarding, to start from a template. Based on our discovery, the marketplace template is a good option for site builders who would like to have a marketplace up and running fast and don’t want to explore the development in detail. \nThe pOS marketplace template is a fully functional marketplace built on platformOS with features like user onboarding, ad listings and ads, purchase and checkout process, and online payment. Following the tutorial we added, users can deploy this code within minutes to have a list of working features and start customizing the back- and front-end code.\nWe also keep fine-tuning our content for clarity, brevity, readability, accessibility, and inclusive language. We have regular accessibility reviews where we pay attention to aspects, such as terminology, technical language, gender-neutral pronouns, and informative link text while avoiding ableist language, metaphors, and colloquialisms. We summarized our experience with fine-tuning accessibility in the article “Code and Content for Accessibility on the platformOS Developer Portal” which includes examples of what we changed and how. \nFuture Plans\nThe platformOS Developer Portal was very positively received and even won a few peer-reviewed awards. We are honored and grateful that our efforts have yielded such great recognition. We will keep revalidating and improving our onboarding just like we have been doing since the beginning. We are also working on a developer education program for our soon-to-be-launched community site that includes various learning pathways that will try to accommodate users’ different learning styles and also offer ways for them to get more involved with our developer community. \n\nConclusions\nSo, after years of working on our onboarding, what are our key takeaways?\n\nDon’t feel pressured to get everything right the first time around. Instead, become comfortable with change and consider each adjustment progress.\nGet to know your target audience and be ready to revalidate and shift target audience segments based on your findings.\nGet familiar with different user research methods to know when to use which approach. Carry out extensive user research and, in turn, listen to your users. To support feedback, allow users multiple different channels to give you feedback.\nChoose a flexible workflow, so that the editorial process does not become an obstacle to continuous change. We love Docs as Code.\nA product is never ready. Shaping and updating an already done flow is perfectly fine.\nIteration and prioritization are your best friends when it comes to delivering large amounts of work.\n\n\nWe hope that this case study helps and encourages you as you build an onboarding experience for your product.  ",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/69a59d30-3186-49e9-943d-a023f7bf1f29/developing-award-winning-onboarding-process-case-study.jpg",
      "date_published": "2022-05-24T11:30:00.000Z",
      "date_modified": "2022-05-24T11:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/lesser-known-underused-css-features-2022/",
      "url": "https://smashingmagazine.com/2022/05/lesser-known-underused-css-features-2022/",
      "title": "Lesser-Known And Underused CSS Features In 2022",
      "summary": "CSS is constantly evolving, and some cool and useful properties either go completely unnoticed or are not talked about as much as others for some reason or another. In this article, we’ll cover a fraction of those CSS properties and selectors.",
      "content_html": "<p>After reading Louis Lazaris’ insightful article “<a href=\"https://www.smashingmagazine.com/2022/03/html-attributes-you-never-use/\">Those HTML Attributes You Never Use</a>”, I’ve asked myself (<a href=\"https://twitter.com/AdrianBeceDev/status/1511312060780630019\">and the community</a>) which properties and selectors are lesser-known or should be used more often. Some answers from the community surprised me, as they’ve included some very useful and often-requested CSS features which were made available in the past year or two.</p>\n<p>The following list is created with community requests and my personal picks. So, let’s get started!</p>\n<code>all</code> Property\n<p>This is a shorthand property which is often used for <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/all\">resetting all properties</a> to their respective initial value by effectively stopping inheritance, or to enforce inheritance for all properties.</p>\n<ul>\n<li><code>initial</code><br />Sets all properties to their respective initial values.</li>\n<li><code>inherit</code><br />Sets all properties to their inherited values.</li>\n<li><code>unset</code><br />Changes all values to their respective default value which is either <code>inherit</code> or <code>initial</code>.</li>\n<li><code>revert</code><br />Resulting values depend on the stylesheet origin where this property is located.</li>\n<li><code>revert-layer</code><br />Resulting values will match a previous cascade layer or the next matching rule.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/744bbae0-ea35-481d-bdbe-a5b424c3f17e/1-lesser-known-underused-css-features-2022.png\" /></p>\n<code>aspect-ratio</code> for Sizing Control\n<p>When <code>aspect-ratio</code> was initially released, I thought I won’t use it outside image and video elements and in very narrow use-cases. I was surprised to find myself using it in a similar way I would use <code>currentColor</code> — to avoid unnecessarily setting multiple properties with the same value.</p>\n<p>With <code>aspect-ratio</code>, we can easily <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/aspect-ratio\">control size</a> of an element. For example, equal width and height buttons will have an aspect ratio of <code>1</code>. That way, we can easily create buttons that adapt to their content and varying icon sizes, while maintaining the required shape.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/643992dc-a2da-4f97-b6dd-cef517ea085e/2-lesser-known-underused-css-features-2022.png\" /></p>\n<p>I assumed that this issue cannot be fixed, and I moved on. One of the tweets from the community poll suggested that I should look into <code>font-variant-numeric: tabular-nums</code>, and I was surprised to find a plethora of options that affect font rendering. </p>\n<p>For example, <code>tabular-nums</code> fixed the aforementioned issue by setting the equal width for all numeric characters.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8d7cb6ce-3084-4c28-ba42-bebb7beecb11/3-lesser-known-underused-css-features-2022.png\" /></p>\nRender Performance Optimization\n<p>When it comes to rendering performance, it’s very rare to run into these issues when working on regular projects. However, in the case of large DOM trees with several thousands of elements or other similar edge cases, we can run into some performance issues related to CSS and rendering. Luckily, we have a direct way of dealing with these performance issues that cause lag, unresponsiveness to user inputs, low FPS, etc.</p>\n<p>This is where <code>contain</code> property comes in. It tells the browser what won’t change in the render cycle, so the browser can safely skip it. This can have consequences on the layout and style, so make sure to test if this property doesn’t introduce any visual bugs.</p>\n<div>\n<pre><code>.container {\n  /* child elements won't display outside of this container so only the contents of this container should be rendered*/\n  contain: paint;\n{</code></pre>\n</div>\n\n<p>This property is quite complex, and <a href=\"https://www.smashingmagazine.com/2019/12/browsers-containment-css-contain-property/\">Rachel Andrew has covered it</a> in great detail in her article. This property is somewhat difficult to demonstrate, as it is most useful in those very specific edge cases. For example, Johan Isaksson covered one of those <a href=\"https://medium.com/%40johan.isaksson/how-i-made-googles-data-grid-scroll-10x-faster-with-one-line-of-css-78cb1e8d9cb1\">examples in his article</a>, where he noticed a major scroll lag on Google Search Console. It was caused by having over 38 000 elements on a page and was fixed by containing property!</p>\n<p>As you can see, <code>contain</code> relies on <strong>the developer knowing exactly which properties won’t change</strong> and knowing how to avoid potential regressions. So, it’s a bit difficult to use this property safely. </p>\n<p>However, there is an option where we can signal the browser to apply the required <code>contain</code> value automatically. We can use the <code>content-visibility</code> property. With <a href=\"https://web.dev/content-visibility/#skipping-rendering-work-with-content-visibility\">this property</a>, we can defer the rendering of off-screen and below-the-fold content. Some even refer to this as “lazy-rendering”.</p>\n<p>Una Kravets and Vladimir Levin covered this property in their <a href=\"https://web.dev/content-visibility/#example\">travel blog example</a>. They apply the following class name to the below-the-fold blog sections.</p>\n<div>\n<pre><code>.story {\n  content-visibility: auto; /* Behaves like overflow: hidden; */\n  contain-intrinsic-size: 100px 1000px;\n}</code></pre>\n</div>\n\n<p>With <code>contain-intrinsic-size</code>, we can estimate the size of the section that is going to be rendered. Without this property, the size of the content would be <code>0</code>, and page dimensions would keep increasing, as content is loaded.</p>\n<p>Going back to Una Kravets and Vladimir Levin’s travel blog example. Notice how the scrollbar jumps around, as you scroll or drag it. This is because of the difference between the placeholder (estimated) size set with <code>contain-intrinsic-size</code> and the actual render size. If we omit this property, the scroll jumps would be even more jarring.</p>\n<p>See the Pen <a href=\"https://codepen.io/smashingmag/pen/jOZMapm\">Content-visibility Demo: Base (With Content Visibility)</a> by <a href=\"https://codepen.io/vmpstr\">Vladimir Levin</a>.</p>\n<p>Thijs Terluin covers <a href=\"https://www.terluinwebdesign.nl/en/css/calculating-contain-intrinsic-size-for-content-visibility/\">several ways of calculating</a> this value including PHP and JavaScript. Server-side calculation using PHP is especially impressive, as it can automate the value estimation on larger set of various pages and make it more accurate for a subset of screen sizes.</p>\n<p>Keep in mind that <strong>these properties should be used to fix issues once they happen</strong>, so it’s safe to omit them until you encounter render performance issues.</p>\nConclusion\n<p>CSS evolves constantly, with more features being added each year. It’s important to keep up with the latest features and best practices, but also keep an eye out on browser support and use progressive enhancement.</p>\n<p>I’m sure there are more CSS properties and selectors that aren’t included here. Feel free to let us know in the comments which properties or selectors are less known or should be used more often, but may be a bit convoluted or there is not enough buzz around them.</p>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/2019/07/css-custom-properties-cascade/\">CSS Custom Properties In The Cascade</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2021/09/simplifying-form-styles-accent-color/\">Simplifying Form Styles With <code>accent-color</code></a></li>\n<li><a href=\"https://www.smashingmagazine.com/2020/01/understanding-css-grid-container/\">Understanding CSS Grid: Creating A Grid Container</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2019/01/html5-svg-fill-animation-css3-vanilla-javascript/\">HTML5 SVG Fill Animation With CSS3 And Vanilla JavaScript</a></li>\n</ul>",
      "content_text": "After reading Louis Lazaris’ insightful article “Those HTML Attributes You Never Use”, I’ve asked myself (and the community) which properties and selectors are lesser-known or should be used more often. Some answers from the community surprised me, as they’ve included some very useful and often-requested CSS features which were made available in the past year or two.\nThe following list is created with community requests and my personal picks. So, let’s get started!\nall Property\nThis is a shorthand property which is often used for resetting all properties to their respective initial value by effectively stopping inheritance, or to enforce inheritance for all properties.\n\ninitialSets all properties to their respective initial values.\ninheritSets all properties to their inherited values.\nunsetChanges all values to their respective default value which is either inherit or initial.\nrevertResulting values depend on the stylesheet origin where this property is located.\nrevert-layerResulting values will match a previous cascade layer or the next matching rule.\n\n\naspect-ratio for Sizing Control\nWhen aspect-ratio was initially released, I thought I won’t use it outside image and video elements and in very narrow use-cases. I was surprised to find myself using it in a similar way I would use currentColor — to avoid unnecessarily setting multiple properties with the same value.\nWith aspect-ratio, we can easily control size of an element. For example, equal width and height buttons will have an aspect ratio of 1. That way, we can easily create buttons that adapt to their content and varying icon sizes, while maintaining the required shape.\n\nI assumed that this issue cannot be fixed, and I moved on. One of the tweets from the community poll suggested that I should look into font-variant-numeric: tabular-nums, and I was surprised to find a plethora of options that affect font rendering. \nFor example, tabular-nums fixed the aforementioned issue by setting the equal width for all numeric characters.\n\nRender Performance Optimization\nWhen it comes to rendering performance, it’s very rare to run into these issues when working on regular projects. However, in the case of large DOM trees with several thousands of elements or other similar edge cases, we can run into some performance issues related to CSS and rendering. Luckily, we have a direct way of dealing with these performance issues that cause lag, unresponsiveness to user inputs, low FPS, etc.\nThis is where contain property comes in. It tells the browser what won’t change in the render cycle, so the browser can safely skip it. This can have consequences on the layout and style, so make sure to test if this property doesn’t introduce any visual bugs.\n\n.container {\n  /* child elements won't display outside of this container so only the contents of this container should be rendered*/\n  contain: paint;\n{\n\n\nThis property is quite complex, and Rachel Andrew has covered it in great detail in her article. This property is somewhat difficult to demonstrate, as it is most useful in those very specific edge cases. For example, Johan Isaksson covered one of those examples in his article, where he noticed a major scroll lag on Google Search Console. It was caused by having over 38 000 elements on a page and was fixed by containing property!\nAs you can see, contain relies on the developer knowing exactly which properties won’t change and knowing how to avoid potential regressions. So, it’s a bit difficult to use this property safely. \nHowever, there is an option where we can signal the browser to apply the required contain value automatically. We can use the content-visibility property. With this property, we can defer the rendering of off-screen and below-the-fold content. Some even refer to this as “lazy-rendering”.\nUna Kravets and Vladimir Levin covered this property in their travel blog example. They apply the following class name to the below-the-fold blog sections.\n\n.story {\n  content-visibility: auto; /* Behaves like overflow: hidden; */\n  contain-intrinsic-size: 100px 1000px;\n}\n\n\nWith contain-intrinsic-size, we can estimate the size of the section that is going to be rendered. Without this property, the size of the content would be 0, and page dimensions would keep increasing, as content is loaded.\nGoing back to Una Kravets and Vladimir Levin’s travel blog example. Notice how the scrollbar jumps around, as you scroll or drag it. This is because of the difference between the placeholder (estimated) size set with contain-intrinsic-size and the actual render size. If we omit this property, the scroll jumps would be even more jarring.\nSee the Pen Content-visibility Demo: Base (With Content Visibility) by Vladimir Levin.\nThijs Terluin covers several ways of calculating this value including PHP and JavaScript. Server-side calculation using PHP is especially impressive, as it can automate the value estimation on larger set of various pages and make it more accurate for a subset of screen sizes.\nKeep in mind that these properties should be used to fix issues once they happen, so it’s safe to omit them until you encounter render performance issues.\nConclusion\nCSS evolves constantly, with more features being added each year. It’s important to keep up with the latest features and best practices, but also keep an eye out on browser support and use progressive enhancement.\nI’m sure there are more CSS properties and selectors that aren’t included here. Feel free to let us know in the comments which properties or selectors are less known or should be used more often, but may be a bit convoluted or there is not enough buzz around them.\nFurther Reading on Smashing Magazine\n\nCSS Custom Properties In The Cascade\nSimplifying Form Styles With accent-color\nUnderstanding CSS Grid: Creating A Grid Container\nHTML5 SVG Fill Animation With CSS3 And Vanilla JavaScript\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9c50c872-d96b-41ae-8289-25b78c7f279f/lesser-known-underused-css-features-2022.jpg",
      "date_published": "2022-05-23T09:30:00.000Z",
      "date_modified": "2022-05-23T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/ultimate-free-solo-blog-setup-ghost-gatsby/",
      "url": "https://smashingmagazine.com/2022/05/ultimate-free-solo-blog-setup-ghost-gatsby/",
      "title": "The Ultimate Free Solo Blog Setup With Ghost And Gatsby",
      "summary": "In this article, we will see step-by-step how you can get the best of customization with easy admin by using Ghost as a headless CMS for a Gatsby static site — everything for free.",
      "content_html": "<p>These days it seems there are an endless number of tools and platforms for creating your own blog. However, lots of the options out there lean towards non-technical users and abstract away all of the options for customization and truly making something your own.</p>\n<p>If you are someone who knows their way around front-end development, it can be frustrating to find a solution that gives you the control you want, while removing the admin from managing your blog content.</p>\n<p>Enter the Headless Content Management System (CMS). With a Headless CMS, you can get all of the tools to create and organize your content, while maintaining 100% control of how it is delivered to your readers. In other words, you get all of the backend structure of a CMS while not being limited to its rigid front-end themes and templates.</p>\n<p>When it comes to Headless CMS systems, I’m a big fan of Ghost. Ghost is open-source and simple to use, with lots of great APIs that make it flexible to use with static site builders like Gatsby.</p>\n<p>In this article, I will show you how you can use Ghost and Gatsby together to get the ultimate personal blog setup that lets you keep full control of your front-end delivery, but leaves all the boring content management to Ghost.</p>\n<p>Oh, and it’s 100% free to set up and run. That’s because we will be running our Ghost instance locally and then deploying to Netlify, taking advantage of their generous free tier.</p>\n<p>Let’s dive in!</p>\nSetting Up Ghost And Gatsby\n<p>I’ve written a starter post on this before that covers the very basics, so I won’t go too in-depth into them here. Instead, I will focus on the more advanced issues and gotchas that come up when running a headless blog.</p>\n<p>But in short, here’s what we need to do to get a basic set-up up and running that we can work from:</p>\n<ul>\n<li>Install a local version of the Gatsby Starter Blog</li>\n<li>Install Ghost locally</li>\n<li>Change the source data from Markdown to Ghost (swap out <code>gatsby-source-file</code> system for <code>gatsby-source-ghost</code>)</li>\n<li>Modify the GraphQL queries in your <code>gatsby-node</code>, templates, and pages to match the <code>gatsby-source-ghost</code> schema</li>\n</ul>\n<p>For more details on any of these steps, you can check out <a href=\"https://hackernoon.com/how-to-build-a-gatsby-static-site-using-ghost-as-a-headless-cms-1k2o35sw\">my previous article</a>.</p>\n<p>Or you can just start from the code in <a href=\"https://github.com/gjdickens/gatsby-ghost-example\">this Github repository</a>.</p>\nDealing With Images\n<p>With the basics out of the way, the first issue we run into with a headless blog that builds locally is what to do with images.</p>\n<p>Ghost by default serves images from its own server. So when you go headless with a static site, you will run into a situation where your content is built and served from an edge provider like Netlify, but your images are still being served by your Ghost server.</p>\n<p>This isn’t ideal from a performance perspective and it makes it impossible to build and deploy your site locally (which means you would have to pay monthly fees for a Digital Ocean droplet, AWS EC2 instance, or some other server to host your Ghost instance).</p>\n<p>But we can get around that if we can find another solution to host our images &amp;mdash, and thankfully, Ghost has storage converters that enable you to store images in the cloud.</p>\n<p>For our purposes, we are going to use an <a href=\"https://ghost.org/integrations/amazon-s3/\">AWS S3 converter</a>, which enables us to host our images on AWS S3 along with Cloudfront to give us a similar performance to the rest of our content.</p>\n<p>There are two open-source options available: <a href=\"https://github.com/colinmeinke/ghost-storage-adapter-s3\">ghost-storage-adapter-s3</a> and <a href=\"https://github.com/spanishdict/ghost-s3-compat\">ghost-s3-compat</a>. I use <code>ghost-storage-adapter-s3</code> since I find the docs easier to follow and it was more recently updated.</p>\n<p>That being said, if I followed the docs exactly, I got some AWS errors, so here’s the process that I followed that worked for me:</p>\n<ul>\n<li>Create a new S3 Bucket in AWS and select Disable Static Hosting</li>\n<li>Next, create a new Cloudfront Distribution and select the S3 Bucket as the Origin</li>\n<li><p>When configuring the Cloudfront Distribution, under S3 Bucket Access:</p>\n<ul>\n<li>Select “Yes, use OAI (bucket can restrict access to only Cloudfront)”</li>\n<li>Create a New OAI</li>\n<li><p>And finally, select “Yes, update the bucket policy”</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6c5adc4a-c4af-4bfb-8a46-a2ab17498c00/1-the-ultimate-free-solo-blog-setup-with-ghost-and-gatsby.jpg\" /></p>\n<p>This creates an AWS S3 Bucket that can only be accessed via the Cloudfront Distribution that you have created.</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>Then, you just need to create an IAM User for Ghost that will enable it to write new images to your new S3 Bucket. To do this, create a new Programmatic IAM User and attach this policy to it:</p>\n<pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": \"s3:ListBucket\",\n            \"Resource\": \"arn:aws:s3:::YOUR-S3-BUCKET-NAME\"\n        },\n        {\n            \"Sid\": \"VisualEditor1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:PutObject\",\n                \"s3:GetObject\",\n                \"s3:PutObjectVersionAcl\",\n                \"s3:DeleteObject\",\n                \"s3:PutObjectAcl\"\n            ],\n            \"Resource\": \"arn:aws:s3:::YOUR-S3-BUCKET-NAME/*\"\n        }\n    ]\n} \n</code></pre>\n\n<p>With that, our AWS setup is complete, we just need to tell Ghost to read and write our images there instead of to its local server.</p>\n<p>To do that, we need to go to the folder where our Ghost instance is installed and open the file: <code>ghost.development.json</code> or<code>ghost.production.json.</code>(depending on what environment you’re currently running)</p>\n<p>Then we just need to add the following:</p>\n<pre><code>{\n  \"storage\": {\n  \"active\": \"s3\",\n  \"s3\": {\n    \"accessKeyId\": \"[key]\",\n    \"secretAccessKey\": \"[secret]\",\n    \"region\": \"[region]\",\n    \"bucket\": \"[bucket]\",\n    \"assetHost\": \"https://[subdomain].example.com\", // cloudfront\n    \"forcePathStyle\": true,\n    \"acl\": \"private\"\n  }\n}\n</code></pre>\n\n<p>The values for <code>accessKeyId</code> and <code>secretAccessKey</code> can be found from your IAM setup, while the region and bucket refer to the region and bucket name of your S3 bucket. Finally, the <code>assetHost</code> is the URL of your Cloudfront distribution.</p>\n<p>Now, if you restart your Ghost instance, you will see that any new images you save are in your S3 bucket and Ghost knows to link to them there. (Note: Ghost won’t make updates retroactively, so be sure to do this first thing after a fresh Ghost install so you don’t have to re-upload images later)</p>\nHandling Internal Links\n<p>With Images out of the way, the next tricky thing we need to think about is internal links. As you are writing content in Ghost and inserting links in Posts and Pages, Ghost will automatically add the site’s URL to all internal links.</p>\n<p>So for example, if you put a link in your blog post that goes to <code>/my-post/</code>, Ghost is going to create a link that goes to <a href=\"https://mysite.com/my-post/\">https://mysite.com/my-post/</a>.</p>\n<p>Normally, this isn’t a big deal, but for Headless blogs this causes problems. This is because your Ghost instance will be hosted somewhere separate from your front-end and in our case it won’t even be reachable online since we will be building locally.</p>\n<p>This means that we will need to go through each blog post and page to correct any internal links. Thankfully, this isn’t as hard as it sounds.</p>\n<p>First, we will add this HTML parsing script in a new file called <code>replaceLinks.js</code> and put it in a new utils folder at <code>src/utils</code>:</p>\n<pre><code>const url = require(`url`);\nconst cheerio = require('cheerio');\n\nconst replaceLinks = async (htmlInput, siteUrlString) =&gt; {\n  const siteUrl = url.parse(siteUrlString);\n  const $ = cheerio.load(htmlInput);\n  const links = $('a');\n  links.attr('href', function(i, href){\n    if (href) {\n      const hrefUrl = url.parse(href);\n      if (hrefUrl.protocol === siteUrl.protocol &amp;&amp; hrefUrl.host === siteUrl.host) {\n        return hrefUrl.path\n      }\n\n      return href;\n    }\n\n  });\n  return $.html();\n}\n\nmodule.exports = replaceLinks;\n</code></pre>\n\n<p>Then we will add the following to our <code>gatsby-node.js</code> file:</p>\n<pre><code>exports.onCreateNode = async ({ actions, node, getNodesByType }) =&gt; {\n  if (node.internal.owner !== `gatsby-source-ghost`) {\n    return\n  }\n  if (node.internal.type === 'GhostPage' || node.internal.type === 'GhostPost') {\n    const settings = getNodesByType(`GhostSettings`);\n    actions.createNodeField({\n      name: 'html',\n      value: replaceLinks(node.html, settings[0].url),\n      node\n    })\n  }\n}\n</code></pre>\n\n<p>You will see that we are adding two new packages in replaceLinks.js, so let’s start by installing those with NPM:</p>\n<pre><code>npm install --save url cheerio\n</code></pre>\n\n<p>In our <code>gatsby-node.js</code> file, we are hooking into <a href=\"https://www.gatsbyjs.com/docs/reference/config-files/gatsby-node/#onCreateNode\">Gatsby’s onCreateNode</a>, and specifically into any nodes that are created from data that comes from <code>gatsby-source-ghost</code> (as opposed to metadata that comes from our config file that we don’t care about for now).</p>\n<p>Then we are checking the node type, to filter out any nodes that are not Ghost Pages or Posts (since these are the only ones that will have links inside their content).</p>\n<p>Next, we are getting the URL of the Ghost site from the Ghost settings and passing that to our <code>removeLinks</code> function along with the HTML content from the Page/Post.</p>\n<p>In <code>replaceLinks</code>, we are using cheerio to parse the HTML. Then we can then select all of the links in this HTML content and map through their <code>href</code> attributes. We can then check if the <code>href</code> attribute matches the URL of the Ghost Site — if it does, we will replace the <code>href</code> attribute with just the URL path, which is the internal link that we are looking for (e.g. something like <code>/my-post/</code>).</p>\n<p>Finally, we are making this new HTML content available through GraphQL using <a href=\"https://www.gatsbyjs.com/docs/reference/config-files/actions/#createNodeField\">Gatsby’s createNodeField</a> (Note: we must do it this way since Gatsby does not allow you to overwrite fields at this phase in the build).</p>\n<p>Now our new HTML content will be available in our <code>blog-post.js</code> template and we can access it by changing our GraphQL query to:</p>\n<pre><code>ghostPost(slug: { eq: $slug }) {\n  id\n  title\n  slug\n  excerpt\n  published_at_pretty: published_at(formatString: \"DD MMMM, YYYY\")\n  html\n  meta_title\n  fields {\n  html\n  } \n}\n</code></pre>\n\n<p>And with that, we just need to tweak this section in the template:</p>\n<pre><code>&lt;section\n  dangerouslySetInnerHTML={{ __html: post.html }}\n  itemProp=\"articleBody\"\n/&gt;\n</code></pre>\n\n<p>To be:</p>\n<pre><code>&lt;section\n dangerouslySetInnerHTML={{ __html: post.fields.html }}\n  itemProp=\"articleBody\"\n/&gt;\n</code></pre>\n\n<p>This makes all of our internal links reachable, but we still have one more problem. All of these links are <code>&lt;a&gt;</code>anchor tags while with Gatsby we should be using Gatsby <code>Link</code> for internal links (to avoid page refreshes and to provide a more seamless experience).</p>\n<p>Thankfully, there is a Gatsby plugin that makes this really easy to solve. It’s called <a href=\"https://www.gatsbyjs.com/plugins/gatsby-plugin-catch-links/\">gatsby-plugin-catch-links</a> and it looks for any internal links and automatically replaces the &lt;a&gt; anchor tags with Gatsby &lt;Link&gt;.</p>\n<p>All we need to do is install it using NPM:</p>\n<pre><code>npm install --save gatsby-plugin-catch-links\n</code></pre>\n\n<p>And add <code>gatsby-plugin-catch-links</code> into our plugins array in our <code>gatsby-config</code> file.</p>\nAdding Templates And Styles\n<p>Now the big stuff is technically working, but we are missing out on some of the content from our Ghost instance.</p>\n<p>The Gatsby Starter Blog only has an Index page and a template for Blog Posts, while Ghost by default has Posts, Pages, as well as pages for Tags and Authors. So we need to create templates for each of these.</p>\n<p>For this, we can leverage the <a href=\"https://github.com/TryGhost/gatsby-starter-ghost\">Gatsby starter that was created by the Ghost team</a>.</p>\n<p>As a starting point for this project, we can just copy and paste a lot of the files directly into our project. Here’s what we will take:</p>\n<ul>\n<li>The entire folder <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/tree/master/src/components/common/meta\">src/components/common/meta</a> — we will copy this into our <code>src/components</code> folder (so we will now have a folder <code>src/components/meta</code>)</li>\n<li>The component files <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/components/common/Pagination.js\">Pagination.js</a> and <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/components/common/PostCard.js\">PostCard.js</a> — we will copy these into our <code>src/components</code> folder</li>\n<li>We will create a <code>src/utils</code> folder and add two files from their <code>src/utils</code> folder: <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/utils/fragments.js\">fragments.js</a> and <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/utils/siteConfig.js\">siteConfig.js</a></li>\n<li>And the following templates from their <code>src/templates</code> folder: <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/templates/tag.js\">tag.js</a>, <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/templates/page.js\">page.js</a>, <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/templates/author.js\">author.js</a>, and <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/templates/post.js\">post.js</a></li>\n</ul>\n<p>The meta files are adding JSON structured data markup to our templates. This is a great benefit that Ghost offers by default on their platform and they’ve transposed it into Gatsby as part of their starter template.</p>\n<p>Then we took the <code>Pagination</code> and <code>PostCard.js</code> components that we can drop right into our project. And with those components, we can take the template files and drop them into our project and they will work.</p>\n<p>The <code>fragments.js</code> file makes our GraphQL queries a lot cleaner for each of our pages and templates — we now just have a central source for all of our GraphQL queries. And the <code>siteConfig.js</code> file has a few Ghost configuration options that are easiest to put in a separate file.</p>\n<p>Now we will just need to install a few npm packages and update our <code>gatsby-node</code> file to use our new templates.</p>\n<p>The packages that we will need to install are <a href=\"https://www.gatsbyjs.com/plugins/gatsby-awesome-pagination/\">gatsby-awesome-pagination</a>, <code>@tryghost/helpers</code>, and <code>@tryghost/helpers-gatsby</code>.</p>\n<p>So we will do:</p>\n<pre><code>npm install --save gatsby-awesome-pagination @tryghost/helpers @tryghost/helpers-gatsby\n</code></pre>\n\n<p>Then we need to make some updates to our <code>gatsby-node</code> file.</p>\n<p>First, we will add the following new imports to the top of our file:</p>\n<pre><code>const { paginate } = require(`gatsby-awesome-pagination`);\nconst { postsPerPage } = require(`./src/utils/siteConfig`);\n</code></pre>\n\n<p>Next, in our <code>exports.createPages</code>, we will update our GraphQL query to:</p>\n<pre><code>{\n  allGhostPost(sort: { order: ASC, fields: published_at }) {\n      edges {\n          node {\n              slug\n          }\n      }\n  }\n  allGhostTag(sort: { order: ASC, fields: name }) {\n      edges {\n          node {\n              slug\n              url\n              postCount\n          }\n      }\n  }\n  allGhostAuthor(sort: { order: ASC, fields: name }) {\n      edges {\n          node {\n              slug\n              url\n              postCount\n          }\n      }\n  }\n  allGhostPage(sort: { order: ASC, fields: published_at }) {\n      edges {\n          node {\n              slug\n              url\n          }\n      }\n  }\n}\n</code></pre>\n\n<p>This will pull all of the GraphQL data we need for Gatsby to build pages based on our new templates.</p>\n<p>To do that, we will extract all of those queries and assign them to variables:</p>\n<pre><code>// Extract query results\n  const tags = result.data.allGhostTag.edges\n  const authors = result.data.allGhostAuthor.edges\n  const pages = result.data.allGhostPage.edges\n  const posts = result.data.allGhostPost.edges\n</code></pre>\n\n<p>Then we will load all of our templates:</p>\n<pre><code>// Load templates\n  const tagsTemplate = path.resolve(`./src/templates/tag.js`)\n  const authorTemplate = path.resolve(`./src/templates/author.js`)\n  const pageTemplate = path.resolve(`./src/templates/page.js`)\n  const postTemplate = path.resolve(`./src/templates/post.js`)\n</code></pre>\n\n<p>Note here that we are replacing our old <code>blog-post.js</code> template with <code>post.js</code>, so we can go ahead and delete <code>blog-post.js</code> from our templates folder.</p>\n<p>Finally, we will add this code to build pages from our templates and GraphQL data:</p>\n<pre><code>// Create tag pages\ntags.forEach(({ node }) =&gt; {\n    const totalPosts = node.postCount !== null ? node.postCount : 0\n\n    // This part here defines, that our tag pages will use\n    // a `/tag/:slug/` permalink.\n    const url = `/tag/${node.slug}`\n\n    const items = Array.from({length: totalPosts})\n\n    // Create pagination\n    paginate({\n        createPage,\n        items: items,\n        itemsPerPage: postsPerPage,\n        component: tagsTemplate,\n        pathPrefix: ({ pageNumber }) =&gt; (pageNumber === 0) ? url : `${url}/page`,\n        context: {\n            slug: node.slug\n        }\n    })\n})\n\n// Create author pages\nauthors.forEach(({ node }) =&gt; {\n    const totalPosts = node.postCount !== null ? node.postCount : 0\n\n    // This part here defines, that our author pages will use\n    // a `/author/:slug/` permalink.\n    const url = `/author/${node.slug}`\n\n    const items = Array.from({length: totalPosts})\n\n    // Create pagination\n    paginate({\n        createPage,\n        items: items,\n        itemsPerPage: postsPerPage,\n        component: authorTemplate,\n        pathPrefix: ({ pageNumber }) =&gt; (pageNumber === 0) ? url : `${url}/page`,\n        context: {\n            slug: node.slug\n        }\n    })\n})\n\n// Create pages\npages.forEach(({ node }) =&gt; {\n  // This part here defines, that our pages will use\n  // a `/:slug/` permalink.\n  node.url = `/${node.slug}/`\n\n  createPage({\n      path: node.url,\n      component: pageTemplate,\n      context: {\n          // Data passed to context is available\n          // in page queries as GraphQL variables.\n          slug: node.slug,\n      },\n  })\n})\n\n// Create post pages\nposts.forEach(({ node }) =&gt; {\n    // This part here defines, that our posts will use\n    // a `/:slug/` permalink.\n    node.url = `/${node.slug}/`\n    createPage({\n        path: node.url,\n        component: postTemplate,\n        context: {\n            // Data passed to context is available\n            // in page queries as GraphQL variables.\n            slug: node.slug,\n        },\n    })\n})\n</code></pre>\n\n<p>Here, we are looping in turn through our tags, authors, pages, and posts. For our pages and posts, we are simply creating slugs and then creating a new page using that slug and telling Gatsby what template to use.</p>\n<p>For the tags and author pages, we are also adding pagination info using <code>gatsby-awesome-pagination</code> that will be passed into the page’s <code>pageContext</code>.</p>\n<p>With that, all of our content should now be successfully built and displayed. But we could use a bit of work on styling. Since we copied over our templates directly from the Ghost Starter, we can use their styles as well.</p>\n<p>Not all of these will be applicable, but to keep things simple and not get too bogged down in styling, I took all of the styles from Ghost’s <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/styles/app.css\">src/styles/app.css</a> starting from the section Layout until the end. Then you will just paste these into the end of your <code>src/styles.css</code> file.</p>\n<p>Observe all of the styles starting with <code>kg</code> — this refers to Koening which is the name of the Ghost editor. These styles are very important for the Post and Page templates, as they have specific styles that handle the content that is created in the Ghost editor. These styles ensure that all of the content you are writing in your editor is translated over and displayed on your blog correctly.</p>\n<p>Lastly, we need our <code>page.js</code> and <code>post.js</code> files to accommodate our internal link replacement from the previous step, starting with the queries:</p>\n<p><code>Page.js</code></p>\n<pre><code>ghostPage(slug: { eq: $slug } ) {\n  ...GhostPageFields\n    fields {\n      html\n     }\n}\n</code></pre>\n\n\n<p><code>Post.js</code></p>\n<pre><code>ghostPost(slug: { eq: $slug } ) {\n  ...GhostPostFields\n    fields {\n      html\n    }\n}\n</code></pre>\n\n<p>And then the sections of our templates that are using the HTML content. So in our <code>post.js</code> we will change:</p>\n<pre><code>&lt;section\nclassName=\"content-body load-external-scripts\"\ndangerouslySetInnerHTML={{ __html: post.html }} /&gt;\n</code></pre>\n\n<p>To:</p>\n<pre><code>&lt;section\nclassName=\"content-body load-external-scripts\"\ndangerouslySetInnerHTML={{ __html: post.fields.html }} /&gt;\n</code></pre>\n\n<p>And similarly, in our <code>page.js</code> file, we will change <code>page.html</code> to <code>page.fields.html</code>.</p>\nDynamic Page Content\n<p>One of the disadvantages of Ghost when used as a traditional CMS, is that it is not possible to edit individual pieces of content on a page without going into your actual theme files and hard coding it.</p>\n<p>Say you have a section on your site that is a Call-to-Action or customer testimonials. If you want to change the text in these boxes, you will have to edit the actual HTML files.</p>\n<p>One of the great parts of going headless is that we can make dynamic content on our site that we can easily edit using Ghost. We are going to do this by using Pages that we will mark with ‘internal’ tags or tags that start with a <code>#</code> symbol.</p>\n<p>So as an example, let’s go into our Ghost backend, create a new Page called Message, type something as content, and most importantly, we will add the tag <code>#message</code>.</p>\n<p>Now let’s go back to our <code>gatsby-node</code> file. Currently, we are building pages for all of our tags and pages, but if we modify our GraphQL query in <code>createPages</code>, we can exclude everything internal:</p>\n<pre><code>allGhostTag(sort: { order: ASC, fields: name }, **filter: {slug: {regex: \"/^((?!hash-).)*$/\"}}**) {\n    edges {\n        node {\n            slug\n            url\n            postCount\n        }\n    }\n}\n//...\nallGhostPage(sort: { order: ASC, fields: published_at }, **filter: {tags: {elemMatch: {slug: {regex: \"/^((?!hash-).)*$/\"}}}}**) {\n    edges {\n        node {\n            slug\n            url\n            html\n        }\n    }\n}\n</code></pre>\n\n<p>We are adding a filter on tag slugs with the regex expression <code>/^((?!hash-).)*$/</code>. This expression is saying to exclude any tag slugs that include <code>hash-</code>.</p>\n<p>Now, we won’t be creating pages for our internal content, but we can still access it from our other GraphQL queries. So let’s add it to our <code>index.js</code> page by adding this to our query:</p>\n<pre><code>query GhostIndexQuery($limit: Int!, $skip: Int!) {\n    site {\n      siteMetadata {\n        title\n      }\n    }\n    message: ghostPage\n      (tags: {elemMatch: {slug: {eq: \"hash-message\"}}}) {\n        fields {\n          html\n        }\n    }\n    allGhostPost(\n        sort: { order: DESC, fields: [published_at] },\n        limit: $limit,\n        skip: $skip\n    ) {\n      edges {\n        node {\n          ...GhostPostFields\n        }\n      }\n    }\n  }\n</code></pre>\n\n<p>Here we are creating a new query called “message” that is looking for our internal content page by filtering specifically on the tag <code>#message</code>. Then let’s use the content from our #message page by adding this to our page:</p>\n<pre><code>//...\nconst BlogIndex = ({ data, location, pageContext }) =&gt; {\n  const siteTitle = data.site.siteMetadata?.title || `Title`\n  const posts = data.allGhostPost.edges\n  const message = data.message;\n//...\nreturn (\n  &lt;Layout location={location} title={siteTitle}&gt;\n    &lt;Seo title=\"All posts\" /&gt;\n    &lt;section\n      dangerouslySetInnerHTML={{\n        __html: message.fields.html,\n      }}\n    /&gt;\n  )\n}\n</code></pre>\n\n\n\nFinishing Touches\n<p>Now we’ve got a really great blog setup, but we can add a few final touches: pagination on our index page, a sitemap, and RSS feed.</p>\n<p>First, to add pagination, we will need to convert our <code>index.js</code> page into a template. All we need to do is cut and paste our index.js file from our <code>src/pages</code> folder over to our src/templates folder and then add this to the section where we load our templates in <code>gatsby-node.js</code>:</p>\n<pre><code>// Load templates\n const indexTemplate = path.resolve(`./src/templates/index.js`)\n</code></pre>\n\n<p>Then we need to tell Gatsby to create our index page with our <code>index.js</code> template and tell it to create the pagination context.</p>\n<p>Altogether we will add this code right after where we create our post pages:</p>\n<pre><code>// Create Index page with pagination\n  paginate({\n      createPage,\n      items: posts,\n      itemsPerPage: postsPerPage,\n      component: indexTemplate,\n      pathPrefix: ({ pageNumber }) =&gt; {\n          if (pageNumber === 0) {\n            return `/`\n          } else {\n              return `/page`\n            }\n      },\n  })\n</code></pre>\n\n<p>Now let’s open up our <code>index.js</code> template and import our Pagination component and add it right underneath where we map through our posts:</p>\n<pre><code>import Pagination from '../components/pagination'\n//...\n      &lt;/ol&gt;\n      &lt;Pagination pageContext={pageContext} /&gt;\n    &lt;/Layout&gt;\n//...\n</code></pre>\n\n<p>Then we just need to change the link to our blog posts from:</p>\n<pre><code>&lt;Link to={post.node.slug} itemProp=\"url\"&gt;\n</code></pre>\n\n<p>to: </p>\n<pre><code>&lt;Link to={`/${post.node.slug}/`} itemProp=\"url\"&gt;\n</code></pre>\n\n<p>This prevents Gatsby Link from prefixing our links on pagination pages — in other words, if we didn’t do this, a link on page 2 would show as <code>/page/2/my-post/</code> instead of just <code>/my-post/</code> like we want.</p>\n<p>With that done, let’s set up our RSS feed. This is a pretty simple step, as we can use a ready-made script from the Ghost team’s Gatsby starter. Let’s copy their file <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/src/utils/rss/generate-feed.js\">generate-feed.js</a> into our <code>src/utils</code> folder.</p>\n<p>Then let’s use it in our <code>gatsby-config.js</code> by replacing the existing <code>gatsby-plugin-feed</code> section with:</p>\n<pre><code>{\n  resolve: `gatsby-plugin-feed`,\n  options: {\n      query: `\n      {\n          allGhostSettings {\n              edges {\n                  node {\n                      title\n                      description\n                  }\n              }\n          }\n      }\n    `,\n      feeds: [\n          generateRSSFeed(config),\n      ],\n  },\n}\n</code></pre>\n\n<p>We will need to import our script along with our <code>siteConfig.js</code> file:</p>\n<pre><code>const config = require(`./src/utils/siteConfig`);\nconst generateRSSFeed = require(`./src/utils/generate-feed`);\n//...</code></pre>\n\n<p>Finally, we need to make one important addition to our <code>generate-feed.js</code> file. Right after the GraphQL query and the output field, we need to add a title field:</p>\n<pre><code>#...\noutput: `/rss.xml`,\ntitle: \"Gatsby Starter Blog RSS Feed\",\n#...\n</code></pre>\n\n<p>Without this title field, <code>gatsby-plugin-feed</code> will throw an error on the build.</p>\n<p>Then for our last finishing touch, let’s add our sitemap by installing the package <code>gatsby-plugin-advanced-sitemap</code>:</p>\n<pre><code>npm install --save gatsby-plugin-advanced-sitemap\n</code></pre>\n\n<p>And adding it to our <code>gatsby-config.js</code> file:</p>\n<pre><code>{\n  resolve: `gatsby-plugin-advanced-sitemap`,\n  options: {\n      query: `\n        {\n            allGhostPost {\n                edges {\n                    node {\n                        id\n                        slug\n                        updated_at\n                        created_at\n                        feature_image\n                    }\n                }\n            }\n            allGhostPage {\n                edges {\n                    node {\n                        id\n                        slug\n                        updated_at\n                        created_at\n                        feature_image\n                    }\n                }\n            }\n            allGhostTag {\n                edges {\n                    node {\n                        id\n                        slug\n                        feature_image\n                    }\n                }\n            }\n            allGhostAuthor {\n                edges {\n                    node {\n                        id\n                        slug\n                        profile_image\n                    }\n                }\n            }\n        }`,\n        mapping: {\n            allGhostPost: {\n                sitemap: `posts`,\n            },\n            allGhostTag: {\n                sitemap: `tags`,\n            },\n            allGhostAuthor: {\n                sitemap: `authors`,\n            },\n            allGhostPage: {\n                sitemap: `pages`,\n            },\n        },\n        exclude: [\n            `/dev-404-page`,\n            `/404`,\n            `/404.html`,\n            `/offline-plugin-app-shell-fallback`,\n        ],\n        createLinkInHead: true,\n        addUncaughtPages: true,\n    }\n}\n}\n</code></pre>\n\n<p>The query, which also comes from the <a href=\"https://github.com/TryGhost/gatsby-starter-ghost/blob/master/gatsby-config.js\">Ghost team’s Gatsby starter</a>, creates individual sitemaps for our pages and posts as well as our author and tag pages.</p>\n<p>Now, we just have to make one small change to this query to exclude our internal content. Same as we did in the prior step, we need to update these queries to filter out tag slugs that contain ‘hash-’:</p>\n<pre><code>allGhostPage(filter: {tags: {elemMatch: {slug: {regex: \"/^((?!hash-).)*$/\"}}}}) {\n    edges {\n        node {\n            id\n            slug\n            updated_at\n            created_at\n            feature_image\n        }\n    }\n}\nallGhostTag(filter: {slug: {regex: \"/^((?!hash-).)*$/\"}}) {\n    edges {\n        node {\n            id\n            slug\n            feature_image\n        }\n    }\n}\n</code></pre>\n\nWrapping Up\n<p>With that, you now have a fully functioning Ghost blog running on Gatsby that you can customize from here. You can create all of your content by running Ghost on your localhost and then when you are ready to deploy, you simply run:</p>\n<pre><code>gatsby build\n</code></pre>\n\n<p>And then you can deploy to Netlify using their command-line tool:</p>\n<pre><code>netlify deploy -p\n</code></pre>\n\n<p>Since your content only lives on your local machine, it is also a good idea to make occasional backups, which you can do using Ghost’s export feature.</p>\n<p>This exports all of your content to a json file. Note, it doesn’t include your images, but these will be saved on the cloud anyway so you don’t need to worry as much about backing these up.</p>\n<p>I hope you enjoyed this tutorial where we covered:</p>\n<ul>\n<li>Setting up Ghost and Gatsby;</li>\n<li>Handling Ghost Images using a storage converter;</li>\n<li>Converting Ghost internal links to Gatsby Link;</li>\n<li>Adding templates and styles for all Ghost content types;</li>\n<li>Using dynamic content created in Ghost;</li>\n<li>Setting up RSS feeds, sitemaps, and pagination.</li>\n</ul>\n<p>If you are interested in exploring further what’s possible with a headless CMS, check out my work at <a href=\"https://www.epilocal.com/\">Epilocal</a>, where I’m using a similar tech stack to build tools for local news and other independent, online publishers.</p>\n<p><strong>Note</strong>: <em>You can find the <a href=\"https://github.com/gjdickens/smashing-ghost-gatsby-blog\">full code for this project on Github here</a>, and you can also see a <a href=\"https://ultimate-ghost-gatsby-blog.epilocal.com/\">working demo here</a>.</em></p>\n<h3>Further Reading on Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/12/building-gatsby-themes-wordpress-powered-websites/\">Building Gatsby Themes For WordPress-Powered Websites</a>,” Paulina Hetman  </li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/10/building-api-gatsby-functions/\">Building An API With Gatsby Functions</a>,” Paul Scanlon</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2020/09/advanced-graphql-usage-gatsby-websites/\">Advanced GraphQL Usage In Gatsby Websites</a>,” Aleem Isiaka</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2021/07/gatsby-serverless-functions-international-space-station/\">Gatsby Serverless Functions And The International Space Station</a>,” Paul Scanlon</li>\n</ul>",
      "content_text": "These days it seems there are an endless number of tools and platforms for creating your own blog. However, lots of the options out there lean towards non-technical users and abstract away all of the options for customization and truly making something your own.\nIf you are someone who knows their way around front-end development, it can be frustrating to find a solution that gives you the control you want, while removing the admin from managing your blog content.\nEnter the Headless Content Management System (CMS). With a Headless CMS, you can get all of the tools to create and organize your content, while maintaining 100% control of how it is delivered to your readers. In other words, you get all of the backend structure of a CMS while not being limited to its rigid front-end themes and templates.\nWhen it comes to Headless CMS systems, I’m a big fan of Ghost. Ghost is open-source and simple to use, with lots of great APIs that make it flexible to use with static site builders like Gatsby.\nIn this article, I will show you how you can use Ghost and Gatsby together to get the ultimate personal blog setup that lets you keep full control of your front-end delivery, but leaves all the boring content management to Ghost.\nOh, and it’s 100% free to set up and run. That’s because we will be running our Ghost instance locally and then deploying to Netlify, taking advantage of their generous free tier.\nLet’s dive in!\nSetting Up Ghost And Gatsby\nI’ve written a starter post on this before that covers the very basics, so I won’t go too in-depth into them here. Instead, I will focus on the more advanced issues and gotchas that come up when running a headless blog.\nBut in short, here’s what we need to do to get a basic set-up up and running that we can work from:\n\nInstall a local version of the Gatsby Starter Blog\nInstall Ghost locally\nChange the source data from Markdown to Ghost (swap out gatsby-source-file system for gatsby-source-ghost)\nModify the GraphQL queries in your gatsby-node, templates, and pages to match the gatsby-source-ghost schema\n\nFor more details on any of these steps, you can check out my previous article.\nOr you can just start from the code in this Github repository.\nDealing With Images\nWith the basics out of the way, the first issue we run into with a headless blog that builds locally is what to do with images.\nGhost by default serves images from its own server. So when you go headless with a static site, you will run into a situation where your content is built and served from an edge provider like Netlify, but your images are still being served by your Ghost server.\nThis isn’t ideal from a performance perspective and it makes it impossible to build and deploy your site locally (which means you would have to pay monthly fees for a Digital Ocean droplet, AWS EC2 instance, or some other server to host your Ghost instance).\nBut we can get around that if we can find another solution to host our images &mdash, and thankfully, Ghost has storage converters that enable you to store images in the cloud.\nFor our purposes, we are going to use an AWS S3 converter, which enables us to host our images on AWS S3 along with Cloudfront to give us a similar performance to the rest of our content.\nThere are two open-source options available: ghost-storage-adapter-s3 and ghost-s3-compat. I use ghost-storage-adapter-s3 since I find the docs easier to follow and it was more recently updated.\nThat being said, if I followed the docs exactly, I got some AWS errors, so here’s the process that I followed that worked for me:\n\nCreate a new S3 Bucket in AWS and select Disable Static Hosting\nNext, create a new Cloudfront Distribution and select the S3 Bucket as the Origin\nWhen configuring the Cloudfront Distribution, under S3 Bucket Access:\n\nSelect “Yes, use OAI (bucket can restrict access to only Cloudfront)”\nCreate a New OAI\nAnd finally, select “Yes, update the bucket policy”\n\nThis creates an AWS S3 Bucket that can only be accessed via the Cloudfront Distribution that you have created.\n\n\n\n\nThen, you just need to create an IAM User for Ghost that will enable it to write new images to your new S3 Bucket. To do this, create a new Programmatic IAM User and attach this policy to it:\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": \"s3:ListBucket\",\n            \"Resource\": \"arn:aws:s3:::YOUR-S3-BUCKET-NAME\"\n        },\n        {\n            \"Sid\": \"VisualEditor1\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:PutObject\",\n                \"s3:GetObject\",\n                \"s3:PutObjectVersionAcl\",\n                \"s3:DeleteObject\",\n                \"s3:PutObjectAcl\"\n            ],\n            \"Resource\": \"arn:aws:s3:::YOUR-S3-BUCKET-NAME/*\"\n        }\n    ]\n} \n\n\nWith that, our AWS setup is complete, we just need to tell Ghost to read and write our images there instead of to its local server.\nTo do that, we need to go to the folder where our Ghost instance is installed and open the file: ghost.development.json orghost.production.json.(depending on what environment you’re currently running)\nThen we just need to add the following:\n{\n  \"storage\": {\n  \"active\": \"s3\",\n  \"s3\": {\n    \"accessKeyId\": \"[key]\",\n    \"secretAccessKey\": \"[secret]\",\n    \"region\": \"[region]\",\n    \"bucket\": \"[bucket]\",\n    \"assetHost\": \"https://[subdomain].example.com\", // cloudfront\n    \"forcePathStyle\": true,\n    \"acl\": \"private\"\n  }\n}\n\n\nThe values for accessKeyId and secretAccessKey can be found from your IAM setup, while the region and bucket refer to the region and bucket name of your S3 bucket. Finally, the assetHost is the URL of your Cloudfront distribution.\nNow, if you restart your Ghost instance, you will see that any new images you save are in your S3 bucket and Ghost knows to link to them there. (Note: Ghost won’t make updates retroactively, so be sure to do this first thing after a fresh Ghost install so you don’t have to re-upload images later)\nHandling Internal Links\nWith Images out of the way, the next tricky thing we need to think about is internal links. As you are writing content in Ghost and inserting links in Posts and Pages, Ghost will automatically add the site’s URL to all internal links.\nSo for example, if you put a link in your blog post that goes to /my-post/, Ghost is going to create a link that goes to https://mysite.com/my-post/.\nNormally, this isn’t a big deal, but for Headless blogs this causes problems. This is because your Ghost instance will be hosted somewhere separate from your front-end and in our case it won’t even be reachable online since we will be building locally.\nThis means that we will need to go through each blog post and page to correct any internal links. Thankfully, this isn’t as hard as it sounds.\nFirst, we will add this HTML parsing script in a new file called replaceLinks.js and put it in a new utils folder at src/utils:\nconst url = require(`url`);\nconst cheerio = require('cheerio');\n\nconst replaceLinks = async (htmlInput, siteUrlString) => {\n  const siteUrl = url.parse(siteUrlString);\n  const $ = cheerio.load(htmlInput);\n  const links = $('a');\n  links.attr('href', function(i, href){\n    if (href) {\n      const hrefUrl = url.parse(href);\n      if (hrefUrl.protocol === siteUrl.protocol && hrefUrl.host === siteUrl.host) {\n        return hrefUrl.path\n      }\n\n      return href;\n    }\n\n  });\n  return $.html();\n}\n\nmodule.exports = replaceLinks;\n\n\nThen we will add the following to our gatsby-node.js file:\nexports.onCreateNode = async ({ actions, node, getNodesByType }) => {\n  if (node.internal.owner !== `gatsby-source-ghost`) {\n    return\n  }\n  if (node.internal.type === 'GhostPage' || node.internal.type === 'GhostPost') {\n    const settings = getNodesByType(`GhostSettings`);\n    actions.createNodeField({\n      name: 'html',\n      value: replaceLinks(node.html, settings[0].url),\n      node\n    })\n  }\n}\n\n\nYou will see that we are adding two new packages in replaceLinks.js, so let’s start by installing those with NPM:\nnpm install --save url cheerio\n\n\nIn our gatsby-node.js file, we are hooking into Gatsby’s onCreateNode, and specifically into any nodes that are created from data that comes from gatsby-source-ghost (as opposed to metadata that comes from our config file that we don’t care about for now).\nThen we are checking the node type, to filter out any nodes that are not Ghost Pages or Posts (since these are the only ones that will have links inside their content).\nNext, we are getting the URL of the Ghost site from the Ghost settings and passing that to our removeLinks function along with the HTML content from the Page/Post.\nIn replaceLinks, we are using cheerio to parse the HTML. Then we can then select all of the links in this HTML content and map through their href attributes. We can then check if the href attribute matches the URL of the Ghost Site — if it does, we will replace the href attribute with just the URL path, which is the internal link that we are looking for (e.g. something like /my-post/).\nFinally, we are making this new HTML content available through GraphQL using Gatsby’s createNodeField (Note: we must do it this way since Gatsby does not allow you to overwrite fields at this phase in the build).\nNow our new HTML content will be available in our blog-post.js template and we can access it by changing our GraphQL query to:\nghostPost(slug: { eq: $slug }) {\n  id\n  title\n  slug\n  excerpt\n  published_at_pretty: published_at(formatString: \"DD MMMM, YYYY\")\n  html\n  meta_title\n  fields {\n  html\n  } \n}\n\n\nAnd with that, we just need to tweak this section in the template:\n<section\n  dangerouslySetInnerHTML={{ __html: post.html }}\n  itemProp=\"articleBody\"\n/>\n\n\nTo be:\n<section\n dangerouslySetInnerHTML={{ __html: post.fields.html }}\n  itemProp=\"articleBody\"\n/>\n\n\nThis makes all of our internal links reachable, but we still have one more problem. All of these links are <a>anchor tags while with Gatsby we should be using Gatsby Link for internal links (to avoid page refreshes and to provide a more seamless experience).\nThankfully, there is a Gatsby plugin that makes this really easy to solve. It’s called gatsby-plugin-catch-links and it looks for any internal links and automatically replaces the <a> anchor tags with Gatsby <Link>.\nAll we need to do is install it using NPM:\nnpm install --save gatsby-plugin-catch-links\n\n\nAnd add gatsby-plugin-catch-links into our plugins array in our gatsby-config file.\nAdding Templates And Styles\nNow the big stuff is technically working, but we are missing out on some of the content from our Ghost instance.\nThe Gatsby Starter Blog only has an Index page and a template for Blog Posts, while Ghost by default has Posts, Pages, as well as pages for Tags and Authors. So we need to create templates for each of these.\nFor this, we can leverage the Gatsby starter that was created by the Ghost team.\nAs a starting point for this project, we can just copy and paste a lot of the files directly into our project. Here’s what we will take:\n\nThe entire folder src/components/common/meta — we will copy this into our src/components folder (so we will now have a folder src/components/meta)\nThe component files Pagination.js and PostCard.js — we will copy these into our src/components folder\nWe will create a src/utils folder and add two files from their src/utils folder: fragments.js and siteConfig.js\nAnd the following templates from their src/templates folder: tag.js, page.js, author.js, and post.js\n\nThe meta files are adding JSON structured data markup to our templates. This is a great benefit that Ghost offers by default on their platform and they’ve transposed it into Gatsby as part of their starter template.\nThen we took the Pagination and PostCard.js components that we can drop right into our project. And with those components, we can take the template files and drop them into our project and they will work.\nThe fragments.js file makes our GraphQL queries a lot cleaner for each of our pages and templates — we now just have a central source for all of our GraphQL queries. And the siteConfig.js file has a few Ghost configuration options that are easiest to put in a separate file.\nNow we will just need to install a few npm packages and update our gatsby-node file to use our new templates.\nThe packages that we will need to install are gatsby-awesome-pagination, @tryghost/helpers, and @tryghost/helpers-gatsby.\nSo we will do:\nnpm install --save gatsby-awesome-pagination @tryghost/helpers @tryghost/helpers-gatsby\n\n\nThen we need to make some updates to our gatsby-node file.\nFirst, we will add the following new imports to the top of our file:\nconst { paginate } = require(`gatsby-awesome-pagination`);\nconst { postsPerPage } = require(`./src/utils/siteConfig`);\n\n\nNext, in our exports.createPages, we will update our GraphQL query to:\n{\n  allGhostPost(sort: { order: ASC, fields: published_at }) {\n      edges {\n          node {\n              slug\n          }\n      }\n  }\n  allGhostTag(sort: { order: ASC, fields: name }) {\n      edges {\n          node {\n              slug\n              url\n              postCount\n          }\n      }\n  }\n  allGhostAuthor(sort: { order: ASC, fields: name }) {\n      edges {\n          node {\n              slug\n              url\n              postCount\n          }\n      }\n  }\n  allGhostPage(sort: { order: ASC, fields: published_at }) {\n      edges {\n          node {\n              slug\n              url\n          }\n      }\n  }\n}\n\n\nThis will pull all of the GraphQL data we need for Gatsby to build pages based on our new templates.\nTo do that, we will extract all of those queries and assign them to variables:\n// Extract query results\n  const tags = result.data.allGhostTag.edges\n  const authors = result.data.allGhostAuthor.edges\n  const pages = result.data.allGhostPage.edges\n  const posts = result.data.allGhostPost.edges\n\n\nThen we will load all of our templates:\n// Load templates\n  const tagsTemplate = path.resolve(`./src/templates/tag.js`)\n  const authorTemplate = path.resolve(`./src/templates/author.js`)\n  const pageTemplate = path.resolve(`./src/templates/page.js`)\n  const postTemplate = path.resolve(`./src/templates/post.js`)\n\n\nNote here that we are replacing our old blog-post.js template with post.js, so we can go ahead and delete blog-post.js from our templates folder.\nFinally, we will add this code to build pages from our templates and GraphQL data:\n// Create tag pages\ntags.forEach(({ node }) => {\n    const totalPosts = node.postCount !== null ? node.postCount : 0\n\n    // This part here defines, that our tag pages will use\n    // a `/tag/:slug/` permalink.\n    const url = `/tag/${node.slug}`\n\n    const items = Array.from({length: totalPosts})\n\n    // Create pagination\n    paginate({\n        createPage,\n        items: items,\n        itemsPerPage: postsPerPage,\n        component: tagsTemplate,\n        pathPrefix: ({ pageNumber }) => (pageNumber === 0) ? url : `${url}/page`,\n        context: {\n            slug: node.slug\n        }\n    })\n})\n\n// Create author pages\nauthors.forEach(({ node }) => {\n    const totalPosts = node.postCount !== null ? node.postCount : 0\n\n    // This part here defines, that our author pages will use\n    // a `/author/:slug/` permalink.\n    const url = `/author/${node.slug}`\n\n    const items = Array.from({length: totalPosts})\n\n    // Create pagination\n    paginate({\n        createPage,\n        items: items,\n        itemsPerPage: postsPerPage,\n        component: authorTemplate,\n        pathPrefix: ({ pageNumber }) => (pageNumber === 0) ? url : `${url}/page`,\n        context: {\n            slug: node.slug\n        }\n    })\n})\n\n// Create pages\npages.forEach(({ node }) => {\n  // This part here defines, that our pages will use\n  // a `/:slug/` permalink.\n  node.url = `/${node.slug}/`\n\n  createPage({\n      path: node.url,\n      component: pageTemplate,\n      context: {\n          // Data passed to context is available\n          // in page queries as GraphQL variables.\n          slug: node.slug,\n      },\n  })\n})\n\n// Create post pages\nposts.forEach(({ node }) => {\n    // This part here defines, that our posts will use\n    // a `/:slug/` permalink.\n    node.url = `/${node.slug}/`\n    createPage({\n        path: node.url,\n        component: postTemplate,\n        context: {\n            // Data passed to context is available\n            // in page queries as GraphQL variables.\n            slug: node.slug,\n        },\n    })\n})\n\n\nHere, we are looping in turn through our tags, authors, pages, and posts. For our pages and posts, we are simply creating slugs and then creating a new page using that slug and telling Gatsby what template to use.\nFor the tags and author pages, we are also adding pagination info using gatsby-awesome-pagination that will be passed into the page’s pageContext.\nWith that, all of our content should now be successfully built and displayed. But we could use a bit of work on styling. Since we copied over our templates directly from the Ghost Starter, we can use their styles as well.\nNot all of these will be applicable, but to keep things simple and not get too bogged down in styling, I took all of the styles from Ghost’s src/styles/app.css starting from the section Layout until the end. Then you will just paste these into the end of your src/styles.css file.\nObserve all of the styles starting with kg — this refers to Koening which is the name of the Ghost editor. These styles are very important for the Post and Page templates, as they have specific styles that handle the content that is created in the Ghost editor. These styles ensure that all of the content you are writing in your editor is translated over and displayed on your blog correctly.\nLastly, we need our page.js and post.js files to accommodate our internal link replacement from the previous step, starting with the queries:\nPage.js\nghostPage(slug: { eq: $slug } ) {\n  ...GhostPageFields\n    fields {\n      html\n     }\n}\n\n\n\nPost.js\nghostPost(slug: { eq: $slug } ) {\n  ...GhostPostFields\n    fields {\n      html\n    }\n}\n\n\nAnd then the sections of our templates that are using the HTML content. So in our post.js we will change:\n<section\nclassName=\"content-body load-external-scripts\"\ndangerouslySetInnerHTML={{ __html: post.html }} />\n\n\nTo:\n<section\nclassName=\"content-body load-external-scripts\"\ndangerouslySetInnerHTML={{ __html: post.fields.html }} />\n\n\nAnd similarly, in our page.js file, we will change page.html to page.fields.html.\nDynamic Page Content\nOne of the disadvantages of Ghost when used as a traditional CMS, is that it is not possible to edit individual pieces of content on a page without going into your actual theme files and hard coding it.\nSay you have a section on your site that is a Call-to-Action or customer testimonials. If you want to change the text in these boxes, you will have to edit the actual HTML files.\nOne of the great parts of going headless is that we can make dynamic content on our site that we can easily edit using Ghost. We are going to do this by using Pages that we will mark with ‘internal’ tags or tags that start with a # symbol.\nSo as an example, let’s go into our Ghost backend, create a new Page called Message, type something as content, and most importantly, we will add the tag #message.\nNow let’s go back to our gatsby-node file. Currently, we are building pages for all of our tags and pages, but if we modify our GraphQL query in createPages, we can exclude everything internal:\nallGhostTag(sort: { order: ASC, fields: name }, **filter: {slug: {regex: \"/^((?!hash-).)*$/\"}}**) {\n    edges {\n        node {\n            slug\n            url\n            postCount\n        }\n    }\n}\n//...\nallGhostPage(sort: { order: ASC, fields: published_at }, **filter: {tags: {elemMatch: {slug: {regex: \"/^((?!hash-).)*$/\"}}}}**) {\n    edges {\n        node {\n            slug\n            url\n            html\n        }\n    }\n}\n\n\nWe are adding a filter on tag slugs with the regex expression /^((?!hash-).)*$/. This expression is saying to exclude any tag slugs that include hash-.\nNow, we won’t be creating pages for our internal content, but we can still access it from our other GraphQL queries. So let’s add it to our index.js page by adding this to our query:\nquery GhostIndexQuery($limit: Int!, $skip: Int!) {\n    site {\n      siteMetadata {\n        title\n      }\n    }\n    message: ghostPage\n      (tags: {elemMatch: {slug: {eq: \"hash-message\"}}}) {\n        fields {\n          html\n        }\n    }\n    allGhostPost(\n        sort: { order: DESC, fields: [published_at] },\n        limit: $limit,\n        skip: $skip\n    ) {\n      edges {\n        node {\n          ...GhostPostFields\n        }\n      }\n    }\n  }\n\n\nHere we are creating a new query called “message” that is looking for our internal content page by filtering specifically on the tag #message. Then let’s use the content from our #message page by adding this to our page:\n//...\nconst BlogIndex = ({ data, location, pageContext }) => {\n  const siteTitle = data.site.siteMetadata?.title || `Title`\n  const posts = data.allGhostPost.edges\n  const message = data.message;\n//...\nreturn (\n  <Layout location={location} title={siteTitle}>\n    <Seo title=\"All posts\" />\n    <section\n      dangerouslySetInnerHTML={{\n        __html: message.fields.html,\n      }}\n    />\n  )\n}\n\n\n\n\nFinishing Touches\nNow we’ve got a really great blog setup, but we can add a few final touches: pagination on our index page, a sitemap, and RSS feed.\nFirst, to add pagination, we will need to convert our index.js page into a template. All we need to do is cut and paste our index.js file from our src/pages folder over to our src/templates folder and then add this to the section where we load our templates in gatsby-node.js:\n// Load templates\n const indexTemplate = path.resolve(`./src/templates/index.js`)\n\n\nThen we need to tell Gatsby to create our index page with our index.js template and tell it to create the pagination context.\nAltogether we will add this code right after where we create our post pages:\n// Create Index page with pagination\n  paginate({\n      createPage,\n      items: posts,\n      itemsPerPage: postsPerPage,\n      component: indexTemplate,\n      pathPrefix: ({ pageNumber }) => {\n          if (pageNumber === 0) {\n            return `/`\n          } else {\n              return `/page`\n            }\n      },\n  })\n\n\nNow let’s open up our index.js template and import our Pagination component and add it right underneath where we map through our posts:\nimport Pagination from '../components/pagination'\n//...\n      </ol>\n      <Pagination pageContext={pageContext} />\n    </Layout>\n//...\n\n\nThen we just need to change the link to our blog posts from:\n<Link to={post.node.slug} itemProp=\"url\">\n\n\nto: \n<Link to={`/${post.node.slug}/`} itemProp=\"url\">\n\n\nThis prevents Gatsby Link from prefixing our links on pagination pages — in other words, if we didn’t do this, a link on page 2 would show as /page/2/my-post/ instead of just /my-post/ like we want.\nWith that done, let’s set up our RSS feed. This is a pretty simple step, as we can use a ready-made script from the Ghost team’s Gatsby starter. Let’s copy their file generate-feed.js into our src/utils folder.\nThen let’s use it in our gatsby-config.js by replacing the existing gatsby-plugin-feed section with:\n{\n  resolve: `gatsby-plugin-feed`,\n  options: {\n      query: `\n      {\n          allGhostSettings {\n              edges {\n                  node {\n                      title\n                      description\n                  }\n              }\n          }\n      }\n    `,\n      feeds: [\n          generateRSSFeed(config),\n      ],\n  },\n}\n\n\nWe will need to import our script along with our siteConfig.js file:\nconst config = require(`./src/utils/siteConfig`);\nconst generateRSSFeed = require(`./src/utils/generate-feed`);\n//...\n\nFinally, we need to make one important addition to our generate-feed.js file. Right after the GraphQL query and the output field, we need to add a title field:\n#...\noutput: `/rss.xml`,\ntitle: \"Gatsby Starter Blog RSS Feed\",\n#...\n\n\nWithout this title field, gatsby-plugin-feed will throw an error on the build.\nThen for our last finishing touch, let’s add our sitemap by installing the package gatsby-plugin-advanced-sitemap:\nnpm install --save gatsby-plugin-advanced-sitemap\n\n\nAnd adding it to our gatsby-config.js file:\n{\n  resolve: `gatsby-plugin-advanced-sitemap`,\n  options: {\n      query: `\n        {\n            allGhostPost {\n                edges {\n                    node {\n                        id\n                        slug\n                        updated_at\n                        created_at\n                        feature_image\n                    }\n                }\n            }\n            allGhostPage {\n                edges {\n                    node {\n                        id\n                        slug\n                        updated_at\n                        created_at\n                        feature_image\n                    }\n                }\n            }\n            allGhostTag {\n                edges {\n                    node {\n                        id\n                        slug\n                        feature_image\n                    }\n                }\n            }\n            allGhostAuthor {\n                edges {\n                    node {\n                        id\n                        slug\n                        profile_image\n                    }\n                }\n            }\n        }`,\n        mapping: {\n            allGhostPost: {\n                sitemap: `posts`,\n            },\n            allGhostTag: {\n                sitemap: `tags`,\n            },\n            allGhostAuthor: {\n                sitemap: `authors`,\n            },\n            allGhostPage: {\n                sitemap: `pages`,\n            },\n        },\n        exclude: [\n            `/dev-404-page`,\n            `/404`,\n            `/404.html`,\n            `/offline-plugin-app-shell-fallback`,\n        ],\n        createLinkInHead: true,\n        addUncaughtPages: true,\n    }\n}\n}\n\n\nThe query, which also comes from the Ghost team’s Gatsby starter, creates individual sitemaps for our pages and posts as well as our author and tag pages.\nNow, we just have to make one small change to this query to exclude our internal content. Same as we did in the prior step, we need to update these queries to filter out tag slugs that contain ‘hash-’:\nallGhostPage(filter: {tags: {elemMatch: {slug: {regex: \"/^((?!hash-).)*$/\"}}}}) {\n    edges {\n        node {\n            id\n            slug\n            updated_at\n            created_at\n            feature_image\n        }\n    }\n}\nallGhostTag(filter: {slug: {regex: \"/^((?!hash-).)*$/\"}}) {\n    edges {\n        node {\n            id\n            slug\n            feature_image\n        }\n    }\n}\n\n\nWrapping Up\nWith that, you now have a fully functioning Ghost blog running on Gatsby that you can customize from here. You can create all of your content by running Ghost on your localhost and then when you are ready to deploy, you simply run:\ngatsby build\n\n\nAnd then you can deploy to Netlify using their command-line tool:\nnetlify deploy -p\n\n\nSince your content only lives on your local machine, it is also a good idea to make occasional backups, which you can do using Ghost’s export feature.\nThis exports all of your content to a json file. Note, it doesn’t include your images, but these will be saved on the cloud anyway so you don’t need to worry as much about backing these up.\nI hope you enjoyed this tutorial where we covered:\n\nSetting up Ghost and Gatsby;\nHandling Ghost Images using a storage converter;\nConverting Ghost internal links to Gatsby Link;\nAdding templates and styles for all Ghost content types;\nUsing dynamic content created in Ghost;\nSetting up RSS feeds, sitemaps, and pagination.\n\nIf you are interested in exploring further what’s possible with a headless CMS, check out my work at Epilocal, where I’m using a similar tech stack to build tools for local news and other independent, online publishers.\nNote: You can find the full code for this project on Github here, and you can also see a working demo here.\nFurther Reading on Smashing Magazine\n\n“Building Gatsby Themes For WordPress-Powered Websites,” Paulina Hetman  \n“Building An API With Gatsby Functions,” Paul Scanlon\n“Advanced GraphQL Usage In Gatsby Websites,” Aleem Isiaka\n“Gatsby Serverless Functions And The International Space Station,” Paul Scanlon\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/dee282b4-4b4e-4b89-b8e1-4d319ce85367/ultimate-free-solo-blog-setup-ghost-gatsby.jpg",
      "date_published": "2022-05-20T08:30:00.000Z",
      "date_modified": "2022-05-20T08:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/kubernetes-front-end-developers/",
      "url": "https://smashingmagazine.com/2022/05/kubernetes-front-end-developers/",
      "title": "Kubernetes For Frontend Developers",
      "summary": "In this article, Benjamin Ajibade introduces Kubernetes to front-end engineers and explaines why Kubernetes is integral in a production-ready microservice architecture. Some key terms that are important for team collaboration will be discussed and conclude the post with a quick deployment to getting started as a beginner.",
      "content_html": "<p>Kubernetes, also known as k8s, was coined by a Google engineer in mid-2014 and is now widely used throughout the developer ecosystem. According to the <a href=\"https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\">Kuberenetes Documentation</a>: </p>\n<blockquote>“Kubernetes is an open-source platform for managing containerized workloads and services that allow declarative configuration and automation. It enables developers to build containerized applications that can react to critical application needs in the event of a traffic spike or a service failure.”</blockquote> \n\nDockers and Containers\n<p>Docker is the most popular container technology tool. It is a tool used for building, running, and deploying containerized applications. An application’s code, libraries, tools, dependencies, and other files are all contained in a Docker image; when a user executes an image, it turns into a container. An image built will always only run one container (an image can have multiple layers and then be used to build multiple images, but an image will always only create one container).</p>\n<p>Docker images can be likened to a template of instructions to build a container. It helps to abstract application code from the underlying infrastructure, simplifying version management and enabling portability across various deployment environments.</p>\n<p>Basically, <strong>a containerized application is stateless</strong>, i.e. it does not retain session information. And since multiple instances of a container image can run simultaneously, developers use containers as instances that can be initiated to replace failed ones without disruption to the application’s operation.</p>\n<p>In terms of resource management, it is very important to know that the use of resources is highly constrained, unlike VMs, as its access to physical resources (memory, storage, and CPU) is limited by the host OS. As a result, containers are lighter and more scalable than virtual machines.</p>\n<blockquote>“Containers are the foundation of modern application design and development, which means it will be almost impossible for any IT organization to avoid a container commitment.”<br /><br />— Tom Nolle, “<a href=\"https://searchitoperations.techtarget.com/feature/Container-deployment-and-the-container-management-system\">Explore Container Deployment Benefits And Core Components</a>”</blockquote>\n\n<p>For a container deployment, there is the server for Container hosting with OS support together with a container management tool like Docker or ContainerD. When there is a need for application capabilities, such as the ability to scale under load and recover from hardware failures without disruption or human intervention, then an orchestration tool would be needed.</p>\n<p>Kubernetes(K8s) is <strong>a container orchestration tool</strong> that takes over tasks that would otherwise require manual intervention, preventing lots of time-consuming routine checks, changes in configuration, updates, and other software maintenance work. Using Kubernetes deployment would significantly help to automate such repetitive processes and makes loads of manual jobs a breeze when working on a production-ready application. </p>\nWhy Would A Frontend Developer Use Kubernetes?\n<p>For an improved digital experience, Microservices have been successfully implemented by tech giants, such as Netflix, Google, Amazon, and other industry leaders; businesses see this architecture as a cost-effective means of expanding their operations. On the other hand, microservice architecture has gained popularity in recent years due to its effectiveness in developing, deploying, and scaling multiple application backends.</p>\n<p>Adoption of the Microservice architecture in production would be generally considered good practice when an application is simply getting too large for any single developer to fully maintain, or there is an increase in orchestration and interaction between services after every release. It is important to know that not all levels of business organization would be required to use microservices to benefit from using Kubernetes.</p>\nK8s Or Docker Compose: Which One Should I Use?\n<p>Docker-compose is a tool that accepts a YAML file that specifies a cross container application and automates the creation and removal of all those containers without the need to write several docker commands for each one. It should be used for testing and development.</p>\n<p>Kubernetes, on the other hand, is a platform for managing production-ready containerized workloads and services that allows for declarative setup as well as automation.</p>\nGetting Familiar With Terminology\n<p>To utilize Kubernetes efficiently, one must have a reasonable understanding of its terminologies. Here are a few key terminologies to get you started:</p>\n<ul>\n<li><strong>Docker</strong><br />A container resource referring to a Docker image and provides all of the necessary configurations that Kubernetes needs (deploy, execute, expose, monitor, and safeguard the Docker container).</li>\n<li><strong>Container</strong><br />The fundamental concept is the Container — since Kubernetes is a container orchestration tool. A container is a standard unit of software that packages up code and all that the application depends on to run reliably.</li>\n<li><strong>Pods</strong><br />A pod is a collection of one or more containers with common storage and network resources, as well as a set of rules for how the containers should be run. It is the smallest deployable unit that Kubernetes allows you to create and manage. </li>\n<li><strong>Nodes</strong><br />The components (physical computers or virtual machines) that run these applications are known as worker nodes. Worker nodes carry out the tasks that the master node has assigned to them.</li>\n<li><strong>Cluster</strong><br />A cluster is a collection of nodes that are used to run containerized applications. A Kubernetes cluster is made up of a set of master nodes and a number of worker nodes. Minikube is highly suggested for new users who want to start building a Kubernetes cluster.</li>\n<li><strong>Objects</strong><br />Kubernetes objects are persistent entities in the Kubernetes system. Kubernetes uses objects to represent the state of our cluster. They describe the desired state for running applications, the available resources for the running applications, and the policies guiding these applications. It holds information about cluster workload.</li>\n<li><strong>Namespaces</strong><br />Namespaces are a way to distribute cluster resources needed for use in situations with various teams or projects with a large number of users.</li>\n<li><strong>Ingress Controller</strong><br />Kubernetes Ingress is an API object that manages external users’ access to services in a Kubernetes cluster by providing routing rules. This external request is frequently made using HTTPS/HTTP. You can easily set up rules for traffic routing with Ingress without having to create a bunch of Load Balancers or expose each service on the node.</li>\n</ul>\n<blockquote>“Enterprises are drifting further away from monoliths and closer toward a microservice architecture for every app, website, and digital experience they develop.”<br /><br />— Kaya Ismail (2018)</blockquote>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1b88d678-9006-4c90-a8bb-4d7206f74976/5-v2-kubernetes-front-end-developers.jpg\" /></p>\n<p>Monolithic architecture is a common way of building an infrastructure as a single unit that includes a user interface, a server-side framework, and a relational database. Since all of the app’s layers and components are interconnected, changing one component would require you to update the entire app.</p>\n<p>Another approach is the Microservice architecture. By using the microservices approach, a complex program is broken down into loosely linked parts. Loose coupling establishes a system in which each service or component has its own logically distinct lifecycle, protocols, and database. This standalone component can be designed, implemented, scaled, and managed separately from the rest of the app which will continue to function normally.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/dcd3ca40-83fa-4125-9bcf-fba3819d0395/4-kubernetes-front-end-developers.jpg\" /></p>\n<p>We begin to wonder how this can interact, as we consider the two methods. This is where containerization comes in: each stand-alone unit is packed into a container which is then enclosed in a pod (which contains multiple containers that are shared in a cluster of nodes). When a Pod contains several containers, they are handled as a single entity, and all containers in the Pod share the Pod’s resources, including namespace, IP address, and network ports at the same time.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4ffe0c25-5cac-4e6b-92b4-204af513ee47/2-kubernetes-front-end-developers.jpg\" /></p>\n<p>(K8s) is a container-centric infrastructure manager. It manages container lifecycles, that is to say, it optimizes container orchestration deployment by provisioning Pods (creating and destroying them) based on the application’s requirements. Kubernetes exposes pods to requests using the Service object which maps IP addresses to a collection of pods. The service ensures routes to the Pods from any authorized source (within or outside the cluster) through a designated port.</p>\n<p>As for frontend developers, we do need to have basic knowledge of setting up the inter-communication between this infrastructure and services. A clear understanding of how things function is essential.</p>\n<blockquote> Often referred to as an Ops problem and that by giving it up, we are missing out on opportunities to understand the possibilities of what we create and how we can improve its availability in production.</blockquote>\n\n<p>While the Ops role should be in charge of cluster setup, configuration, and management, the developer should be aware of and responsible for putting up the bare minimum necessary to run their app.</p>\n<p>As a result, understanding the fundamentals of Kubernetes will allow you to optimize the configuration of your application and make it more scalable; and such to participate in the release process of what they created.</p>\n<p>Teams would benefit from having a general understanding of Kubernetes around the software stack while sharing terminologies and addressing their project. It also <strong>allows you complete control over the entire project lifecycle</strong> — from code to implementation — allowing you to test the application’s deployment, understand how your project should be deployed, and assist in maintaining the layer as well as specifying the environment. </p>\n<p>A good example is when a friend Cari (software engineer) described her experience working with a team a few years ago, where the backend engineers were only interested in getting involved in frontend development and Kubernetes alone. They willingly chose to learn Kubernetes and wouldn’t want to directly work with the backend layers, but only consume it. The team enjoyed having the ability to define how their application is deployed on Kubernetes.</p>\n<p>Having this control over their project helps them be a part of the release journey of their projects, and more importantly will allow you to optimize the configuration of your application and make it more scalable. Also, understanding the production-deployment configuration allows developers to <strong>spot and fix crucial micro performance issues</strong> such as caching, amount of requests, and time-to-first-byte, as well as knowing how staging/testing differs from production before releasing the app.</p>\n<p>There are scenarios where the terminology often overlaps between front-end and back-end teams, for example:</p>\n<ul>\n<li><strong>port and services</strong><br />When specifying a version of an app deployed, and then the ports exposed e.g. “we can interact with our application using the service name and port xx: xx”.</li>\n<li><strong>namespaces</strong><br />Knowing that our project sits in a namespace on Kubernetes. Namespaces are a way for multiple users to share cluster resources.</li>\n<li><strong>RBAC</strong> (Role-Based Access and Control)<br />Knowing how the access control permissions on Kubernetes affect your projects.</li>\n</ul>\n<p>An understanding of how Docker images build and run will allow teams to clearly communicate the requirements for each application in the cluster.</p>\nDeployment and service\n<p>The resources that you identified in a configuration are created by a deployment. All of the resources that make up a deployment are specified in a configuration file. </p>\n<p>To make a deployment, you’ll need a configuration file. YAML syntax is required for a configuration file. It contains fields, such as version, name, kind, replicas field (the desired number of Pod resources), selector, and the label field, etc, as shown below:</p>\n<pre><code>....\n  name: \nspec:\n  selector:\n    matchLabels:\n      app: \n      tier: \n\n  replicas:\n    metadata:\n      labels:\n        app: \n        tier: \n\n    spec:\n      containers:\n        - name: \n          image: \n          ...</code></pre>\n\n<p>A Kubernetes Service, on the other hand, is an abstraction layer that describes a logical group of Pods and allows for external traffic exposure, load balancing, and service discovery for such Pods.</p>\n<h3>Updating a Deployment</h3>\n<p>A deployment can be updated to the desired object state from the current state, this is often done declaratively by updating the objects of interest in the configuration file and then deploying as an update. With a rolling update deployment strategy, old Pod resources will be gradually replaced with new ones. This means that two Pod resource versions can be deployed and accessed at the same time while ensuring that there is no downtime.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0318315c-b1a9-4ac1-bb02-3a24d620367f/3-kubernetes-front-end-developers.png\" /></p>\nBackend Service Object\n<p>In this article, the Pods in the front-end Deployment will run an Nginx image that will be configured to proxy requests to a Service with the key of <code>app: backend</code>. We assume the backend team has already ensured that their pods are running on the cluster, and that we only want to create and connect our app via a deployment to the backend. </p>\n<p>In order to allow access to the backend application, we need to create a service for it. A Service creates a persistent IP address and DNS name entry for the application in question which makes it accessible to other pods. It also uses selectors to find the Pods that it routes traffic to.</p>\n<p>Here is an example of a <code>backend-service.yaml</code> configuration file which would expose the backend app to other pods in the cluster. Below is the sample backend service configuration file:</p>\n<pre><code>---\napiVersion: v1\nkind: Service\nmetadata:\n  name: backend-serv\nspec:\n  selector:\n    app: hello\n    tier: backend\n  ports:\n  - protocol: TCP\n    port: 80\n    ...</code></pre>\n\n<p>The above YAML file shows that the service is configured to route traffic to the Pods that have the label <code>app: hello</code> and <code>tier: backend</code> of the cluster through port <code>80</code> only.</p>\nCreating the Frontend\n<p>You typically create a container image of your application and push it to a registry (e.g. docker registry) before referring to it in a Pod. Since this is an introductory article, we will make use of a sample front-end image from the <a href=\"http://gcr.io/google-samples/hello-frontend:1.0\">google container repository</a>. The frontend sends requests to the backend worker Pods by using the DNS name given to the backend Service which is the value of the name field in the <code>backend-service.yaml</code> configuration file.</p>\n<p>The Pods in the front-end Deployment run an <code>Nginx</code> image that is configured to proxy requests to the backend Service. The configuration file specifies the server and the listening port. When an ingress is created in Kubernetes, <code>nginx</code> upstreams point to services that match specified selectors.</p>\n<p><strong><code>nginx.conf</code> configuration file</strong></p>\n<pre><code>upstream Backend {   \n    server backend-serv;\n}\nserver {\n    listen 80;\n    location / {\n                proxy_pass http://Backend;\n    }\n}\n</code></pre>\n\n<p>Note that the internal DNS name used by the backend Service inside Kubernetes is used to specify.</p>\n<p>The frontend, like the backend, has a Deployment and a Service. The setup for the front-end Service has <code>type: LoadBalancer</code> which means that the Service would use a load balancer provisioned by the cloud service provider and would be reachable from outside the cluster.</p>\n<pre><code>---\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend-serv\nspec:\n  selector:\n    app: hello\n    tier: frontend\n  ports:\n  - protocol: \"TCP\"\n    port: 80\n    targetPort: 80\n  type: LoadBalancer\n...</code></pre>\n\n<pre><code>---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend-depl\nspec:\n  selector:\n    matchLabels:\n      app: hello\n      tier: frontend\n      track: stable\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hello\n        tier: frontend\n        track: stable\n    spec:\n      containers:\n        - name: nginx\n          image: \"gcr.io/google-samples/hello-frontend:1.0\"\n          ...</code></pre>\n\n<h3>Create The Front-End Deployment And Service</h3>\n<p>Now, that the configuration files are ready, we can run a <code>kubectl apply</code> command to create the resources as specified:</p>\n<pre><code>kubectl apply -f [insert URL to saved frontend-deployment YAML file] \n\nkubectl apply -f [insert URL to saved frontend-service YAML file]</code></pre>\n\n<p>The output verifies that both resources were created:</p>\n<pre><code>deployment.apps/frontend-depl created\nservice/frontend-serv created</code></pre>\n\n\n\nInteracting with the Front-end Deployment and Service\n<p>You can use this command to obtain the external IP address, once you’ve created a <code>LoadBalancer</code> Service:</p>\n<p><code>kubectl get service frontend-serv --watch</code></p>\n<p>This shows the front-end Service’s configurations and monitors for changes. The internal cluster IP would be immediately provisioned, while the external IP address is initially marked as pending:</p>\n<div>\n<pre><code>  NAME          TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)  AGE\nfrontend-serv   LoadBalancer   10.xx.xxx.xxx   &lt;pending&gt;     80/TCP   10s</code></pre>\n</div>\n\n<p>As soon as an external IP is provisioned, however, the configuration updates to include the new IP under the<code>EXTERNAL-IP</code>heading:</p>\n<div>\n<pre><code>NAME       TYPE           CLUSTER-IP      EXTERNAL-IP        PORT(S)  AGE\nfrontend-serv   LoadBalancer   10.xx.xxx.xx   XXX.XXX.XXX.XXX    80/TCP   1m</code></pre>\n</div>\n\n<p>The provisioned IP can be used to communicate with the front-end service from outside the cluster. We can now send traffic through the frontend, because the frontend and backend are now linked. Using the curl command on the external IP of your front-end Service, we can reach the endpoint.</p>\nConclusion\n<p>A company-wide vision for providing reliable software may be driven by a broad understanding of Kubernetes and how your application works on Kubernetes. The microservices architecture is more beneficial for complex and evolving applications. It offers effective solutions for handling a complicated system of different functions and services within one application.</p>\n<p> Microservices are ideal when it comes to the platforms, covering many user journeys and workflows. But without proper microservices expertise, applying this model would be impossible.</p>\n<p>However, it is critical to understand that the microservice design is not appropriate for every level of business organization. You should start with a monolith if your business idea is new and you want to validate it. For a small technical team attempting to design a basic and lightweight application, microservices can be considered superfluous, since monolith can be deployed via Kube without any problems, and you can still benefit from replication options and other features.</p>\n<h3>Further Reading On Smashing Magazine</h3>\n<ul>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/01/from-chaos-to-system-design-teams/\">From Chaos To System In Design Teams</a>,” Javier Cuello</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/02/recipe-good-design-system/\">A Recipe For A Good Design System</a>,” Atila Fassina</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2017/10/large-scale-design-system-us-government/\">Building A Large-Scale Design System For The U.S. Government (Case Study)</a>,” Maya Benari</li>\n<li>“<a href=\"https://www.smashingmagazine.com/2022/03/easy-information-architecture/\">How To Create An Information Architecture That Is Easy To Use</a>,” Paul Boag</li>\n</ul>",
      "content_text": "Kubernetes, also known as k8s, was coined by a Google engineer in mid-2014 and is now widely used throughout the developer ecosystem. According to the Kuberenetes Documentation: \n“Kubernetes is an open-source platform for managing containerized workloads and services that allow declarative configuration and automation. It enables developers to build containerized applications that can react to critical application needs in the event of a traffic spike or a service failure.” \n\nDockers and Containers\nDocker is the most popular container technology tool. It is a tool used for building, running, and deploying containerized applications. An application’s code, libraries, tools, dependencies, and other files are all contained in a Docker image; when a user executes an image, it turns into a container. An image built will always only run one container (an image can have multiple layers and then be used to build multiple images, but an image will always only create one container).\nDocker images can be likened to a template of instructions to build a container. It helps to abstract application code from the underlying infrastructure, simplifying version management and enabling portability across various deployment environments.\nBasically, a containerized application is stateless, i.e. it does not retain session information. And since multiple instances of a container image can run simultaneously, developers use containers as instances that can be initiated to replace failed ones without disruption to the application’s operation.\nIn terms of resource management, it is very important to know that the use of resources is highly constrained, unlike VMs, as its access to physical resources (memory, storage, and CPU) is limited by the host OS. As a result, containers are lighter and more scalable than virtual machines.\n“Containers are the foundation of modern application design and development, which means it will be almost impossible for any IT organization to avoid a container commitment.”— Tom Nolle, “Explore Container Deployment Benefits And Core Components”\n\nFor a container deployment, there is the server for Container hosting with OS support together with a container management tool like Docker or ContainerD. When there is a need for application capabilities, such as the ability to scale under load and recover from hardware failures without disruption or human intervention, then an orchestration tool would be needed.\nKubernetes(K8s) is a container orchestration tool that takes over tasks that would otherwise require manual intervention, preventing lots of time-consuming routine checks, changes in configuration, updates, and other software maintenance work. Using Kubernetes deployment would significantly help to automate such repetitive processes and makes loads of manual jobs a breeze when working on a production-ready application. \nWhy Would A Frontend Developer Use Kubernetes?\nFor an improved digital experience, Microservices have been successfully implemented by tech giants, such as Netflix, Google, Amazon, and other industry leaders; businesses see this architecture as a cost-effective means of expanding their operations. On the other hand, microservice architecture has gained popularity in recent years due to its effectiveness in developing, deploying, and scaling multiple application backends.\nAdoption of the Microservice architecture in production would be generally considered good practice when an application is simply getting too large for any single developer to fully maintain, or there is an increase in orchestration and interaction between services after every release. It is important to know that not all levels of business organization would be required to use microservices to benefit from using Kubernetes.\nK8s Or Docker Compose: Which One Should I Use?\nDocker-compose is a tool that accepts a YAML file that specifies a cross container application and automates the creation and removal of all those containers without the need to write several docker commands for each one. It should be used for testing and development.\nKubernetes, on the other hand, is a platform for managing production-ready containerized workloads and services that allows for declarative setup as well as automation.\nGetting Familiar With Terminology\nTo utilize Kubernetes efficiently, one must have a reasonable understanding of its terminologies. Here are a few key terminologies to get you started:\n\nDockerA container resource referring to a Docker image and provides all of the necessary configurations that Kubernetes needs (deploy, execute, expose, monitor, and safeguard the Docker container).\nContainerThe fundamental concept is the Container — since Kubernetes is a container orchestration tool. A container is a standard unit of software that packages up code and all that the application depends on to run reliably.\nPodsA pod is a collection of one or more containers with common storage and network resources, as well as a set of rules for how the containers should be run. It is the smallest deployable unit that Kubernetes allows you to create and manage. \nNodesThe components (physical computers or virtual machines) that run these applications are known as worker nodes. Worker nodes carry out the tasks that the master node has assigned to them.\nClusterA cluster is a collection of nodes that are used to run containerized applications. A Kubernetes cluster is made up of a set of master nodes and a number of worker nodes. Minikube is highly suggested for new users who want to start building a Kubernetes cluster.\nObjectsKubernetes objects are persistent entities in the Kubernetes system. Kubernetes uses objects to represent the state of our cluster. They describe the desired state for running applications, the available resources for the running applications, and the policies guiding these applications. It holds information about cluster workload.\nNamespacesNamespaces are a way to distribute cluster resources needed for use in situations with various teams or projects with a large number of users.\nIngress ControllerKubernetes Ingress is an API object that manages external users’ access to services in a Kubernetes cluster by providing routing rules. This external request is frequently made using HTTPS/HTTP. You can easily set up rules for traffic routing with Ingress without having to create a bunch of Load Balancers or expose each service on the node.\n\n“Enterprises are drifting further away from monoliths and closer toward a microservice architecture for every app, website, and digital experience they develop.”— Kaya Ismail (2018)\n\n\nMonolithic architecture is a common way of building an infrastructure as a single unit that includes a user interface, a server-side framework, and a relational database. Since all of the app’s layers and components are interconnected, changing one component would require you to update the entire app.\nAnother approach is the Microservice architecture. By using the microservices approach, a complex program is broken down into loosely linked parts. Loose coupling establishes a system in which each service or component has its own logically distinct lifecycle, protocols, and database. This standalone component can be designed, implemented, scaled, and managed separately from the rest of the app which will continue to function normally.\n\nWe begin to wonder how this can interact, as we consider the two methods. This is where containerization comes in: each stand-alone unit is packed into a container which is then enclosed in a pod (which contains multiple containers that are shared in a cluster of nodes). When a Pod contains several containers, they are handled as a single entity, and all containers in the Pod share the Pod’s resources, including namespace, IP address, and network ports at the same time.\n\n(K8s) is a container-centric infrastructure manager. It manages container lifecycles, that is to say, it optimizes container orchestration deployment by provisioning Pods (creating and destroying them) based on the application’s requirements. Kubernetes exposes pods to requests using the Service object which maps IP addresses to a collection of pods. The service ensures routes to the Pods from any authorized source (within or outside the cluster) through a designated port.\nAs for frontend developers, we do need to have basic knowledge of setting up the inter-communication between this infrastructure and services. A clear understanding of how things function is essential.\n Often referred to as an Ops problem and that by giving it up, we are missing out on opportunities to understand the possibilities of what we create and how we can improve its availability in production.\n\nWhile the Ops role should be in charge of cluster setup, configuration, and management, the developer should be aware of and responsible for putting up the bare minimum necessary to run their app.\nAs a result, understanding the fundamentals of Kubernetes will allow you to optimize the configuration of your application and make it more scalable; and such to participate in the release process of what they created.\nTeams would benefit from having a general understanding of Kubernetes around the software stack while sharing terminologies and addressing their project. It also allows you complete control over the entire project lifecycle — from code to implementation — allowing you to test the application’s deployment, understand how your project should be deployed, and assist in maintaining the layer as well as specifying the environment. \nA good example is when a friend Cari (software engineer) described her experience working with a team a few years ago, where the backend engineers were only interested in getting involved in frontend development and Kubernetes alone. They willingly chose to learn Kubernetes and wouldn’t want to directly work with the backend layers, but only consume it. The team enjoyed having the ability to define how their application is deployed on Kubernetes.\nHaving this control over their project helps them be a part of the release journey of their projects, and more importantly will allow you to optimize the configuration of your application and make it more scalable. Also, understanding the production-deployment configuration allows developers to spot and fix crucial micro performance issues such as caching, amount of requests, and time-to-first-byte, as well as knowing how staging/testing differs from production before releasing the app.\nThere are scenarios where the terminology often overlaps between front-end and back-end teams, for example:\n\nport and servicesWhen specifying a version of an app deployed, and then the ports exposed e.g. “we can interact with our application using the service name and port xx: xx”.\nnamespacesKnowing that our project sits in a namespace on Kubernetes. Namespaces are a way for multiple users to share cluster resources.\nRBAC (Role-Based Access and Control)Knowing how the access control permissions on Kubernetes affect your projects.\n\nAn understanding of how Docker images build and run will allow teams to clearly communicate the requirements for each application in the cluster.\nDeployment and service\nThe resources that you identified in a configuration are created by a deployment. All of the resources that make up a deployment are specified in a configuration file. \nTo make a deployment, you’ll need a configuration file. YAML syntax is required for a configuration file. It contains fields, such as version, name, kind, replicas field (the desired number of Pod resources), selector, and the label field, etc, as shown below:\n....\n  name: \nspec:\n  selector:\n    matchLabels:\n      app: \n      tier: \n\n  replicas:\n    metadata:\n      labels:\n        app: \n        tier: \n\n    spec:\n      containers:\n        - name: \n          image: \n          ...\n\nA Kubernetes Service, on the other hand, is an abstraction layer that describes a logical group of Pods and allows for external traffic exposure, load balancing, and service discovery for such Pods.\nUpdating a Deployment\nA deployment can be updated to the desired object state from the current state, this is often done declaratively by updating the objects of interest in the configuration file and then deploying as an update. With a rolling update deployment strategy, old Pod resources will be gradually replaced with new ones. This means that two Pod resource versions can be deployed and accessed at the same time while ensuring that there is no downtime.\n\nBackend Service Object\nIn this article, the Pods in the front-end Deployment will run an Nginx image that will be configured to proxy requests to a Service with the key of app: backend. We assume the backend team has already ensured that their pods are running on the cluster, and that we only want to create and connect our app via a deployment to the backend. \nIn order to allow access to the backend application, we need to create a service for it. A Service creates a persistent IP address and DNS name entry for the application in question which makes it accessible to other pods. It also uses selectors to find the Pods that it routes traffic to.\nHere is an example of a backend-service.yaml configuration file which would expose the backend app to other pods in the cluster. Below is the sample backend service configuration file:\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: backend-serv\nspec:\n  selector:\n    app: hello\n    tier: backend\n  ports:\n  - protocol: TCP\n    port: 80\n    ...\n\nThe above YAML file shows that the service is configured to route traffic to the Pods that have the label app: hello and tier: backend of the cluster through port 80 only.\nCreating the Frontend\nYou typically create a container image of your application and push it to a registry (e.g. docker registry) before referring to it in a Pod. Since this is an introductory article, we will make use of a sample front-end image from the google container repository. The frontend sends requests to the backend worker Pods by using the DNS name given to the backend Service which is the value of the name field in the backend-service.yaml configuration file.\nThe Pods in the front-end Deployment run an Nginx image that is configured to proxy requests to the backend Service. The configuration file specifies the server and the listening port. When an ingress is created in Kubernetes, nginx upstreams point to services that match specified selectors.\nnginx.conf configuration file\nupstream Backend {   \n    server backend-serv;\n}\nserver {\n    listen 80;\n    location / {\n                proxy_pass http://Backend;\n    }\n}\n\n\nNote that the internal DNS name used by the backend Service inside Kubernetes is used to specify.\nThe frontend, like the backend, has a Deployment and a Service. The setup for the front-end Service has type: LoadBalancer which means that the Service would use a load balancer provisioned by the cloud service provider and would be reachable from outside the cluster.\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend-serv\nspec:\n  selector:\n    app: hello\n    tier: frontend\n  ports:\n  - protocol: \"TCP\"\n    port: 80\n    targetPort: 80\n  type: LoadBalancer\n...\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend-depl\nspec:\n  selector:\n    matchLabels:\n      app: hello\n      tier: frontend\n      track: stable\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hello\n        tier: frontend\n        track: stable\n    spec:\n      containers:\n        - name: nginx\n          image: \"gcr.io/google-samples/hello-frontend:1.0\"\n          ...\n\nCreate The Front-End Deployment And Service\nNow, that the configuration files are ready, we can run a kubectl apply command to create the resources as specified:\nkubectl apply -f [insert URL to saved frontend-deployment YAML file] \n\nkubectl apply -f [insert URL to saved frontend-service YAML file]\n\nThe output verifies that both resources were created:\ndeployment.apps/frontend-depl created\nservice/frontend-serv created\n\n\n\nInteracting with the Front-end Deployment and Service\nYou can use this command to obtain the external IP address, once you’ve created a LoadBalancer Service:\nkubectl get service frontend-serv --watch\nThis shows the front-end Service’s configurations and monitors for changes. The internal cluster IP would be immediately provisioned, while the external IP address is initially marked as pending:\n\n  NAME          TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)  AGE\nfrontend-serv   LoadBalancer   10.xx.xxx.xxx   <pending>     80/TCP   10s\n\n\nAs soon as an external IP is provisioned, however, the configuration updates to include the new IP under theEXTERNAL-IPheading:\n\nNAME       TYPE           CLUSTER-IP      EXTERNAL-IP        PORT(S)  AGE\nfrontend-serv   LoadBalancer   10.xx.xxx.xx   XXX.XXX.XXX.XXX    80/TCP   1m\n\n\nThe provisioned IP can be used to communicate with the front-end service from outside the cluster. We can now send traffic through the frontend, because the frontend and backend are now linked. Using the curl command on the external IP of your front-end Service, we can reach the endpoint.\nConclusion\nA company-wide vision for providing reliable software may be driven by a broad understanding of Kubernetes and how your application works on Kubernetes. The microservices architecture is more beneficial for complex and evolving applications. It offers effective solutions for handling a complicated system of different functions and services within one application.\n Microservices are ideal when it comes to the platforms, covering many user journeys and workflows. But without proper microservices expertise, applying this model would be impossible.\nHowever, it is critical to understand that the microservice design is not appropriate for every level of business organization. You should start with a monolith if your business idea is new and you want to validate it. For a small technical team attempting to design a basic and lightweight application, microservices can be considered superfluous, since monolith can be deployed via Kube without any problems, and you can still benefit from replication options and other features.\nFurther Reading On Smashing Magazine\n\n“From Chaos To System In Design Teams,” Javier Cuello\n“A Recipe For A Good Design System,” Atila Fassina\n“Building A Large-Scale Design System For The U.S. Government (Case Study),” Maya Benari\n“How To Create An Information Architecture That Is Easy To Use,” Paul Boag\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a377d64d-af16-4fb1-8159-2c9fa0ab72c4/kubernetes-front-end-developers.jpg",
      "date_published": "2022-05-19T11:30:00.000Z",
      "date_modified": "2022-05-19T11:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/smashing-podcast-episode-46/",
      "url": "https://smashingmagazine.com/2022/05/smashing-podcast-episode-46/",
      "title": "Smashing Podcast Episode 46 With Vitaly Friedman: Who Is Elliot Jay Stocks?",
      "summary": "In this episode, we ask how one man can go from designing websites for local bands to heading up Google Fonts Knowledge. Smashing’s Vitaly Friedman talks to Elliot Jay Stocks to find out.",
      "content_html": "<p>This article is a sponsored by <a href=\"https://www.wix.com/\">Wix</a></p>\n<p>In this episode, we ask how one man can go from designing websites for local bands to heading up Google Fonts Knowledge. Smashing’s Vitaly Friedman talks to Elliot Jay Stocks to find out.</p>\n\n\n<h3>Show Notes</h3>\n<ul>\n<li><a href=\"https://fonts.google.com/knowledge\">Google Fonts Knowledge</a></li>\n<li><a href=\"https://smashingconf.com/sf-2022/\">Smashing Conf San Francisco 2022</a></li>\n<li>Elliot’s <a href=\"https://elliotjaystocks.com\">personal website</a></li>\n<li>Elliot on <a href=\"https://twitter.com/elliotjaystocks\">Twitter</a></li>\n</ul>\n<h4>Weekly Update</h4>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/2022/05/performance-game-changer-back-forward-cache/\">Performance Game Changer: Browser Back/Forward Cache</a> written by Barry Pollard</li>\n<li><a href=\"https://www.smashingmagazine.com/2022/05/magical-svg-techniques/\">Magical SVG Techniques</a> written by Cosima Mielke</li>\n<li><a href=\"https://www.smashingmagazine.com/2022/05/sunuva-case-study-ux-changes-result-increase-conversion/\">How Even Small UX Changes Can Result In An Increase In Conversion</a> written by Denis Studennikov</li>\n<li><a href=\"https://www.smashingmagazine.com/2022/05/google-crux-analysis-comparison-performance-javascript-frameworks/\">How To Use Google CrUX To Analyze And Compare The Performance Of JS Frameworks</a> written by Dan Shappir</li>\n<li><a href=\"https://www.smashingmagazine.com/2022/05/top-tasks-focus-what-matters-must-defocus-what-doesnt/\">Top Tasks: To Focus On What Matters You Must De-Focus On What Doesn’t</a> written by Gerry McGovern</li>\n</ul>\n<h3>Transcript</h3>\n<p></p><p><a href=\"https://twitter.com/elliotjaystocks\"><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/cec52a04-f24d-4894-839a-61acf7fcb467/elliot-jay-stocks-250x250.jpg\" /></a> Vitaly Friedman: He loves typography from the bottom of his heart. And in recent years, he’s led creative direction for several products and services, including the print magazines 8 Faces and Lagom. He worked as a creative director of Adobe Typekit now called Adobe Fonts, and these days he’s running things at Google Fonts Knowledge.</p>\n<p>Vitaly: Outside of the realm of design, he also does electronic music as other form, and has also released music on several independent labels. Well, we know that he’s an expert in typography and electronic music, but did you know that he’s an avid fan of underground Icelandic techno music from the late ’90s and usually dreams about pixels, font sizes, and REM units.</p>\n<p>Vitaly: My Smashing friends, please welcome Elliot Jay Stocks. Elliot, hello and how are you doing today?</p>\n<p>Elliot Jay Stocks: I am smashing, thank you.</p>\n<p>Vitaly: Oh, well you look smashing as well if I may so. You haven’t changed a bit.</p>\n<p>Elliot: That’s very kind of you to say. I was going to already say that I feel smashing even before I was directed to do so.</p>\n<p>Vitaly: Oh, I don’t know who directed you to do that at all. Don’t you reveal the secrets that we have here.</p>\n<p>Vitaly: Elliot, when we actually look back now, I don’t know, we saw each other when like the last time, was it like 15 years ago?</p>\n<p>Elliot: I was going to say, \"That’s crazy. No way,\" but actually, I mean maybe, yeah.</p>\n<p>Vitaly: 15? No, not 15.</p>\n<p>Elliot: When we saw each other, oh, sorry. I thought you meant when we first met. When we first met, maybe it was 15 years ago.</p>\n<p>Vitaly: Yes. And when did we see each other last time?</p>\n<p>Elliot: Oh, wow. It’s been a long time since I’ve seen anybody.</p>\n<p>Vitaly: Yeah. Well you do see a lot of electronic music though.</p>\n<p>Elliot: Yes. That’s true.</p>\n<p>Vitaly: So that counts for something.</p>\n<p>Elliot: Oh, boy. I think it was in, I don’t know, Jonathan Snook was there. Where were we? It was you, me and Jonathan Snook. I don’t know. Was it during a talk, maybe?</p>\n<p>Vitaly: I have a feeling it was maybe, probably a room with people and the stage and you probably were speaking. Right?</p>\n<p>Elliot: Maybe.</p>\n<p>Vitaly: That’s probably... But before we actually dive into the specifics, I know that many of our listeners will have heard about your work and your blog post and also your music and all the wonderful things that you’re doing. But I’m always interested in people, like really coming back to the roots, there must be something that started all of this, right?</p>\n<p>Vitaly: And so I really want to hear a little bit about your backstory. So how does a boy with curly hair born in the suburbs of London gets his life through kind of thoroughly defined by web topography and design and electronic music. How does that happen? Tell us.</p>\n<p>Elliot: Well, thank you for the question. I think a lot of it is all just accidents, happy accidents, and just trying stuff out and seeing where that goes and not being too worried about the future plans, I suppose. I suppose I think that’s kind of probably the thing that’s defined my career path as it were.</p>\n<p>Elliot: So when I was a kid, I did a lot of drawing. I remember like my dad teaching me things about perspective and stuff when I was young and I used to do things like a lot of illustrations for the school, they’d have like a play on and I’d do the little pamphlet illustration for the program of the play and all sorts of things like that.</p>\n<p>Elliot: So I was always kind of doing drawing for fun and then asked by people to do with the school, to do like other stuff around that. It was always kind of art based. And I didn’t really dabble with design properly until I suppose I graduated from high school. And before I went to uni, I took a year out and I worked in a music shop in Virgin Megastores, when they still existed.</p>\n<p>Elliot: And I was doing a little bit of music at the time with some other people who worked there and we released a CD, which sounds very quaint now doesn’t it?</p>\n<p>Vitaly: Yeah. Oh a little bit. How old were you then?</p>\n<p>Elliot: Well, so I would’ve been 18, I guess.</p>\n<p>Vitaly: Yeah. Okay. So, that’s what cool people do then in nowadays.</p>\n<p>Elliot: Yeah.</p>\n<p>Vitaly: They just sing on CDs.</p>\n<p>Elliot: That’s right. Well maybe, and the managers of the store allowed us to put the CD on sale in the store. And so it fell to me to design the cover and I’d started dabbling with... I don’t know what it was.</p>\n<p>Elliot: It was like some sort of version of Photoshop, like a free version of Photoshop or something like that. And I was doing kind of stuff with terrible Photoshop filters and things like that. And-</p>\n<p>Vitaly: So that’s where it’s all started. I can see that, now.</p>\n<p>Elliot: Yeah. It was all this kind of thing. And I did the POS and the website for it. And it was the first website I’d kind of done. Well, yeah, it was my first experience. And the web was relatively new at this time. And I used an editor called Homestead, which was like a sort of WYSIWYG editor. And that whole thing was just kind of my first experience of design, I suppose.</p>\n<p>Elliot: Web design and print design. And that kind of, I guess, ignited that interest in that. And then for a few years at university, I did a lot of stuff on the side for music, for bands’ websites and stuff like that.</p>\n<p>Elliot: And then when I graduated from university, I got a job working for the record label, EMI working on a bunch of music sites. So, that was kind of how that all came about, really. I was working a lot of web stuff. It was all very music related and it sort of just happened, I guess, a little bit by accident and gradually over the years, I kind of... I don’t think I’m a web designer anymore.</p>\n<p>Elliot: I kind of realized recently that’s in the past that I’ve sort of gone on to do other things. But everything kind of came from there and there’s been a really strong, I suppose, musical current throughout the whole thing and lots of side projects.</p>\n<p>Elliot: And this is also what I’m going to be talking about at Smashing Conf as well, in fact. This whole thing and how it’s all interrelated and how a lot of side projects have led to, as I said, these kind of happy accidents, doing stuff that’s really fun just by sort of trying it out and not having too much of a plan.</p>\n<p>Vitaly: No, it’s interesting because every time I think about my childhood and how things used to be when I was growing up, I always think about these important people who kind of defined my career, my view on things. I don’t know, but I always, I mean especially over the last couple of weeks now, I’ve been for some reason thinking about the blog post by Mark Bolton and the blog that you were writing.</p>\n<p>Vitaly: And this was a very exciting time for me. I mean, you have no idea just how I just really felt that this is it, this is really changing my life. I kind of had this feeling in my head when I was kind of working through this and in my heart as well. So maybe just kind of throwing this question at you, maybe you could talk about people who really defined your way of thinking about design?</p>\n<p>Vitaly: Like what really made the most significant impact. Was it maybe a talk somewhere? Maybe it’s an article that you read, a book? I don’t know, just a random coincidence where you just met somebody and they said something? What was that really kind of defined your work in many ways?</p>\n<p>Elliot: Yeah, oh, wow. I remember those years as well. That felt really fun and everything on the web was new and we were all sort of just figuring it out and it was kind of the wild west of the web design days. I loved it.</p>\n<p>Elliot: But yeah, I guess from my own perspective, I’ve definitely been, in the early days, I was really influenced by a lot of those people doing some really cutting edge Flash websites. So this is probably around 2001, 2002, 2003, I guess, to advanced PreyStation, tokyoplastic, My Pet Skeleton.</p>\n<p>Vitaly: Oh, those were the times.</p>\n<p>Elliot: Yeah. The real heady days of Flash-based web design. And they were very influential on me, not just for the web, but they just, like you said, something you felt in your heart, it’s just this exciting, \"Wow, this is this just amazing stuff going on. It’s not just the web, but about design in general and creativity in general.\" And that really, really was just a very exciting time, and that kind of influenced me a lot in those early years.</p>\n<p>Elliot: I think that whole kind of grungy style and that very kind of David Carson influence thing. I don’t think I realized until later that it was a lot of David Carson influence on that lot. You know, people like JUXT Interactive who I loved at the time and kind of looking back now, it’s a very David Carson kind of thing. But that was very influential on me.</p>\n<p>Elliot: And then I got into, when I was working in the music industry and I was working at EMI, we started to move away from Flash and web standards was becoming a thing. And obviously like Zeldman’s writing and Eric Meyer and Dave Shay was doing the CSS Zen Garden. And then that again was like this really exciting, like, \"Oh, wow, what is this whole new way of exploring the web and building on the web and designing on the web and working within these new constraints?\"</p>\n<p>Elliot: And I think aesthetically, I went away from that kind of outlandish grungy stuff. Well, I mean, eventually I did, to more kind of like clean and eventually my focus on typography and things like that. And I think it was probably, I mean, Erik Spiekermann obviously is a hugely influential person anyway. And his kind of... I think sort of knowing Erik and getting to know him through projects like 8 Faces and things like that, his influence on the real minutiae of typographic design, the real specific geeky details, that kind of led me down that path into less focused on, I guess, some of the big, \"How do you design something from scratch?\" But more into like, how do we really tweak and refine this very small part of a design to be the best it can possibly be?</p>\n<p>Elliot: And I think almost like Erik is kind of at the opposite end to the David Carson side of design. But I think in sort of recent years, I’ve gone a bit more in that direction. And as you get older, I think your interest change. And for a long time, I was very, I don’t know, I guess really distrustful of people who were kind of involved in design, but didn’t want to do the whole thing.</p>\n<p>Elliot: And I was really distrustful of people who were kind of like directors, but they weren’t necessarily at the coalface doing the design work. Whereas now I’ve sort of come round to being okay with just focusing on one part of it and letting other people kind of get concerned with design systems, and developing things.</p>\n<p>Elliot: And I don’t know, web design is such a different beast these days anyway, I think.</p>\n<p>Vitaly: Yeah, I don’t know. Is it just me, Elliot? But I feel like every time somebody brings up a notion of web designs, isn’t it like a term from 2000 somehow? Or 2010 or something, web design? Like we’re just UX designs. We are UX engineers. We are... I don’t know. There are so many old kind of different roles. What role do you see yourself now? Who are you today? Like if you had to define your role, like something that really, I don’t know, a term that really defines and captures your essence, what would that be?</p>\n<p>Vitaly: I don’t know, if it’s a good answer, question to answer.</p>\n<p>Elliot: It’s a great question to answer. And one, I’m constantly asking myself. Yeah, I don’t know. At the moment I am sort of describing, well, I’m not really actively describing myself, but I suppose the work that I’ve done recently and I’m doing at the moment is more of, I guess I’m sort of a ... Oh boy, I don’t know. I guess it’s like a typographic consultant, I suppose, in that I’m doing a lot of work that is very... I mean, all design is and should be typography focused in many ways, but it is very focused on typography with... I’m doing very little in terms of like hands-on design these days, but it’s more kind of helping steer something from a typographic perspective, and advising people on that.</p>\n<p>Elliot: And the work that I’ve been doing with Google is all about sort of education around typography in general.</p>\n<p>Elliot: But prior to this, I was doing a lot of creative director roles. So I sort of stopped being a designer in the more traditional sense and was more just a creative director. Sort of from my time when I was a Typekit. And then the roles that I then had after that, they were all kind of creative director roles.</p>\n<p>Elliot: But and again, fairly recently when the pandemic kind of hit and I lost the job that I was currently working in at the time as creative director for an agency in London called Maido, Everyone kind of, that sort of had to disband, and I found myself doing some... Sort of going back to, well 2020 was a really weird year and everyone had to kind of go and do these different, sort of take on different kind of work to make ends meet and everything.</p>\n<p>Elliot: And then after that, I think I realized that I didn’t really want to go back into that design leadership thing for a while. I think I’d got a little bit jaded by just sort of... It’s not that I wanted to be at the coalface, designing everything and building everything again, but I also wanted to do something that was a little bit more, I guess, kind of insular and kind of self-contained. And not involving big teams and stuff like that.</p>\n<p>Elliot: And yeah, that’s kind of led me even further away from web design in a way, which has been nice. For a while, I was having this real existential crisis of trying to answer that question of who am I, what am I doing? And I think-</p>\n<p>Vitaly: But I think we have pretty good understanding now, do we?</p>\n<p>Elliot: Yeah. I think now I’m comfortable with where I am at for now. Ask me tomorrow, I’ll change my mind.</p>\n<p>Vitaly: Okay. I will definitely ask tomorrow as well. But now actually and it interesting looking back with, because you had all the different roles and you worked with all the different people and we just briefly talked about some influential people and who changed your view on things. And in my life it was you. You don’t even remember, I’m sure. I think you don’t even remember.</p>\n<p>Elliot: That’s very kind of you.</p>\n<p>Vitaly: I remember us. Yeah, I will explain in a moment why. Because when we were working on some project, who knows what project that was over the last, I don’t know, 11, 12 years now, 15, maybe. I remember you saying one thing. I think it was a navigation design that we changed in Smashing of 2013, ’14 something.</p>\n<p>Vitaly: And you said, \"Well, if something is different, you need to make it look very different. It can’t be just close enough or a little bit different. It has to be bold and decisive and different enough, so people can notice that this is a decision and not a mistake.\"</p>\n<p>Vitaly: Right. And I remember this, we were there. I mean, this has stuck with me for quite some time and actually many things that you’re mentioning about paying attention to details and being very careful and all those things, they kind of define my kind of way of working as well.</p>\n<p>Vitaly: But I didn’t spend a lot of time working with different agents in all the different roles. Basically I have for last, what 12 years, I’ve been in the same, more or less the same position. But looking at you now, because you’ve been working with all the different teams and all the different people, is there something that you would recommend to yourself when you’re working with them?</p>\n<p>Vitaly: Maybe do some... A little bit more of that. Do a little bit less of this in your career, as you kind of keep the ball and keep rolling. Is there something that you wish you would have done differently?</p>\n<p>Elliot: Mm yeah. Well, first of all, thank you for saying that’s, that’s really awesome to know that that was influential and helpful. And yeah, I don’t quite remember that, but that is awesome. And that must have been when we were doing the Smashing redesign, which was-</p>\n<p>Vitaly: Yeah, I think so.</p>\n<p>Elliot: Yeah. A while ago now.</p>\n<p>Vitaly: Like six, seven, eight years ago now.</p>\n<p>Elliot: Yeah. Wow. Yeah. In terms of the sort of career advice, things I wish I’d known when I was younger, stuff like that, I think learning to trust your gut is super important. And there were definitely times when I look back on projects that I said yes to that maybe I’d already got that gut feeling that they might not be great and perhaps I shouldn’t have taken them on. And I did anyway.</p>\n<p>Elliot: And I think listening to your gut, if you’ve got a feeling that says, \"I shouldn’t be doing this,\" for whatever reason, then there’s probably a valid reason for why you’re feeling that way. I’ve got a print that Erik did that I bought from his print shop P98A and it says, \"Don’t work with assholes, don’t work for assholes.\" Or maybe the other way round. But the meaning is the same.</p>\n<p>Elliot: And that again is like I think sometimes you can tell quite early on how someone is going to be, and it’s useful to not persevere with projects that are perhaps run by or with assholes. So I wish that I had had that framed on my wall earlier on in my career. It’s on my wall now, but it perhaps should have been a mantra that was adopted sooner.</p>\n<p>Elliot: But I think one of the things that I’m very grateful for is, that I’ve been in the position where I’ve been able to pursue things that I really care about. And although passion is this thing that’s kind of, this term that everyone says, it’s bandied about the whole time.</p>\n<p>Elliot: I think it’s really important. And I’ve always thought it’s important, to really care about what you’re doing. And the reality is that we are at work for most of the day, most of the hours that we are awake in the day. And so we should be spending those hours doing something we love.</p>\n<p>Elliot: Now, that’s all well and good. You know, that’s not necessarily helpful advice to give to somebody who may be stuck in a job that they absolutely need to stay in to pay the bills.</p>\n<p>Elliot: But I think it’s not necessarily about just going, \"Right. I’m going to quit my job and going pursue my dreams.\" It’s about sort of finding meaning in what you’re doing. And if there isn’t a direct way to do that in your day job, then I think side projects have always been a great outlet for that.</p>\n<p>Elliot: And for me personally, being able to, I guess, seek creative fulfillment through side projects has led me to pursue those passions almost, as I said before, by accident. It’s the side projects and just sort of going for them and not worrying too much about the consequences that have, later on, led to the really good work.</p>\n<p>Elliot: So even if you can’t leave your current job now that you might hate because you want to pursue your passions, I think finding a way to work your passions into it somehow, or to express yourself through a side project will help you eventually get involved with projects that you do really care about. And I’ve certainly been fortunate enough that that’s been the case.</p>\n<p>Elliot: And some of the jobs I’ve had have been direct results of the work that I’ve done on side projects. And then those jobs in themselves have led to further things. And there’s always been kind of that snowball effect. And so I mean, it’s hard to, I think when you’re younger and you’re starting out, it’s hard to necessarily... There’s on the one hand, that you can be sort of like full of this youthful naivety and kind of go, \"Yeah, let’s go for it and do whatever,\" but that can also lead to some not great situations.</p>\n<p>Elliot: But definitely looking back, being slightly older and having done this for a while now, I can definitely say that the times where things really worked or where I was really happy were because I sort of just followed what I was interested in, rather than what was the kind of sensible perceived route that I should take.</p>\n<p>Vitaly: Yeah. I think it’s, for me personally, it’s really a matter of being strategic and there are so many things I wish I had known earlier and not solely related to design or UX or web or topography or anything. But it’s just, sometimes you might even think about just very routine, basic life stuff. Right?</p>\n<p>Vitaly: I mean, you know me, but I’ve been exploring the world of cutting cucumbers and watermelons for, I don’t know how many months and years now, and I still haven’t found the right way. And I’m always disappointed with my outcome. The same goes for coffee and for so many other things, which could be just small things that would be really, really enjoyable. Right?</p>\n<p>Vitaly: And so, for example, one thing that I really wish I would know a bit more about is just how to do basic simple accounting. How to estimate better, how to deliver on time, how to get a bit more disciplined and things. Because these are all the things that I had to learn over time.</p>\n<p>Vitaly: But, oh, my. I’ve been overestimating, underestimating, going wild and just literally guess working all the way. Do you have sort of a structure, system? How do you work? Are you one of those people who are very like, Paul Maduro and 45 minutes and then this. The alarm goes on and off I go making a break. Or how do you work?</p>\n<p>Elliot: Yeah, no, I’m definitely not one of those people. I really struggle, to be honest, I have.</p>\n<p>Vitaly: Oh, by the way, not to say that we have anything against these people. They’re very kind, they very productive. Don’t mean to be kind of disapproving in any way, just looking about different ways of how we all work today.</p>\n<p>Elliot: Yeah. I have, so somewhat, I guess, it’s a little bit of a contradiction, but I try and set up a relatively focused schedule because I’m very easily distracted. So someone might look at my calendar or my approach to productivity and perhaps think that I’m quite well organized. And I think it’s, I’m not. This is why I’m using these things to try and and focus myself.</p>\n<p>Elliot: So a few years ago, Jessica Hische posted a thing about her calendar, that she’d blocked out part parts of the day to kind of be productive. And it was really interesting. And I think I wrote a blog post, where I sort of had my own take on it. Although, I’ve since kind of changed that.</p>\n<p>Elliot: But still the idea is basically blocking out time on your calendar to say, \"This is productivity time. This is client work time. This is freelance project time, or this is family time, whatever.\" That sort of helps. That part of that structure’s been forced on me in a good way by having a family.</p>\n<p>Elliot: So I have two young kids now and I always stop at five o’clock to go and have dinner with them. And I usually pick up some work stuff later on in the evening, even if it’s just kind of messages and stuff like that. But I have a pretty rigid stop time, which is, which is really nice because it means that I get some time with my family.</p>\n<p>Elliot: And it also just forces a bit of a structure on my day. Plus I have things like school pickups and clubs that the kids do. And lunch and very specific things that aren’t that movable these days, which is good, which is really good.</p>\n<p>Elliot: But I’ve also recently, I think to try and combat the fact that I’m quite easily distracted and just go down different rabbit holes, I’ve started moving to a paper based to-do list. So I still use things which I love as an app for that. And I use Notion for all kinds of general to-dos. But for my every single day, I write down on a little card, all of my tasks.</p>\n<p>Elliot: So I was influenced by Jeff Sheldon and his project, I think it’s called Analog, where he did a nice kickstart with these beautifully designed a little cards. And he had a little system going for the priorities in his card and a nice little case for it, and all this kind of thing. I wanted to sort of take that, but make a much more low-fi version.</p>\n<p>Elliot: So I made this system called Today And Soon, although I’ve since kind of changed it to just be focused on Today’s, which is basically I made a little template, a Moo card template that you can just download for free and get it printed. And it’s a series of tick boxes and there’s something about writing it down.</p>\n<p>Elliot: You know, I’ve got my where you can’t see this. I can show you, but you won’t be able to hear this. And this is written down. And it’s some basic stuff that I want to do every day. You know, I want to Duolingo every day, and I’ve got to call this person today and I’ve got to finish this particular bit of work and all this kind of stuff.</p>\n<p>Elliot: But just having it written down and like literally sat there next to my iMac, like balancing against my monitor there. And I get to do a big check mark with a big Sharpie every time I finish something, big or small, has really helped recently. Really helped with just keeping me focused. And I have stuff on there that’s like a big work task or it’s buy new flea medication for the dog or something.</p>\n<p>Elliot: But the sense of being productive by checking those things off the list is really nice. And so that coupled with a fairly rigid calendar and time kind of blocked off, has really helped my productivity. And I think that’s kind of, I suppose that’s kind of how I work.</p>\n<p>Elliot: But it’s still, my work day-to-day is a lot of like flitting between different things. It’s like some time in Figma working on some illustrations for Google Fonts Knowledge. And it’s time in Google Docs writing or editing, and it’s time in Notion doing some planning and it’s time on social media stuff, doing bits for my music project.</p>\n<p>Elliot: And it’s a little bit, and time in chat talking to colleagues and planning stuff and meetings and whatnot. And it’s quite varied. And I think that variation can easily lead to distraction, but also I do quite like having things varied. I’ve realized over time that I’m not very good at just staying and doing one thing. I can’t sort of sit down there at nine o’clock and design all day and then finish at five.</p>\n<p>Elliot: Like that’s never really been me and I’ve certainly failed when I’ve tried to do that.</p>\n<p>Vitaly: Yeah. So I think it’s interesting because for me, sometimes I feel like we are maybe twins from different universes or something like that, I don’t even know. Because I mean, I have moved my calendar quite a bit and I actually, I think my partner in late December, just planning ahead for the next year. We were sitting down, we just really thinking about what was the year like, and what’s the next year it’s going to be like? And of course it’s a very common thing, and some people would say, \"Well, everybody’s doing that or whatever,\" but it was really critical because I really had to kind of question everything.</p>\n<p>Vitaly: That’s really been on my agenda for the last couple of months now. I just, it’s impossible for me to read a book. I’m questioning every single sentence in the book, now. It’s just really, really hard and it really changed because then I totally revamped my calendar.</p>\n<p>Vitaly: And so I block out Fridays altogether, and there are dedicated times for meetings. And that’s it. And this kind of structure thing again, is probably something that gives you sort of, I don’t know, comfortable framework to work within?</p>\n<p>Elliot: Yeah.</p>\n<p>Vitaly: Right. So you just know that, okay, you’re going to do this and you have limitations in terms of the amount of time you will spend on this, because this is going to be a cutoff at five o’clock or six o’clock.</p>\n<p>Vitaly: So I can totally see how kind of how it all comes together, how it’s all working for you as well.</p>\n<p>Vitaly: Are there any things that you just let go? This was actually quite important for me as well, because I’ve been working with a couple of projects and we had to think about not the design strategy, but the deleting strategy or archiving strategy-</p>\n<p>Elliot: Oh yeah. Interesting.</p>\n<p>Vitaly: ... for very old and outdated content. So what are some things that you just recently let go or just stopped doing and that helped you as well?</p>\n<p>Elliot: Yeah, that’s a really good question because I think it is so important to say no. And I remember doing talks a few years ago when I was kind of talking about freelance life and stuff like that, and talking a lot about being confident in saying no to clients and turning away work that you didn’t agree with and stuff like that. In terms recently, I guess it’s been sort of juggling stuff.</p>\n<p>Elliot: I’ve, for a long time, had the opportunity to do maybe like a little bit of freelance work on the side and stuff like that. And I’ve recently with Google Fonts Knowledge and stuff, just settled into doing kind of one fixed kind of solid thing all day. Just working on Google Fonts Knowledge pretty much. And that’s been really nice to do.</p>\n<p>Elliot: That said, I mean, I still have my music projects and a lot of admin around running the label and stuff like that. So that still happens in the evenings and things like that. And as I said, there’s bit of like social media posts and stuff like that. So my mind is still bouncing around these different things, but I’ve definitely turned down a lot of freelance projects that have come my way, just because it’s... I know that it’d be so easy to fill the hours doing that stuff.</p>\n<p>Elliot: And I’m personally not very good at sitting there and just relaxing. Like I have this often detrimental need to be creating or making something. And I don’t really, I’m not great at playing video games and stuff because I feel like, \"Oh, I should be making some music or taking a thing on or doing more work or whatever.\"</p>\n<p>Elliot: Like I said, having kids has definitely helped in that my time with them is my time with them. And that’s really nice because nothing really eats into that, apart from the very occasional meeting or something like that. But on the whole, it’s dedicated.</p>\n<p>Elliot: But yeah, I think there’s nothing recently apart from just saying no to some other freelance projects coming in. But I should do more sitting down and relaxing and just being okay with not doing much.</p>\n<p>Vitaly: I think everybody’s saying that. And then nobody really does. I think personally I find it so difficult to just sit and do nothing. It’s just so, I mean, maybe I’m just impatient and I always have these questions raising up. These question marks coming up in my head. It’s sometimes it’s just difficult to fall asleep because I think, \"Oh, I have this idea for that thing and I should be following this and I should be writing it down and I should not be writing this down, but then maybe I want to write it down.\" Kind of this ongoing story.</p>\n<p>Elliot: Yeah, yeah.</p>\n<p>Vitaly: But I mean, you’re adventurous, you’re just exploring and it’s just... I know that we’ll be kind of wrapping up shortly, but I do want to just find out how do you end up becoming or getting, kind of embarking on this journey from music on a new level? Because I know that for a while you have not been on that journey, you’ve been doing a lot of design and maybe I’m wrong. Please, correct me if I’m wrong.</p>\n<p>Vitaly: But it’s only recently that we had this conversation, a few potentially on DJing at Smashing Conferences as well. And that’s something I wouldn’t imagine, like I say, 10 years ago when I saw you speaking on stage.</p>\n<p>Vitaly: So you really fell deeply in love with electronic music again and now having your own label and all. And can you tell us just briefly that story? It’s like, why and how, and just how it happened and also where it goes?</p>\n<p>Elliot: Yeah, sure. I mean, so I have actually been doing music for many, many years, in a very non-serious way. So I sort of started releasing some of my own music when I was in that year off that I mentioned before university. So I was like 18, and I released self-released a couple of EPs after that, but I was never really serious about it.</p>\n<p>Elliot: And it wasn’t until, I think it was like 2015, something like that, 2014, 2015, where there were a couple of catalysts. One is that I’d kind of always liked some electronic music, but I was more into kind of rock and metal and stuff like that. And it wasn’t until then that I discovered some techno that for me, I thought, \"Wow, this is really interesting music. This is people doing something that I haven’t really heard.\"</p>\n<p>Elliot: And although it was kind of dance music, it’s not just about dancing. There’s just way more to it than that. And it was really interesting to me. There were a few different artists doing some cool stuff around this time, Monique and Shifted and KiloWatt and Manny D and some people that I just come across. And I found their music genuinely really interesting as a listener.</p>\n<p>Elliot: But it spurred me on to kind of say, \"Oh, maybe I could do some stuff like this.\" And then at exactly the same time I bought some hardware synths from... You can see them, they’re in the background there, these Volcas from, from Korg. And they’re really cheap. They’re analog synths, but they a really, really cheap, really dirty, and they’re just really fun to play with.</p>\n<p>Elliot: And as soon as I was playing with them and like tweaking, turning knobs and moving sliders and just playing with the hardware and all those kind of happy accidents, again, that come with playing around with stuff like that. And coupled with the influence of these new artists, I thought, \"Wow, this is really interesting. Maybe I could make this kind of thing.\"</p>\n<p>Elliot: And it just sort of, I suppose, made me start taking it a little bit more seriously. And there was one other catalyst. So in 2015, we had our first daughter and sort of from then, my time to be productive musically, but in general has definitely been very limited.</p>\n<p>Elliot: And ironically that’s the time when I spent the most kind of going, \"Right, I have to do this thing, I have to be serious about music now.\" But I really do think that having that limited time to do this in, whereas before where the world is your oyster, you can spend all the time in the world, having a tiny window in which to be productive has actually helped me focus.</p>\n<p>Elliot: Again, that was sort of happened to me rather than anything that... I didn’t kind of like plan for that level of productivity, but that really did help.</p>\n<p>Elliot: And so I released my first EP as other form in 2017 and since, and even then I did it and then I kind of went quiet for a bit, but around 2019, things started to pick up again. Started to be making a lot more music, put something else out on a different label. And then I played a gig in Berlin at the end of 2019 and was like, \"Hey, this is the start of playing live in like some clubs around the world and stuff.\"</p>\n<p>Elliot: And then of course, we all know how 2020 went, but during that time, during the pandemic and everything, I really kind of doubled down on getting music out and growing the label and releasing other people’s music not just my own stuff. And it’s been just a whole other adventure, as you say. Just kind of working out that side of things and I love it.</p>\n<p>Elliot: It’s very different to design. I don’t think there are many parallels, really. There are certain organizational things that have helped. I mean, I kind of run my design life and my music life on Notion, for instance. But in terms of like their creativity and the kind of label admin stuff, I think it’s very different to my kind of day jobby stuff, and also takes up quite a lot of time. But it’s all fun.</p>\n<p>Elliot: As soon as it stops being fun, I’m going to stop doing it.</p>\n<p>Vitaly: Yeah. Well, I think that it’s incredible to see this energy in your eyes when I can see it now.</p>\n<p>Elliot: Thank you.</p>\n<p>Vitaly: And it’s wonderful to see you really kind of shining through, and maybe who knows maybe in a couple of months or so, we’ll see you all over the world. And I know that you will be in some parts of the world, that will be San Francisco.</p>\n<p>Elliot: That’s right.</p>\n<p>Vitaly: For the smashing conference. So that might be the time when we should be expecting your live performance, as well. What is a snippet of it, right?</p>\n<p>Elliot: Maybe, maybe.</p>\n<p>Vitaly: Well, maybe we’ll see about that. Well, if you, dear listener would like to hear more from Elliott. You can find him on Twitter where he’s well, what a big surprise, Elliot @elliotjaystocks, and also on his website, which is also a big surprise, elliotjaystocks.com. So you can always follow along and see what Elliot has to say, and also what he’s working on.</p>\n<p>Vitaly: Well, thank you so much today for joining us, Elliot. Do you have any parting words of wisdom with the wonderful peoples listening to us today?</p>\n<p>Elliot: No, I don’t have any parting words of wisdom. I hope you didn’t come here expecting wisdom.</p>\n<p>Vitaly: Well, that counts for something, right? Well, thank you so much, Elliot and I’m very much looking forward to seeing you in San Francisco.</p>\n<p>Elliot: You too. Thank you for having me, Vitaly.</p>",
      "content_text": "This article is a sponsored by Wix\nIn this episode, we ask how one man can go from designing websites for local bands to heading up Google Fonts Knowledge. Smashing’s Vitaly Friedman talks to Elliot Jay Stocks to find out.\n\n\nShow Notes\n\nGoogle Fonts Knowledge\nSmashing Conf San Francisco 2022\nElliot’s personal website\nElliot on Twitter\n\nWeekly Update\n\nPerformance Game Changer: Browser Back/Forward Cache written by Barry Pollard\nMagical SVG Techniques written by Cosima Mielke\nHow Even Small UX Changes Can Result In An Increase In Conversion written by Denis Studennikov\nHow To Use Google CrUX To Analyze And Compare The Performance Of JS Frameworks written by Dan Shappir\nTop Tasks: To Focus On What Matters You Must De-Focus On What Doesn’t written by Gerry McGovern\n\nTranscript\n Vitaly Friedman: He loves typography from the bottom of his heart. And in recent years, he’s led creative direction for several products and services, including the print magazines 8 Faces and Lagom. He worked as a creative director of Adobe Typekit now called Adobe Fonts, and these days he’s running things at Google Fonts Knowledge.\nVitaly: Outside of the realm of design, he also does electronic music as other form, and has also released music on several independent labels. Well, we know that he’s an expert in typography and electronic music, but did you know that he’s an avid fan of underground Icelandic techno music from the late ’90s and usually dreams about pixels, font sizes, and REM units.\nVitaly: My Smashing friends, please welcome Elliot Jay Stocks. Elliot, hello and how are you doing today?\nElliot Jay Stocks: I am smashing, thank you.\nVitaly: Oh, well you look smashing as well if I may so. You haven’t changed a bit.\nElliot: That’s very kind of you to say. I was going to already say that I feel smashing even before I was directed to do so.\nVitaly: Oh, I don’t know who directed you to do that at all. Don’t you reveal the secrets that we have here.\nVitaly: Elliot, when we actually look back now, I don’t know, we saw each other when like the last time, was it like 15 years ago?\nElliot: I was going to say, \"That’s crazy. No way,\" but actually, I mean maybe, yeah.\nVitaly: 15? No, not 15.\nElliot: When we saw each other, oh, sorry. I thought you meant when we first met. When we first met, maybe it was 15 years ago.\nVitaly: Yes. And when did we see each other last time?\nElliot: Oh, wow. It’s been a long time since I’ve seen anybody.\nVitaly: Yeah. Well you do see a lot of electronic music though.\nElliot: Yes. That’s true.\nVitaly: So that counts for something.\nElliot: Oh, boy. I think it was in, I don’t know, Jonathan Snook was there. Where were we? It was you, me and Jonathan Snook. I don’t know. Was it during a talk, maybe?\nVitaly: I have a feeling it was maybe, probably a room with people and the stage and you probably were speaking. Right?\nElliot: Maybe.\nVitaly: That’s probably... But before we actually dive into the specifics, I know that many of our listeners will have heard about your work and your blog post and also your music and all the wonderful things that you’re doing. But I’m always interested in people, like really coming back to the roots, there must be something that started all of this, right?\nVitaly: And so I really want to hear a little bit about your backstory. So how does a boy with curly hair born in the suburbs of London gets his life through kind of thoroughly defined by web topography and design and electronic music. How does that happen? Tell us.\nElliot: Well, thank you for the question. I think a lot of it is all just accidents, happy accidents, and just trying stuff out and seeing where that goes and not being too worried about the future plans, I suppose. I suppose I think that’s kind of probably the thing that’s defined my career path as it were.\nElliot: So when I was a kid, I did a lot of drawing. I remember like my dad teaching me things about perspective and stuff when I was young and I used to do things like a lot of illustrations for the school, they’d have like a play on and I’d do the little pamphlet illustration for the program of the play and all sorts of things like that.\nElliot: So I was always kind of doing drawing for fun and then asked by people to do with the school, to do like other stuff around that. It was always kind of art based. And I didn’t really dabble with design properly until I suppose I graduated from high school. And before I went to uni, I took a year out and I worked in a music shop in Virgin Megastores, when they still existed.\nElliot: And I was doing a little bit of music at the time with some other people who worked there and we released a CD, which sounds very quaint now doesn’t it?\nVitaly: Yeah. Oh a little bit. How old were you then?\nElliot: Well, so I would’ve been 18, I guess.\nVitaly: Yeah. Okay. So, that’s what cool people do then in nowadays.\nElliot: Yeah.\nVitaly: They just sing on CDs.\nElliot: That’s right. Well maybe, and the managers of the store allowed us to put the CD on sale in the store. And so it fell to me to design the cover and I’d started dabbling with... I don’t know what it was.\nElliot: It was like some sort of version of Photoshop, like a free version of Photoshop or something like that. And I was doing kind of stuff with terrible Photoshop filters and things like that. And-\nVitaly: So that’s where it’s all started. I can see that, now.\nElliot: Yeah. It was all this kind of thing. And I did the POS and the website for it. And it was the first website I’d kind of done. Well, yeah, it was my first experience. And the web was relatively new at this time. And I used an editor called Homestead, which was like a sort of WYSIWYG editor. And that whole thing was just kind of my first experience of design, I suppose.\nElliot: Web design and print design. And that kind of, I guess, ignited that interest in that. And then for a few years at university, I did a lot of stuff on the side for music, for bands’ websites and stuff like that.\nElliot: And then when I graduated from university, I got a job working for the record label, EMI working on a bunch of music sites. So, that was kind of how that all came about, really. I was working a lot of web stuff. It was all very music related and it sort of just happened, I guess, a little bit by accident and gradually over the years, I kind of... I don’t think I’m a web designer anymore.\nElliot: I kind of realized recently that’s in the past that I’ve sort of gone on to do other things. But everything kind of came from there and there’s been a really strong, I suppose, musical current throughout the whole thing and lots of side projects.\nElliot: And this is also what I’m going to be talking about at Smashing Conf as well, in fact. This whole thing and how it’s all interrelated and how a lot of side projects have led to, as I said, these kind of happy accidents, doing stuff that’s really fun just by sort of trying it out and not having too much of a plan.\nVitaly: No, it’s interesting because every time I think about my childhood and how things used to be when I was growing up, I always think about these important people who kind of defined my career, my view on things. I don’t know, but I always, I mean especially over the last couple of weeks now, I’ve been for some reason thinking about the blog post by Mark Bolton and the blog that you were writing.\nVitaly: And this was a very exciting time for me. I mean, you have no idea just how I just really felt that this is it, this is really changing my life. I kind of had this feeling in my head when I was kind of working through this and in my heart as well. So maybe just kind of throwing this question at you, maybe you could talk about people who really defined your way of thinking about design?\nVitaly: Like what really made the most significant impact. Was it maybe a talk somewhere? Maybe it’s an article that you read, a book? I don’t know, just a random coincidence where you just met somebody and they said something? What was that really kind of defined your work in many ways?\nElliot: Yeah, oh, wow. I remember those years as well. That felt really fun and everything on the web was new and we were all sort of just figuring it out and it was kind of the wild west of the web design days. I loved it.\nElliot: But yeah, I guess from my own perspective, I’ve definitely been, in the early days, I was really influenced by a lot of those people doing some really cutting edge Flash websites. So this is probably around 2001, 2002, 2003, I guess, to advanced PreyStation, tokyoplastic, My Pet Skeleton.\nVitaly: Oh, those were the times.\nElliot: Yeah. The real heady days of Flash-based web design. And they were very influential on me, not just for the web, but they just, like you said, something you felt in your heart, it’s just this exciting, \"Wow, this is this just amazing stuff going on. It’s not just the web, but about design in general and creativity in general.\" And that really, really was just a very exciting time, and that kind of influenced me a lot in those early years.\nElliot: I think that whole kind of grungy style and that very kind of David Carson influence thing. I don’t think I realized until later that it was a lot of David Carson influence on that lot. You know, people like JUXT Interactive who I loved at the time and kind of looking back now, it’s a very David Carson kind of thing. But that was very influential on me.\nElliot: And then I got into, when I was working in the music industry and I was working at EMI, we started to move away from Flash and web standards was becoming a thing. And obviously like Zeldman’s writing and Eric Meyer and Dave Shay was doing the CSS Zen Garden. And then that again was like this really exciting, like, \"Oh, wow, what is this whole new way of exploring the web and building on the web and designing on the web and working within these new constraints?\"\nElliot: And I think aesthetically, I went away from that kind of outlandish grungy stuff. Well, I mean, eventually I did, to more kind of like clean and eventually my focus on typography and things like that. And I think it was probably, I mean, Erik Spiekermann obviously is a hugely influential person anyway. And his kind of... I think sort of knowing Erik and getting to know him through projects like 8 Faces and things like that, his influence on the real minutiae of typographic design, the real specific geeky details, that kind of led me down that path into less focused on, I guess, some of the big, \"How do you design something from scratch?\" But more into like, how do we really tweak and refine this very small part of a design to be the best it can possibly be?\nElliot: And I think almost like Erik is kind of at the opposite end to the David Carson side of design. But I think in sort of recent years, I’ve gone a bit more in that direction. And as you get older, I think your interest change. And for a long time, I was very, I don’t know, I guess really distrustful of people who were kind of involved in design, but didn’t want to do the whole thing.\nElliot: And I was really distrustful of people who were kind of like directors, but they weren’t necessarily at the coalface doing the design work. Whereas now I’ve sort of come round to being okay with just focusing on one part of it and letting other people kind of get concerned with design systems, and developing things.\nElliot: And I don’t know, web design is such a different beast these days anyway, I think.\nVitaly: Yeah, I don’t know. Is it just me, Elliot? But I feel like every time somebody brings up a notion of web designs, isn’t it like a term from 2000 somehow? Or 2010 or something, web design? Like we’re just UX designs. We are UX engineers. We are... I don’t know. There are so many old kind of different roles. What role do you see yourself now? Who are you today? Like if you had to define your role, like something that really, I don’t know, a term that really defines and captures your essence, what would that be?\nVitaly: I don’t know, if it’s a good answer, question to answer.\nElliot: It’s a great question to answer. And one, I’m constantly asking myself. Yeah, I don’t know. At the moment I am sort of describing, well, I’m not really actively describing myself, but I suppose the work that I’ve done recently and I’m doing at the moment is more of, I guess I’m sort of a ... Oh boy, I don’t know. I guess it’s like a typographic consultant, I suppose, in that I’m doing a lot of work that is very... I mean, all design is and should be typography focused in many ways, but it is very focused on typography with... I’m doing very little in terms of like hands-on design these days, but it’s more kind of helping steer something from a typographic perspective, and advising people on that.\nElliot: And the work that I’ve been doing with Google is all about sort of education around typography in general.\nElliot: But prior to this, I was doing a lot of creative director roles. So I sort of stopped being a designer in the more traditional sense and was more just a creative director. Sort of from my time when I was a Typekit. And then the roles that I then had after that, they were all kind of creative director roles.\nElliot: But and again, fairly recently when the pandemic kind of hit and I lost the job that I was currently working in at the time as creative director for an agency in London called Maido, Everyone kind of, that sort of had to disband, and I found myself doing some... Sort of going back to, well 2020 was a really weird year and everyone had to kind of go and do these different, sort of take on different kind of work to make ends meet and everything.\nElliot: And then after that, I think I realized that I didn’t really want to go back into that design leadership thing for a while. I think I’d got a little bit jaded by just sort of... It’s not that I wanted to be at the coalface, designing everything and building everything again, but I also wanted to do something that was a little bit more, I guess, kind of insular and kind of self-contained. And not involving big teams and stuff like that.\nElliot: And yeah, that’s kind of led me even further away from web design in a way, which has been nice. For a while, I was having this real existential crisis of trying to answer that question of who am I, what am I doing? And I think-\nVitaly: But I think we have pretty good understanding now, do we?\nElliot: Yeah. I think now I’m comfortable with where I am at for now. Ask me tomorrow, I’ll change my mind.\nVitaly: Okay. I will definitely ask tomorrow as well. But now actually and it interesting looking back with, because you had all the different roles and you worked with all the different people and we just briefly talked about some influential people and who changed your view on things. And in my life it was you. You don’t even remember, I’m sure. I think you don’t even remember.\nElliot: That’s very kind of you.\nVitaly: I remember us. Yeah, I will explain in a moment why. Because when we were working on some project, who knows what project that was over the last, I don’t know, 11, 12 years now, 15, maybe. I remember you saying one thing. I think it was a navigation design that we changed in Smashing of 2013, ’14 something.\nVitaly: And you said, \"Well, if something is different, you need to make it look very different. It can’t be just close enough or a little bit different. It has to be bold and decisive and different enough, so people can notice that this is a decision and not a mistake.\"\nVitaly: Right. And I remember this, we were there. I mean, this has stuck with me for quite some time and actually many things that you’re mentioning about paying attention to details and being very careful and all those things, they kind of define my kind of way of working as well.\nVitaly: But I didn’t spend a lot of time working with different agents in all the different roles. Basically I have for last, what 12 years, I’ve been in the same, more or less the same position. But looking at you now, because you’ve been working with all the different teams and all the different people, is there something that you would recommend to yourself when you’re working with them?\nVitaly: Maybe do some... A little bit more of that. Do a little bit less of this in your career, as you kind of keep the ball and keep rolling. Is there something that you wish you would have done differently?\nElliot: Mm yeah. Well, first of all, thank you for saying that’s, that’s really awesome to know that that was influential and helpful. And yeah, I don’t quite remember that, but that is awesome. And that must have been when we were doing the Smashing redesign, which was-\nVitaly: Yeah, I think so.\nElliot: Yeah. A while ago now.\nVitaly: Like six, seven, eight years ago now.\nElliot: Yeah. Wow. Yeah. In terms of the sort of career advice, things I wish I’d known when I was younger, stuff like that, I think learning to trust your gut is super important. And there were definitely times when I look back on projects that I said yes to that maybe I’d already got that gut feeling that they might not be great and perhaps I shouldn’t have taken them on. And I did anyway.\nElliot: And I think listening to your gut, if you’ve got a feeling that says, \"I shouldn’t be doing this,\" for whatever reason, then there’s probably a valid reason for why you’re feeling that way. I’ve got a print that Erik did that I bought from his print shop P98A and it says, \"Don’t work with assholes, don’t work for assholes.\" Or maybe the other way round. But the meaning is the same.\nElliot: And that again is like I think sometimes you can tell quite early on how someone is going to be, and it’s useful to not persevere with projects that are perhaps run by or with assholes. So I wish that I had had that framed on my wall earlier on in my career. It’s on my wall now, but it perhaps should have been a mantra that was adopted sooner.\nElliot: But I think one of the things that I’m very grateful for is, that I’ve been in the position where I’ve been able to pursue things that I really care about. And although passion is this thing that’s kind of, this term that everyone says, it’s bandied about the whole time.\nElliot: I think it’s really important. And I’ve always thought it’s important, to really care about what you’re doing. And the reality is that we are at work for most of the day, most of the hours that we are awake in the day. And so we should be spending those hours doing something we love.\nElliot: Now, that’s all well and good. You know, that’s not necessarily helpful advice to give to somebody who may be stuck in a job that they absolutely need to stay in to pay the bills.\nElliot: But I think it’s not necessarily about just going, \"Right. I’m going to quit my job and going pursue my dreams.\" It’s about sort of finding meaning in what you’re doing. And if there isn’t a direct way to do that in your day job, then I think side projects have always been a great outlet for that.\nElliot: And for me personally, being able to, I guess, seek creative fulfillment through side projects has led me to pursue those passions almost, as I said before, by accident. It’s the side projects and just sort of going for them and not worrying too much about the consequences that have, later on, led to the really good work.\nElliot: So even if you can’t leave your current job now that you might hate because you want to pursue your passions, I think finding a way to work your passions into it somehow, or to express yourself through a side project will help you eventually get involved with projects that you do really care about. And I’ve certainly been fortunate enough that that’s been the case.\nElliot: And some of the jobs I’ve had have been direct results of the work that I’ve done on side projects. And then those jobs in themselves have led to further things. And there’s always been kind of that snowball effect. And so I mean, it’s hard to, I think when you’re younger and you’re starting out, it’s hard to necessarily... There’s on the one hand, that you can be sort of like full of this youthful naivety and kind of go, \"Yeah, let’s go for it and do whatever,\" but that can also lead to some not great situations.\nElliot: But definitely looking back, being slightly older and having done this for a while now, I can definitely say that the times where things really worked or where I was really happy were because I sort of just followed what I was interested in, rather than what was the kind of sensible perceived route that I should take.\nVitaly: Yeah. I think it’s, for me personally, it’s really a matter of being strategic and there are so many things I wish I had known earlier and not solely related to design or UX or web or topography or anything. But it’s just, sometimes you might even think about just very routine, basic life stuff. Right?\nVitaly: I mean, you know me, but I’ve been exploring the world of cutting cucumbers and watermelons for, I don’t know how many months and years now, and I still haven’t found the right way. And I’m always disappointed with my outcome. The same goes for coffee and for so many other things, which could be just small things that would be really, really enjoyable. Right?\nVitaly: And so, for example, one thing that I really wish I would know a bit more about is just how to do basic simple accounting. How to estimate better, how to deliver on time, how to get a bit more disciplined and things. Because these are all the things that I had to learn over time.\nVitaly: But, oh, my. I’ve been overestimating, underestimating, going wild and just literally guess working all the way. Do you have sort of a structure, system? How do you work? Are you one of those people who are very like, Paul Maduro and 45 minutes and then this. The alarm goes on and off I go making a break. Or how do you work?\nElliot: Yeah, no, I’m definitely not one of those people. I really struggle, to be honest, I have.\nVitaly: Oh, by the way, not to say that we have anything against these people. They’re very kind, they very productive. Don’t mean to be kind of disapproving in any way, just looking about different ways of how we all work today.\nElliot: Yeah. I have, so somewhat, I guess, it’s a little bit of a contradiction, but I try and set up a relatively focused schedule because I’m very easily distracted. So someone might look at my calendar or my approach to productivity and perhaps think that I’m quite well organized. And I think it’s, I’m not. This is why I’m using these things to try and and focus myself.\nElliot: So a few years ago, Jessica Hische posted a thing about her calendar, that she’d blocked out part parts of the day to kind of be productive. And it was really interesting. And I think I wrote a blog post, where I sort of had my own take on it. Although, I’ve since kind of changed that.\nElliot: But still the idea is basically blocking out time on your calendar to say, \"This is productivity time. This is client work time. This is freelance project time, or this is family time, whatever.\" That sort of helps. That part of that structure’s been forced on me in a good way by having a family.\nElliot: So I have two young kids now and I always stop at five o’clock to go and have dinner with them. And I usually pick up some work stuff later on in the evening, even if it’s just kind of messages and stuff like that. But I have a pretty rigid stop time, which is, which is really nice because it means that I get some time with my family.\nElliot: And it also just forces a bit of a structure on my day. Plus I have things like school pickups and clubs that the kids do. And lunch and very specific things that aren’t that movable these days, which is good, which is really good.\nElliot: But I’ve also recently, I think to try and combat the fact that I’m quite easily distracted and just go down different rabbit holes, I’ve started moving to a paper based to-do list. So I still use things which I love as an app for that. And I use Notion for all kinds of general to-dos. But for my every single day, I write down on a little card, all of my tasks.\nElliot: So I was influenced by Jeff Sheldon and his project, I think it’s called Analog, where he did a nice kickstart with these beautifully designed a little cards. And he had a little system going for the priorities in his card and a nice little case for it, and all this kind of thing. I wanted to sort of take that, but make a much more low-fi version.\nElliot: So I made this system called Today And Soon, although I’ve since kind of changed it to just be focused on Today’s, which is basically I made a little template, a Moo card template that you can just download for free and get it printed. And it’s a series of tick boxes and there’s something about writing it down.\nElliot: You know, I’ve got my where you can’t see this. I can show you, but you won’t be able to hear this. And this is written down. And it’s some basic stuff that I want to do every day. You know, I want to Duolingo every day, and I’ve got to call this person today and I’ve got to finish this particular bit of work and all this kind of stuff.\nElliot: But just having it written down and like literally sat there next to my iMac, like balancing against my monitor there. And I get to do a big check mark with a big Sharpie every time I finish something, big or small, has really helped recently. Really helped with just keeping me focused. And I have stuff on there that’s like a big work task or it’s buy new flea medication for the dog or something.\nElliot: But the sense of being productive by checking those things off the list is really nice. And so that coupled with a fairly rigid calendar and time kind of blocked off, has really helped my productivity. And I think that’s kind of, I suppose that’s kind of how I work.\nElliot: But it’s still, my work day-to-day is a lot of like flitting between different things. It’s like some time in Figma working on some illustrations for Google Fonts Knowledge. And it’s time in Google Docs writing or editing, and it’s time in Notion doing some planning and it’s time on social media stuff, doing bits for my music project.\nElliot: And it’s a little bit, and time in chat talking to colleagues and planning stuff and meetings and whatnot. And it’s quite varied. And I think that variation can easily lead to distraction, but also I do quite like having things varied. I’ve realized over time that I’m not very good at just staying and doing one thing. I can’t sort of sit down there at nine o’clock and design all day and then finish at five.\nElliot: Like that’s never really been me and I’ve certainly failed when I’ve tried to do that.\nVitaly: Yeah. So I think it’s interesting because for me, sometimes I feel like we are maybe twins from different universes or something like that, I don’t even know. Because I mean, I have moved my calendar quite a bit and I actually, I think my partner in late December, just planning ahead for the next year. We were sitting down, we just really thinking about what was the year like, and what’s the next year it’s going to be like? And of course it’s a very common thing, and some people would say, \"Well, everybody’s doing that or whatever,\" but it was really critical because I really had to kind of question everything.\nVitaly: That’s really been on my agenda for the last couple of months now. I just, it’s impossible for me to read a book. I’m questioning every single sentence in the book, now. It’s just really, really hard and it really changed because then I totally revamped my calendar.\nVitaly: And so I block out Fridays altogether, and there are dedicated times for meetings. And that’s it. And this kind of structure thing again, is probably something that gives you sort of, I don’t know, comfortable framework to work within?\nElliot: Yeah.\nVitaly: Right. So you just know that, okay, you’re going to do this and you have limitations in terms of the amount of time you will spend on this, because this is going to be a cutoff at five o’clock or six o’clock.\nVitaly: So I can totally see how kind of how it all comes together, how it’s all working for you as well.\nVitaly: Are there any things that you just let go? This was actually quite important for me as well, because I’ve been working with a couple of projects and we had to think about not the design strategy, but the deleting strategy or archiving strategy-\nElliot: Oh yeah. Interesting.\nVitaly: ... for very old and outdated content. So what are some things that you just recently let go or just stopped doing and that helped you as well?\nElliot: Yeah, that’s a really good question because I think it is so important to say no. And I remember doing talks a few years ago when I was kind of talking about freelance life and stuff like that, and talking a lot about being confident in saying no to clients and turning away work that you didn’t agree with and stuff like that. In terms recently, I guess it’s been sort of juggling stuff.\nElliot: I’ve, for a long time, had the opportunity to do maybe like a little bit of freelance work on the side and stuff like that. And I’ve recently with Google Fonts Knowledge and stuff, just settled into doing kind of one fixed kind of solid thing all day. Just working on Google Fonts Knowledge pretty much. And that’s been really nice to do.\nElliot: That said, I mean, I still have my music projects and a lot of admin around running the label and stuff like that. So that still happens in the evenings and things like that. And as I said, there’s bit of like social media posts and stuff like that. So my mind is still bouncing around these different things, but I’ve definitely turned down a lot of freelance projects that have come my way, just because it’s... I know that it’d be so easy to fill the hours doing that stuff.\nElliot: And I’m personally not very good at sitting there and just relaxing. Like I have this often detrimental need to be creating or making something. And I don’t really, I’m not great at playing video games and stuff because I feel like, \"Oh, I should be making some music or taking a thing on or doing more work or whatever.\"\nElliot: Like I said, having kids has definitely helped in that my time with them is my time with them. And that’s really nice because nothing really eats into that, apart from the very occasional meeting or something like that. But on the whole, it’s dedicated.\nElliot: But yeah, I think there’s nothing recently apart from just saying no to some other freelance projects coming in. But I should do more sitting down and relaxing and just being okay with not doing much.\nVitaly: I think everybody’s saying that. And then nobody really does. I think personally I find it so difficult to just sit and do nothing. It’s just so, I mean, maybe I’m just impatient and I always have these questions raising up. These question marks coming up in my head. It’s sometimes it’s just difficult to fall asleep because I think, \"Oh, I have this idea for that thing and I should be following this and I should be writing it down and I should not be writing this down, but then maybe I want to write it down.\" Kind of this ongoing story.\nElliot: Yeah, yeah.\nVitaly: But I mean, you’re adventurous, you’re just exploring and it’s just... I know that we’ll be kind of wrapping up shortly, but I do want to just find out how do you end up becoming or getting, kind of embarking on this journey from music on a new level? Because I know that for a while you have not been on that journey, you’ve been doing a lot of design and maybe I’m wrong. Please, correct me if I’m wrong.\nVitaly: But it’s only recently that we had this conversation, a few potentially on DJing at Smashing Conferences as well. And that’s something I wouldn’t imagine, like I say, 10 years ago when I saw you speaking on stage.\nVitaly: So you really fell deeply in love with electronic music again and now having your own label and all. And can you tell us just briefly that story? It’s like, why and how, and just how it happened and also where it goes?\nElliot: Yeah, sure. I mean, so I have actually been doing music for many, many years, in a very non-serious way. So I sort of started releasing some of my own music when I was in that year off that I mentioned before university. So I was like 18, and I released self-released a couple of EPs after that, but I was never really serious about it.\nElliot: And it wasn’t until, I think it was like 2015, something like that, 2014, 2015, where there were a couple of catalysts. One is that I’d kind of always liked some electronic music, but I was more into kind of rock and metal and stuff like that. And it wasn’t until then that I discovered some techno that for me, I thought, \"Wow, this is really interesting music. This is people doing something that I haven’t really heard.\"\nElliot: And although it was kind of dance music, it’s not just about dancing. There’s just way more to it than that. And it was really interesting to me. There were a few different artists doing some cool stuff around this time, Monique and Shifted and KiloWatt and Manny D and some people that I just come across. And I found their music genuinely really interesting as a listener.\nElliot: But it spurred me on to kind of say, \"Oh, maybe I could do some stuff like this.\" And then at exactly the same time I bought some hardware synths from... You can see them, they’re in the background there, these Volcas from, from Korg. And they’re really cheap. They’re analog synths, but they a really, really cheap, really dirty, and they’re just really fun to play with.\nElliot: And as soon as I was playing with them and like tweaking, turning knobs and moving sliders and just playing with the hardware and all those kind of happy accidents, again, that come with playing around with stuff like that. And coupled with the influence of these new artists, I thought, \"Wow, this is really interesting. Maybe I could make this kind of thing.\"\nElliot: And it just sort of, I suppose, made me start taking it a little bit more seriously. And there was one other catalyst. So in 2015, we had our first daughter and sort of from then, my time to be productive musically, but in general has definitely been very limited.\nElliot: And ironically that’s the time when I spent the most kind of going, \"Right, I have to do this thing, I have to be serious about music now.\" But I really do think that having that limited time to do this in, whereas before where the world is your oyster, you can spend all the time in the world, having a tiny window in which to be productive has actually helped me focus.\nElliot: Again, that was sort of happened to me rather than anything that... I didn’t kind of like plan for that level of productivity, but that really did help.\nElliot: And so I released my first EP as other form in 2017 and since, and even then I did it and then I kind of went quiet for a bit, but around 2019, things started to pick up again. Started to be making a lot more music, put something else out on a different label. And then I played a gig in Berlin at the end of 2019 and was like, \"Hey, this is the start of playing live in like some clubs around the world and stuff.\"\nElliot: And then of course, we all know how 2020 went, but during that time, during the pandemic and everything, I really kind of doubled down on getting music out and growing the label and releasing other people’s music not just my own stuff. And it’s been just a whole other adventure, as you say. Just kind of working out that side of things and I love it.\nElliot: It’s very different to design. I don’t think there are many parallels, really. There are certain organizational things that have helped. I mean, I kind of run my design life and my music life on Notion, for instance. But in terms of like their creativity and the kind of label admin stuff, I think it’s very different to my kind of day jobby stuff, and also takes up quite a lot of time. But it’s all fun.\nElliot: As soon as it stops being fun, I’m going to stop doing it.\nVitaly: Yeah. Well, I think that it’s incredible to see this energy in your eyes when I can see it now.\nElliot: Thank you.\nVitaly: And it’s wonderful to see you really kind of shining through, and maybe who knows maybe in a couple of months or so, we’ll see you all over the world. And I know that you will be in some parts of the world, that will be San Francisco.\nElliot: That’s right.\nVitaly: For the smashing conference. So that might be the time when we should be expecting your live performance, as well. What is a snippet of it, right?\nElliot: Maybe, maybe.\nVitaly: Well, maybe we’ll see about that. Well, if you, dear listener would like to hear more from Elliott. You can find him on Twitter where he’s well, what a big surprise, Elliot @elliotjaystocks, and also on his website, which is also a big surprise, elliotjaystocks.com. So you can always follow along and see what Elliot has to say, and also what he’s working on.\nVitaly: Well, thank you so much today for joining us, Elliot. Do you have any parting words of wisdom with the wonderful peoples listening to us today?\nElliot: No, I don’t have any parting words of wisdom. I hope you didn’t come here expecting wisdom.\nVitaly: Well, that counts for something, right? Well, thank you so much, Elliot and I’m very much looking forward to seeing you in San Francisco.\nElliot: You too. Thank you for having me, Vitaly.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/54ed7013-6796-4ff5-b13f-7133e3395de7/smashing-podcast-episode-46.png",
      "date_published": "2022-05-17T11:00:00.000Z",
      "date_modified": "2022-05-17T11:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/elementor-modern-way-create-host-wordpress-site/",
      "url": "https://smashingmagazine.com/2022/05/elementor-modern-way-create-host-wordpress-site/",
      "title": "The Modern Way To Create And Host A WordPress Site",
      "summary": "Let’s take a closer look at how you can create your very own WordPress site up and running created and hosted with the Elementor Cloud Website.",
      "content_html": "<p>This article is a sponsored by <a href=\"https://elementor.com/?utm_source=smashingmag&amp;utm_medium=referral&amp;utm_campaign=outreach\">Elementor</a></p>\n<p>What does it take to design a new website in 2022? Well, it’s possible to break this process into a few steps. You likely start with choosing a domain name for your website and buying it. Next, you will compare various hosting services and choose the one that satisfies your needs, and lastly, you will select a content management system (CMS) that fits your needs. After installing CMS on your hosting provider, you can start designing your website.</p>\n<p>Sounds tedious, right? With so many tools available on the market right now, finding the right tools can take hours or even days, and there is no guarantee that you will have a decent solution in the end. </p>\n<p>This proved to be the catalyst for Elementor’s latest solution: the <a href=\"https://elementor.com/features/cloud/?utm_source=smashingmag&amp;utm_medium=referral&amp;utm_campaign=outreach\">Elementor Cloud Website</a>. The Elementor team aimed to overcome this challenge. The <em>Elementor Cloud Website</em> is a new tool that will expand the WordPress website builder’s offerings with built-in hosting features. This hosting solution is based on the Google Cloud Platform, known for world-class security, scalability, and reliability. The platform offers 20 GB storage, 100 GB bandwidth, and 100K monthly visits which are enough for most types of websites. What it means is that with Elementor’s <em>Cloud Website</em>, web designers and developers can build and host their WordPress websites without the need to switch between different tools.</p>\nCreating A New Website With Elementor Cloud Website\n<p>The process of creating a new website with Cloud Website is simplified and faster. If you’re new to Elementor, you can visit the <a href=\"https://elementor.com/features/cloud/?utm_source=smashingmag&amp;utm_medium=referral&amp;utm_campaign=outreach\">Elementor Cloud Website</a> and click “Join Now” to create a new account. Once you’ve created a new account, you need to choose the option “Build &amp; Publish a complete Hosted Elementor Website”.</p>\n<p>If you are an Elementor user, you can log in to the Elementor admin panel where you will see a large button named “Create Cloud Website” at the top right corner of the page:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5d93b800-2eeb-435a-a752-7ea97a396ea9/1-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>Once you click this button, you will be invited to provide basic information about your website step-by-step. You will provide the website’s name, domain name, and type of website.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0211e64a-86e4-475c-810d-76c57cecac82/2-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>All websites created using Elementor Cloud Website will be hosted on subdomain <code>.elementor.cloud</code> by default, but you can easily link your own with no extra costs.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/57ae88e7-d445-4eff-bca7-bbaef0e85b17/3-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>You will be asked to specify the type of website you want to build. Elementor will use this information to suggest a relevant pre-designed website kit for your project. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a87ce585-df21-45e4-9809-7182161d80a6/4-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>Lastly, you will be asked to choose the visual kit for your website from the list of available options. You can always choose to design a website from scratch. For our example, I decided to use the Basic kit from the list suggested by Elementor. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5e84b395-3f9a-4f30-aded-9f0e4b0f04d2/5-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>Once you do that, Elementor will start building your website. The process of creating a new instance of your website will take a few minutes. Once it is done, you will see a shiny new instance of your website ready for use. Our instance is called WakeUp.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/246c4844-f5b3-421a-bc64-13686d77b946/6-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>You may notice the badge “Site Lock is On.” When Site Lock is enabled, search engines won’t display your site, so you don’t need to worry that someone will have access to your unfinished website. </p>\n<p>But what exactly comes with a newly created instance? You will have access to the WordPress dashboard, Elementor editor, and website settings. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/52af27b8-49cd-4cb2-b668-a05b2ae89714/7-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>Let’s click “Edit with Elementor” to start designing our website right away. </p>\nModifying Page Layout With Elementor Editor\n<p>All front-end designs of your website can be done with the Elementor editor. Elementor offers a WYSIWYG (What You See Is What You Get) editor for your web pages. When you introduce changes to your web page, you immediately see the results of your changes. For example, when we want to change the text in the hero section, all we need to do is to click on the content block and modify the text in it. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/50ab7a59-8f0b-4e2a-b26f-224293087073/8-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>If you want to add a new content section on your page, add a new section, choose the most relevant widget from the collection of 100+ widgets, and drag &amp; drop it into this section. Elementor supports almost all types of content — from text to visuals. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b6c5a9ee-f7a1-4203-8054-077400fbff86/9-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>But the process of editing is not limited to text or images. You can introduce fancy animated effects such as motion effects on scrolling. Such an effect can help you create a more dynamic scrolling experience and can convey a feeling that your website is alive.</p>\n<p>For example, here, I defined the “Fade In” effect with a duration of 300 ms for the section that comes after the Hero section and describes features that our product offers:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/87b455b1-743e-49ba-b3b2-136dc77670c1/10-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>The great thing about the Elementor editor is that you can check how your website looks on mobile or any other medium. Simply click “Responsive” Mode in the bottom left menu (next to the button “Update”) and click on the “Mobile” option. What you will see is how your website will look on mobile devices:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/806391d4-5330-42a5-8e66-6038af9d4173/11-elementor-modern-way-create-host-wordpress-site.png\" /></p>\nManaging The Website Using WordPress\n<p>Elementor Cloud Website provides access to full WordPress instances. It’s the same version of WordPress that you might download from the <a href=\"https://wordpress.com/\">official WordPress website</a> and install on your local or remote machine. Out of the box, this instance of WordPress comes with all essential features. You will have admin access to the CMS and be able to manage users who can access your website, import/export content, and install required plugins. But Elementor Cloud Website also offers a few neat benefits. WordPress comes with a pre-installed Elementor Pro plugin, Activity Log, which tells you what activities are taking place on your dashboard, and a collection of hundreds of visual themes that you can use for your website. Elementor Hello theme is already pre-installed as well.</p>\n<p>Another vital thing about Elementor Cloud Website is that you have all ownership of your content. If you decide to move your website to another platform (i.e., switch from WordPress to any other CMS), you can export your website at any time.</p>\nSetting Backups And Connecting Domain\n<p>Once you finish designing your website, you need to do two things: create a backup and connect the domain name. There are two kinds of people: those who back up and those who have never lost all their data. With Elementor Cloud Website, setting up backups is easy. All you have to do is click the “Manage This Website” option and find the “Backups” section. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1129ad7d-6d53-4d35-815d-69dcf370218c/12-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>As you can see, Elementor creates automatic backups for your website every 24 hours, but you can also create your own backup at any other moment using the “Create new backup” section.  </p>\n<p>Next, you need to connect your domain name to this website. It can also be done on this page, in the Manage Domain section. Some web creation platforms charge extra for connecting a custom domain name, but Elementor Cloud Website does it at no additional cost. </p>\n<p>You can notice that an SSL certificate is also enabled for our website. Elementor Cloud Website provides its users with a built-in free Secure Socket Layer (SSL) from Cloudflare. It gives you a couple of benefits — better search engine ranking (Google ranks <a href=\"https://developers.google.com/search/blog/2014/08/https-as-ranking-signal\">SSL higher than non-SSL counterparts</a>) and better user experience (if your website requires data input, site visitors will never see a \"Not Secure connection\" message in their browser). You can also install your own SSL certificate if required.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4e5b9b29-3bdc-42a0-8a78-7f68b0c3b42d/13-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>After a custom domain is connected, we can safely turn \"Site Lock\" off so search engines can discover our website. It also can be done in this section. </p>\nMeasuring The Performance Of Our Newly Created Website\n<p>Website performance plays a crucial role in how users think and feel about our website. Nobody likes interacting with slow websites, and when it comes to web performance, every second counts (literally). With every second you make your users wait for the site to load, you <a href=\"https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/mobile-page-speed-new-industry-benchmarks-load-time-vs-bounce/\">increase the chance that they abandon your site</a>.</p>\n<p>Measuring performance should be a regular exercise for site owners, so let’s use a popular tool called <a href=\"https://pagespeed.web.dev/\">PageSpeed Insights</a> to see how our newly created website performs. As you can see, the website has a score of 94 out of 100, which is really good. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/157e22d1-c259-4266-aa04-10c27b411326/14-elementor-modern-way-create-host-wordpress-site.png\" /></p>\n<p>You may wonder, what might cause slow website performance? While many problems can be responsible for slow site loading, high latency and using heavy imagery are at the top of the list:</p>\n<ul>\n<li><strong>High latency.</strong><br />Latency is the time it takes for data to pass from one point on a network to another. High latency can be caused by geographic location. For example, your website is located in the US, but your visitor accesses it from Europe.</li>\n<li><strong>Using many heavy imagery assets.</strong><br />Rendering too many high-resolution images in raw formats such as PNG can be time-consuming.</li>\n</ul>\n<p>But if you use Elementor Cloud Website, you are safe because it uses content delivery networks (CDNs) distributed worldwide. A CDN allows for the quick transfer of assets needed for loading, including images and videos. Your website content is stored in over 200 locations globally, so it responds quickly wherever your visitors are.</p>\n<blockquote>“Okay, this tool demonstrates solid performance when we test it for one visitor, but what happens when hundreds or thousands of visitors access it?”</blockquote>\n\n<p>Rest assured, you will be fine. Elementor Cloud Website harnesses the power of <a href=\"https://kubernetes.io/\">Kubernetes</a>, an open-source system for the management and scaling of containerized applications. Kubernetes enables Elementor Cloud Website to scale its hosting both fast and reliably regardless of a website’s usage, whether it draws ten or ten thousand visitors.</p>\nHow Much Does An Elementor Cloud Website Cost?\n<p>It took us less than an hour to create and publish a website using Elementor Cloud Website. You may assume that this tool will cost a lot of money. But in reality, this solution only costs $99.00/year (excluding VAT). For this sum, you will receive 100GB bandwidth for your website, 100K monthly unique visits, and 20GB of storage for all your content and assets. It’s important to note that Elementor Pro is thrown into the mix (a plan that costs $49 per year). There are no hidden costs. All those features are included at one price. </p>\nConclusion\n<p>Web design should be fun and accessible for anyone. After all, when we build a new website, our primary goal is to share our idea, product, or service with the world, not to dive into solving technical problems. Elementor Cloud Website saves us from the tedious and monotonous work of comparing various web services and helps us to focus on what’s really important—sharing our vision with people we care about.  </p>\n<p><em>This article has been kindly supported by our dear friends at <a href=\"https://elementor.com/?utm_source=smashingmag&amp;utm_medium=referral&amp;utm_campaign=outreach\">Elementor</a> whose goal is to empower web creators to design, publish and manage powerful and beautiful WordPress websites using the most comprehensive all-in-one design solution. Thank you!</em></p>",
      "content_text": "This article is a sponsored by Elementor\nWhat does it take to design a new website in 2022? Well, it’s possible to break this process into a few steps. You likely start with choosing a domain name for your website and buying it. Next, you will compare various hosting services and choose the one that satisfies your needs, and lastly, you will select a content management system (CMS) that fits your needs. After installing CMS on your hosting provider, you can start designing your website.\nSounds tedious, right? With so many tools available on the market right now, finding the right tools can take hours or even days, and there is no guarantee that you will have a decent solution in the end. \nThis proved to be the catalyst for Elementor’s latest solution: the Elementor Cloud Website. The Elementor team aimed to overcome this challenge. The Elementor Cloud Website is a new tool that will expand the WordPress website builder’s offerings with built-in hosting features. This hosting solution is based on the Google Cloud Platform, known for world-class security, scalability, and reliability. The platform offers 20 GB storage, 100 GB bandwidth, and 100K monthly visits which are enough for most types of websites. What it means is that with Elementor’s Cloud Website, web designers and developers can build and host their WordPress websites without the need to switch between different tools.\nCreating A New Website With Elementor Cloud Website\nThe process of creating a new website with Cloud Website is simplified and faster. If you’re new to Elementor, you can visit the Elementor Cloud Website and click “Join Now” to create a new account. Once you’ve created a new account, you need to choose the option “Build & Publish a complete Hosted Elementor Website”.\nIf you are an Elementor user, you can log in to the Elementor admin panel where you will see a large button named “Create Cloud Website” at the top right corner of the page:\n\nOnce you click this button, you will be invited to provide basic information about your website step-by-step. You will provide the website’s name, domain name, and type of website.\n\nAll websites created using Elementor Cloud Website will be hosted on subdomain .elementor.cloud by default, but you can easily link your own with no extra costs.\n\nYou will be asked to specify the type of website you want to build. Elementor will use this information to suggest a relevant pre-designed website kit for your project. \n\nLastly, you will be asked to choose the visual kit for your website from the list of available options. You can always choose to design a website from scratch. For our example, I decided to use the Basic kit from the list suggested by Elementor. \n\nOnce you do that, Elementor will start building your website. The process of creating a new instance of your website will take a few minutes. Once it is done, you will see a shiny new instance of your website ready for use. Our instance is called WakeUp.\n\nYou may notice the badge “Site Lock is On.” When Site Lock is enabled, search engines won’t display your site, so you don’t need to worry that someone will have access to your unfinished website. \nBut what exactly comes with a newly created instance? You will have access to the WordPress dashboard, Elementor editor, and website settings. \n\nLet’s click “Edit with Elementor” to start designing our website right away. \nModifying Page Layout With Elementor Editor\nAll front-end designs of your website can be done with the Elementor editor. Elementor offers a WYSIWYG (What You See Is What You Get) editor for your web pages. When you introduce changes to your web page, you immediately see the results of your changes. For example, when we want to change the text in the hero section, all we need to do is to click on the content block and modify the text in it. \n\nIf you want to add a new content section on your page, add a new section, choose the most relevant widget from the collection of 100+ widgets, and drag & drop it into this section. Elementor supports almost all types of content — from text to visuals. \n\nBut the process of editing is not limited to text or images. You can introduce fancy animated effects such as motion effects on scrolling. Such an effect can help you create a more dynamic scrolling experience and can convey a feeling that your website is alive.\nFor example, here, I defined the “Fade In” effect with a duration of 300 ms for the section that comes after the Hero section and describes features that our product offers:\n\nThe great thing about the Elementor editor is that you can check how your website looks on mobile or any other medium. Simply click “Responsive” Mode in the bottom left menu (next to the button “Update”) and click on the “Mobile” option. What you will see is how your website will look on mobile devices:\n\nManaging The Website Using WordPress\nElementor Cloud Website provides access to full WordPress instances. It’s the same version of WordPress that you might download from the official WordPress website and install on your local or remote machine. Out of the box, this instance of WordPress comes with all essential features. You will have admin access to the CMS and be able to manage users who can access your website, import/export content, and install required plugins. But Elementor Cloud Website also offers a few neat benefits. WordPress comes with a pre-installed Elementor Pro plugin, Activity Log, which tells you what activities are taking place on your dashboard, and a collection of hundreds of visual themes that you can use for your website. Elementor Hello theme is already pre-installed as well.\nAnother vital thing about Elementor Cloud Website is that you have all ownership of your content. If you decide to move your website to another platform (i.e., switch from WordPress to any other CMS), you can export your website at any time.\nSetting Backups And Connecting Domain\nOnce you finish designing your website, you need to do two things: create a backup and connect the domain name. There are two kinds of people: those who back up and those who have never lost all their data. With Elementor Cloud Website, setting up backups is easy. All you have to do is click the “Manage This Website” option and find the “Backups” section. \n\nAs you can see, Elementor creates automatic backups for your website every 24 hours, but you can also create your own backup at any other moment using the “Create new backup” section.  \nNext, you need to connect your domain name to this website. It can also be done on this page, in the Manage Domain section. Some web creation platforms charge extra for connecting a custom domain name, but Elementor Cloud Website does it at no additional cost. \nYou can notice that an SSL certificate is also enabled for our website. Elementor Cloud Website provides its users with a built-in free Secure Socket Layer (SSL) from Cloudflare. It gives you a couple of benefits — better search engine ranking (Google ranks SSL higher than non-SSL counterparts) and better user experience (if your website requires data input, site visitors will never see a \"Not Secure connection\" message in their browser). You can also install your own SSL certificate if required.\n\nAfter a custom domain is connected, we can safely turn \"Site Lock\" off so search engines can discover our website. It also can be done in this section. \nMeasuring The Performance Of Our Newly Created Website\nWebsite performance plays a crucial role in how users think and feel about our website. Nobody likes interacting with slow websites, and when it comes to web performance, every second counts (literally). With every second you make your users wait for the site to load, you increase the chance that they abandon your site.\nMeasuring performance should be a regular exercise for site owners, so let’s use a popular tool called PageSpeed Insights to see how our newly created website performs. As you can see, the website has a score of 94 out of 100, which is really good. \n\nYou may wonder, what might cause slow website performance? While many problems can be responsible for slow site loading, high latency and using heavy imagery are at the top of the list:\n\nHigh latency.Latency is the time it takes for data to pass from one point on a network to another. High latency can be caused by geographic location. For example, your website is located in the US, but your visitor accesses it from Europe.\nUsing many heavy imagery assets.Rendering too many high-resolution images in raw formats such as PNG can be time-consuming.\n\nBut if you use Elementor Cloud Website, you are safe because it uses content delivery networks (CDNs) distributed worldwide. A CDN allows for the quick transfer of assets needed for loading, including images and videos. Your website content is stored in over 200 locations globally, so it responds quickly wherever your visitors are.\n“Okay, this tool demonstrates solid performance when we test it for one visitor, but what happens when hundreds or thousands of visitors access it?”\n\nRest assured, you will be fine. Elementor Cloud Website harnesses the power of Kubernetes, an open-source system for the management and scaling of containerized applications. Kubernetes enables Elementor Cloud Website to scale its hosting both fast and reliably regardless of a website’s usage, whether it draws ten or ten thousand visitors.\nHow Much Does An Elementor Cloud Website Cost?\nIt took us less than an hour to create and publish a website using Elementor Cloud Website. You may assume that this tool will cost a lot of money. But in reality, this solution only costs $99.00/year (excluding VAT). For this sum, you will receive 100GB bandwidth for your website, 100K monthly unique visits, and 20GB of storage for all your content and assets. It’s important to note that Elementor Pro is thrown into the mix (a plan that costs $49 per year). There are no hidden costs. All those features are included at one price. \nConclusion\nWeb design should be fun and accessible for anyone. After all, when we build a new website, our primary goal is to share our idea, product, or service with the world, not to dive into solving technical problems. Elementor Cloud Website saves us from the tedious and monotonous work of comparing various web services and helps us to focus on what’s really important—sharing our vision with people we care about.  \nThis article has been kindly supported by our dear friends at Elementor whose goal is to empower web creators to design, publish and manage powerful and beautiful WordPress websites using the most comprehensive all-in-one design solution. Thank you!",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/74301596-05b5-4dff-98ad-dd8c62c97c69/elementor-modern-way-create-host-wordpress-site.jpg",
      "date_published": "2022-05-17T10:30:00.000Z",
      "date_modified": "2022-05-17T10:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/rethinking-server-timing-monitoring-tool/",
      "url": "https://smashingmagazine.com/2022/05/rethinking-server-timing-monitoring-tool/",
      "title": "Rethinking Server-Timing As A Critical Monitoring Tool",
      "summary": "What makes the underused `Server-Timing` header uniquely powerful among all other response headers? We’ll rethink the expectation for using it exclusively for timing and see fast solutions for hard-to-solve monitoring challenges.",
      "content_html": "<p>In the world of HTTP Headers, there is one header that I believe deserves more air-time and that is the <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Server-Timing\"><code>Server-Timing</code> header</a>. To me, it’s a must-use in any project where real user monitoring (RUM) is being instrumented. To my surprise, web performance monitoring conversations rarely surface <code>Server-Timing</code> or cover a very shallow understanding of its application — despite it being out for many years.</p>\n<p>Part of that is due to the perceived limitation that it’s exclusively for tracking time on the server — it can provide so much more value! Let’s rethink how we can leverage this header. In this piece, we will dive deeper to show how <code>Server-Timing</code> headers are so uniquely powerful, show some practical examples by solving challenging monitoring problems with this header, and provoke some creative inspiration by combining this technique with service workers.</p>\n<p><code>Server-Timing</code> is uniquely powerful, because it is the <strong>only</strong> HTTP Response header that supports setting free-form values for a specific resource and makes them accessible from a JavaScript Browser API separate from the Request/Response references themselves. This allows resource requests, including the HTML document itself, to be enriched with data during its lifecycle, and that information can be inspected for measuring the attributes of that resource!</p>\n<p>The only other header that’s close to this capability is the HTTP <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie\"><code>Set-Cookie</code></a> / <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cookie\"><code>Cookie</code></a> headers. Unlike <code>Cookie</code> headers, <code>Server-Timing</code> is only on the response for a specific resource where <code>Cookies</code> are sent on requests and responses for all resources after they’re set and unexpired. Having this data bound to a single resource response is preferable, as it prevents ephemeral data about all responses from becoming ambiguous and contributes to a growing collection of cookies sent for remaining resources during a page load. </p>\nSetting <code>Server-Timing</code>\n<p>This header can be set on the response of any network resource, such as XHR, fetch, images, HTML, stylesheets, etc. Any server or proxy can add this header to the request to provide inspectable data. The header is constructed via a name with an optional description and/or metric value. The only required field is the name. Additionally, there can be many <code>Server-Timing</code> headers set on the same response which would be combined and separated via a comma.</p>\n<p>A few simple examples:</p>\n<pre><code>Server-Timing: cdn_process;desc=”cach_hit\";dur=123\n\nServer-Timing: cdn_process;desc=”cach_hit\", server_process; dur=42;\n\nServer-Timing: cdn_cache_hit\n\nServer-Timing: cdn_cache_hit; dur=123</code></pre>\n\n<p><strong>Important Note</strong>: For cross-origin resources, <code>Server-Timing</code> and other potentially sensitive timing values are not exposed to consumers. To allow these features, we will also need the <code>Timing-Allow-Origin</code> header that includes our origin or the <code>*</code> value.</p>\n<p>For this article, that’s all we’ll need to start exposing the value and leave other more specific articles to go deeper. <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Server-Timing\">MDN docs</a>.</p>\nConsuming <code>Server-Timing</code>\n<p>Web browsers expose a global Performance Timeline API to inspect details about specific metrics/events that have happened during the page lifecycle. From this API we can access built-in performance API extensions which expose timings in the form of <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/PerformanceEntry\"><code>PerformanceEntries</code></a>.</p>\n<p>There are a handful of different entry subtypes but, for the scope of this article, we will be concerned with the <code>PerformanceResourceTiming</code> and <code>PerformanceNavigationTiming</code> subtypes. These subtypes are currently the only subtypes related to network requests and thus exposing the <code>Server-Timing</code> information.</p>\n<p>For the top-level HTML document, it is fetched upon user navigation but is still a resource request. So, instead of having different <code>PerformanceEntries</code> for the navigation and the resource aspects, the <code>PerformanceNavigationTiming</code> provides resource loading data as well as additional navigation-specific data. Because we are looking at just the resource load data, we will exclusively refer to the requests (navigational docs or otherwise) simply as resources.</p>\n<p>To query performance entries, we have 3 APIs that we can call: <code>performance.getEntries()</code>, <code>performance.getEntriesByType()</code>, <code>performance.getEntriesByName()</code>. Each will return an array of performance entries with increasing specificity.</p>\n<pre><code>const navResources = performance.getEntriesByType('navigation');\nconst allOtherResources = performance.getEntriesByType('resource');</code></pre>\n\n<p>Finally, each of these resources will have a <code>serverTiming</code> field which is an array of objects mapped from the information provided in the <code>Server-Timing</code> header — where <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/PerformanceServerTiming\"><code>PerformanceEntryServerTiming</code></a> is supported (see considerations below). The shape of the objects in this array is defined by the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/PerformanceServerTiming\"><code>PerformanceEntryServerTiming</code></a> interface which essentially maps the respective <code>Server-Timing</code> header metric options: <code>name</code>, <code>description</code>, and <code>duration</code>.</p>\n<p>Let’s look at this in a complete example.</p>\n<p>A request was made to our data endpoint and among the headers, we sent back the following:</p>\n<pre><code>Server-Timing: lookup_time; dur=42, db_cache; desc=”hit”;</code></pre>\n\n<p>On the client-side, let’s assume this is our only resource loaded on this page:</p>\n<pre><code>\nconst dataEndpointEntry = performance.getEntriesByName('resource')[0];\n\nconsole.log( dataEndpointEntry.serverTiming );\n\n// outputs:\n// [\n//   { name: “lookup_time”, description: undefined, duration: 42 },\n//   { name: “db_cache”, description:”hit”, duration: 0.0 },\n// ]</code></pre>\n\n<p>That covers the fundamental APIs used to access resource entries and the information provided from a <code>Server-Timing</code> header. For links to more details on these APIs, see the resources section at the bottom.</p>\n<p>Now that we have the fundamentals of how to set and use this header/API combo, let’s dive into the fun stuff.</p>\nIt’s Not Just About Time\n<p>From my conversations and work with other developers, the name “Server-Timing” impresses a strong connection that this is a tool used to track spans of time or a detail about a span of time exclusively. This is entirely justified by the name and the intent of the feature. However, the spec for this header is very flexible; allowing for values and expressing information that could have nothing to do with timing or performance in any way. Even the <code>duration</code> field has no predefined unit of measurement — you can put any number (double) in that field. By stepping back and realizing that the fields available have no special bindings to particular types of data, we can see that this technique is also an effective delivery mechanism for any arbitrary data allowing lots of interesting possibilities.  </p>\n<p>Examples of non-timing information you could send: HTTP Response status code, regions, request ids, etc. — any freeform data that suits your needs. In some cases, we might send redundant information that might be in other headers already, but that’s ok. As we will cover, accessing other headers for resources quite often isn’t possible, and if it has monitoring value, then it’s ok to be redundant.</p>\nNo References Required\n<p>Due to the design of web browser APIs, there are currently no mechanisms for querying requests and their relative responses after the fact. This is important because of the need to manage memory. To read information about a request or its respective response, we have to have a direct reference to these objects. All of the web performance monitoring software we work with provide RUM clients that put additional layers of monkey patching on the page to maintain direct access to a request being made or the response coming back. This is how they offer drop-in monitoring of all requests being made without us needing to change our code to monitor a request. This is also why these clients require us to put the client before any request that we want to monitor. The complexities of patching all of the various networking APIs and their linked functionality can become very complex very quickly. If there were an easy access mechanism to pull relevant resource/request information about a request, we would certainly prefer to do that on the monitoring side.</p>\n<p>To make matters more difficult, this monkey-patching pattern only works for resources where JavaScript is directly used to initiate the networking. For Images, Stylesheets, JS files, the HTML Doc, etc. the methods for monitoring the request/response details are very limited, as usually there is no direct reference available. </p>\n<p>This is where the Performance Timeline API provides great value. As we saw earlier, it quite literally is a list of requests made and some data about each of them respectively. The data for each performance entry is very minimal and almost entirely limited to timing information and some fields that, depending on their value, would impact how a resource’s performance is measured relative to other resources. Among the timing fields, we have direct access to the <code>serverTiming</code> data.</p>\n<p>Putting all of the pieces together, resources can have <code>Server-Timing</code> headers in their network responses that contain arbitrary data. Those resources can then be easily queried, and the <code>Server-Timing</code> data can be accessed without a direct reference to the request/response itself. With this, it doesn’t matter if you can access/manage references for a resource, all resources can be enriched with arbitrary data accessible from an easy-to-use web browser API. That’s a very unique and powerful capability!</p>\n<p>Next, let’s apply this pattern to some traditionally tough challenges to measure.</p>\nSolution 1: Inspecting Images and Other Asset Responses\n<p>Images, stylesheets, JavaScript files, etc. typically aren’t created by using direct references to the networking APIs with information about those requests. For example, we almost always trigger image downloads by putting an <code>img</code> element in our HTML. There are techniques for loading these assets which require using JavaScript <code>fetch</code>/<code>xhr</code> APIs to pull the data and push it into an asset reference directly. While that alternate technique makes them easier to monitor, it is catastrophic to performance in most cases. The challenge is how do we inspect these resources without having direct networking API references?</p>\n<p>To tie this to real-world use cases, it’s important to ask why might we want to inspect and capture response information about these resources? Here are a few reasons:</p>\n<ul>\n<li><strong>We might want to proactively capture details like status codes for our resources, so we can triage any changes.</strong><br />For example, missing images (404s) are likely totally different issues and types of work than dealing with images returning server errors (500s).</li>\n<li><strong>Adding monitoring to parts of our stack that we don’t control.</strong><br />Usually, teams offload these types of assets to a CDN to store and deliver to users. If they are having issues, how quickly will the team be able to detect the issue?</li>\n<li><strong>Runtime or on-demand variations of resources have become more commonplace techniques.</strong><br />For example, image resizing, automatic polyfilling of scripts on the CDN, etc — these systems can have many limits and reasons for why they might not be able to create or deliver a variation. If you expect that 100% of users retrieve a particular type of asset variation, it’s valuable to be able to confirm that.<br />This came up at a previous company I worked at where on-demand image resizing was used for thumbnail images. Due to the limitations of the provider, a significant number of users would get worse experiences due to full-size images loading where thumbnails are supposed to appear. So, where we thought &gt;99% of users would get optimal images, &gt;30% would hit performance issues, because images did not resize.</li>\n</ul>\n<p>Now that we have some understanding of what might motivate us to inspect these resources, let’s see how <code>Server-Timing</code> can be leveraged for inspection. </p>\n<p>Image HTML:</p>\n<div>\n<pre><code>&lt;img src=\"/user-rsrc/12345?resize=true&amp;height=80&amp;width=80&amp;format=webp\" alt=\"...\"/&gt;</code></pre>\n</div>\n\n<p>Image response headers:</p>\n<div>\n<pre><code>Status: 200\n…\nServer-Timing: status_code; dur=200;, resizing; desc=”failed”; dur=1200; req_id; desc=”zyx4321”</code></pre>\n</div>\n\n<p>Inspecting the image response information:</p>\n<div>\n<pre><code>const imgPerfEntry = performance.getEntriesByName('/user-rsrc/12345?resize=true&amp;height=80&amp;width=80&amp;format=webp')[0];\n\n// filter/capture entry data as needed\nconsole.log(imgPerfEntry.serverTiming);\n\n// outputs:\n// [\n//   { name: “status_code”, description: undefined, duration: 200 },\n//   { name: “resizing”, description:”failed”, duration: 1200 },\n//   { name: “req_id”, description:”zyx4321”, duration: 0.0 },\n// ]</code></pre>\n</div>\n\n<p>This metric was very valuable because, despite returning “happy” responses (200s), our images weren’t resized and potentially not converted to the right format, etc. Along with the other performance information on the entry like download times, we see the status was served as <code>200</code> (not triggering our onerror handlers on the element), resizing failed after spending <code>1.2s</code> on attempting to resize, and we have a request-id that we can use to debug this in our other tooling. By sending this data to our RUM provider, we can aggregate and proactively monitor how often these conditions happen.</p>\nSolution 2: Inspect Resources That Return Before JS Runs\n<p>Code used to monitor resources (fetch, XHR, images, stylesheets, scripts, HTML, etc.) requires JavaScript code to aggregate and then send the information somewhere. This almost always means there’s an expectation for the monitoring code to run before the resources that are being monitored. The example presented earlier of the basic monkey patching used to automatically monitor fetch requests is a good example of this. That code has to run before any fetch request that needs to be monitored. However, there are lots of cases, from performance to technical constraints, where we might not be able to or simply should not change the order in which a resource is requested to make it easier to be monitored.</p>\n<p>Another very common monitoring technique is to put event listeners on the page to capture events that might have monitoring value. This usually comes in the form of <code>onload</code> or <code>onerror</code> handlers on elements or using <code>addEventListener</code> more abstractly. This technique requires JS to have been set before the event fires, or before the listener itself is attached. So, this approach still carries the characteristic only monitoring events going forward, after the monitoring JS is run, thus requiring the JS to execute before the resources requiring measurement.</p>\n<p>Mapping this to real-world use-cases, e-commerce sites put a heavy emphasis on “above the fold” content rendering very quickly — typically deferring JS as much as possible. That said, there might be resources that are impactful to measure, such as successful delivery of the product image. In other situations, we might also decide that the monitoring library itself shouldn’t be in the critical path due to page weight. What are the options to inspect these requests retroactively?</p>\n<p>The technique is the same as Solution #1! This is possible because browsers automatically maintain a buffer of all of the Performance Entries (subject to the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Performance/setResourceTimingBufferSize\">buffer size limit</a> that can be changed). This allows us to defer JS until later in the page load cycle without needing to add listeners ahead of the resource.</p>\n<p>Instead of repeating the Solution #1 example, let’s look at what both retroactive and future inspection of performance entries looks like to show the difference of where they can be leveraged. Please note that, while we are inspecting images in these examples, we can do this for any resource type.</p>\n<p>Setting up context for this code, our need is that we have to ensure our product images are being delivered successfully. Let’s assume all website images return this <code>Server-Timing</code> header structure. Some of our important images can happen before our monitoring script and, as the user navigates, more will continue to load. How do we handle both?</p>\n<p>Image response headers:</p>\n<div>\n<pre><code>Status: 200\n…\nServer-Timing: status_code; dur=200;, resizing; desc=\"success\"; dur=30; req_id; desc=\"randomId\"</code></pre>\n</div>\n\n<p>Our monitoring logic. We expect this to run after the critical path content of the page.</p>\n<p>Inspecting the image response information:</p>\n<div>\n<pre><code>function monitorImages(perfEntries){\n  perfEntries.forEach((perfEntry)=&gt;{\n  // monitoring for the performance entries\n\nconsole.log(perfEntry.serverTiming);\n})\n}\n\nconst alreadyLoadedImageEntries = performance.getEntriesByType('resource').filter(({ initiatorType })=&gt; initiatorType === 'img');\n\nmonitorImages( alreadyLoadedImageEntries );\n\nconst imgObserver = new PerformanceObserver(function(entriesList) {\nconst newlyLoadedImageEntries = entriesList.getEntriesByType('resource').filter(({ initiatorType })=&gt; initiatorType === 'img');\n  monitorImages( newlyLoadedImageEntries );\n});\nimgObserver.observe({entryTypes: [\"resource\"]});\n</code></pre>\n</div>\n\n<p>Despite deferring our monitoring script until it was out of the critical path, we are capturing the data for all images which have loaded before our script and will continue to monitor them, as the user continues using the site.</p>\nSolution 3: Inspecting the HTML Doc\n<p>The final example solution we will look at is related to the ultimate “before JS can run” resource — the HTML document itself. If our monitoring solutions are loaded as JS via the HTML, how can we monitor the delivery of the HTML document?</p>\n<p>There is some precedence in monitoring HTML doc delivery. For monitoring response data, the most common setup is to use server logs/metrics/traces to capture this information. That is a good solution but depending on the tooling, the data may be decoupled from RUM data causing us to need multiple tools to inspect our user experiences. Additionally, this practice could also miss metadata (page instance identifiers for example) that allows us to aggregate and correlate information for a given page load — for example, correlating async requests failing when the doc returns certain document response codes.</p>\n<p>A common pattern for doing this work is putting the content inside of the HTML content itself. This has to be put into the HTML content, because the JS-based monitoring logic does not have access to the HTML request headers that came before it. This turns our HTML document into a dynamic document content. This may be fine for our needs and allows us to take that information and provide it to our RUM tooling. However, this could become a challenge if our system for HTML delivery is out of our control, or if the system has some assumptions into how HTML delivery must function. Examples of this might be, expecting that the HTML is fully static, such that we can cache it downstream in some deterministic manner — “partially dynamic” HTML bodies are much more likely to be handled incorrectly by caching logic. </p>\n<p>Within the HTML delivery process, there could also be additional data that we want to understand, such as what datacenters processed the request throughout the chain. We might have a CDN edge handler that proxies a request from an origin. In this case, we can’t expect each layer could/should process and inject HTML content. How might <code>Server-Timing</code> headers help us here?</p>\n<p>Building on the concepts of Solution #1 and Solution #2, here’s how we can capture valuable data about the HTML document itself. Keep in mind that any part of the stack can add a <code>Server-Timing</code> header to the response, and it will be joined together in the final header value.</p>\n<p>Let’s assume we have a CDN edge handler and an origin which can process the document:</p>\n<p>CDN added response headers:</p>\n<div>\n<pre><code>Status: 200\n…\nServer-Timing: cdn_status_code; dur=200;, cdn_cache; desc=”expired”; dur=15; cdn_datacenter; desc=”ATL”; cdn_req_id; desc=”zyx321abc789”; cdn_time; dur=120;\n</code></pre>\n</div>\n\n<p>Origin added response headers:</p>\n<div>\n<pre><code>Status: 200\n…\nServer-Timing: origin_status_code; dur=200;, origin_time; dur=30; origin_region; desc=”us-west”; origin_req_id; desc=\"qwerty321ytrewq789\";\n</code></pre>\n</div>\n\n<p>Inspecting the HTML response information:</p>\n<div>\n<pre><code>// as mentioned earlier, the HTML document is a 'navigation' type of Performance Entry\n// that has a superset of information related to the resource and the navigation-specific info\nconst htmlPerfEntry = performance.getEntriesByType('navigation')[0];\n\n// filter/capture entry data as needed\nconsole.log(htmlPerfEntry.serverTiming);\n\n// outputs:\n// [\n//   { name: “cdn_status_code”, description: undefined, duration: 200 },\n//   { name: “cdn_cache”, description:”expired”, duration: 0.0},\n//   { name: “cdn_datacenter”, description:”ATL”, duration: 0.0 },\n//   { name: “cdn_req_id”, description:”zyx321abc789”, duration: 0.0 },\n//   { name: “cdn_time”, description: undefined, duration: 120 },\n//   { name: “origin_status_code”, description: undefined, duration: 200 },\n//   { name: “origin_time”, description: undefined, duration: 30 },\n//   { name: “origin_region”, description:”us-west”, duration: 0.0 },\n//   { name: “origin_req_id”, description:”qwerty321ytrewq789”, duration: 0.0 },\n// ]</code></pre>\n</div>\n\n<p>From this information, our monitoring JavaScript (which could have been loaded way later) can aggregate where the HTML processing happened, status codes from the different servers (which can differ for legit reasons — or bugs), and request identifiers if they need to correlate this with server logs. It also knows how much time was taken on the “server” via the <code>cdn_time</code> duration — “server” time being the total time starting at the first non-user proxy/server that we provide. Using that <code>cdn_time</code> duration, the already accessible HTML Time-To-First-Byte value and the <code>origin_time</code> duration, we can determine latency sections more accurately, such as the user latency, the <code>cdn</code> to origin latency, etc. This is incredibly powerful in optimizing such a critical delivery point and protecting it from regression.</p>\nCombining Server-Timing with Service Workers\n<p><a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API\">Service Workers</a> are scripts that are initialized by the website to sit between the website, the browser, and the network (when available). When acting as a proxy, they can be used to read and modify requests coming from and responses returning to the website. Given service workers are so feature rich, we won’t attempt to cover them in depth in this article — a simple web search will yield a mountain of information about their capabilities. For this article, we will focus on the proxying capability of a service worker — it’s ability to process requests/responses. </p>\n<p>The key to combining these tools is knowing that the <code>Server-Timing</code> header and its respective <code>PerformanceEntry</code> is calculated <strong>after</strong> service worker proxying takes place. This allows us to use the service workers to add <code>Server-Timing</code> headers to responses that can provide valuable information about the request itself.</p>\n<p>What type of information might we want to capture within the service worker? As mentioned before, service workers have lots of capabilities, and any one of those actions could produce something valuable to capture. Here are a few that come to mind:</p>\n<ul>\n<li>Is this request served from the service worker cache?</li>\n<li>Is this served from the service worker while off-line?</li>\n<li>What service worker strategy for this request type is being used?</li>\n<li>What version of the service worker is being used?<br />This is helpful in checking our assumptions about service worker invalidation.</li>\n<li>Take values from other headers and put them into a <code>Server-Timing</code> header for downstream aggregation.<br />Valuable when we don’t have the option to change the headers on the request but would like to inspect them in RUM — such is usually the case with CDN providers.</li>\n<li>How long has a resource been in service worker cache?</li>\n</ul>\n<p>Service workers have to be initialized on the website which is an asynchronous process itself. Furthermore, service workers only process requests within the defined scope. As such, even the basic question of, “is this request processed by the service worker?” can drive interesting conversations on how much we are leaning on its capabilities to drive great experiences.</p>\n<p>Let’s dive into how this might look in the code.</p>\n<p>Basic JS logic used on the site to initialize the service worker:</p>\n<div>\n<pre><code>if ('serviceWorker' in navigator) {\nnavigator.serviceWorker.register('/service-worker.js').then(function (registration) {\nregistration.update(); // immediately start using this sw\n });\n}</code></pre>\n</div>\n\n<p>Inside of <code>/service-worker.js</code>, basic request/response proxying:</p>\n<div>\n<pre><code>const CACHE_NAME = 'sw-cached-files-v1';\n\nself.addEventListener('fetch', function (event) {\n  event.respondWith(\n    // check to see if this request is cached\n    caches.match(event.request)\n      .then(function (response) {\n\n        // Cache hit - return response\n        if (response) {\n          const updatedHeaders = new Headers(response.headers);\n          updatedHeaders.append('Server-Timing', 'sw_cache; desc=\"hit\";');\n          const updatedResponse = new Response(response.body, {\n            ...response,\n            headers: updatedHeaders\n          });\n          return updatedResponse;\n        }\n\n        return fetch(event.request).then(function (response) {\n\n            // depending on the scope where we load our service worker,\n            // we might need to filter our responses to only process our\n            // first-party requests/responses\n            // Regex match on the event.request.url hostname should\n\n            const updatedHeaders = new Headers(response.headers);\n            updatedHeaders.append('Server-Timing', <code>status&amp;#95;code;desc=${response.status};, sw&amp;#95;cache; desc=\"miss\";</code>)\n\n            const modifiableResponse = new Response(response.body, {\n              ...response,\n              headers: updatedHeaders\n            });\n\n            // only cache known good state responses\n            if (!response || response.status !== 200 || response.type !== 'basic' || response.headers.get('Content-Type').includes('text/html')) {\n              return modifiableResponse;\n            }\n\n            const responseToCache = modifiableResponse.clone();\n\n            caches.open(CACHE_NAME).then(function (cache) {\n              cache.put(event.request, responseToCache);\n            });\n\n            return modifiableResponse;\n          }\n        );\n      })\n  );\n});</code></pre>\n</div>\n\n<p>Requests that are processed from the service worker, now will have a <code>Server-Timing</code> header appended to their responses. This allows us to inspect that data via the Performance Timeline API, as we demonstrated in all of our prior examples. In practice, we likely didn’t add the service worker for this single need — meaning we already have it instrumented for handling requests. Adding the one header in 2 places allowed us to measure status codes for all requests, service worker-based cache-hit ratios, and how often service workers are processing requests.</p>\n<h3>Why Use <code>Server-Timing</code> If We Have Service Workers?</h3>\n<p>This is an important question that comes up when discussing combining these techniques. If a service worker can grab all of the header and content information, why do we need a different tool to aggregate it? </p>\n<p>The work of measuring timing and other arbitrary metadata about requests is almost always, so that we can send this information to a RUM provider for analysis, alerting, etc. All major RUM clients have 1 or 2 windows for which we can enrich the data about a request — when the response happens, and when the <code>PerformanceEntry</code> is detected. For example, if we make a fetch request, the RUM client captures the request/response details and sends it. If a <code>PerformanceEntry</code> is observed, the client sends that information as well — attempting to associate it to the prior request if possible. If RUM clients offer the ability to add information about that requests/entries, those were the only windows to do it. </p>\n<p>In practice, a service worker may or may not be activated yet, a request/response may or may not have processed the service worker, and all service worker data sharing requires async messaging to the site via <code>postMessage()</code> API. All of these aspects introduce race conditions for a service worker to be active, able to capture data, and then send that data in time to be enriched by the RUM client.</p>\n<p>Contrasting this with <code>Server-Timing</code>, a RUM client that processes the Performance Timeline API will immediately have access to any <code>Server-Timing</code> data set on the <code>PerformanceEntry</code>.</p>\n<p>Given this assessment of service worker’s challenges with enriching request/response data reliably, my recommendation is that service workers be used to provide more data and context instead of being the exclusive mechanism for delivering data to the RUM client on the main thread. That is, use <code>Server-Timing</code> and, where needed, use service worker to add more context or in cases where <code>Server-Timing</code> isn’t supported — if required. In this case, we might be creating custom events/metrics instead of enriching the original request/response data aggregation, as we will assume that the race conditions mentioned will lead to missing the windows for general RUM client enrichment.</p>\nConsiderations for <code>Server-Timing</code> Usage\n<p>As uniquely powerful as it is, it’s not without important considerations. Here’s a list of considerations based on the current implementation at time of writing:</p>\n<ul>\n<li><strong>Browser Support</strong> — Safari does not support putting the <code>Server-Timing</code> data into the Performance Timeline API (they do show it in DevTools).<br />This is a shame, however, given this is not about functionality for users, but instead it’s about improved capabilities for performance monitoring — I side with this not being a blocking problem. With browser-based monitoring, we never expect to measure 100% of browsers/users. Currently, this means we’d look to get ~70-75% support based on global browser usage data. Which is usually more than enough to feel confident that our metrics are showing us good signals about the health and performance or our systems. As mentioned, <code>Server-Timing</code> is sometimes the only way to get those metrics reliably, so we should feel confident about leveraging this tool.<br />As mentioned previously, if we absolutely have to have this data for Safari, we could explore using a cookie-based solution for Safari users. Any solutions here would have to be tested heavily to ensure they don’t hinder performance. </li>\n<li><strong>If we are looking to improve performance, we want to avoid adding lots of weight to our responses, including headers.</strong> This is a trade-off of additional weight for value added metadata. My recommendation is that if you’re not in the range 500 bytes or more to your <code>Server-Timing</code> header, I would not be concerned. If you are worried, try varying lengths and measure its impact!</li>\n<li><strong>When appending multiple <code>Server-Timing</code> headers on a single response, there is a risk of duplicate <code>Server-Timing</code> metric names.</strong> Browsers will surface all of them in the <code>serverTiming</code> array on the <code>PerformanceEntry</code>. It’s best to ensure that this is avoided by specific or namespaced naming. If it can’t be avoided, then we would break down the order of events that added each header and define a convention we can trust. Otherwise, we can create a utility that doesn’t blindly add <code>Server-Timing</code> entries but will also update existing entries if they are already on the Response.</li>\n<li><strong>Try to avoid the mistake of misremembering that responses cache the <code>Server-Timing</code> values as well.</strong> In some cases you might want to filter out the timing-related data of cached responses that, before they were cached, spent time on the server. There are varying ways to detect if the request went to the network with data on the <code>PerformanceEntry</code>, such as <code>entry.transferSize &gt; 0</code>, or <code>entry.decodedBodySize &gt; 0</code>, or <code>entry.duration &gt; 40</code>. We can also lean into what we’ve learned with <code>Server-Timing</code> to set a timestamp on the header for comparison.</li>\n</ul>\nWrapping Up\n<p>We’ve gone pretty deep into the application of the <code>Server-Timing</code> Header for use cases that aren’t aligned to the “timing” use case that this header is generally associated with. We’ve seen its power to add freeform data about a resource and access the data without needing a reference to the networking API used to make it. This is a very unique capability that we leveraged to measure resources of all types, inspect them retroactively, and even capture data about the HTML doc itself. Combining this technique with service workers, we can add more information from the service worker itself or to map response information from uncontrolled server responses to <code>Server-Timing</code> for easy access.</p>\n<p>I believe that <code>Server-Timing</code> is so impressively unique that it should be used way more, but I also believe that it shouldn’t be used for everything. In the past, this has been a must-have tool for performance instrumentation projects I’ve worked on to provide impossible to access resource data and identify where latency is occuring. If you’re not getting value out of having the data in this header, or if it doesn’t fit your needs — there’s no reason to use it. The goal of this article was to provide you with a new perspective on <code>Server-Timing</code> as a tool to reach for, even if you’re not measuring time. </p>\n<h3>Resources</h3>\n<ul>\n<li><a href=\"https://www.w3.org/TR/server-timing/\">W3C Server Timing</a></li>\n<li><a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Server-Timing\">Server-Timing MDN</a></li>\n<li>“<a href=\"https://www.smashingmagazine.com/2018/10/performance-server-timing/\">Measuring Performance With Server Timing</a>”, Drew McLellan</li>\n<li><a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Performance_Timeline\">Performance Timeline MDN</a></li>\n</ul>",
      "content_text": "In the world of HTTP Headers, there is one header that I believe deserves more air-time and that is the Server-Timing header. To me, it’s a must-use in any project where real user monitoring (RUM) is being instrumented. To my surprise, web performance monitoring conversations rarely surface Server-Timing or cover a very shallow understanding of its application — despite it being out for many years.\nPart of that is due to the perceived limitation that it’s exclusively for tracking time on the server — it can provide so much more value! Let’s rethink how we can leverage this header. In this piece, we will dive deeper to show how Server-Timing headers are so uniquely powerful, show some practical examples by solving challenging monitoring problems with this header, and provoke some creative inspiration by combining this technique with service workers.\nServer-Timing is uniquely powerful, because it is the only HTTP Response header that supports setting free-form values for a specific resource and makes them accessible from a JavaScript Browser API separate from the Request/Response references themselves. This allows resource requests, including the HTML document itself, to be enriched with data during its lifecycle, and that information can be inspected for measuring the attributes of that resource!\nThe only other header that’s close to this capability is the HTTP Set-Cookie / Cookie headers. Unlike Cookie headers, Server-Timing is only on the response for a specific resource where Cookies are sent on requests and responses for all resources after they’re set and unexpired. Having this data bound to a single resource response is preferable, as it prevents ephemeral data about all responses from becoming ambiguous and contributes to a growing collection of cookies sent for remaining resources during a page load. \nSetting Server-Timing\nThis header can be set on the response of any network resource, such as XHR, fetch, images, HTML, stylesheets, etc. Any server or proxy can add this header to the request to provide inspectable data. The header is constructed via a name with an optional description and/or metric value. The only required field is the name. Additionally, there can be many Server-Timing headers set on the same response which would be combined and separated via a comma.\nA few simple examples:\nServer-Timing: cdn_process;desc=”cach_hit\";dur=123\n\nServer-Timing: cdn_process;desc=”cach_hit\", server_process; dur=42;\n\nServer-Timing: cdn_cache_hit\n\nServer-Timing: cdn_cache_hit; dur=123\n\nImportant Note: For cross-origin resources, Server-Timing and other potentially sensitive timing values are not exposed to consumers. To allow these features, we will also need the Timing-Allow-Origin header that includes our origin or the * value.\nFor this article, that’s all we’ll need to start exposing the value and leave other more specific articles to go deeper. MDN docs.\nConsuming Server-Timing\nWeb browsers expose a global Performance Timeline API to inspect details about specific metrics/events that have happened during the page lifecycle. From this API we can access built-in performance API extensions which expose timings in the form of PerformanceEntries.\nThere are a handful of different entry subtypes but, for the scope of this article, we will be concerned with the PerformanceResourceTiming and PerformanceNavigationTiming subtypes. These subtypes are currently the only subtypes related to network requests and thus exposing the Server-Timing information.\nFor the top-level HTML document, it is fetched upon user navigation but is still a resource request. So, instead of having different PerformanceEntries for the navigation and the resource aspects, the PerformanceNavigationTiming provides resource loading data as well as additional navigation-specific data. Because we are looking at just the resource load data, we will exclusively refer to the requests (navigational docs or otherwise) simply as resources.\nTo query performance entries, we have 3 APIs that we can call: performance.getEntries(), performance.getEntriesByType(), performance.getEntriesByName(). Each will return an array of performance entries with increasing specificity.\nconst navResources = performance.getEntriesByType('navigation');\nconst allOtherResources = performance.getEntriesByType('resource');\n\nFinally, each of these resources will have a serverTiming field which is an array of objects mapped from the information provided in the Server-Timing header — where PerformanceEntryServerTiming is supported (see considerations below). The shape of the objects in this array is defined by the PerformanceEntryServerTiming interface which essentially maps the respective Server-Timing header metric options: name, description, and duration.\nLet’s look at this in a complete example.\nA request was made to our data endpoint and among the headers, we sent back the following:\nServer-Timing: lookup_time; dur=42, db_cache; desc=”hit”;\n\nOn the client-side, let’s assume this is our only resource loaded on this page:\n\nconst dataEndpointEntry = performance.getEntriesByName('resource')[0];\n\nconsole.log( dataEndpointEntry.serverTiming );\n\n// outputs:\n// [\n//   { name: “lookup_time”, description: undefined, duration: 42 },\n//   { name: “db_cache”, description:”hit”, duration: 0.0 },\n// ]\n\nThat covers the fundamental APIs used to access resource entries and the information provided from a Server-Timing header. For links to more details on these APIs, see the resources section at the bottom.\nNow that we have the fundamentals of how to set and use this header/API combo, let’s dive into the fun stuff.\nIt’s Not Just About Time\nFrom my conversations and work with other developers, the name “Server-Timing” impresses a strong connection that this is a tool used to track spans of time or a detail about a span of time exclusively. This is entirely justified by the name and the intent of the feature. However, the spec for this header is very flexible; allowing for values and expressing information that could have nothing to do with timing or performance in any way. Even the duration field has no predefined unit of measurement — you can put any number (double) in that field. By stepping back and realizing that the fields available have no special bindings to particular types of data, we can see that this technique is also an effective delivery mechanism for any arbitrary data allowing lots of interesting possibilities.  \nExamples of non-timing information you could send: HTTP Response status code, regions, request ids, etc. — any freeform data that suits your needs. In some cases, we might send redundant information that might be in other headers already, but that’s ok. As we will cover, accessing other headers for resources quite often isn’t possible, and if it has monitoring value, then it’s ok to be redundant.\nNo References Required\nDue to the design of web browser APIs, there are currently no mechanisms for querying requests and their relative responses after the fact. This is important because of the need to manage memory. To read information about a request or its respective response, we have to have a direct reference to these objects. All of the web performance monitoring software we work with provide RUM clients that put additional layers of monkey patching on the page to maintain direct access to a request being made or the response coming back. This is how they offer drop-in monitoring of all requests being made without us needing to change our code to monitor a request. This is also why these clients require us to put the client before any request that we want to monitor. The complexities of patching all of the various networking APIs and their linked functionality can become very complex very quickly. If there were an easy access mechanism to pull relevant resource/request information about a request, we would certainly prefer to do that on the monitoring side.\nTo make matters more difficult, this monkey-patching pattern only works for resources where JavaScript is directly used to initiate the networking. For Images, Stylesheets, JS files, the HTML Doc, etc. the methods for monitoring the request/response details are very limited, as usually there is no direct reference available. \nThis is where the Performance Timeline API provides great value. As we saw earlier, it quite literally is a list of requests made and some data about each of them respectively. The data for each performance entry is very minimal and almost entirely limited to timing information and some fields that, depending on their value, would impact how a resource’s performance is measured relative to other resources. Among the timing fields, we have direct access to the serverTiming data.\nPutting all of the pieces together, resources can have Server-Timing headers in their network responses that contain arbitrary data. Those resources can then be easily queried, and the Server-Timing data can be accessed without a direct reference to the request/response itself. With this, it doesn’t matter if you can access/manage references for a resource, all resources can be enriched with arbitrary data accessible from an easy-to-use web browser API. That’s a very unique and powerful capability!\nNext, let’s apply this pattern to some traditionally tough challenges to measure.\nSolution 1: Inspecting Images and Other Asset Responses\nImages, stylesheets, JavaScript files, etc. typically aren’t created by using direct references to the networking APIs with information about those requests. For example, we almost always trigger image downloads by putting an img element in our HTML. There are techniques for loading these assets which require using JavaScript fetch/xhr APIs to pull the data and push it into an asset reference directly. While that alternate technique makes them easier to monitor, it is catastrophic to performance in most cases. The challenge is how do we inspect these resources without having direct networking API references?\nTo tie this to real-world use cases, it’s important to ask why might we want to inspect and capture response information about these resources? Here are a few reasons:\n\nWe might want to proactively capture details like status codes for our resources, so we can triage any changes.For example, missing images (404s) are likely totally different issues and types of work than dealing with images returning server errors (500s).\nAdding monitoring to parts of our stack that we don’t control.Usually, teams offload these types of assets to a CDN to store and deliver to users. If they are having issues, how quickly will the team be able to detect the issue?\nRuntime or on-demand variations of resources have become more commonplace techniques.For example, image resizing, automatic polyfilling of scripts on the CDN, etc — these systems can have many limits and reasons for why they might not be able to create or deliver a variation. If you expect that 100% of users retrieve a particular type of asset variation, it’s valuable to be able to confirm that.This came up at a previous company I worked at where on-demand image resizing was used for thumbnail images. Due to the limitations of the provider, a significant number of users would get worse experiences due to full-size images loading where thumbnails are supposed to appear. So, where we thought >99% of users would get optimal images, >30% would hit performance issues, because images did not resize.\n\nNow that we have some understanding of what might motivate us to inspect these resources, let’s see how Server-Timing can be leveraged for inspection. \nImage HTML:\n\n<img src=\"/user-rsrc/12345?resize=true&height=80&width=80&format=webp\" alt=\"...\"/>\n\n\nImage response headers:\n\nStatus: 200\n…\nServer-Timing: status_code; dur=200;, resizing; desc=”failed”; dur=1200; req_id; desc=”zyx4321”\n\n\nInspecting the image response information:\n\nconst imgPerfEntry = performance.getEntriesByName('/user-rsrc/12345?resize=true&height=80&width=80&format=webp')[0];\n\n// filter/capture entry data as needed\nconsole.log(imgPerfEntry.serverTiming);\n\n// outputs:\n// [\n//   { name: “status_code”, description: undefined, duration: 200 },\n//   { name: “resizing”, description:”failed”, duration: 1200 },\n//   { name: “req_id”, description:”zyx4321”, duration: 0.0 },\n// ]\n\n\nThis metric was very valuable because, despite returning “happy” responses (200s), our images weren’t resized and potentially not converted to the right format, etc. Along with the other performance information on the entry like download times, we see the status was served as 200 (not triggering our onerror handlers on the element), resizing failed after spending 1.2s on attempting to resize, and we have a request-id that we can use to debug this in our other tooling. By sending this data to our RUM provider, we can aggregate and proactively monitor how often these conditions happen.\nSolution 2: Inspect Resources That Return Before JS Runs\nCode used to monitor resources (fetch, XHR, images, stylesheets, scripts, HTML, etc.) requires JavaScript code to aggregate and then send the information somewhere. This almost always means there’s an expectation for the monitoring code to run before the resources that are being monitored. The example presented earlier of the basic monkey patching used to automatically monitor fetch requests is a good example of this. That code has to run before any fetch request that needs to be monitored. However, there are lots of cases, from performance to technical constraints, where we might not be able to or simply should not change the order in which a resource is requested to make it easier to be monitored.\nAnother very common monitoring technique is to put event listeners on the page to capture events that might have monitoring value. This usually comes in the form of onload or onerror handlers on elements or using addEventListener more abstractly. This technique requires JS to have been set before the event fires, or before the listener itself is attached. So, this approach still carries the characteristic only monitoring events going forward, after the monitoring JS is run, thus requiring the JS to execute before the resources requiring measurement.\nMapping this to real-world use-cases, e-commerce sites put a heavy emphasis on “above the fold” content rendering very quickly — typically deferring JS as much as possible. That said, there might be resources that are impactful to measure, such as successful delivery of the product image. In other situations, we might also decide that the monitoring library itself shouldn’t be in the critical path due to page weight. What are the options to inspect these requests retroactively?\nThe technique is the same as Solution #1! This is possible because browsers automatically maintain a buffer of all of the Performance Entries (subject to the buffer size limit that can be changed). This allows us to defer JS until later in the page load cycle without needing to add listeners ahead of the resource.\nInstead of repeating the Solution #1 example, let’s look at what both retroactive and future inspection of performance entries looks like to show the difference of where they can be leveraged. Please note that, while we are inspecting images in these examples, we can do this for any resource type.\nSetting up context for this code, our need is that we have to ensure our product images are being delivered successfully. Let’s assume all website images return this Server-Timing header structure. Some of our important images can happen before our monitoring script and, as the user navigates, more will continue to load. How do we handle both?\nImage response headers:\n\nStatus: 200\n…\nServer-Timing: status_code; dur=200;, resizing; desc=\"success\"; dur=30; req_id; desc=\"randomId\"\n\n\nOur monitoring logic. We expect this to run after the critical path content of the page.\nInspecting the image response information:\n\nfunction monitorImages(perfEntries){\n  perfEntries.forEach((perfEntry)=>{\n  // monitoring for the performance entries\n\nconsole.log(perfEntry.serverTiming);\n})\n}\n\nconst alreadyLoadedImageEntries = performance.getEntriesByType('resource').filter(({ initiatorType })=> initiatorType === 'img');\n\nmonitorImages( alreadyLoadedImageEntries );\n\nconst imgObserver = new PerformanceObserver(function(entriesList) {\nconst newlyLoadedImageEntries = entriesList.getEntriesByType('resource').filter(({ initiatorType })=> initiatorType === 'img');\n  monitorImages( newlyLoadedImageEntries );\n});\nimgObserver.observe({entryTypes: [\"resource\"]});\n\n\n\nDespite deferring our monitoring script until it was out of the critical path, we are capturing the data for all images which have loaded before our script and will continue to monitor them, as the user continues using the site.\nSolution 3: Inspecting the HTML Doc\nThe final example solution we will look at is related to the ultimate “before JS can run” resource — the HTML document itself. If our monitoring solutions are loaded as JS via the HTML, how can we monitor the delivery of the HTML document?\nThere is some precedence in monitoring HTML doc delivery. For monitoring response data, the most common setup is to use server logs/metrics/traces to capture this information. That is a good solution but depending on the tooling, the data may be decoupled from RUM data causing us to need multiple tools to inspect our user experiences. Additionally, this practice could also miss metadata (page instance identifiers for example) that allows us to aggregate and correlate information for a given page load — for example, correlating async requests failing when the doc returns certain document response codes.\nA common pattern for doing this work is putting the content inside of the HTML content itself. This has to be put into the HTML content, because the JS-based monitoring logic does not have access to the HTML request headers that came before it. This turns our HTML document into a dynamic document content. This may be fine for our needs and allows us to take that information and provide it to our RUM tooling. However, this could become a challenge if our system for HTML delivery is out of our control, or if the system has some assumptions into how HTML delivery must function. Examples of this might be, expecting that the HTML is fully static, such that we can cache it downstream in some deterministic manner — “partially dynamic” HTML bodies are much more likely to be handled incorrectly by caching logic. \nWithin the HTML delivery process, there could also be additional data that we want to understand, such as what datacenters processed the request throughout the chain. We might have a CDN edge handler that proxies a request from an origin. In this case, we can’t expect each layer could/should process and inject HTML content. How might Server-Timing headers help us here?\nBuilding on the concepts of Solution #1 and Solution #2, here’s how we can capture valuable data about the HTML document itself. Keep in mind that any part of the stack can add a Server-Timing header to the response, and it will be joined together in the final header value.\nLet’s assume we have a CDN edge handler and an origin which can process the document:\nCDN added response headers:\n\nStatus: 200\n…\nServer-Timing: cdn_status_code; dur=200;, cdn_cache; desc=”expired”; dur=15; cdn_datacenter; desc=”ATL”; cdn_req_id; desc=”zyx321abc789”; cdn_time; dur=120;\n\n\n\nOrigin added response headers:\n\nStatus: 200\n…\nServer-Timing: origin_status_code; dur=200;, origin_time; dur=30; origin_region; desc=”us-west”; origin_req_id; desc=\"qwerty321ytrewq789\";\n\n\n\nInspecting the HTML response information:\n\n// as mentioned earlier, the HTML document is a 'navigation' type of Performance Entry\n// that has a superset of information related to the resource and the navigation-specific info\nconst htmlPerfEntry = performance.getEntriesByType('navigation')[0];\n\n// filter/capture entry data as needed\nconsole.log(htmlPerfEntry.serverTiming);\n\n// outputs:\n// [\n//   { name: “cdn_status_code”, description: undefined, duration: 200 },\n//   { name: “cdn_cache”, description:”expired”, duration: 0.0},\n//   { name: “cdn_datacenter”, description:”ATL”, duration: 0.0 },\n//   { name: “cdn_req_id”, description:”zyx321abc789”, duration: 0.0 },\n//   { name: “cdn_time”, description: undefined, duration: 120 },\n//   { name: “origin_status_code”, description: undefined, duration: 200 },\n//   { name: “origin_time”, description: undefined, duration: 30 },\n//   { name: “origin_region”, description:”us-west”, duration: 0.0 },\n//   { name: “origin_req_id”, description:”qwerty321ytrewq789”, duration: 0.0 },\n// ]\n\n\nFrom this information, our monitoring JavaScript (which could have been loaded way later) can aggregate where the HTML processing happened, status codes from the different servers (which can differ for legit reasons — or bugs), and request identifiers if they need to correlate this with server logs. It also knows how much time was taken on the “server” via the cdn_time duration — “server” time being the total time starting at the first non-user proxy/server that we provide. Using that cdn_time duration, the already accessible HTML Time-To-First-Byte value and the origin_time duration, we can determine latency sections more accurately, such as the user latency, the cdn to origin latency, etc. This is incredibly powerful in optimizing such a critical delivery point and protecting it from regression.\nCombining Server-Timing with Service Workers\nService Workers are scripts that are initialized by the website to sit between the website, the browser, and the network (when available). When acting as a proxy, they can be used to read and modify requests coming from and responses returning to the website. Given service workers are so feature rich, we won’t attempt to cover them in depth in this article — a simple web search will yield a mountain of information about their capabilities. For this article, we will focus on the proxying capability of a service worker — it’s ability to process requests/responses. \nThe key to combining these tools is knowing that the Server-Timing header and its respective PerformanceEntry is calculated after service worker proxying takes place. This allows us to use the service workers to add Server-Timing headers to responses that can provide valuable information about the request itself.\nWhat type of information might we want to capture within the service worker? As mentioned before, service workers have lots of capabilities, and any one of those actions could produce something valuable to capture. Here are a few that come to mind:\n\nIs this request served from the service worker cache?\nIs this served from the service worker while off-line?\nWhat service worker strategy for this request type is being used?\nWhat version of the service worker is being used?This is helpful in checking our assumptions about service worker invalidation.\nTake values from other headers and put them into a Server-Timing header for downstream aggregation.Valuable when we don’t have the option to change the headers on the request but would like to inspect them in RUM — such is usually the case with CDN providers.\nHow long has a resource been in service worker cache?\n\nService workers have to be initialized on the website which is an asynchronous process itself. Furthermore, service workers only process requests within the defined scope. As such, even the basic question of, “is this request processed by the service worker?” can drive interesting conversations on how much we are leaning on its capabilities to drive great experiences.\nLet’s dive into how this might look in the code.\nBasic JS logic used on the site to initialize the service worker:\n\nif ('serviceWorker' in navigator) {\nnavigator.serviceWorker.register('/service-worker.js').then(function (registration) {\nregistration.update(); // immediately start using this sw\n });\n}\n\n\nInside of /service-worker.js, basic request/response proxying:\n\nconst CACHE_NAME = 'sw-cached-files-v1';\n\nself.addEventListener('fetch', function (event) {\n  event.respondWith(\n    // check to see if this request is cached\n    caches.match(event.request)\n      .then(function (response) {\n\n        // Cache hit - return response\n        if (response) {\n          const updatedHeaders = new Headers(response.headers);\n          updatedHeaders.append('Server-Timing', 'sw_cache; desc=\"hit\";');\n          const updatedResponse = new Response(response.body, {\n            ...response,\n            headers: updatedHeaders\n          });\n          return updatedResponse;\n        }\n\n        return fetch(event.request).then(function (response) {\n\n            // depending on the scope where we load our service worker,\n            // we might need to filter our responses to only process our\n            // first-party requests/responses\n            // Regex match on the event.request.url hostname should\n\n            const updatedHeaders = new Headers(response.headers);\n            updatedHeaders.append('Server-Timing', status&#95;code;desc=${response.status};, sw&#95;cache; desc=\"miss\";)\n\n            const modifiableResponse = new Response(response.body, {\n              ...response,\n              headers: updatedHeaders\n            });\n\n            // only cache known good state responses\n            if (!response || response.status !== 200 || response.type !== 'basic' || response.headers.get('Content-Type').includes('text/html')) {\n              return modifiableResponse;\n            }\n\n            const responseToCache = modifiableResponse.clone();\n\n            caches.open(CACHE_NAME).then(function (cache) {\n              cache.put(event.request, responseToCache);\n            });\n\n            return modifiableResponse;\n          }\n        );\n      })\n  );\n});\n\n\nRequests that are processed from the service worker, now will have a Server-Timing header appended to their responses. This allows us to inspect that data via the Performance Timeline API, as we demonstrated in all of our prior examples. In practice, we likely didn’t add the service worker for this single need — meaning we already have it instrumented for handling requests. Adding the one header in 2 places allowed us to measure status codes for all requests, service worker-based cache-hit ratios, and how often service workers are processing requests.\nWhy Use Server-Timing If We Have Service Workers?\nThis is an important question that comes up when discussing combining these techniques. If a service worker can grab all of the header and content information, why do we need a different tool to aggregate it? \nThe work of measuring timing and other arbitrary metadata about requests is almost always, so that we can send this information to a RUM provider for analysis, alerting, etc. All major RUM clients have 1 or 2 windows for which we can enrich the data about a request — when the response happens, and when the PerformanceEntry is detected. For example, if we make a fetch request, the RUM client captures the request/response details and sends it. If a PerformanceEntry is observed, the client sends that information as well — attempting to associate it to the prior request if possible. If RUM clients offer the ability to add information about that requests/entries, those were the only windows to do it. \nIn practice, a service worker may or may not be activated yet, a request/response may or may not have processed the service worker, and all service worker data sharing requires async messaging to the site via postMessage() API. All of these aspects introduce race conditions for a service worker to be active, able to capture data, and then send that data in time to be enriched by the RUM client.\nContrasting this with Server-Timing, a RUM client that processes the Performance Timeline API will immediately have access to any Server-Timing data set on the PerformanceEntry.\nGiven this assessment of service worker’s challenges with enriching request/response data reliably, my recommendation is that service workers be used to provide more data and context instead of being the exclusive mechanism for delivering data to the RUM client on the main thread. That is, use Server-Timing and, where needed, use service worker to add more context or in cases where Server-Timing isn’t supported — if required. In this case, we might be creating custom events/metrics instead of enriching the original request/response data aggregation, as we will assume that the race conditions mentioned will lead to missing the windows for general RUM client enrichment.\nConsiderations for Server-Timing Usage\nAs uniquely powerful as it is, it’s not without important considerations. Here’s a list of considerations based on the current implementation at time of writing:\n\nBrowser Support — Safari does not support putting the Server-Timing data into the Performance Timeline API (they do show it in DevTools).This is a shame, however, given this is not about functionality for users, but instead it’s about improved capabilities for performance monitoring — I side with this not being a blocking problem. With browser-based monitoring, we never expect to measure 100% of browsers/users. Currently, this means we’d look to get ~70-75% support based on global browser usage data. Which is usually more than enough to feel confident that our metrics are showing us good signals about the health and performance or our systems. As mentioned, Server-Timing is sometimes the only way to get those metrics reliably, so we should feel confident about leveraging this tool.As mentioned previously, if we absolutely have to have this data for Safari, we could explore using a cookie-based solution for Safari users. Any solutions here would have to be tested heavily to ensure they don’t hinder performance. \nIf we are looking to improve performance, we want to avoid adding lots of weight to our responses, including headers. This is a trade-off of additional weight for value added metadata. My recommendation is that if you’re not in the range 500 bytes or more to your Server-Timing header, I would not be concerned. If you are worried, try varying lengths and measure its impact!\nWhen appending multiple Server-Timing headers on a single response, there is a risk of duplicate Server-Timing metric names. Browsers will surface all of them in the serverTiming array on the PerformanceEntry. It’s best to ensure that this is avoided by specific or namespaced naming. If it can’t be avoided, then we would break down the order of events that added each header and define a convention we can trust. Otherwise, we can create a utility that doesn’t blindly add Server-Timing entries but will also update existing entries if they are already on the Response.\nTry to avoid the mistake of misremembering that responses cache the Server-Timing values as well. In some cases you might want to filter out the timing-related data of cached responses that, before they were cached, spent time on the server. There are varying ways to detect if the request went to the network with data on the PerformanceEntry, such as entry.transferSize > 0, or entry.decodedBodySize > 0, or entry.duration > 40. We can also lean into what we’ve learned with Server-Timing to set a timestamp on the header for comparison.\n\nWrapping Up\nWe’ve gone pretty deep into the application of the Server-Timing Header for use cases that aren’t aligned to the “timing” use case that this header is generally associated with. We’ve seen its power to add freeform data about a resource and access the data without needing a reference to the networking API used to make it. This is a very unique capability that we leveraged to measure resources of all types, inspect them retroactively, and even capture data about the HTML doc itself. Combining this technique with service workers, we can add more information from the service worker itself or to map response information from uncontrolled server responses to Server-Timing for easy access.\nI believe that Server-Timing is so impressively unique that it should be used way more, but I also believe that it shouldn’t be used for everything. In the past, this has been a must-have tool for performance instrumentation projects I’ve worked on to provide impossible to access resource data and identify where latency is occuring. If you’re not getting value out of having the data in this header, or if it doesn’t fit your needs — there’s no reason to use it. The goal of this article was to provide you with a new perspective on Server-Timing as a tool to reach for, even if you’re not measuring time. \nResources\n\nW3C Server Timing\nServer-Timing MDN\n“Measuring Performance With Server Timing”, Drew McLellan\nPerformance Timeline MDN\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4f69c3e0-764f-4cfb-b8f8-7a4420d0e2f6/rethinking-server-timing-monitoring-tool.jpg",
      "date_published": "2022-05-16T10:00:00.000Z",
      "date_modified": "2022-05-16T10:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/top-tasks-focus-what-matters-must-defocus-what-doesnt/",
      "url": "https://smashingmagazine.com/2022/05/top-tasks-focus-what-matters-must-defocus-what-doesnt/",
      "title": "Top Tasks: To Focus On What Matters You Must De-Focus On What Doesn’t",
      "summary": "We waste so much today. One way of focusing on what truly matters is by identifying Top Tasks for yourself. Learn how to make tough decisions by focusing on the real, quantifiable evidence that will help create a better experience for your users.",
      "content_html": "<p>Let us start with a simple explanation of the word “task”. A task is something someone wants to do using your website or app. If you have a technology website, then tasks might include pricing, installation, and troubleshooting. If you have a university website, then tasks might include courses, lecturer/professor profiles, and accommodation. If you have a hospital website, then tasks might include what to do: before treatment, during treatment, and after treatment. If you are running an intranet, then tasks might include training, finding people, pay, and benefits. If you have a website for vaccines, then tasks might include immunity, side effects, and availability.</p>\n<p>Now, “Top Tasks” focus on the task itself. Once identified, the next steps include measuring whether people are successful at completing the Top Tasks, and how long it takes them. You’re always trying to improve completion rates and reduce completion times for Top Tasks. It’s about focusing on the outcome from a user’s perspective, rather than the input (content, code, design).   </p>\nWhen Should You Consider Using Top Tasks?\n<ul>\n<li><strong>There’s no agreement about what’s most important</strong>, and it has been decided that it’s time for some consensus, some unity of purpose and design.</li>\n<li><strong>There’s a need to consolidate and simplify.</strong> Too many websites, too many features, too much content. Top Tasks will help you create a single, streamlined, unified approach.</li>\n<li><strong>There is a lot of out-of-date, low-quality content.</strong> This tiny task content is cluttering the search and navigation, and you need evidence in order to remove it.</li>\n<li><strong>The navigation is terrible</strong>, because it is not focused on top tasks, and instead it is focused on organizational units, systems, ego projects, and vague meaningless terms, such as “Resources”.</li>\n<li><strong>Nobody really knows why they’re doing what they’re doing</strong>, whether it really has any value or not. The metrics are all about volume, and chasing volume is not delivering quality or value. Top Tasks is about focusing on what really matters. </li>\n</ul>\nIt Starts With a Survey\n<p>The most essential element of Top Tasks is a survey that identifies a prioritized list of tasks, from the most important tasks (the top tasks) to the least important tasks (the tiny tasks). </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d2a9d095-003d-4a29-96f3-5e6d8d9f172c/1-top-tasks-focus-what-matters-de-focus-what-doesnt.png\" /></p>\n<p>The results from a Top Tasks survey can be used to:</p>\n<ul>\n<li>prioritize features and content on a website or app;</li>\n<li>de-prioritize or remove tiny task features and content;</li>\n<li>design a more effective classification and navigation;</li>\n<li>implement a metrics model based on measuring the success rate and the time it takes to complete the top tasks.</li>\n</ul>\n<p>Designing for Top Tasks is about designing for the long term because tasks last. As humans, we do the same core things day in and day out, year in and year out. The first major Top Tasks project I did was back around 2003. It was for a national tourism website, and we ran surveys in multiple countries. The Top Tasks were: </p>\n<ul>\n<li>Special Offers,</li>\n<li>Accommodation,</li>\n<li>Things to Do &amp; See,</li>\n<li>Planning a Trip,</li>\n<li>Getting Here &amp; Around.</li>\n</ul>\n<p>In 2020, people still want special offers. They still want a five-star hotel at a two-star price. The tools to help you find that great offer have changed a lot, but the basic top task of wanting a great deal hasn’t and will not change, because deep down we’re all cheap. Another core characteristic of humans is, of course, that we don’t like to be seen as cheap. </p>\n<p>When I was carrying out the Top Tasks tourism survey research, I noticed some interesting patterns when it came to search. People weren’t searching so much for “special offers”. Rather, they were searching for “deals”. This is an interesting aspect of search behavior. <strong>Sometimes, the words that bring you to a website are not the words that bring you through a website.</strong> We found that while people searched for “deals”, they clicked far more on links that said “special offers” once they were on the website. Makes sense. You may search for a “cheap hotel”, but you don’t necessarily want to be greeted on the hotel homepage with a message saying: “Welcome to our dirt cheap hotel!”</p>\n<p>Many organizations have said to me that they already know their top tasks because they’ve got search and website analytics. Search and website analytics are simply not sufficient to give you true and comprehensive insights into the top tasks. For starters, they will rarely give you insight on tasks that you have no content on. </p>\n<p>Once we did a Top Tasks for a university that specialized in business master’s degrees. A key task that emerged was that potential students wanted to know how doing the master’s would “advance their career”. Nobody was searching to “advance my career”. </p>\n<p>The Microsoft Excel Web team noticed that lots of people were searching for “remove conditional formatting”. So, they created a page for this. But the page always got huge dissatisfaction, no matter how much they edited it. Finally, after much research and discussion, they discovered that removing conditional formatting was a symptom. The real task — the true task — was about how to use conditional formatting properly. Top Tasks is about getting to these deeper, truer tasks. Doing it well requires a lot of research, a lot of thinking, and a lot of talking and discussing. </p>\n<p>The Top Tasks methodology is a holistic, 360º examination of the entire physical and digital environment. It goes deep and comprehensive, looking at the entire environment that the user exists within, not simply a website or app. So, if you’re looking for a quick fix, if you’re thinking about the low-hanging fruit, stop reading. Top Tasks is most definitely not for you.</p>\n<p>Still here? Top Tasks is hard, boring, systematic, rigorous, comprehensive, highly collaborative, time-consuming, and profound work. A typical Top Tasks survey <strong>takes about 12 weeks to complete</strong>:</p>\n<ul>\n<li>3-4 weeks to gather an initial list of tasks (typically 200-400).</li>\n<li>3-4 weeks of collaborative discussions to get to a final list of 50-80 tasks.</li>\n<li>2-4 weeks to run the survey. Ideally, you want 400-plus responses to get statistically reliable results, but definitely need a minimum of 100.</li>\n<li>2 weeks to analyze and present results.</li>\n</ul>\nSecrets To Success\n<p>The more diverse, the more cross-functional, the more cross-departmental, the more user-facing the group of people you get to do a Top Tasks project, the better. If things are working well, you’re going to have deep, almost existential conversations about what is a task, which tasks are relevant, and which are not. If, for example, you were doing a Top Tasks about COVID-19, you’d be examining the total environment, not simply the stuff you have now on your website or app about COVID-19. You’d be trying to get a total map of a pandemic through a series of tasks. </p>\n<p>What’s the best group?</p>\n<ul>\n<li>Between three and eight people ideally.</li>\n<li>Broad group of representative stakeholders.</li>\n<li>Genuine experienced people who truly understand human needs.</li>\n<li>If you’re doing an intranet Top Tasks survey, you should have representatives from Support, Marketing, Sales, Products, Web, IT, HR, and Communications.</li>\n<li>If you’re doing a public Top Tasks survey, you should have representatives from Support, Marketing, Sales, Products, Web, and Communications.</li>\n<li>Aim to have the same group throughout the entire Top Tasks process.</li>\n</ul>\n<p>I know. I know. I know. Getting this group together is time-consuming and very complicated. If you’re finding it almost impossible, then that’s a message. Your organization is probably not ready for Top Tasks, because if people won’t join the group, then the chances of them or their departments taking the results seriously are very, very low.</p>\n<p>Here are the benefits of spending the time and effort to get a great shortlisting group together:</p>\n<ul>\n<li>more rounded and comprehensive task list;</li>\n<li>a much deeper understanding of the organization;</li>\n<li>less likely that tiny tasks from any one department will be over-represented;</li>\n<li>bridge-building and future collaboration;</li>\n<li>identifying tasks that have different names in different departments;</li>\n<li>identifying duplicate content and tools across departments/units;</li>\n<li>greater chance of buy-in and real change when the results are delivered.</li>\n</ul>\n<p>When we did a Top Tasks for WHO about COVID-19 in May 2020, here are the top tasks that emerged:</p>\n<ul>\n<li>vaccine (development, availability, safety);</li>\n<li>latest news, latest research (alerts, directives, updates);</li>\n<li>transmission, spread, epidemiology;</li>\n<li>immunity, antibody testing (criteria, availability, accuracy);</li>\n<li>WHO guidelines, standards, decisions;</li>\n<li>symptoms, signs;</li>\n<li>research papers, studies;</li>\n<li>end date, new normal, safe again;</li>\n<li>virus survival/viability/persistence on surfaces, in air.</li>\n</ul>\n<p>How did we get to a result like that? The first step is to gather the potential list of tasks. Here are some sources:</p>\n<ul>\n<li>existing website / app;</li>\n<li>top 50 annual search (internal, external);</li>\n<li>top 50 website pages / app sections most visited;</li>\n<li>surveys and research on customers in the last two to three years;</li>\n<li>top 50 annual support, help, feedback;</li>\n<li>competitor / peer websites / apps;</li>\n<li>social media, blogs, communities.</li>\n</ul>\n<p>For example, when we did Microsoft Visual Studio, we got lots of great tasks by visiting the independent developer communities. Depending on the complexity of the environment, the initial longlist of tasks can range from 200 to 400. In exceptional circumstances, such as when we did a Top Tasks for the European Commission, it ran into thousands. </p>\n<p>Below is a tiny sample of these early tasks for a healthy environment:</p>\n<ul>\n<li>access to my journal;</li>\n<li>advice in cases of physical disability;</li>\n<li>advice on treatment or hospitals abroad;</li>\n<li>advice, guidance, rights, and practical information to relatives;</li>\n<li>aids (prostheses, wigs, etc.);</li>\n<li>aids in the hospital/treatment site;</li>\n<li>alternative treatment;</li>\n<li>analysis and testing of organic food;</li>\n<li>analysis of food safety (pesticide, dioxin...).</li>\n</ul>\n<p>You can see that there’s a lot of work to be done to get from this rough list of hundreds to a refined list of 50-80.</p>\nShortlisting: the Hardest Part\n<p>Words are by far the most powerful — and often most underrated — invention humans have ever made. Without words, there is no Web. The Web is built from words, from the first search to the last click. Getting the words exactly right, and organizing them in the most intuitive way can prove so challenging that many organizations simply ignore the challenge or address it in the most flippant, derisory manner. </p>\n<p>Tasks are the things people want to do on your website or app. More than anything else, they’ll use words to help them complete that task. The shortlisting process will be super intense because it’s a process of editing words. But if done right, it will be super rewarding. It may, in fact, be the first time your organization has come together to discuss and agree on what it is you are about, and what it is you are genuinely useful for. This is a quite profound process.</p>\n<p>Getting from a long list to a short list will usually take between two and four weeks. That’s roughly five to eight sessions with the shortlisting group, each session lasting 90 minutes. For each of these sessions, you will have to do an equivalent preparatory session. Have no more than three sessions a week, because this is intense work. Also, it’s good to let the list settle — it will mature and become clearer over time. The longlist shouldn’t be more than 150 for the first shortlisting group session. What this means is that you will probably have to do quite a bit of preparatory work cleaning up the initial list of 200-400 tasks, so that it is ready for that first session.</p>\n<p>The art of shortlisting is about slowly stripping away words until all that’s left are the most essential words that describe the most essential tasks. Here are some shortlisting tips:</p>\n<ul>\n<li><strong>Avoid verbs (get, find).</strong> Nouns make the best tasks. Verbs are waffly and vague. You don’t need “Find a job”. All you need is “Jobs”.</li>\n<li><strong>Avoid statements (I want to…).</strong></li>\n<li><strong>Avoid questions (Can I…).</strong></li>\n<li><strong>Remove conjunctions.</strong> From “Installation and configuration” to “Installation, configuration”.</li>\n<li><strong>Use brackets where necessary</strong>: “Conservation (ecology, nature, woodlands)”.</li>\n<li><strong>Keep each task under 65 characters</strong> (8-10 words).</li>\n<li><strong>Avoid first-word repetition</strong> (no more than four in any list).<ul>\n<li>European Commission at work</li>\n<li>European Commission competition</li>\n<li>European Commission directory</li>\n</ul>\n</li>\n<li><strong>Delete exact duplicates.</strong></li>\n<li><strong>Remove overlaps.</strong> This gets hard. Aim for a list of unique tasks, each one separate and distinct from the others. </li>\n<li><strong>Remove brands, products, departments, and subjects.</strong><ul>\n<li>University: no subjects, courses (English, Computer Science, Law, etc.)</li>\n<li>Intranet: no departments (HR, IT, Accounting)</li>\n<li>Government: no departments, brands</li>\n<li>Company: no products, brands</li>\n<li>Healthcare: no diseases, conditions</li>\n</ul>\n</li>\n<li><strong>No audiences, demographics.</strong>    <ul>\n<li>Don’t have:  <ul>\n<li>Women’s health</li>\n<li>Men’s health</li>\n</ul>\n</li>\n<li>Don’t have:  <ul>\n<li>Development policy for Austria</li>\n<li>Development policy for Ireland  </li>\n</ul>\n</li>\n<li>Don’t have:  <ul>\n<li>Training for developers</li>\n<li>Training for testers</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>Avoid formats and channels.</strong><ul>\n<li>No formats: reports, newsletters, documents, tools, videos, forms, templates</li>\n<li>No channels: Twitter, Facebook, YouTube, Instagram</li>\n<li>Avoid Web conventions: search, navigation, pages</li>\n</ul>\n</li>\n<li><strong>No Dirty Magnets.</strong> A dirty magnet is a word or phrase that can mean different things to different people. It is vague and meaningless and can draw attention because it seems like it might be useful. Examples of dirty magnets include Resources; Knowledge Base; Quick Links, and Useful Links. By far, the worst dirty magnet of all is Frequently Asked Questions, which in my experience is the single worst Web design feature I have come across in more than 25 years of helping design websites.</li>\n</ul>\nPreparing the Survey\n<p>No. The answer is no, you can’t. Just no. You can’t break up the list. You’re not allowed. It’s not how it works. One single list. One. Randomly presented. You ask people to quickly scan the list and choose no more than five of their top tasks from the list. </p>\n<p>The amount of times designers and researchers have said to me, “But people aren’t going to vote on a list that long. It’s too long. We have to break it up.” No. The whole idea and concept of Top Tasks is a single list that delivers a single table of tasks ranked from the one that got the most votes to the one that got the least. If you break up the list, it’s no longer Top Tasks. It’s worked over 600 times. More than half a million people have voted in multiple languages in over 120 countries in the world. Since 2003, I have never had one single instance where it’s failed. Not one. </p>\n<p>You will need a framing statement to introduce the task list. When we did a survey on COVID-19 vaccination, the framing statement for the list was:</p>\n<blockquote>In relation to the COVID-19 vaccine, select up to 5 things that are MOST IMPORTANT to you.</blockquote>\n\n<p>When you’re writing the framing statement, try not to focus on your website or app. Focus on the world of people. Make it about the vaccine and what’s important to them, not your website and what’s important to you.</p>\n<p>The survey typically has three parts:</p>\n<ol>\n<li>the top tasks voting;</li>\n<li>segmentation and demographic questions (role, gender, location);</li>\n<li>website/app experience questions.</li>\n</ol>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1ac4ab16-f7e7-4535-81f0-182e286c0d87/3-top-tasks-focus-what-matters-de-focus-what-doesnt.png\" /></p>\n<p>Even after 30 voters, you should expect to see the top tasks begin to emerge. For example, the largest survey we ever did was for the European Commission. We had over 107,000 people voting. The top three tasks were:</p>\n<ol>\n<li>EU law, rules, treaties, judgments;</li>\n<li>research and innovation;</li>\n<li>funding, grants, subsidies.</li>\n</ol>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2b9923b4-6570-43fc-9951-b1ead6644784/2-top-tasks-focus-what-matters-de-focus-what-doesnt.png\" /></p>\n<p>Amazingly, after just 30 voters, these top three tasks had emerged, and they were the same three tasks after 107,000 voters.</p>\n<p>However, the more people you get to vote, the more the table stabilizes. We have found that having 400 voters gets us good solid results. The best way to get people to vote is with a popup on the website/app that is the main focus of the tasks.</p>\nSolve Deep Needs. Design for the Long Term\n<p>There’s nothing cool or fashionable about Top Tasks. It’s a boring, deliberate, methodical process. It’s very much focused on the needs of the user, not the ego of the organization. </p>\n<p>When a tiny task goes to sleep at night, it dreams of being a top task. Websites are flooded with tiny task content, and apps are flooded with tiny task features. Invariably, when we do a Top Tasks survey, the ego of the organization is at the bottom of the table — it gets the least votes.</p>\n<p>When we did Liverpool City Council in 2009, the top tasks included the following: </p>\n<ol>\n<li>find a job,</li>\n<li>leisure,</li>\n<li>waste,</li>\n<li>libraries,</li>\n<li>schools.</li>\n</ol>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ff7636ff-ff05-4ef4-b7db-184fe8393ac4/5-top-tasks-focus-what-matters-de-focus-what-doesnt.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6d2e0767-15c2-48c5-ba91-7a46bb7776bf/4-top-tasks-focus-what-matters-de-focus-what-doesnt.png\" /></p>\n<p>The team analyzed the publishing activities within the council and found that there was an inverse relationship between the importance of the task to a Liverpudlian and the amount of content being published on that task. The more important the task was to citizens, the less content was being published on it. The less important a task was to citizens, the more content was being published on it.</p>\n<p>Out of some 4,000 pages, 200 were getting 85% of traffic, and these 200 were not getting the proper care and attention, because the Web team’s time was taken up with dealing with tiny tasks. Top Tasks gave the team the evidence to delete over 80% of their website. The result was a much better experience for citizens.</p>\n<p> Top Tasks is about designing for the long term.</p>\n<p>My passion now is sustainable digital design, and that means designing things that will be as light as possible and will last for the longest possible time. The same tasks we identified in 2009 (waste, leisure, schools) are still on the Liverpool homepage in 2022. Top Tasks can give you a classification, navigation, and information architecture that will stand the test of time because top tasks last. The most important things people want to do tend not to change much over time.</p>\n<p>It’s about stripping away and removing the unnecessary, and about defocusing on the tiny tasks. Top Tasks gives you real, quantifiable evidence to make tough decisions that will create a better experience for your users.</p>",
      "content_text": "Let us start with a simple explanation of the word “task”. A task is something someone wants to do using your website or app. If you have a technology website, then tasks might include pricing, installation, and troubleshooting. If you have a university website, then tasks might include courses, lecturer/professor profiles, and accommodation. If you have a hospital website, then tasks might include what to do: before treatment, during treatment, and after treatment. If you are running an intranet, then tasks might include training, finding people, pay, and benefits. If you have a website for vaccines, then tasks might include immunity, side effects, and availability.\nNow, “Top Tasks” focus on the task itself. Once identified, the next steps include measuring whether people are successful at completing the Top Tasks, and how long it takes them. You’re always trying to improve completion rates and reduce completion times for Top Tasks. It’s about focusing on the outcome from a user’s perspective, rather than the input (content, code, design).   \nWhen Should You Consider Using Top Tasks?\n\nThere’s no agreement about what’s most important, and it has been decided that it’s time for some consensus, some unity of purpose and design.\nThere’s a need to consolidate and simplify. Too many websites, too many features, too much content. Top Tasks will help you create a single, streamlined, unified approach.\nThere is a lot of out-of-date, low-quality content. This tiny task content is cluttering the search and navigation, and you need evidence in order to remove it.\nThe navigation is terrible, because it is not focused on top tasks, and instead it is focused on organizational units, systems, ego projects, and vague meaningless terms, such as “Resources”.\nNobody really knows why they’re doing what they’re doing, whether it really has any value or not. The metrics are all about volume, and chasing volume is not delivering quality or value. Top Tasks is about focusing on what really matters. \n\nIt Starts With a Survey\nThe most essential element of Top Tasks is a survey that identifies a prioritized list of tasks, from the most important tasks (the top tasks) to the least important tasks (the tiny tasks). \n\nThe results from a Top Tasks survey can be used to:\n\nprioritize features and content on a website or app;\nde-prioritize or remove tiny task features and content;\ndesign a more effective classification and navigation;\nimplement a metrics model based on measuring the success rate and the time it takes to complete the top tasks.\n\nDesigning for Top Tasks is about designing for the long term because tasks last. As humans, we do the same core things day in and day out, year in and year out. The first major Top Tasks project I did was back around 2003. It was for a national tourism website, and we ran surveys in multiple countries. The Top Tasks were: \n\nSpecial Offers,\nAccommodation,\nThings to Do & See,\nPlanning a Trip,\nGetting Here & Around.\n\nIn 2020, people still want special offers. They still want a five-star hotel at a two-star price. The tools to help you find that great offer have changed a lot, but the basic top task of wanting a great deal hasn’t and will not change, because deep down we’re all cheap. Another core characteristic of humans is, of course, that we don’t like to be seen as cheap. \nWhen I was carrying out the Top Tasks tourism survey research, I noticed some interesting patterns when it came to search. People weren’t searching so much for “special offers”. Rather, they were searching for “deals”. This is an interesting aspect of search behavior. Sometimes, the words that bring you to a website are not the words that bring you through a website. We found that while people searched for “deals”, they clicked far more on links that said “special offers” once they were on the website. Makes sense. You may search for a “cheap hotel”, but you don’t necessarily want to be greeted on the hotel homepage with a message saying: “Welcome to our dirt cheap hotel!”\nMany organizations have said to me that they already know their top tasks because they’ve got search and website analytics. Search and website analytics are simply not sufficient to give you true and comprehensive insights into the top tasks. For starters, they will rarely give you insight on tasks that you have no content on. \nOnce we did a Top Tasks for a university that specialized in business master’s degrees. A key task that emerged was that potential students wanted to know how doing the master’s would “advance their career”. Nobody was searching to “advance my career”. \nThe Microsoft Excel Web team noticed that lots of people were searching for “remove conditional formatting”. So, they created a page for this. But the page always got huge dissatisfaction, no matter how much they edited it. Finally, after much research and discussion, they discovered that removing conditional formatting was a symptom. The real task — the true task — was about how to use conditional formatting properly. Top Tasks is about getting to these deeper, truer tasks. Doing it well requires a lot of research, a lot of thinking, and a lot of talking and discussing. \nThe Top Tasks methodology is a holistic, 360º examination of the entire physical and digital environment. It goes deep and comprehensive, looking at the entire environment that the user exists within, not simply a website or app. So, if you’re looking for a quick fix, if you’re thinking about the low-hanging fruit, stop reading. Top Tasks is most definitely not for you.\nStill here? Top Tasks is hard, boring, systematic, rigorous, comprehensive, highly collaborative, time-consuming, and profound work. A typical Top Tasks survey takes about 12 weeks to complete:\n\n3-4 weeks to gather an initial list of tasks (typically 200-400).\n3-4 weeks of collaborative discussions to get to a final list of 50-80 tasks.\n2-4 weeks to run the survey. Ideally, you want 400-plus responses to get statistically reliable results, but definitely need a minimum of 100.\n2 weeks to analyze and present results.\n\nSecrets To Success\nThe more diverse, the more cross-functional, the more cross-departmental, the more user-facing the group of people you get to do a Top Tasks project, the better. If things are working well, you’re going to have deep, almost existential conversations about what is a task, which tasks are relevant, and which are not. If, for example, you were doing a Top Tasks about COVID-19, you’d be examining the total environment, not simply the stuff you have now on your website or app about COVID-19. You’d be trying to get a total map of a pandemic through a series of tasks. \nWhat’s the best group?\n\nBetween three and eight people ideally.\nBroad group of representative stakeholders.\nGenuine experienced people who truly understand human needs.\nIf you’re doing an intranet Top Tasks survey, you should have representatives from Support, Marketing, Sales, Products, Web, IT, HR, and Communications.\nIf you’re doing a public Top Tasks survey, you should have representatives from Support, Marketing, Sales, Products, Web, and Communications.\nAim to have the same group throughout the entire Top Tasks process.\n\nI know. I know. I know. Getting this group together is time-consuming and very complicated. If you’re finding it almost impossible, then that’s a message. Your organization is probably not ready for Top Tasks, because if people won’t join the group, then the chances of them or their departments taking the results seriously are very, very low.\nHere are the benefits of spending the time and effort to get a great shortlisting group together:\n\nmore rounded and comprehensive task list;\na much deeper understanding of the organization;\nless likely that tiny tasks from any one department will be over-represented;\nbridge-building and future collaboration;\nidentifying tasks that have different names in different departments;\nidentifying duplicate content and tools across departments/units;\ngreater chance of buy-in and real change when the results are delivered.\n\nWhen we did a Top Tasks for WHO about COVID-19 in May 2020, here are the top tasks that emerged:\n\nvaccine (development, availability, safety);\nlatest news, latest research (alerts, directives, updates);\ntransmission, spread, epidemiology;\nimmunity, antibody testing (criteria, availability, accuracy);\nWHO guidelines, standards, decisions;\nsymptoms, signs;\nresearch papers, studies;\nend date, new normal, safe again;\nvirus survival/viability/persistence on surfaces, in air.\n\nHow did we get to a result like that? The first step is to gather the potential list of tasks. Here are some sources:\n\nexisting website / app;\ntop 50 annual search (internal, external);\ntop 50 website pages / app sections most visited;\nsurveys and research on customers in the last two to three years;\ntop 50 annual support, help, feedback;\ncompetitor / peer websites / apps;\nsocial media, blogs, communities.\n\nFor example, when we did Microsoft Visual Studio, we got lots of great tasks by visiting the independent developer communities. Depending on the complexity of the environment, the initial longlist of tasks can range from 200 to 400. In exceptional circumstances, such as when we did a Top Tasks for the European Commission, it ran into thousands. \nBelow is a tiny sample of these early tasks for a healthy environment:\n\naccess to my journal;\nadvice in cases of physical disability;\nadvice on treatment or hospitals abroad;\nadvice, guidance, rights, and practical information to relatives;\naids (prostheses, wigs, etc.);\naids in the hospital/treatment site;\nalternative treatment;\nanalysis and testing of organic food;\nanalysis of food safety (pesticide, dioxin...).\n\nYou can see that there’s a lot of work to be done to get from this rough list of hundreds to a refined list of 50-80.\nShortlisting: the Hardest Part\nWords are by far the most powerful — and often most underrated — invention humans have ever made. Without words, there is no Web. The Web is built from words, from the first search to the last click. Getting the words exactly right, and organizing them in the most intuitive way can prove so challenging that many organizations simply ignore the challenge or address it in the most flippant, derisory manner. \nTasks are the things people want to do on your website or app. More than anything else, they’ll use words to help them complete that task. The shortlisting process will be super intense because it’s a process of editing words. But if done right, it will be super rewarding. It may, in fact, be the first time your organization has come together to discuss and agree on what it is you are about, and what it is you are genuinely useful for. This is a quite profound process.\nGetting from a long list to a short list will usually take between two and four weeks. That’s roughly five to eight sessions with the shortlisting group, each session lasting 90 minutes. For each of these sessions, you will have to do an equivalent preparatory session. Have no more than three sessions a week, because this is intense work. Also, it’s good to let the list settle — it will mature and become clearer over time. The longlist shouldn’t be more than 150 for the first shortlisting group session. What this means is that you will probably have to do quite a bit of preparatory work cleaning up the initial list of 200-400 tasks, so that it is ready for that first session.\nThe art of shortlisting is about slowly stripping away words until all that’s left are the most essential words that describe the most essential tasks. Here are some shortlisting tips:\n\nAvoid verbs (get, find). Nouns make the best tasks. Verbs are waffly and vague. You don’t need “Find a job”. All you need is “Jobs”.\nAvoid statements (I want to…).\nAvoid questions (Can I…).\nRemove conjunctions. From “Installation and configuration” to “Installation, configuration”.\nUse brackets where necessary: “Conservation (ecology, nature, woodlands)”.\nKeep each task under 65 characters (8-10 words).\nAvoid first-word repetition (no more than four in any list).\nEuropean Commission at work\nEuropean Commission competition\nEuropean Commission directory\n\n\nDelete exact duplicates.\nRemove overlaps. This gets hard. Aim for a list of unique tasks, each one separate and distinct from the others. \nRemove brands, products, departments, and subjects.\nUniversity: no subjects, courses (English, Computer Science, Law, etc.)\nIntranet: no departments (HR, IT, Accounting)\nGovernment: no departments, brands\nCompany: no products, brands\nHealthcare: no diseases, conditions\n\n\nNo audiences, demographics.    \nDon’t have:  \nWomen’s health\nMen’s health\n\n\nDon’t have:  \nDevelopment policy for Austria\nDevelopment policy for Ireland  \n\n\nDon’t have:  \nTraining for developers\nTraining for testers\n\n\n\n\nAvoid formats and channels.\nNo formats: reports, newsletters, documents, tools, videos, forms, templates\nNo channels: Twitter, Facebook, YouTube, Instagram\nAvoid Web conventions: search, navigation, pages\n\n\nNo Dirty Magnets. A dirty magnet is a word or phrase that can mean different things to different people. It is vague and meaningless and can draw attention because it seems like it might be useful. Examples of dirty magnets include Resources; Knowledge Base; Quick Links, and Useful Links. By far, the worst dirty magnet of all is Frequently Asked Questions, which in my experience is the single worst Web design feature I have come across in more than 25 years of helping design websites.\n\nPreparing the Survey\nNo. The answer is no, you can’t. Just no. You can’t break up the list. You’re not allowed. It’s not how it works. One single list. One. Randomly presented. You ask people to quickly scan the list and choose no more than five of their top tasks from the list. \nThe amount of times designers and researchers have said to me, “But people aren’t going to vote on a list that long. It’s too long. We have to break it up.” No. The whole idea and concept of Top Tasks is a single list that delivers a single table of tasks ranked from the one that got the most votes to the one that got the least. If you break up the list, it’s no longer Top Tasks. It’s worked over 600 times. More than half a million people have voted in multiple languages in over 120 countries in the world. Since 2003, I have never had one single instance where it’s failed. Not one. \nYou will need a framing statement to introduce the task list. When we did a survey on COVID-19 vaccination, the framing statement for the list was:\nIn relation to the COVID-19 vaccine, select up to 5 things that are MOST IMPORTANT to you.\n\nWhen you’re writing the framing statement, try not to focus on your website or app. Focus on the world of people. Make it about the vaccine and what’s important to them, not your website and what’s important to you.\nThe survey typically has three parts:\n\nthe top tasks voting;\nsegmentation and demographic questions (role, gender, location);\nwebsite/app experience questions.\n\n\nEven after 30 voters, you should expect to see the top tasks begin to emerge. For example, the largest survey we ever did was for the European Commission. We had over 107,000 people voting. The top three tasks were:\n\nEU law, rules, treaties, judgments;\nresearch and innovation;\nfunding, grants, subsidies.\n\n\nAmazingly, after just 30 voters, these top three tasks had emerged, and they were the same three tasks after 107,000 voters.\nHowever, the more people you get to vote, the more the table stabilizes. We have found that having 400 voters gets us good solid results. The best way to get people to vote is with a popup on the website/app that is the main focus of the tasks.\nSolve Deep Needs. Design for the Long Term\nThere’s nothing cool or fashionable about Top Tasks. It’s a boring, deliberate, methodical process. It’s very much focused on the needs of the user, not the ego of the organization. \nWhen a tiny task goes to sleep at night, it dreams of being a top task. Websites are flooded with tiny task content, and apps are flooded with tiny task features. Invariably, when we do a Top Tasks survey, the ego of the organization is at the bottom of the table — it gets the least votes.\nWhen we did Liverpool City Council in 2009, the top tasks included the following: \n\nfind a job,\nleisure,\nwaste,\nlibraries,\nschools.\n\n\n\nThe team analyzed the publishing activities within the council and found that there was an inverse relationship between the importance of the task to a Liverpudlian and the amount of content being published on that task. The more important the task was to citizens, the less content was being published on it. The less important a task was to citizens, the more content was being published on it.\nOut of some 4,000 pages, 200 were getting 85% of traffic, and these 200 were not getting the proper care and attention, because the Web team’s time was taken up with dealing with tiny tasks. Top Tasks gave the team the evidence to delete over 80% of their website. The result was a much better experience for citizens.\n Top Tasks is about designing for the long term.\nMy passion now is sustainable digital design, and that means designing things that will be as light as possible and will last for the longest possible time. The same tasks we identified in 2009 (waste, leisure, schools) are still on the Liverpool homepage in 2022. Top Tasks can give you a classification, navigation, and information architecture that will stand the test of time because top tasks last. The most important things people want to do tend not to change much over time.\nIt’s about stripping away and removing the unnecessary, and about defocusing on the tiny tasks. Top Tasks gives you real, quantifiable evidence to make tough decisions that will create a better experience for your users.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e92d1278-297a-41d9-8ba2-e5100063610e/top-tasks-focus-what-matters-must-defocus-what-doesnt.jpg",
      "date_published": "2022-05-13T11:30:00.000Z",
      "date_modified": "2022-05-13T11:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/google-crux-analysis-comparison-performance-javascript-frameworks/",
      "url": "https://smashingmagazine.com/2022/05/google-crux-analysis-comparison-performance-javascript-frameworks/",
      "title": "How To Use Google CrUX To Analyze And Compare The Performance Of JS Frameworks",
      "summary": "In this article, Dan Shappir analyzes the performance cost associated with various frameworks and explains the wide variety of framework and platform choices that are currently available to front-end and fullstack developers.",
      "content_html": "<p>In recent years, frameworks have taken over web development, and React is leading the charge. These days it is fairly uncommon to encounter a new website or web app that doesn’t rely on some framework, or a platform such as a CMS.</p>\n<p>And while React’s tagline is “a JavaScript library for building user interfaces” rather than a framework, I think that ship has sailed: most React developers consider it to be a framework and use it as such. Or they use it as a part of a larger application framework such as NextJS, Gatsby, or RemixJS.</p>\n<p>But what price do we pay, as web developers, for the improved developer experience provided by such frameworks? And more importantly what price, if any, do our users pay for this choice that we are making?</p>\n<p>Recently Noam Rosenthal published two articles analyzing the <a href=\"https://www.smashingmagazine.com/author/noam-rosenthal/\">common benefits and capabilities provided by various frameworks</a>, and also their associated costs. I highly recommend checking out these articles. One of the costs that Noam mentions is the increased download size, especially JavaScript bundle sizes, that stem from the use of frameworks and other libraries. In particular, the increase in the amount of downloaded JavaScript can have a direct impact on website performance. And there are other aspects of framework usage that can impact performance as well.</p>\n<p>In this article, I will analyze the performance cost associated with various frameworks, based on field data collected by the <a href=\"https://developers.google.com/web/tools/chrome-user-experience-report\">Google Chrome User Experience Report</a>, or CrUX for short. I think this information is both interesting and useful, in particular given the wide variety of framework and platform choices currently available to front-end and fullstack developers.</p>\n<p>However, when reviewing this data, it’s important not to conflate correlation and causation. Just because webpages built using a particular framework more often have better or poorer performance than another framework doesn’t mean that the framework itself is always at fault. For example, it could be because certain frameworks are more commonly used for building heavier websites.</p>\n<p>That said, this data can assist in making informed decisions about which framework to choose when implementing front-end projects. When possible, I would prefer frameworks that have a higher good performance ratio.</p>\nCollecting Core Web Vitals From The Field\n<p>As I previously mentioned, my primary data source for this analysis is Google CrUX. CrUX is a cloud-based database into which Real User Measurements (RUM) are collected from live Chrome browser sessions. If you have opted-in to syncing browsing history, have not set up a Sync passphrase, and have usage statistics reporting enabled then whenever you load a webpage using Chrome, information about your session is automatically reported to CrUX. In particular, the collected measurements include the three <a href=\"https://web.dev/vitals/\">Core Web Vitals metrics</a> measured for each session.</p>\n<p>In recent years, these metrics have become the cornerstone of modern Web performance analysis:</p>\n<ul>\n<li><a href=\"https://web.dev/lcp/\">Largest Contentful Paint (LCP)</a>,</li>\n<li><a href=\"https://web.dev/fid/\">First Input Delay (FID)</a>,</li>\n<li><a href=\"https://web.dev/cls/\">Cumulative Layout Shift (CLS)</a>.</li>\n</ul>\n<p>For each such metric, Google has defined ranges that can be considered good (green), average / needs improvement (orange), and poor (red).</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8a7ba82c-083d-489e-b178-e76db08115e6/18-analyzing-comparing-performance-javascript-frameworks.jpg\" /></p>\n<p>Starting in June 2021, these metrics have become a ranking factor for Google search. This also increases their importance.</p>\n<p>In addition to collecting field data for each such session, synthetic measurements are performed on the websites, using the <a href=\"https://www.webpagetest.org/\">WebPageTest</a> tool. These lab measurements are collected into another online repository called the <a href=\"https://httparchive.org/\">HTTP Archive</a>. This includes analyzing which technologies a webpage uses, including which JavaScript frameworks, using the <a href=\"https://www.wappalyzer.com/\">Wappalyzer</a> service.</p>\n<p>Google makes it possible to execute queries on both these collections using its BigQuery project. However, the easiest way to gain insights from this data is to use the <a href=\"https://cwvtech.report/\">Core Web Vitals Technology Report</a> created by Rick Viscomi. (Rick is Staff DevRel Engineer at Google and manages both CrUX and the HTTP Archive.) This report provides a means of interactively graphing performance-related data for various web-based platforms and technologies and easily compares them to each other.</p>\n<p>For this article, I primarily rely on insights gained from analyzing data presented using the Core Web Vitals Technology Report.</p>\n<p>There are a few caveats to note when analyzing this data:</p>\n<ul>\n<li>While field data is collected by page, the Technology Report displays it per origin. The origin value is an aggregate of the values of all the pages for that origin, computed as a weighted average based on page traffic.</li>\n<li>On the other hand, the ratios of good origins are not weighted. This means that an origin that has relatively little traffic, but sufficient to be included in the dataset, is counted equally to a very popular, high-traffic origin. This aspect of the computation can be mitigated by filtering origins by popularity ranking</li>\n<li>HTTP Archive only analyzes the homepage for each origin. This means that the framework determination is only made for the home page, and all other pages belonging to that origin are aggregated for it, regardless of if they use it or not, or even if they use some other framework.</li>\n<li>Subdomains are measured as distinct origins.</li>\n</ul>\nComparing CWV of JavaScript Frameworks\n<p>Let’s start by comparing the performance of various JavaScript frameworks. Specifically the ratio of websites built using each of these frameworks that have good (green) scores for all three CWV metrics out of the total sites built using them. Sites that have good scores for all three CWV metrics should provide a better user experience in terms of performance, and are also eligible for the maximum Google search ranking boost.</p>\n<p>I have filtered the data to include only sessions in the USA in order to eliminate the impact of different geographical distributions between the different frameworks. The ALL line in the graphs refers to all websites in CrUX, not just those that use frameworks, and is used as a reference for comparison.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fd821e42-d59e-47a7-9275-cf97564d7ea7/2-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/852f78c3-1de3-493f-8e7e-29134402a7d6/7-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p><strong>Note</strong>: <em>Mobile in this case does not include iOS devices, such as iPhone. This is because Chrome on iOS is just a thin wrapper around a Safari core, and does not measure or report CWV. (This is true for all browsers on iOS — they are all just Safari on the inside.)</em></p>\n<p>First of all, we can see that different frameworks produce noticeably different results. Moreover, for better or worse, these results are mostly stable over the entire past year. (Preact is an exception to this, and I will explain the cause of this variation shortly.) This indicates that scores are meaningful, and not flukes, or results of statistical anomalies.</p>\n<p>Based on these measurements, as Noam Rosenthal’s article indicates, using frameworks does come at a performance cost: by comparing to the ALL baseline we see that websites built using any of these frameworks are generally less likely to have good CWV than websites built without frameworks. While some frameworks like React, Preact and Svelte do come close to the overall average, it is interesting to note that none of the frameworks provide significantly better performance than the others.</p>\n<p>React and Preact are essentially neck and neck — some may be surprised by this given how much smaller Preact is than React: approximately 4KB download vs 32KB (minified and gzipped in both cases). Apparently that 28KB download difference is not so significant in most cases. Jason Miller, the creator of Preact <a href=\"https://twitter.com/_developit/status/1492150651014496260\">recently had this to say about it</a>:</p>\n<blockquote><p>Preact isn't associated with any specific SSR or serving solutions, which dominate the impact on CWV. While Preact usage may have some correlation to CWV (really only FID), it is nowhere near as direct as tech choices involved in page delivery.</p>— Jason Miller 🦊⚛ (@_developit) <a href=\"https://twitter.com/_developit/status/1492150651014496260?ref_src=twsrc%5Etfw\">February 11, 2022</a></blockquote>\n\n<p>I’ll inspect the impact of Server-Side Rendering (SSR) and also Static Site Generation (SSG) as page generation/delivery options in more detail later on in this article.</p>\n<p>Vue and AngularJS are both in a second-tier — approximately 20-25% less likely to get good CWV on mobile, and 15-20% less likely on desktop. (Again, excluding iOS.) That said, Vue appears to be gaining ground and slowly reducing the gap with React in terms of performance.</p>\n<p>The big dip in Preact performance is <strong>not</strong> related to any change in the framework itself or its usage. Rather it has to do with Preact’s identification by Wappalyzer. Unfortunately, this service missed most uses of Preact prior to November 2021. As a result, the earlier results for Preact should be ignored as being invalid.</p>\nChecking Top Sites\n<p>When we limit our view to only the top 1,000,000 sites in the USA (based on traffic) an interesting change is that Vue almost catches up with React because the ratio of sites having good performance using Vue goes up and for React it surprisingly goes down:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d33f474f-fd7f-4455-8b51-4e3e5f604b79/14-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6e14078d-68c4-4a0c-8a7b-5e1f74258b89/19-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>And we see the same behavior with the top 100,000 sites, with React’s ratio actually dipping lower so that Vue slightly surpasses it. I didn’t try to limit the results even more because usage numbers for some frameworks dropped so low that they were no longer sufficiently statistically significant.</p>\n<p>But looking at the numbers we do have, the fact that Vue performance improves for higher-traffic sites perhaps indicates that <strong>achieving good performance with Vue</strong> requires greater expertise in that framework than simply being able to use it? This is because higher traffic sites are more likely to be built by organizations that can afford to employ developers that have greater expertise. Moreover, larger organizations can afford to spend more on infrastructure that is optimized for performance.</p>\n<p>On the other hand, React sites actually go down when limiting the number of sites measured by traffic.</p>\n<blockquote>Why is it that React developers with greater expertise are apparently less likely to produce fast loading websites?</blockquote>\n\n<p>Well, that’s a very interesting mystery that I will try to solve. </p>\nAnalyzing Per Metric\n<p>In addition to examining CWV as a whole, the Technology Report also makes it possible to examine each metric individually. Let’s start by looking at FID:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/723974d0-dfd5-4b77-bfbc-f06192335145/3-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>You might have expected that websites using frameworks would pay a penalty in the responsiveness metric, as it’s the one that should be the most impacted by the significant use of JavaScript. But, in practice, this is not the case. In fact, the FID metric is essentially meaningless, with all frameworks achieving a nearly perfect score.</p>\n<p>The same is true even when looking at the aggregation of all websites in the collection. For this reason, <a href=\"https://web.dev/better-responsiveness-metric/\">Google is researching a better responsiveness metric</a> and is <a href=\"https://web.dev/responsiveness/\">requesting feedback for the experimental metric they’re already testing</a>.</p>\n<p>Examining the LCP metric is much more meaningful:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0d2b0f88-f6f2-477f-bd10-db5c221e2b7b/1-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>Interestingly, LCP scores are a strong match for CWV as a whole, but more spread out: ALL, React, Preact, and Svelte are approximately 10% higher, while Vue and AngularJS remain essentially the same. But when we limit to the top 1,000,000 sites we see Preact and Svelte improve some more, but React doesn’t. As a result, Vue catches up with it.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7e23716c-9a58-44c5-b0c5-ea886ea889ed/8-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>Finally let’s look at CLS, starting with all websites:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/17b6d27b-e8d4-483d-be5b-486fa3f18ef1/10-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>And for the top 1,000,000 websites:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/95da909d-ff3c-445e-bf65-7115b5e7cccd/5-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>Here we see both React and Preact, especially React, going substantially down, resulting in Vue surpassing both of them.</p>\n<p>In other words, for Vue, both the ratio of good LCP and CLS improve when we check top sites only. For React, on the other hand, LCP remains mostly the same, while CLS actually degrades.</p>\n<p>This could indicate that a reason for the performance degradation seen for top sites using React is an increase in the amount of ads on pages. Ads often adversely impact CLS because as they appear they push other content down. However, I don’t think that’s the case because it doesn’t explain the difference in behavior between React and the other frameworks. Also, you would expect ads to impact LCP as well, but we see that LCP remains essentially the same.</p>\n<p>To try to better understand this behavior, let’s check other webpage aspects visualized by the Technology Report.</p>\nAnalyzing Additional Webpage Aspects\n<p>In addition to performance scores, the Technology Report enables analysis of resource download sizes. It’s well known that the amount of JavaScript used by a page can have a direct impact on its performance because all the code needs to be downloaded, parsed and executed. Let’s compare the amount of JavaScript downloaded by the various frameworks:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/19ff0949-d1fe-4836-9525-ecacaef63c9c/13-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>Unsurprisingly, websites that use frameworks download significantly more JavaScript than websites in general. This is due to all the functionality required for Single Page Applications (SPA), such as routing and client-side rendering.</p>\n<p>Also unsurprisingly, <strong>websites built using Svelte download less JavaScript than any other of these frameworks</strong>. This is due to the Svelte compiler handling at build-time a lot of functionality that other frameworks need to perform at run-time. As a result, Svelte doesn’t need to deploy the code required for such functionality. It’s also possible that developers using Svelte place a greater premium on delivering lean-and-mean webpages than developers using other platforms.</p>\n<p>That said, the 226KB difference between the median for Svelte sites and React sites only translates to <strong>a 2.4% increase</strong> in the amount of sites that have good CWV. This highlights the amazing improvement that browsers have been able to achieve in handling larger JavaScript payloads, for example by parsing the JavaScript off of the main thread, during the download. I assume that caching, both in the browser and CDNs, contributes to this as well.</p>\n<p>It’s also interesting to note that websites and <strong>apps using Preact actually download more JavaScript than those using React</strong>. Perhaps these sites chose Preact in an effort to reduce their total weight. In any event, this may explain why we didn’t see noticeable performance improvements for Preact over React: whatever benefits Preact provides are offset by the application code itself.</p>\n<p>When we look at the top 1,000,000 we see that the amount of JavaScript increases, with the interesting exception of Vue.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/fa4b4676-1053-4dca-b085-22f999e996f1/9-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>This may explain why we saw such a significant improvement for Vue for the top sites, compared to the other frameworks. In the case of those other frameworks, it appears that whatever greater expertise the developers working on top sites may have, it does not translate to reduced JavaScript download sizes. Actually, the opposite is true — perhaps due to the extra functionality provided by such websites.</p>\n<p>Another very interesting comparison is the amount of image data downloaded:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/da8b92c2-6fe2-408f-addd-c9d54bd1b80f/16-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>Here we see that sites built using React, Svelte and Angular download significantly less image data than websites in general. This may have to do with such sites leveraging modern techniques for reducing image downloads, such as lazy loading and newer image formats. Interestingly, Angular sites download significantly less image data than any other framework.</p>\n<p>Looking at the top sites we see a significant increase in image downloads across the board.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/92222dcf-8b33-4f84-ba95-f4d192400676/15-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>This may have to do with top sites being more content-rich. In particular, top sites are likely to have more ads in them, which are primarily images. And, as we will see, there are other possible explanations as well.</p>\nThe Impact Of SSR And SSG\n<p>As Jason Miller stated in the tweet that I previously quoted, technical choices involving webpage delivery have the greatest impact on the CWV metrics, in particular on LCP. Techniques such as Server-Side Rendering (SSR) and Static Site Generation (SSG) deliver contentful HTML to the browser from the get-go, enabling it to display the content immediately as it arrives. This is usually much earlier than visual content can be generated by client-side rendering techniques, especially when the contentful HTML is cached in a CDN or the browser itself. However, properly implementing the required infrastructure for this method of operation can be challenging when using a JavaScript framework. As a result, in recent years we’ve witnessed the introduction of multiple web application frameworks that provide this functionality out-of-the-box for the leading JavaScript frameworks and UI libraries.</p>\n<p>Given all this, we expect websites built using these web application frameworks to have a noticeably higher ratio of good CWV metrics than websites built using just the JavaScript frameworks or libraries.</p>\n<p>To determine if this is indeed the case, I used the Core Web Vitals Technology Report to compare the ratio of websites having good CWV for React, Vue and Svelte in general with the same ratio for the leading web application frameworks that are built on top of them:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3d0f6a65-0306-485c-9b75-32ebf9ccff2b/20-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>We immediately notice that SvelteKit is able to provide much higher performance than everything else. That being said, there are only 33 websites in this dataset that use SvelteKit. This number is too low to draw conclusions regarding its ability to consistently deliver good performance. But it will be interesting to see if its performance holds up as its usage increases.</p>\n<p>We can see that while the Gatsby framework does indeed provide a significantly higher ratio of good CWV than React in general, this is <strong>not</strong> the case for NextJS. And while NuxtJS does provide a better ratio than Vue in general, that ratio is still lower than for React.</p>\n<p>Also, why did I include Wix in this graph? After all, Wix is not a web application framework built on top of a JavaScript framework. Or is it?</p>\n<p>Actually, Wix is implemented using React, and as a result, every Wix website is also identified as a React website, just like Gatsby and NextJS. In other words, even though you don’t explicitly write React code when using Wix — after all, it’s a drag-and-drop website builder — it does generate a React website for you. Moreover, Wix also employs SSR like Next.js and uses CDN like both NextJS and Gatsby. <strong>And it has a higher good performance ratio than either of them</strong>.</p>\n<p>Now let’s consider the number of websites built using each one of these technologies:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f0a3680a-575f-44e4-91a9-dcbd9ddd9d78/4-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>Not only does Wix significantly outpace the popular web application frameworks, but in fact <strong>about a third of React websites in the USA are actually Wix websites</strong>!</p>\n<p>This is significant because, at such a high ratio, Wix performance noticeably impacts the performance measured for React websites as a whole. Fortunately, as we saw in the performance graph, Wix actually has a higher ratio of good CWV than React sites in general. In other words, <strong>Wix actually raises the performance scores measured for React.</strong></p>\n<p>But when we limit to the top 1,000,000 websites in the USA the ratios change substantially:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e2be9ec8-815c-4286-b6c0-3be56bc75990/17-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>The ratio of Wix and all other web application frameworks out of the total React websites drop significantly when looking only at the top 1,000,000 websites. In this dataset, only 14% of React sites are built with Wix. This means that Wix’s impact on React’s general performance is much reduced when looking only at top sites. This is a significant reason why React’s good performance ratio actually degrades when inspecting only the top sites, unlike the other JavaScript frameworks.</p>\n<p>In other words, Wix is the solution to the mystery of React’s unexpected performance profile. </p>\nPerformance Metrics For Web Application Frameworks\n<p>But what about NextJS and NuxtJS? Why don’t they provide the expected performance benefits across the board that we see with Gatsby (and also with Wix)? Analyzing each metric individually may reveal the root causes for this behavior.</p>\n<p>As before, the FID metric has essentially no impact on the overall performance ratio as all frameworks achieve a good FID ratio above 97%.</p>\n<p>Things get more interesting when we compare CLS ratios:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3b0b9012-8049-4a1c-9abf-0b1c63f69938/6-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>We can see that NextJS actually surpasses React, but that Gatsby is still ahead. Also, NuxtJS is smack in the middle between Vue and React.</p>\n<p>Since all these frameworks have essentially the same good FID ratios and close good CLS ratios, this indicates that the main cause of the difference between these frameworks is LCP:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4b1a7222-5013-45dd-9726-61baadcf9160/12-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>As expected we see that Gatsby is significantly ahead of React, and also that React in general is ahead of Next.js. Given that NextJS utilizes SSR / SSG and modern image formats, this is surprising. Certainly, this is something to watch out for when utilizing that framework.</p>\n<p>NuxtJS has made significant progress in this regard in recent months and has surpassed NextJS for good LCP which is essentially the same as React in general.</p>\n<p>Let’s see if the LCP differences can be explained by the image download sizes since larger images are often detrimental to LCP:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/841a6e12-5668-4850-a4f2-0567636b2e77/11-analyzing-comparing-performance-javascript-frameworks.png\" /></p>\n<p>It’s interesting to see that websites using NuxtJS and Vue download significantly more image data than websites that use React, and that NuxtJS is able to achieve a fairly good LCP ratio despite this.</p>\n<p>Gatsby and NextJS are both efficient in terms of the amount of the downloaded image data. This means that the improved good LCP ratio that Gatsby provides doesn’t stem just from reduced image sizes. To me, this indicates that Gatsby is likely able to start the download of the largest image sooner and to better prioritize it versus other page resources.</p>\n<p>Interestingly, the Gatsby homepage uses WebP for images and the NextJS homepage uses AVIF.</p>\nSummary\n<p>All of the frameworks that I reviewed in this article have good performance ratios higher than 0%, which means that you can build fast-loading sites, as measured by CWV, using any of them. Likewise, all these frameworks have good performance ratios that are lower than 100%, which means that you can also build slow-loading sites using any of them.</p>\n<p>That said, we saw significant differences between the good performance ratios of the various frameworks. This means that the likelihood that a website built using a specific framework will have good performance can be very different than for another framework. Certainly, this is something to consider when deciding which framework to use.</p>\n<p>On the other hand, we also saw that such differences can be misleading — for example, it initially appeared that React has a noticeably higher-good performance ratio than Vue. But when we effectively excluded most Wix websites, which are included in React’s statistics, by looking only at higher traffic sites, Vue actually catches up with React.</p>\n<p>In addition, certain frameworks that have a reputation for greater emphasis on performance, such as Preact and Svelte, don’t necessarily have an advantage for CWV. It will be interesting to see if their impact increases when Google introduces a new responsiveness metric to replace FID in CWV.</p>\n<p>Even more surprisingly, some Web Application frameworks don’t have an advantage either, despite their built-in support for SSG / SSR and the use of CDNs. In other words, using a Web Application framework is not a silver bullet for performance.</p>\n<p>In particular, it appears that NextJS and NuxtJS have a ways to go in terms of increasing the probability that sites built using them have good CWV. Their graphs are on a significant upward trend, especially NuxtJS, but are still noticeably lower than Gatsby or Wix or even the ratio for all websites in general. Hopefully, their improvements will continue and they’ll succeed in catching up.</p>",
      "content_text": "In recent years, frameworks have taken over web development, and React is leading the charge. These days it is fairly uncommon to encounter a new website or web app that doesn’t rely on some framework, or a platform such as a CMS.\nAnd while React’s tagline is “a JavaScript library for building user interfaces” rather than a framework, I think that ship has sailed: most React developers consider it to be a framework and use it as such. Or they use it as a part of a larger application framework such as NextJS, Gatsby, or RemixJS.\nBut what price do we pay, as web developers, for the improved developer experience provided by such frameworks? And more importantly what price, if any, do our users pay for this choice that we are making?\nRecently Noam Rosenthal published two articles analyzing the common benefits and capabilities provided by various frameworks, and also their associated costs. I highly recommend checking out these articles. One of the costs that Noam mentions is the increased download size, especially JavaScript bundle sizes, that stem from the use of frameworks and other libraries. In particular, the increase in the amount of downloaded JavaScript can have a direct impact on website performance. And there are other aspects of framework usage that can impact performance as well.\nIn this article, I will analyze the performance cost associated with various frameworks, based on field data collected by the Google Chrome User Experience Report, or CrUX for short. I think this information is both interesting and useful, in particular given the wide variety of framework and platform choices currently available to front-end and fullstack developers.\nHowever, when reviewing this data, it’s important not to conflate correlation and causation. Just because webpages built using a particular framework more often have better or poorer performance than another framework doesn’t mean that the framework itself is always at fault. For example, it could be because certain frameworks are more commonly used for building heavier websites.\nThat said, this data can assist in making informed decisions about which framework to choose when implementing front-end projects. When possible, I would prefer frameworks that have a higher good performance ratio.\nCollecting Core Web Vitals From The Field\nAs I previously mentioned, my primary data source for this analysis is Google CrUX. CrUX is a cloud-based database into which Real User Measurements (RUM) are collected from live Chrome browser sessions. If you have opted-in to syncing browsing history, have not set up a Sync passphrase, and have usage statistics reporting enabled then whenever you load a webpage using Chrome, information about your session is automatically reported to CrUX. In particular, the collected measurements include the three Core Web Vitals metrics measured for each session.\nIn recent years, these metrics have become the cornerstone of modern Web performance analysis:\n\nLargest Contentful Paint (LCP),\nFirst Input Delay (FID),\nCumulative Layout Shift (CLS).\n\nFor each such metric, Google has defined ranges that can be considered good (green), average / needs improvement (orange), and poor (red).\n\nStarting in June 2021, these metrics have become a ranking factor for Google search. This also increases their importance.\nIn addition to collecting field data for each such session, synthetic measurements are performed on the websites, using the WebPageTest tool. These lab measurements are collected into another online repository called the HTTP Archive. This includes analyzing which technologies a webpage uses, including which JavaScript frameworks, using the Wappalyzer service.\nGoogle makes it possible to execute queries on both these collections using its BigQuery project. However, the easiest way to gain insights from this data is to use the Core Web Vitals Technology Report created by Rick Viscomi. (Rick is Staff DevRel Engineer at Google and manages both CrUX and the HTTP Archive.) This report provides a means of interactively graphing performance-related data for various web-based platforms and technologies and easily compares them to each other.\nFor this article, I primarily rely on insights gained from analyzing data presented using the Core Web Vitals Technology Report.\nThere are a few caveats to note when analyzing this data:\n\nWhile field data is collected by page, the Technology Report displays it per origin. The origin value is an aggregate of the values of all the pages for that origin, computed as a weighted average based on page traffic.\nOn the other hand, the ratios of good origins are not weighted. This means that an origin that has relatively little traffic, but sufficient to be included in the dataset, is counted equally to a very popular, high-traffic origin. This aspect of the computation can be mitigated by filtering origins by popularity ranking\nHTTP Archive only analyzes the homepage for each origin. This means that the framework determination is only made for the home page, and all other pages belonging to that origin are aggregated for it, regardless of if they use it or not, or even if they use some other framework.\nSubdomains are measured as distinct origins.\n\nComparing CWV of JavaScript Frameworks\nLet’s start by comparing the performance of various JavaScript frameworks. Specifically the ratio of websites built using each of these frameworks that have good (green) scores for all three CWV metrics out of the total sites built using them. Sites that have good scores for all three CWV metrics should provide a better user experience in terms of performance, and are also eligible for the maximum Google search ranking boost.\nI have filtered the data to include only sessions in the USA in order to eliminate the impact of different geographical distributions between the different frameworks. The ALL line in the graphs refers to all websites in CrUX, not just those that use frameworks, and is used as a reference for comparison.\n\n\nNote: Mobile in this case does not include iOS devices, such as iPhone. This is because Chrome on iOS is just a thin wrapper around a Safari core, and does not measure or report CWV. (This is true for all browsers on iOS — they are all just Safari on the inside.)\nFirst of all, we can see that different frameworks produce noticeably different results. Moreover, for better or worse, these results are mostly stable over the entire past year. (Preact is an exception to this, and I will explain the cause of this variation shortly.) This indicates that scores are meaningful, and not flukes, or results of statistical anomalies.\nBased on these measurements, as Noam Rosenthal’s article indicates, using frameworks does come at a performance cost: by comparing to the ALL baseline we see that websites built using any of these frameworks are generally less likely to have good CWV than websites built without frameworks. While some frameworks like React, Preact and Svelte do come close to the overall average, it is interesting to note that none of the frameworks provide significantly better performance than the others.\nReact and Preact are essentially neck and neck — some may be surprised by this given how much smaller Preact is than React: approximately 4KB download vs 32KB (minified and gzipped in both cases). Apparently that 28KB download difference is not so significant in most cases. Jason Miller, the creator of Preact recently had this to say about it:\nPreact isn't associated with any specific SSR or serving solutions, which dominate the impact on CWV. While Preact usage may have some correlation to CWV (really only FID), it is nowhere near as direct as tech choices involved in page delivery.— Jason Miller 🦊⚛ (@_developit) February 11, 2022\n\nI’ll inspect the impact of Server-Side Rendering (SSR) and also Static Site Generation (SSG) as page generation/delivery options in more detail later on in this article.\nVue and AngularJS are both in a second-tier — approximately 20-25% less likely to get good CWV on mobile, and 15-20% less likely on desktop. (Again, excluding iOS.) That said, Vue appears to be gaining ground and slowly reducing the gap with React in terms of performance.\nThe big dip in Preact performance is not related to any change in the framework itself or its usage. Rather it has to do with Preact’s identification by Wappalyzer. Unfortunately, this service missed most uses of Preact prior to November 2021. As a result, the earlier results for Preact should be ignored as being invalid.\nChecking Top Sites\nWhen we limit our view to only the top 1,000,000 sites in the USA (based on traffic) an interesting change is that Vue almost catches up with React because the ratio of sites having good performance using Vue goes up and for React it surprisingly goes down:\n\n\nAnd we see the same behavior with the top 100,000 sites, with React’s ratio actually dipping lower so that Vue slightly surpasses it. I didn’t try to limit the results even more because usage numbers for some frameworks dropped so low that they were no longer sufficiently statistically significant.\nBut looking at the numbers we do have, the fact that Vue performance improves for higher-traffic sites perhaps indicates that achieving good performance with Vue requires greater expertise in that framework than simply being able to use it? This is because higher traffic sites are more likely to be built by organizations that can afford to employ developers that have greater expertise. Moreover, larger organizations can afford to spend more on infrastructure that is optimized for performance.\nOn the other hand, React sites actually go down when limiting the number of sites measured by traffic.\nWhy is it that React developers with greater expertise are apparently less likely to produce fast loading websites?\n\nWell, that’s a very interesting mystery that I will try to solve. \nAnalyzing Per Metric\nIn addition to examining CWV as a whole, the Technology Report also makes it possible to examine each metric individually. Let’s start by looking at FID:\n\nYou might have expected that websites using frameworks would pay a penalty in the responsiveness metric, as it’s the one that should be the most impacted by the significant use of JavaScript. But, in practice, this is not the case. In fact, the FID metric is essentially meaningless, with all frameworks achieving a nearly perfect score.\nThe same is true even when looking at the aggregation of all websites in the collection. For this reason, Google is researching a better responsiveness metric and is requesting feedback for the experimental metric they’re already testing.\nExamining the LCP metric is much more meaningful:\n\nInterestingly, LCP scores are a strong match for CWV as a whole, but more spread out: ALL, React, Preact, and Svelte are approximately 10% higher, while Vue and AngularJS remain essentially the same. But when we limit to the top 1,000,000 sites we see Preact and Svelte improve some more, but React doesn’t. As a result, Vue catches up with it.\n\nFinally let’s look at CLS, starting with all websites:\n\nAnd for the top 1,000,000 websites:\n\nHere we see both React and Preact, especially React, going substantially down, resulting in Vue surpassing both of them.\nIn other words, for Vue, both the ratio of good LCP and CLS improve when we check top sites only. For React, on the other hand, LCP remains mostly the same, while CLS actually degrades.\nThis could indicate that a reason for the performance degradation seen for top sites using React is an increase in the amount of ads on pages. Ads often adversely impact CLS because as they appear they push other content down. However, I don’t think that’s the case because it doesn’t explain the difference in behavior between React and the other frameworks. Also, you would expect ads to impact LCP as well, but we see that LCP remains essentially the same.\nTo try to better understand this behavior, let’s check other webpage aspects visualized by the Technology Report.\nAnalyzing Additional Webpage Aspects\nIn addition to performance scores, the Technology Report enables analysis of resource download sizes. It’s well known that the amount of JavaScript used by a page can have a direct impact on its performance because all the code needs to be downloaded, parsed and executed. Let’s compare the amount of JavaScript downloaded by the various frameworks:\n\nUnsurprisingly, websites that use frameworks download significantly more JavaScript than websites in general. This is due to all the functionality required for Single Page Applications (SPA), such as routing and client-side rendering.\nAlso unsurprisingly, websites built using Svelte download less JavaScript than any other of these frameworks. This is due to the Svelte compiler handling at build-time a lot of functionality that other frameworks need to perform at run-time. As a result, Svelte doesn’t need to deploy the code required for such functionality. It’s also possible that developers using Svelte place a greater premium on delivering lean-and-mean webpages than developers using other platforms.\nThat said, the 226KB difference between the median for Svelte sites and React sites only translates to a 2.4% increase in the amount of sites that have good CWV. This highlights the amazing improvement that browsers have been able to achieve in handling larger JavaScript payloads, for example by parsing the JavaScript off of the main thread, during the download. I assume that caching, both in the browser and CDNs, contributes to this as well.\nIt’s also interesting to note that websites and apps using Preact actually download more JavaScript than those using React. Perhaps these sites chose Preact in an effort to reduce their total weight. In any event, this may explain why we didn’t see noticeable performance improvements for Preact over React: whatever benefits Preact provides are offset by the application code itself.\nWhen we look at the top 1,000,000 we see that the amount of JavaScript increases, with the interesting exception of Vue.\n\nThis may explain why we saw such a significant improvement for Vue for the top sites, compared to the other frameworks. In the case of those other frameworks, it appears that whatever greater expertise the developers working on top sites may have, it does not translate to reduced JavaScript download sizes. Actually, the opposite is true — perhaps due to the extra functionality provided by such websites.\nAnother very interesting comparison is the amount of image data downloaded:\n\nHere we see that sites built using React, Svelte and Angular download significantly less image data than websites in general. This may have to do with such sites leveraging modern techniques for reducing image downloads, such as lazy loading and newer image formats. Interestingly, Angular sites download significantly less image data than any other framework.\nLooking at the top sites we see a significant increase in image downloads across the board.\n\nThis may have to do with top sites being more content-rich. In particular, top sites are likely to have more ads in them, which are primarily images. And, as we will see, there are other possible explanations as well.\nThe Impact Of SSR And SSG\nAs Jason Miller stated in the tweet that I previously quoted, technical choices involving webpage delivery have the greatest impact on the CWV metrics, in particular on LCP. Techniques such as Server-Side Rendering (SSR) and Static Site Generation (SSG) deliver contentful HTML to the browser from the get-go, enabling it to display the content immediately as it arrives. This is usually much earlier than visual content can be generated by client-side rendering techniques, especially when the contentful HTML is cached in a CDN or the browser itself. However, properly implementing the required infrastructure for this method of operation can be challenging when using a JavaScript framework. As a result, in recent years we’ve witnessed the introduction of multiple web application frameworks that provide this functionality out-of-the-box for the leading JavaScript frameworks and UI libraries.\nGiven all this, we expect websites built using these web application frameworks to have a noticeably higher ratio of good CWV metrics than websites built using just the JavaScript frameworks or libraries.\nTo determine if this is indeed the case, I used the Core Web Vitals Technology Report to compare the ratio of websites having good CWV for React, Vue and Svelte in general with the same ratio for the leading web application frameworks that are built on top of them:\n\nWe immediately notice that SvelteKit is able to provide much higher performance than everything else. That being said, there are only 33 websites in this dataset that use SvelteKit. This number is too low to draw conclusions regarding its ability to consistently deliver good performance. But it will be interesting to see if its performance holds up as its usage increases.\nWe can see that while the Gatsby framework does indeed provide a significantly higher ratio of good CWV than React in general, this is not the case for NextJS. And while NuxtJS does provide a better ratio than Vue in general, that ratio is still lower than for React.\nAlso, why did I include Wix in this graph? After all, Wix is not a web application framework built on top of a JavaScript framework. Or is it?\nActually, Wix is implemented using React, and as a result, every Wix website is also identified as a React website, just like Gatsby and NextJS. In other words, even though you don’t explicitly write React code when using Wix — after all, it’s a drag-and-drop website builder — it does generate a React website for you. Moreover, Wix also employs SSR like Next.js and uses CDN like both NextJS and Gatsby. And it has a higher good performance ratio than either of them.\nNow let’s consider the number of websites built using each one of these technologies:\n\nNot only does Wix significantly outpace the popular web application frameworks, but in fact about a third of React websites in the USA are actually Wix websites!\nThis is significant because, at such a high ratio, Wix performance noticeably impacts the performance measured for React websites as a whole. Fortunately, as we saw in the performance graph, Wix actually has a higher ratio of good CWV than React sites in general. In other words, Wix actually raises the performance scores measured for React.\nBut when we limit to the top 1,000,000 websites in the USA the ratios change substantially:\n\nThe ratio of Wix and all other web application frameworks out of the total React websites drop significantly when looking only at the top 1,000,000 websites. In this dataset, only 14% of React sites are built with Wix. This means that Wix’s impact on React’s general performance is much reduced when looking only at top sites. This is a significant reason why React’s good performance ratio actually degrades when inspecting only the top sites, unlike the other JavaScript frameworks.\nIn other words, Wix is the solution to the mystery of React’s unexpected performance profile. \nPerformance Metrics For Web Application Frameworks\nBut what about NextJS and NuxtJS? Why don’t they provide the expected performance benefits across the board that we see with Gatsby (and also with Wix)? Analyzing each metric individually may reveal the root causes for this behavior.\nAs before, the FID metric has essentially no impact on the overall performance ratio as all frameworks achieve a good FID ratio above 97%.\nThings get more interesting when we compare CLS ratios:\n\nWe can see that NextJS actually surpasses React, but that Gatsby is still ahead. Also, NuxtJS is smack in the middle between Vue and React.\nSince all these frameworks have essentially the same good FID ratios and close good CLS ratios, this indicates that the main cause of the difference between these frameworks is LCP:\n\nAs expected we see that Gatsby is significantly ahead of React, and also that React in general is ahead of Next.js. Given that NextJS utilizes SSR / SSG and modern image formats, this is surprising. Certainly, this is something to watch out for when utilizing that framework.\nNuxtJS has made significant progress in this regard in recent months and has surpassed NextJS for good LCP which is essentially the same as React in general.\nLet’s see if the LCP differences can be explained by the image download sizes since larger images are often detrimental to LCP:\n\nIt’s interesting to see that websites using NuxtJS and Vue download significantly more image data than websites that use React, and that NuxtJS is able to achieve a fairly good LCP ratio despite this.\nGatsby and NextJS are both efficient in terms of the amount of the downloaded image data. This means that the improved good LCP ratio that Gatsby provides doesn’t stem just from reduced image sizes. To me, this indicates that Gatsby is likely able to start the download of the largest image sooner and to better prioritize it versus other page resources.\nInterestingly, the Gatsby homepage uses WebP for images and the NextJS homepage uses AVIF.\nSummary\nAll of the frameworks that I reviewed in this article have good performance ratios higher than 0%, which means that you can build fast-loading sites, as measured by CWV, using any of them. Likewise, all these frameworks have good performance ratios that are lower than 100%, which means that you can also build slow-loading sites using any of them.\nThat said, we saw significant differences between the good performance ratios of the various frameworks. This means that the likelihood that a website built using a specific framework will have good performance can be very different than for another framework. Certainly, this is something to consider when deciding which framework to use.\nOn the other hand, we also saw that such differences can be misleading — for example, it initially appeared that React has a noticeably higher-good performance ratio than Vue. But when we effectively excluded most Wix websites, which are included in React’s statistics, by looking only at higher traffic sites, Vue actually catches up with React.\nIn addition, certain frameworks that have a reputation for greater emphasis on performance, such as Preact and Svelte, don’t necessarily have an advantage for CWV. It will be interesting to see if their impact increases when Google introduces a new responsiveness metric to replace FID in CWV.\nEven more surprisingly, some Web Application frameworks don’t have an advantage either, despite their built-in support for SSG / SSR and the use of CDNs. In other words, using a Web Application framework is not a silver bullet for performance.\nIn particular, it appears that NextJS and NuxtJS have a ways to go in terms of increasing the probability that sites built using them have good CWV. Their graphs are on a significant upward trend, especially NuxtJS, but are still noticeably lower than Gatsby or Wix or even the ratio for all websites in general. Hopefully, their improvements will continue and they’ll succeed in catching up.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d9ea7394-c230-471d-aafe-9977a30bdf3b/google-crux-analysis-comparison-performance-javascript-frameworks.jpg",
      "date_published": "2022-05-12T09:30:00.000Z",
      "date_modified": "2022-05-12T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/sunuva-case-study-ux-changes-result-increase-conversion/",
      "url": "https://smashingmagazine.com/2022/05/sunuva-case-study-ux-changes-result-increase-conversion/",
      "title": "How Even Small UX Changes Can Result In An Increase In Conversion (A Case Study)",
      "summary": "In this article, we will be taking a closer look at a design case study and discuss possible reasons why its customers abandon their online shopping carts and what solutions are recommended in each particular case.",
      "content_html": "<p><a href=\"https://www.sunuva.com/\">Sunuva</a> is a global fashion brand for kids established in 2007. Today, their products are featured in famous luxury store brands, such as Bloomingdale’s, Harrods, Barneys, Harvey Nichols, and other luxury department store chains. This is a great example of how — after conducting a UX audit — the team and I at Turum-burum established changes based on analytics data that can have significant results.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e316c032-d1b7-461a-afcc-833cea4ee036/11-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\nUX Audit and Support Over the Implementation of Recommendations\n<p>Since our customer, Sunuva, already had a development team, our task was to conduct a thorough <a href=\"https://turumburum.com/upload/Turumburum_presentation_2022.pdf\">UX Audit</a> with further support over the implementation of the recommendations.</p>\n<p>Turum-burum was hired by the swimwear company to do the following:</p>\n<ul>\n<li>Perform a thorough site usability audit with each site detail deeply researched;</li>\n<li>Provide optimal solutions and explanations for the users’ problems;</li>\n<li>Be on hand to advise the customer’s development team for any further clarifications.</li>\n</ul>\n<p>We conducted a thorough audit of the website by using data analytics tools, Hotjar recordings and click maps and data of known user snag points provided by the customer. </p>\n<p>The process of the project review consisted of the following three main stages:</p>\n<ul>\n<li>UX auditing of the website (mobile and desktop);</li>\n<li>Interviewing business representatives;</li>\n<li>Providing further support and advice on any further clarifications.</li>\n</ul>\n<p>After the audit was completed, we have done the following:</p>\n<ul>\n<li>Created a document listing the problems for each key page;</li>\n<li>Prioritized all those issues;</li>\n<li>Provided a full detailed proposal of amendments with documented examples and indications of how each amendment could improve the user experience.</li>\n</ul>\nKey Problems and Recommendations\n<p>The analysis of the website metrics showed that the website had engagement indicators, traffic composition, and the conversion rate for both new and returning users along the bounce and exit rate were within the normal range for this segment.</p>\n<p>Yet, we found several issues that needed to be addressed, such as the interface mistakes that adversely affected the key metrics and prevented customers from converting. The main points of growth include:</p>\n<ul>\n<li>Increase the conversion rate on the mobile;</li>\n<li>Increase the number of views of the product detail pages;</li>\n<li>Increase the add-to-basket rate on the desktop;</li>\n<li>Minimize the shopping cart abandonment rate;</li>\n<li>Increase the checkout completion percentage rate.</li>\n</ul>\n<p>The most critical points that we found were the following:</p>\n<ul>\n<li><a href=\"#catalog-structure\">Catalog structure</a>,</li>\n<li><a href=\"#users-mistakes\">Absence of prevention of users’ mistakes</a>,</li>\n<li><a href=\"#incorrect-notification-on-the-checkout-page\">The checkout page pitfalls</a>,</li>\n<li><a href=\"#no-priority-in-header-elements-and-information\">Absence of priority in header elements</a>,</li>\n<li><a href=\"#absence-of-recently-viewed-blocks\">Absence of “Recently viewed” blocks</a>,</li>\n<li><a href=\"#not-so-obvious-category-blocks\">Issues with category blocks</a>.</li>\n</ul>\n<p>They are all outlined and described in detail below. Let’s dive in!</p>\n<h3>Catalog Structure</h3>\n<h4>Problem</h4>\n<p>The catalog structure resulted in the product list containing a wide range of mixed products. In turn, it became more difficult for users to find the products they needed. According to heat maps, users often used filters — size (age) and gender, if it’s not specified in the selected category. Those who have never used a filter had difficulty finding items on the list. According to our analytics data, only 37% of users who viewed the product list found the product they needed, became interested in them, and decided to go to the product details page.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e060b73b-047d-4431-9035-43104acbaa7a/12-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h4>Recommendation</h4>\n<p>To ease the search for the products, fast tags under the product list with common groups (for example, Boys, Girls, Baby, Kids, Teen; Shorts, Suits, Vests) should be added. Also, it’s recommended to show an expanded list of sizes and gender filters by default, so that users can find them quickly and use them. This should shorten the time needed for the search. In the mobile, the filter button should always stay in a fixed position, while the user scrolls down the page.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/130d7b95-9455-4c7c-a6b6-0c8cfd1be622/8-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/5b936135-e442-4d96-9118-a72e382c7483/15-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h3>Users’ Mistakes</h3>\n<h4>Problem</h4>\n<p>No error notification would pop up whenever users clicked on the “Add to basket” button without selecting a size beforehand. It made them go back, select a size, and click the button again.</p>\n<h4>Recommendation</h4>\n<p>Whenever users don’t select a size and click on the “Add to basket” button, the size list would open automatically, and users tend to shift their focus to it.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/c12c9690-b25e-4cf2-b2f9-8fedf159fe87/6-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/49be446b-8d5c-4f8d-87dd-49d33a9cc40e/17-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h4>Recommendation</h4>\n<p>It would be better not to show the notification that some amount is missing from free shipping on the checkout page. Adding a progress bar in the basket or adding an info message about free shipping and all the details should work much better. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/99905c75-0aca-469a-b86d-559eb05c8895/9-sunuva-case-study-ux-changes-result-increase-conversion.jpg\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2f7f1041-f3c2-4b09-b17e-e514444780f4/18-sunuva-case-study-ux-changes-result-increase-conversion.jpg\" /></p>\n<h3>No Priority In Header Elements And Information</h3>\n<h4>Problem</h4>\n<p>There was no priority in the information and sufficient differences in the visual accent in the header elements. The incorrect placement of the accent confused many users. This issue ruined the customer experience.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/37b1d01e-8573-4f4b-8738-4c7282ac0427/3-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h4>Recommendation</h4>\n<ul>\n<li>Visually separate elements, such as Currency, Wishlist, Search, My Account, and Basket.</li>\n<li>Place more emphasis on the catalog categories. </li>\n<li>Align the currency, wishlist, search, account elements, and so on with the logo. It helps users focus on the more important parts of the site and shortens the time to search for the necessary products.</li>\n</ul>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/36c45471-c7e5-47e5-8bd1-fd2f19949643/10-sunuva-case-study-ux-changes-result-increase-conversion.jpg\" /></p>\n<h4>Problem</h4>\n<p>It was difficult to notice the catalog categories in the burger menu and differentiate them from the info categories. Users had to spend more time finding the necessary category and its items.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0aa039fc-4700-468e-bc4f-44cbfa47b1e0/7-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h4>Recommendation</h4>\n<p>It’s better to visually differentiate the catalog categories from the info categories. Make less emphasis on the info categories. It will help users to focus on the product categories and faster find the needed items.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/85a7702c-289a-4026-bc5c-28650e4e3be8/1-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h3>Absence Of “Recently Viewed” Blocks</h3>\n<h4>Problem</h4>\n<p>There were no blocks or lists with recently viewed items and no quick “Add to basket” button. According to the analytics data, users would be 2.5 times more likely to return than to buy goods during the next session. In this case, they have already seen some goods and may be ready to buy them quicker. Users might not be able to find the items again or spend too much time doing that. This drastically affected the conversion rate.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e8c1f6fb-b813-4c40-9a46-bb9f5e89d033/5-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h4>Recommendation</h4>\n<p>Show the viewed item list. Add the “Add to basket” buttons on the product list cards, hover on desktop, and fixed on the mobile. It will help users find the products they are interested in much quicker.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ea0cd718-97d1-41bd-bbc9-92deb551de6d/16-sunuva-case-study-ux-changes-result-increase-conversion.jpg\" /></p>\n<h3>Not So Obvious Category Blocks</h3>\n<h4>Problem</h4>\n<p>Users never clicked on the category blocks, because the labels were too hard to read, and it seemed to block part of the banner. That’s why it was hard for users to find the necessary items quickly and took more time to search for them.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a03043e2-b856-4d2c-8696-06022fb0c16a/4-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/baeea7b5-775b-4772-99b8-b7c586225de5/19-sunuva-case-study-ux-changes-result-increase-conversion.png\" /></p>\n<h4>Recommendation</h4>\n<p>Change the appearance of the title and the blocks. Visually detach them from the banner, so that users know they are clickable and lead to the category listing.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/964399d6-2aee-4335-8bba-7dc38192ddb2/13-sunuva-case-study-ux-changes-result-increase-conversion.jpg\" /></p>\nResults of the Work Done on the Sunuva Website\n<p>Our team has utilized analytic tools, session recordings, heat maps, and other customer data to execute their tasks and provide recommendations. As a result, our customer has reported an increase in the conversion rate and site traffic after nearly implementing every recommendation.</p>\n<blockquote>“Turum-burum’s work drove an increase in the client’s conversion rate and site traffic. Proactive and detail-oriented, they took the time to understand all of the available data to provide optimal solutions and explanations for the client’s problems. They were supportive and transparent throughout.”<br /><br />— <a href=\"https://clutch.co/profile/turum-burum#review-1910633\">Jennifer Tully, E-Commerce Manager, Sunuva</a></blockquote>\n\nHow to Get Started with UX/UI Changes to Increase the Conversion Rate?\n<p>These are seven simple steps that you can follow in order to conduct a UX audit on your own that will help you find and eliminate some interface mistakes: </p>\n<table>\n  <thead>\n    <tr>\n      <th>Steps</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1. Follow the user’s footsteps.</td>\n      <td>Make a purchase like you are the customer</td>\n    </tr>\n    <tr>\n      <td>2. Analyze micro and macro conversions.</td>\n      <td>Using GTM and GA</td>\n    </tr>\n    <tr>\n      <td>3. Conduct audience research.</td>\n      <td>What is your target audience portrait?</td>\n    </tr>\n    <tr>\n      <td>4. Conduct a technical audit.</td>\n      <td>Is everything working on your website?</td>\n    </tr>\n    <tr>\n      <td>5. Check heatmaps and scroll maps.</td>\n      <td>Hotjar and Plerdy could be helpful.</td>\n    </tr>\n    <tr>\n      <td>6. Watch session recordings.</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>7. Analyze feedback.</td>\n      <td>(Hotjar, Survio)</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>After these steps are taken, establish several hypotheses on how your website could be improved and prioritize them according to their impact on conversion. Following that, start checking these hypotheses with A/B testing or measuring the changes in analytics. This process can be endless.  </p>\n<p>Converting a user who has already visited your site can cost your business much less than attracting new ones with the help of marketing tools. That’s why you should constantly improve the interface to meet new business goals, new market demand, and new user behavior patterns. If you can’t do this on your own, hire a team of UX/UI experts regularly.</p>\n<h3>Find Out More About UX/UI Agency Turum-burum</h3>\n<p>🇺🇦 <em><a href=\"https://turumburum.com/?utm_source=article&amp;utm_medium=SmashingMag&amp;utm_campaign=Sunuva\">Turum-burum</a>, a</em> <strong><em>UX/UI and CRO</em></strong> <em>company from Ukraine, has over 12 years of UX/UI experience, and its primary focus is on e-commerce and SaaS projects. They influence key website metrics to increase clients’ revenue with the help of design.</em></p>\n<p><em>They are Google UX Partners and take part in Retail Development Programs from Google in Ukraine. They cooperate with Baymard Institute, CXL, Hotjar, etc.</em></p>\n<p><em>If you need any UX/UI or CRO services, check this <a href=\"https://turumburum.com/upload/Turumburum_presentation_2022.pdf\">Turum-burum’s presentation</a> where you can find their contacts.</em></p>",
      "content_text": "Sunuva is a global fashion brand for kids established in 2007. Today, their products are featured in famous luxury store brands, such as Bloomingdale’s, Harrods, Barneys, Harvey Nichols, and other luxury department store chains. This is a great example of how — after conducting a UX audit — the team and I at Turum-burum established changes based on analytics data that can have significant results.\n\nUX Audit and Support Over the Implementation of Recommendations\nSince our customer, Sunuva, already had a development team, our task was to conduct a thorough UX Audit with further support over the implementation of the recommendations.\nTurum-burum was hired by the swimwear company to do the following:\n\nPerform a thorough site usability audit with each site detail deeply researched;\nProvide optimal solutions and explanations for the users’ problems;\nBe on hand to advise the customer’s development team for any further clarifications.\n\nWe conducted a thorough audit of the website by using data analytics tools, Hotjar recordings and click maps and data of known user snag points provided by the customer. \nThe process of the project review consisted of the following three main stages:\n\nUX auditing of the website (mobile and desktop);\nInterviewing business representatives;\nProviding further support and advice on any further clarifications.\n\nAfter the audit was completed, we have done the following:\n\nCreated a document listing the problems for each key page;\nPrioritized all those issues;\nProvided a full detailed proposal of amendments with documented examples and indications of how each amendment could improve the user experience.\n\nKey Problems and Recommendations\nThe analysis of the website metrics showed that the website had engagement indicators, traffic composition, and the conversion rate for both new and returning users along the bounce and exit rate were within the normal range for this segment.\nYet, we found several issues that needed to be addressed, such as the interface mistakes that adversely affected the key metrics and prevented customers from converting. The main points of growth include:\n\nIncrease the conversion rate on the mobile;\nIncrease the number of views of the product detail pages;\nIncrease the add-to-basket rate on the desktop;\nMinimize the shopping cart abandonment rate;\nIncrease the checkout completion percentage rate.\n\nThe most critical points that we found were the following:\n\nCatalog structure,\nAbsence of prevention of users’ mistakes,\nThe checkout page pitfalls,\nAbsence of priority in header elements,\nAbsence of “Recently viewed” blocks,\nIssues with category blocks.\n\nThey are all outlined and described in detail below. Let’s dive in!\nCatalog Structure\nProblem\nThe catalog structure resulted in the product list containing a wide range of mixed products. In turn, it became more difficult for users to find the products they needed. According to heat maps, users often used filters — size (age) and gender, if it’s not specified in the selected category. Those who have never used a filter had difficulty finding items on the list. According to our analytics data, only 37% of users who viewed the product list found the product they needed, became interested in them, and decided to go to the product details page.\n\nRecommendation\nTo ease the search for the products, fast tags under the product list with common groups (for example, Boys, Girls, Baby, Kids, Teen; Shorts, Suits, Vests) should be added. Also, it’s recommended to show an expanded list of sizes and gender filters by default, so that users can find them quickly and use them. This should shorten the time needed for the search. In the mobile, the filter button should always stay in a fixed position, while the user scrolls down the page.\n\n\nUsers’ Mistakes\nProblem\nNo error notification would pop up whenever users clicked on the “Add to basket” button without selecting a size beforehand. It made them go back, select a size, and click the button again.\nRecommendation\nWhenever users don’t select a size and click on the “Add to basket” button, the size list would open automatically, and users tend to shift their focus to it.\n\n\nRecommendation\nIt would be better not to show the notification that some amount is missing from free shipping on the checkout page. Adding a progress bar in the basket or adding an info message about free shipping and all the details should work much better. \n\n\nNo Priority In Header Elements And Information\nProblem\nThere was no priority in the information and sufficient differences in the visual accent in the header elements. The incorrect placement of the accent confused many users. This issue ruined the customer experience.\n\nRecommendation\n\nVisually separate elements, such as Currency, Wishlist, Search, My Account, and Basket.\nPlace more emphasis on the catalog categories. \nAlign the currency, wishlist, search, account elements, and so on with the logo. It helps users focus on the more important parts of the site and shortens the time to search for the necessary products.\n\n\nProblem\nIt was difficult to notice the catalog categories in the burger menu and differentiate them from the info categories. Users had to spend more time finding the necessary category and its items.\n\nRecommendation\nIt’s better to visually differentiate the catalog categories from the info categories. Make less emphasis on the info categories. It will help users to focus on the product categories and faster find the needed items.\n\nAbsence Of “Recently Viewed” Blocks\nProblem\nThere were no blocks or lists with recently viewed items and no quick “Add to basket” button. According to the analytics data, users would be 2.5 times more likely to return than to buy goods during the next session. In this case, they have already seen some goods and may be ready to buy them quicker. Users might not be able to find the items again or spend too much time doing that. This drastically affected the conversion rate.\n\nRecommendation\nShow the viewed item list. Add the “Add to basket” buttons on the product list cards, hover on desktop, and fixed on the mobile. It will help users find the products they are interested in much quicker.\n\nNot So Obvious Category Blocks\nProblem\nUsers never clicked on the category blocks, because the labels were too hard to read, and it seemed to block part of the banner. That’s why it was hard for users to find the necessary items quickly and took more time to search for them.\n\n\nRecommendation\nChange the appearance of the title and the blocks. Visually detach them from the banner, so that users know they are clickable and lead to the category listing.\n\nResults of the Work Done on the Sunuva Website\nOur team has utilized analytic tools, session recordings, heat maps, and other customer data to execute their tasks and provide recommendations. As a result, our customer has reported an increase in the conversion rate and site traffic after nearly implementing every recommendation.\n“Turum-burum’s work drove an increase in the client’s conversion rate and site traffic. Proactive and detail-oriented, they took the time to understand all of the available data to provide optimal solutions and explanations for the client’s problems. They were supportive and transparent throughout.”— Jennifer Tully, E-Commerce Manager, Sunuva\n\nHow to Get Started with UX/UI Changes to Increase the Conversion Rate?\nThese are seven simple steps that you can follow in order to conduct a UX audit on your own that will help you find and eliminate some interface mistakes: \n\n  \n    \n      Steps\n      \n    \n  \n  \n    \n      1. Follow the user’s footsteps.\n      Make a purchase like you are the customer\n    \n    \n      2. Analyze micro and macro conversions.\n      Using GTM and GA\n    \n    \n      3. Conduct audience research.\n      What is your target audience portrait?\n    \n    \n      4. Conduct a technical audit.\n      Is everything working on your website?\n    \n    \n      5. Check heatmaps and scroll maps.\n      Hotjar and Plerdy could be helpful.\n    \n    \n      6. Watch session recordings.\n      \n    \n    \n      7. Analyze feedback.\n      (Hotjar, Survio)\n    \n  \n\n\nAfter these steps are taken, establish several hypotheses on how your website could be improved and prioritize them according to their impact on conversion. Following that, start checking these hypotheses with A/B testing or measuring the changes in analytics. This process can be endless.  \nConverting a user who has already visited your site can cost your business much less than attracting new ones with the help of marketing tools. That’s why you should constantly improve the interface to meet new business goals, new market demand, and new user behavior patterns. If you can’t do this on your own, hire a team of UX/UI experts regularly.\nFind Out More About UX/UI Agency Turum-burum\n🇺🇦 Turum-burum, a UX/UI and CRO company from Ukraine, has over 12 years of UX/UI experience, and its primary focus is on e-commerce and SaaS projects. They influence key website metrics to increase clients’ revenue with the help of design.\nThey are Google UX Partners and take part in Retail Development Programs from Google in Ukraine. They cooperate with Baymard Institute, CXL, Hotjar, etc.\nIf you need any UX/UI or CRO services, check this Turum-burum’s presentation where you can find their contacts.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/de6a0a8a-3eae-4d7a-af27-50363c857936/sunuva-case-study-ux-changes-result-increase-conversion.jpg",
      "date_published": "2022-05-11T10:00:00.000Z",
      "date_modified": "2022-05-11T10:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/magical-svg-techniques/",
      "url": "https://smashingmagazine.com/2022/05/magical-svg-techniques/",
      "title": "Magical SVG Techniques",
      "summary": "Smart SVG techniques, from generative SVG grids to SVG paths with masks, grainy SVG gradients, cut-out effects and fractional SVG stars. Let’s look at some magical SVG techniques that you can use right away.",
      "content_html": "<p>SVGs have become more and more popular in the past few years. For good reasons. They are scalable, flexible, and, most importantly, lightweight. And, well, they have even more to offer than you might think. We came across some magical SVG techniques recently that we’d love to share with you. From <strong>SVG grids</strong> and <strong>fractional SVG stars</strong> to SVG masks, fancy <strong>grainy SVG gradients</strong>, and handy SVG tools. We hope you’ll find something useful in here.</p>\n<p>By the way, a while ago, we also looked at <a href=\"https://www.smashingmagazine.com/2021/03/svg-generators/\">SVG Generators</a> — for everything from shapes and backgrounds to SVG path visualizers, cropping tools, and SVG → JSX generators. If you’re tinkering with SVG, these might come in handy, too.</p>\nGenerative SVG Grids\n<p>Generative art is a wonderful opportunity for everyone who would love to create art but feels more at home in code. Let’s say you want to create <strong>geometric patterns</strong>, for example. Generative art will take away the difficult decisions from you: What shapes do I use? Where do I put them? And what colors should I use? If you want to give it a try, Alex Trost wrote a <a href=\"https://frontend.horse/articles/generative-grids/\">tutorial on creating generative art with SVG grids</a> that is bound to tickle your creativity — and teach you more about SVG.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7c3f5704-0a4c-483d-8a63-70601dc84305/generative-grids-opt.png\" /></p>\n<p>The generative art that Alex creates is a grid of blocks with a random number of rows and columns. Each block has a randomly chosen design and colors from a shared color palette. Alex takes you step by step through the process of coding this piece: from setting up the grid and creating isolated <strong>functions to draw SVGs</strong> to working with color palettes, adding animations, and more. A fun little project — not only if you’re new to generative art and creative coding.</p>\nGenerative Landscape Rolls\n<p>An awe-inspiring project that bridges the gap between a century-old tradition and state-of-the-art coding is <a href=\"https://github.com/LingDong-/shan-shui-inf\"><em>{Shan, Shui}</em></a>. Created by Lingdong Huan and inspired by traditional Chinese landscape rolls, it creates procedurally generated, infinitely-scrolling <strong>Chinese landscapes in SVG format</strong>. The mountains and trees in the landscape are modeled from scratch using noise and mathematical functions. Fascinating!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/99853108-7dd6-40c2-950b-47d41be709cc/shan-shui-opt.png\" /></p>\n<p>Now, if you’re asking yourself how something as complex might work, you’re not alone. Victor Shepelev wanted to get behind the secret of {Shan, Shui}* and made it his advent project to understand how it works. And, indeed, it took him 24 days to fully <strong>dig into the code</strong>. He summarized his findings in a <a href=\"https://zverok.github.io/blog/2021-12-28-grok-shan-shui.html\">series of articles</a>.</p>\nSVG Paths With Masks\n<p>SVGs have a lot of benefits compared to raster images. They are small in size, scalable, animatable, they can be edited with code, and a lot more. You can’t get the textured feel that raster graphics can provide, though. However, we can combine the <strong>strengths of vector and raster</strong> to create some charming effects. Like Tom Miller did in his <a href=\"https://codepen.io/creativeocean/pen/abLGMwv\">Silkscreen Squiggles</a> demo.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4fe06f6f-6d54-41fe-8d73-5c7ff06a2103/svg-paths-opt.png\" /></p>\n<p>Silkscreen Squiggles is an animation where squiggles fill a rectangular canvas. What makes the squiggles special is that they appear to have a <strong>paintbrush texture</strong>. The secret: a mask with an alpha layer that gives the simple squiggly paths their texture. Alex Trost <a href=\"https://frontend.horse/articles/painting-svg-paths-with-masks/\">dissects how it works</a>. Inspiring!</p>\nGrainy Gradients\n<p>Noise is a simple technique to <strong>add texture</strong> to an image and make otherwise solid colors or smooth gradients more realistic. But despite designer’s affinity for texture, noise is rarely used in web design. Jimmy Chion explores <a href=\"https://css-tricks.com/grainy-gradients/\">how we can add texture to a gradient</a> with only a small amount of CSS and SVG.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a7f7f36b-6f4c-43db-8dae-d49471554ce8/holographic-type-opt.png\" /></p>\n<p>The trick is to use an SVG filter to create the noise, then apply that noise as a background. Layer it underneath your gradient, boost the brightness and contrast, and that’s already it. Potential use cases could be light and shadows or <strong>holographic foil effects</strong>, for example. The core of this technique is supported by all modern browsers. A clever visual effect to add depth and texture to a design.</p>\nAdding Texture And Depth\n<p>“Analog” materials like paint and paper naturally add depth to an artwork, but when working digitally, we often sacrifice the <strong>organic depth</strong> they provide for precision and speed. Let’s bring some texture back into our work! George Francis shares <a href=\"https://georgefrancis.dev/writing/texture-generative-snacks/\">three ways to do so</a>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b9749a39-5afc-4b17-b091-de9f1cb162ac/texture-generative-snacks-opt.png\" /></p>\n<p>The techniques that George explores are quite simple but effective. Tiny <strong>random shapes</strong> added to a canvas at random points, solid shape fills with lines, and non-overlapping circles distributed evenly but randomly with an algorithm. Inspiring ideas to tinker with.</p>\nCut-Out Effects With CSS And SVG\n<p>In a recent front-end project that Ahmad Shadeed was working on, one of the components included a cut-out effect where an area is cut out of a shape. And because there are multiple ways to create such an effect in CSS or SVG, he decided to explore the <strong>pros and cons</strong> that each of the solutions brings along.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0e4319a1-8dcf-443b-b781-e659380aa800/cut-out-effect-opt.png\" /></p>\n<p>In his blog post “<a href=\"https://ishadeed.com/article/thinking-about-the-cut-out-effect/\">Thinking About The Cut-Out Effect</a>”, Ahmad takes a look at three different use cases for a cutout effect: an avatar with a cut-out <strong>status badge</strong> that indicates that a user is currently online, a “seen avatar” that consists of overlapping circle avatars that are indicators that a message has been seen in a group chat, as well as a website header with a cut-out area behind a circular logo. Ahmad presents different solutions for each use case — SVG-only, CSS-only, and a mix of both — and explains the pros and cons of each one of them. A comprehensive overview.</p>\nFractional SVG Stars\n<p>Are you building a rating component and you want it to support fractional values like 4.2 or 3.7 stars but without using images? Good news, you can achieve <strong>fractional ratings</strong> with only CSS and inline SVG. Samuel Kraft <a href=\"https://samuelkraft.com/blog/fractional-svg-stars-css\">explains how it works</a>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7e4ace33-8648-4ec4-a5a9-68988ad459ce/fractional-stars-opt.png\" /></p>\n<p>The component basically consists of two parts: a list of star icons based on the max rating and an “overlay” <code>div</code> that will be responsible for <strong>changing the colors</strong> of the stars underneath. This is the magic that makes the fractional part work. The technique is supported in all modern browsers; for older browsers, you can fall back to opacity instead. Clever!</p>\nGenerative Mountain Ridge Dividers\n<p>When Alistair Shepherd built his personal website, he wanted to have section dividers that match the mountain theme of the site. But not any mountain dividers, but dividers with <strong>unique ridges</strong> for every divider.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f16fdf7a-1bc9-4d41-acd1-805f897d5025/generative-mountain-divider-opt.png\" /></p>\n<p>Instead of creating a variety of different dividers manually, Alistair decided to use a combination of SVG and terrain generation, a technique that is usually used in <strong>game development</strong>, to generate the dividers automatically. In a <a href=\"https://alistairshepherd.uk/writing/svg-generative-ridges/\">blog post</a>, he explains how it works.</p>\n<p>If you’re up for some more horizontal divider inspiration, also be sure to check out Sara Soueidan’s blog post “<a href=\"https://www.sarasoueidan.com/blog/horizontal-rules/\">Not Your Typical Horizontal Rules</a>” in which she shows how she turned a boring horizontal line into a cute “<strong>birds on a wire</strong>” divider with the help of some CSS and SVG.</p>\nFlexible Repeating SVG Masks\n<p>Sometimes it’s a small idea, a little detail in a project that you tinker with and that you can’t let go off until you come up with a tailor-made solution to make it happen. Nothing that seems like a big deal at first glance, but that requires you to think outside the box. In Tyler Gaw’s case, this little detail was a <strong>flexible header</strong> with a little squiggle at the bottom instead of a straight line. The twist: to make the component future-proof, Tyler wanted to use a seamless, horizontal repeating pattern that he could color with CSS.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/58c7f164-9648-4cb0-8e17-eeca66eee1ad/banner-squiggles-opt.png\" /></p>\n<p>To get the job done, Tyler settled on <a href=\"https://tylergaw.com/articles/css-repeating-svg-masks/\">flexible repeating SVG masks</a>. SVG <strong>provides the shape</strong>, CSS handles the color, and <code>mask-image</code> does the heavy lifting by hiding anything in the underlying <code>div</code> that doesn’t intersect with the shape. A clever approach that can be used as the base for some fun experiments.</p>\nSwipey Image Grids\n<p>When you think of “SVG animation”, what comes to your mind? Illustrative animation? Well, SVG can be useful for much more than pretty graphics. As Cassie Evans points out, a whole new world of <strong>UI styling</strong> opens up once you stop looking at SVG purely as a format for illustrations and icons. One of her favorite use cases for SVG: <a href=\"https://www.cassie.codes/posts/swipey-image-grids/\">responsive animated image grids</a>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1a60334e-e053-484c-9da7-6dde0a1f86d2/swipey-image-grids-opt.png\" /></p>\n<p>Cassie doesn’t build her image grid on CSS Grid but uses SVG’s <strong>internal coordinate system</strong> (which is responsive by design) to design the grid layout. She then adds images to the grid and positions them with <code>preserveAspectRatio</code>. <code>clipPath</code> “swipes” the images in. The final animation relies on GreenSock to ensure that the transforms work consistently across browsers. If you want to dig deeper into the code, be sure to check out Cassie’s <a href=\"https://www.cassie.codes/posts/swipey-image-grids/\">blog post</a> in which she explains each step in detail.</p>\nAnimated SVG Debit Card Illustrations\n<p>What if you could animate a debit card design? Probably not on an actual physical card, but rather for a landing page where you’d like to drive interest towards the card’s <strong>design or features</strong>? Well that’s an unusual challenge to tackle, and Tom Miller decided to take it on.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6be13a6e-5850-49e2-82b0-89d47212c66c/animated-debit-card-opt.png\" /></p>\n<p>In a series of <a href=\"https://codepen.io/collection/MgYZwW\">SVG debit card animations</a>, Tom uses GreenSock to <strong>animate SVG paths and shapes</strong> smoothly, so every card literally comes to life on its own, transforming, rotating, and scaling beautifully, alongside just a few lines of JavaScript. A wonderful inspiration for your next landing page design!</p>\nRaster Image To SVG Converter\n<p>You need to quickly convert a raster image into an SVG? Then <a href=\"https://svgco.de/\">SVGcode</a> is for you. The progressive web app converts image formats like JPG, PNG, GIF, WebP, and AVIF to vector graphics in SVG format.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a6434f1f-f711-472e-89a1-fea1a40edd78/svgcode-opt.png\" /></p>\n<p>To convert an image, drop your raster image into the SVGcode app, and the app will trace the image, color by color, until a vectorized version of the input appears. You can choose between color SVG and monochrome SVG and there also are a number of <strong>customization settings</strong> to improve the output further, by suppressing speckles and adjusting the color, for example. If you install the PWA, you can even use it as a default file handler on your machine. A real timesaver.</p>\nDownload SVGs From Any Site\n<p>A handy little tool to enhance your SVG workflow is <a href=\"https://www.svggobbler.com/\">SVG Gobbler</a>. The browser extension finds the vector content on the page you’re viewing and gives you the option to download, optimize, copy, <strong>view the code</strong>, or export it as an image.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b6930c11-dd66-4b3e-b3d3-8c4a2f88fe1f/svg-gobbler-opt.png\" /></p>\n<p>When you click the browser extension, it shows you all SVGs detected on the site. You can quickly download the ones you like or copy them to your clipboard. When you view the code, you can toggle <strong>optimization options</strong> from SVGO — to beautify the markup or clean up attributes or numeric values, for example. And if you need a PNG version of an SVG, you can export it in any size you want. A fantastic addition to any developer’s toolkit.</p>\nScaling SVGs Made Simple\n<p>Scaling <code>svg</code> elements can be a daunting task, since they act very differently than normal images. Amelia Wattenberger came up with an <a href=\"https://wattenberger.com/guide/scaling-svg\">ingenious comparison</a> to help us make sense of SVGs and their special features: “The <code>svg</code> element is a <strong>telescope</strong> into another world.”</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/53b477a1-4d91-4f1c-af48-5f2f781b716c/scaling-svg-opt.png\" /></p>\n<p>Based on the idea of the telescope, Amelia explains how to use the <code>viewBox</code> property to zoom in or out with your “telescope”, and, thus, change the size of your <code>&lt;svg&gt;</code>. A small tip that works wonders.</p>\nWrapping Up\n<p>We hope that these techniques will tickle your curiosity and inspire you to try some SVG magic yourself. If <em>you</em> came across an interesting SVG technique that left you in awe, please don’t hesitate to share it in the comments below. We’d love to hear about it. Happy creating!</p>\n<h3>More On SVG</h3>\n<ul>\n    <li><a href=\"https://www.smashingmagazine.com/2021/03/svg-generators/\">SVG Generators</a></li>\n    <li><a href=\"https://www.smashingmagazine.com/2019/05/svg-design-tools-practical-guide/\">A Practical Guide To SVG And Design Tools</a></li>\n    <li><a href=\"https://www.smashingmagazine.com/2019/03/svg-circle-decomposition-paths/\">SVG Circle Decomposition To Paths</a></li>\n    <li><a href=\"https://www.smashingmagazine.com/2021/05/accessible-svg-patterns-comparison/\">Accessible SVGs: Perfect Patterns For Screen Reader Users</a></li>\n    <li>Also, <a href=\"/the-smashing-newsletter/\">subscribe to our newsletter</a> to not miss the next ones.</li>\n</ul>",
      "content_text": "SVGs have become more and more popular in the past few years. For good reasons. They are scalable, flexible, and, most importantly, lightweight. And, well, they have even more to offer than you might think. We came across some magical SVG techniques recently that we’d love to share with you. From SVG grids and fractional SVG stars to SVG masks, fancy grainy SVG gradients, and handy SVG tools. We hope you’ll find something useful in here.\nBy the way, a while ago, we also looked at SVG Generators — for everything from shapes and backgrounds to SVG path visualizers, cropping tools, and SVG → JSX generators. If you’re tinkering with SVG, these might come in handy, too.\nGenerative SVG Grids\nGenerative art is a wonderful opportunity for everyone who would love to create art but feels more at home in code. Let’s say you want to create geometric patterns, for example. Generative art will take away the difficult decisions from you: What shapes do I use? Where do I put them? And what colors should I use? If you want to give it a try, Alex Trost wrote a tutorial on creating generative art with SVG grids that is bound to tickle your creativity — and teach you more about SVG.\n\nThe generative art that Alex creates is a grid of blocks with a random number of rows and columns. Each block has a randomly chosen design and colors from a shared color palette. Alex takes you step by step through the process of coding this piece: from setting up the grid and creating isolated functions to draw SVGs to working with color palettes, adding animations, and more. A fun little project — not only if you’re new to generative art and creative coding.\nGenerative Landscape Rolls\nAn awe-inspiring project that bridges the gap between a century-old tradition and state-of-the-art coding is {Shan, Shui}. Created by Lingdong Huan and inspired by traditional Chinese landscape rolls, it creates procedurally generated, infinitely-scrolling Chinese landscapes in SVG format. The mountains and trees in the landscape are modeled from scratch using noise and mathematical functions. Fascinating!\n\nNow, if you’re asking yourself how something as complex might work, you’re not alone. Victor Shepelev wanted to get behind the secret of {Shan, Shui}* and made it his advent project to understand how it works. And, indeed, it took him 24 days to fully dig into the code. He summarized his findings in a series of articles.\nSVG Paths With Masks\nSVGs have a lot of benefits compared to raster images. They are small in size, scalable, animatable, they can be edited with code, and a lot more. You can’t get the textured feel that raster graphics can provide, though. However, we can combine the strengths of vector and raster to create some charming effects. Like Tom Miller did in his Silkscreen Squiggles demo.\n\nSilkscreen Squiggles is an animation where squiggles fill a rectangular canvas. What makes the squiggles special is that they appear to have a paintbrush texture. The secret: a mask with an alpha layer that gives the simple squiggly paths their texture. Alex Trost dissects how it works. Inspiring!\nGrainy Gradients\nNoise is a simple technique to add texture to an image and make otherwise solid colors or smooth gradients more realistic. But despite designer’s affinity for texture, noise is rarely used in web design. Jimmy Chion explores how we can add texture to a gradient with only a small amount of CSS and SVG.\n\nThe trick is to use an SVG filter to create the noise, then apply that noise as a background. Layer it underneath your gradient, boost the brightness and contrast, and that’s already it. Potential use cases could be light and shadows or holographic foil effects, for example. The core of this technique is supported by all modern browsers. A clever visual effect to add depth and texture to a design.\nAdding Texture And Depth\n“Analog” materials like paint and paper naturally add depth to an artwork, but when working digitally, we often sacrifice the organic depth they provide for precision and speed. Let’s bring some texture back into our work! George Francis shares three ways to do so.\n\nThe techniques that George explores are quite simple but effective. Tiny random shapes added to a canvas at random points, solid shape fills with lines, and non-overlapping circles distributed evenly but randomly with an algorithm. Inspiring ideas to tinker with.\nCut-Out Effects With CSS And SVG\nIn a recent front-end project that Ahmad Shadeed was working on, one of the components included a cut-out effect where an area is cut out of a shape. And because there are multiple ways to create such an effect in CSS or SVG, he decided to explore the pros and cons that each of the solutions brings along.\n\nIn his blog post “Thinking About The Cut-Out Effect”, Ahmad takes a look at three different use cases for a cutout effect: an avatar with a cut-out status badge that indicates that a user is currently online, a “seen avatar” that consists of overlapping circle avatars that are indicators that a message has been seen in a group chat, as well as a website header with a cut-out area behind a circular logo. Ahmad presents different solutions for each use case — SVG-only, CSS-only, and a mix of both — and explains the pros and cons of each one of them. A comprehensive overview.\nFractional SVG Stars\nAre you building a rating component and you want it to support fractional values like 4.2 or 3.7 stars but without using images? Good news, you can achieve fractional ratings with only CSS and inline SVG. Samuel Kraft explains how it works.\n\nThe component basically consists of two parts: a list of star icons based on the max rating and an “overlay” div that will be responsible for changing the colors of the stars underneath. This is the magic that makes the fractional part work. The technique is supported in all modern browsers; for older browsers, you can fall back to opacity instead. Clever!\nGenerative Mountain Ridge Dividers\nWhen Alistair Shepherd built his personal website, he wanted to have section dividers that match the mountain theme of the site. But not any mountain dividers, but dividers with unique ridges for every divider.\n\nInstead of creating a variety of different dividers manually, Alistair decided to use a combination of SVG and terrain generation, a technique that is usually used in game development, to generate the dividers automatically. In a blog post, he explains how it works.\nIf you’re up for some more horizontal divider inspiration, also be sure to check out Sara Soueidan’s blog post “Not Your Typical Horizontal Rules” in which she shows how she turned a boring horizontal line into a cute “birds on a wire” divider with the help of some CSS and SVG.\nFlexible Repeating SVG Masks\nSometimes it’s a small idea, a little detail in a project that you tinker with and that you can’t let go off until you come up with a tailor-made solution to make it happen. Nothing that seems like a big deal at first glance, but that requires you to think outside the box. In Tyler Gaw’s case, this little detail was a flexible header with a little squiggle at the bottom instead of a straight line. The twist: to make the component future-proof, Tyler wanted to use a seamless, horizontal repeating pattern that he could color with CSS.\n\nTo get the job done, Tyler settled on flexible repeating SVG masks. SVG provides the shape, CSS handles the color, and mask-image does the heavy lifting by hiding anything in the underlying div that doesn’t intersect with the shape. A clever approach that can be used as the base for some fun experiments.\nSwipey Image Grids\nWhen you think of “SVG animation”, what comes to your mind? Illustrative animation? Well, SVG can be useful for much more than pretty graphics. As Cassie Evans points out, a whole new world of UI styling opens up once you stop looking at SVG purely as a format for illustrations and icons. One of her favorite use cases for SVG: responsive animated image grids.\n\nCassie doesn’t build her image grid on CSS Grid but uses SVG’s internal coordinate system (which is responsive by design) to design the grid layout. She then adds images to the grid and positions them with preserveAspectRatio. clipPath “swipes” the images in. The final animation relies on GreenSock to ensure that the transforms work consistently across browsers. If you want to dig deeper into the code, be sure to check out Cassie’s blog post in which she explains each step in detail.\nAnimated SVG Debit Card Illustrations\nWhat if you could animate a debit card design? Probably not on an actual physical card, but rather for a landing page where you’d like to drive interest towards the card’s design or features? Well that’s an unusual challenge to tackle, and Tom Miller decided to take it on.\n\nIn a series of SVG debit card animations, Tom uses GreenSock to animate SVG paths and shapes smoothly, so every card literally comes to life on its own, transforming, rotating, and scaling beautifully, alongside just a few lines of JavaScript. A wonderful inspiration for your next landing page design!\nRaster Image To SVG Converter\nYou need to quickly convert a raster image into an SVG? Then SVGcode is for you. The progressive web app converts image formats like JPG, PNG, GIF, WebP, and AVIF to vector graphics in SVG format.\n\nTo convert an image, drop your raster image into the SVGcode app, and the app will trace the image, color by color, until a vectorized version of the input appears. You can choose between color SVG and monochrome SVG and there also are a number of customization settings to improve the output further, by suppressing speckles and adjusting the color, for example. If you install the PWA, you can even use it as a default file handler on your machine. A real timesaver.\nDownload SVGs From Any Site\nA handy little tool to enhance your SVG workflow is SVG Gobbler. The browser extension finds the vector content on the page you’re viewing and gives you the option to download, optimize, copy, view the code, or export it as an image.\n\nWhen you click the browser extension, it shows you all SVGs detected on the site. You can quickly download the ones you like or copy them to your clipboard. When you view the code, you can toggle optimization options from SVGO — to beautify the markup or clean up attributes or numeric values, for example. And if you need a PNG version of an SVG, you can export it in any size you want. A fantastic addition to any developer’s toolkit.\nScaling SVGs Made Simple\nScaling svg elements can be a daunting task, since they act very differently than normal images. Amelia Wattenberger came up with an ingenious comparison to help us make sense of SVGs and their special features: “The svg element is a telescope into another world.”\n\nBased on the idea of the telescope, Amelia explains how to use the viewBox property to zoom in or out with your “telescope”, and, thus, change the size of your <svg>. A small tip that works wonders.\nWrapping Up\nWe hope that these techniques will tickle your curiosity and inspire you to try some SVG magic yourself. If you came across an interesting SVG technique that left you in awe, please don’t hesitate to share it in the comments below. We’d love to hear about it. Happy creating!\nMore On SVG\n\n    SVG Generators\n    A Practical Guide To SVG And Design Tools\n    SVG Circle Decomposition To Paths\n    Accessible SVGs: Perfect Patterns For Screen Reader Users\n    Also, subscribe to our newsletter to not miss the next ones.\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6be13a6e-5850-49e2-82b0-89d47212c66c/animated-debit-card-opt.png",
      "date_published": "2022-05-10T10:00:00.000Z",
      "date_modified": "2022-05-10T10:00:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/performance-game-changer-back-forward-cache/",
      "url": "https://smashingmagazine.com/2022/05/performance-game-changer-back-forward-cache/",
      "title": "Performance Game Changer: Browser Back/Forward Cache",
      "summary": "At the end of 2021, the Chrome team shipped some functionality that has the ability to make or break sites meeting the Core Web Vitals. So, let’s learn a little bit more about the Back/Forward Cache (aka bfcache), and what you can do to test if your website is compatible with it.",
      "content_html": "<p>First of all, it would be remiss of me to give the Chrome browser all the credit here, when the other two main browsers (Safari and Firefox) have had this concept for quite some time now, though there are <a href=\"https://docs.google.com/document/d/1JtDCN9A_1UBlDuwkjn1HWxdhQ1H2un9K4kyPLgBqJUc/edit\">some subtle differences in all three implementations</a>.</p>\n<p>So, Chrome was playing catch-up here. However, as the <a href=\"https://gs.statcounter.com/browser-market-share\">world’s most popular browser</a> and the only browser feeding back the Core Web Vitals information for any search ranking boasting, Chrome getting this (finally, some might say) is important. Plus, they’ve created some more transparency about this, both in documentation and tooling. Not to mention the many other Chromium-based browsers (e.g. Edge, Opera, Brave) will now also have gotten this functionality too.</p>\n<p>With that caveat out of the way, let’s get to the guts of the article: What is the Back/Forward Cache and why does it matter so much? As its name implies, this is a special cache used to remember the web page as you browse away from that web page, so <strong>if you browse back to it later, it can load a lot quicker</strong>.</p>\n<p>Think about the number of times you visit a home page, click on an article, then go <em>back</em> to the home page to view another article? Or you click back, then realize you forgot to make a note of something on that article, so click <em>forward</em> again. Similarly from cross-site navigation — think Google search results or the like and then clicking back. All those navigations can benefit from the Back/Forward Cache to instantly restore the page.</p>\nDidn’t The HTTP Cache Do All That Anyway?\n<p>Browsers have <a href=\"https://blog.yoav.ws/tale-of-four-caches/\">lots of caches</a>, the most well-known of which is the HTTP Cache that stores copies of downloaded resources on a local drive for later reuse. Ensuring your website caches most of its assets for future uses has long been touted as essential for web performance. Sadly, however, <a href=\"https://almanac.httparchive.org/en/2021/caching#fig-3\">it is not yet universal</a>, but there are plenty of other articles written about that.</p>\n<p>Using the HTTP Cache can avoid the need to download the same resources over and over again. Going back to the example of visiting a home page and then going to an article page. There are likely lots of shared resources (site-wide CSS and JavaScript, logos, other images, etc.), so reusing them from that home page visit is a good saving. Similarly, before the Back/Forward Cache came along, being able to reuse these assets if going back to the home page was a good gain — even if it wasn’t instant.</p>\n<p>Downloading resources is a slow part of browsing the web no doubt, but there is a lot more to do as well as that: parse the HTML, see and fetch what resources you need (even if they can be gotten relatively quickly from the HTTP Cache), parse the CSS, layout the page, decode the images, run the oodles of JavaScript we so love to load our pages with… etc.</p>\n<p><a href=\"https://www.webpagetest.org/\">WebPageTest</a> is one of the few web performance testing tools that actually tests a reload of the page using a primed HTTP Cache — most of the other tools just flag if your HTTP resources are not explicitly set to be cached. So, running your site through WebPageTest will show the initial load takes some time, but the <em>repeat view</em> should be faster. But it still takes a little time, even if all the resources are being served from the cache. As an aside, that repeat view will likely not be fully representative anyway. Loading with an empty cache or a completely primed cache are the two extremes, but the reality is that you might have a semi-primed cache with some but not all of the resources cached already. Especially if you navigate from another page on the site.</p>\n<p>Here’s an experiment for you. In another tab, load <a href=\"https://www.smashingmagazine.com\">https://www.smashingmagazine.com</a>. Loads pretty quickly, doesn’t it? The Smashing team has done a lot to make a fast website, so even a <em>fresh load</em> (though this experiment may not be a completely fresh load if you came to this article from the home page). Now close the tab. Now open another new tab and load <a href=\"https://www.smashingmagazine.com\">https://www.smashingmagazine.com</a> again. That’s the <em>reload</em> with a fully primed HTTP cache from that initial load. Even faster yeah? But not quite instant. Now, in that tab, click on an article link from <a href=\"https://www.smashingmagazine.com\">https://www.smashingmagazine.com</a> and, once it’s loaded, click back — much faster yeah? Instant, some might say.</p>\n<p>You can also disable the Back/Forward Cache in Chrome at <a>chrome://flags/#back-forward-cache</a> if you want to experiment more, but the above steps should hopefully be a sufficient enough test to give a rough feel for the potential speed gains.</p>\n<p>It might not seem like that much of a difference, but repeat the experiment over a bad mobile connection, or using a heavier and slower website, and you’ll see a big difference. And if you browse a few articles on this site, returning to the home page each time, then the gains multiply.</p>\nWhy is the Back/Forward Cache so much faster?\n<p>The Back/Forward Cache keeps a snapshot of the loaded page including the fully rendered page and the JavaScript heap. You really are returning to the state you left it in rather than just having all the resources you need to render the page.</p>\n<p>Additionally, the Back/Forward Cache is an <strong>in-memory cache</strong>. The HTTP Cache is a disk cache. A disk cache is faster than having to fetch those resources from the network (though <a href=\"https://simonhearne.com/2020/network-faster-than-cache/\">not always, oddly enough</a>!), but there’s an extra boost from not even having to read them from disk. If you ever wondered why browsers need so much memory just to display a simple page — it’s partly for optimizations like this. And mostly, that’s a good thing.</p>\n<p>Finally, not all resources are allowed to be cached in the HTTP Cache. Many sites don’t cache the HTML document itself, for example, and only the resources. This allows the page to be updated without waiting for a cache expiry (subresources normally handle this with unique <a href=\"https://css-tricks.com/strategies-for-cache-busting-css/\">cache-busting URLs</a>, but that can’t be used on the main document, as you don’t want to change the URL each time), but at the cost of the page having to be fetched each time. Unless you’re a real-time news website or similar, I always recommend caching the main document resource for at least a few minutes (or even better hours) to speed up repeat visits. Regardless, the Back/Forward Cache is not limited to this as <strong>it is restoring a page, rather than reloading a page</strong> — so again another reason why it can be faster. However, this isn’t quite a clear cut, and <a href=\"https://groups.google.com/a/chromium.org/g/bfcache-dev/c/zat_po-KKxI\">there is still work going on in this space in Chrome</a>, though <a href=\"https://webkit.org/blog/9609/release-notes-for-safari-technology-preview-94/#:~:text=from%20working%20correctly-,back%2Dforward%20Cache,-Allowed%20pages%20served\">Safari has had this for a bit now</a>.</p>\nOK, But Is It Really That Much Faster For Most Web Browsing Or Are We Just Nitpicking Now?\n<p>The <a href=\"https://web.dev/vitals/\">Core Web Vitals</a> initiative gives us a way of seeing the impact on real user web browsing, and the <a href=\"http://cwvtech.report\">Core Web Vitals Technology Report</a> allows us to see these figures by site based on <a href=\"https://httparchive.org/\">HTTP Archive</a> monthly crawls. Some in the e-commerce web performance community <a href=\"https://twitter.com/rnebhwani/status/1491388690601758720?s=20&amp;t=BkT2G-jFw-q8-o-91HBjOA\">noticed the unexplained improvement in January’s figures</a>:</p>\n<blockquote><p>CRUX data for Jan-22 is out. Let's see how various eCommerce platforms did this month. <a href=\"https://twitter.com/hashtag/webperf?src=hash&amp;ref_src=twsrc%5Etfw\">#webperf</a> <a href=\"https://twitter.com/hashtag/perfmatters?src=hash&amp;ref_src=twsrc%5Etfw\">#perfmatters</a>. <br /><br />Change in % of Origins worldwide having good CWVs (compared to last month)<a href=\"https://twitter.com/LightspeedHQ?ref_src=twsrc%5Etfw\">@LightspeedHQ</a> - 18% up<a href=\"https://twitter.com/ShopifyEng?ref_src=twsrc%5Etfw\">@ShopifyEng</a> - 9% up<a href=\"https://twitter.com/opencart?ref_src=twsrc%5Etfw\">@opencart</a> - 9% up<a href=\"https://twitter.com/squarespace?ref_src=twsrc%5Etfw\">@squarespace</a> - 5% up <a href=\"https://t.co/wbnDdGeRWl\">pic.twitter.com/wbnDdGeRWl</a></p>— Rockey Nebhwani (@rnebhwani) <a href=\"https://twitter.com/rnebhwani/status/1491388690601758720?ref_src=twsrc%5Etfw\">February 9, 2022</a></blockquote>\n\n<p>Annie from the Chrome team <a href=\"https://twitter.com/anniesullie/status/1491399685961293828?s=20&amp;t=BkT2G-jFw-q8-o-91HBjOA\">confirmed this was due to the Back/Forward Cache rollout</a> and was a bit surprised just how noticeable it was:</p>\n<blockquote><p>This is a bit surprising, but the improvement is user-visible; it is caused by the bfcache rollout (<a href=\"https://t.co/9raiXQaYwU\">https://t.co/9raiXQaYwU</a>).<br /><br />What's happening is that when a web page is restored from cache instead of fully loading, it skips all the layout shifts from load. Big CLS improvement!</p>— Annie Sullivan (@anniesullie) <a href=\"https://twitter.com/anniesullie/status/1491399685961293828?ref_src=twsrc%5Etfw\">February 9, 2022</a></blockquote>\n\n<p>Although it is restoring the page from a previous state, <a href=\"https://web.dev/bfcache/#impact-on-core-web-vitals\">as far as Core Web Vitals, as measured by Chrome, is concerned, this is still page navigation</a>. So, the user experience of that load is still measured and counts as an additional page view — just with a much faster and more stable load!</p>\n<p>Be aware, however, that other analytics may not see this as a page load and need to take extra efforts to also measure these. So for some of your tooling you may even have noticed a drop in visitor count and performance as these fast repeat views (which were measured), became even faster restores (but which potentially aren't now measured), so your overall average page loads measured appear to have got slower. Again, I’ll refer you to Philip Walton’s article including a section on <a href=\"https://web.dev/bfcache/#how-bfcache-affects-analytics-and-performance-measurement\">how bfcache affects analytics and performance measurement</a>, for more information.</p>\n<p>I’ve another more dramatic example, closer to home to share, but first a little more background.</p>\nDo I Need To Do Anything, Or Does My Site Just Get A Free Boost?\n<p>Well, this isn’t just some puff piece for the Chrome team — especially since they were late to the party! There is an action for sites to take to ensure they are benefiting from this speed gain because there are a number of reasons you may not be.</p>\n<p>Implementing a Back/Forward Cache sounds simple, but there are a million things to consider that could go wrong. I’ve kept it reasonably light on technical details here (check out Philip Walton’s <a href=\"https://web.dev/bfcache/\">Back/forward cache article</a> for more technical information), but there are many things that could go wrong with this.</p>\n<p>Browser makers have to make sure it’s safe to just restore pages like this, and the problem is many sites are not written with the expectation that a page can be restored like this and think (not entirely unreasonably!) that when the page is navigated away from that the user isn’t coming back without a full page reload.</p>\n<p>For example, some pages may register an <code>unload event listener</code> in JavaScript to perform some clean-up tasks under the assumption the user is finished with this page. That doesn’t work well if the page is then restored from the Back/Forward Cache. Now, to be honest, the <code>unload event listener</code> has been seen as a bad practice for a while now as it is not reliably fired (e.g. if the browser crashes, or the browser is backgrounded on a mobile and then killed), but the Back/Forward cache gives a more pressing reason why it should be avoided because browsers will not use the Back/Forward Cache if your page or any of its resources uses an <code>unload event listener</code>. </p>\n<p>There are a number of other reasons why your page might not be eligible for the Back/Forward cache. Counterintuitively, for a web performance feature, some of these reasons are due to other web performance features:</p>\n<ul>\n<li>Unload listeners were (and in some cases still are) often used log data when the page was finished with. This is particularly useful for Real User Monitoring web performance tools — used by sites that obviously have an interest in ensuring the best performance! There are other better events now that should now be used instead that are compatible, including <code>pagehide</code> and <code>freeze</code>.</li>\n<li>Using a dedicated worker to offload work from the main thread is another performance technique that at the moment makes the website ineligible for the Back/Forward cache. This is used by some popular platforms like Wix, but <a href=\"https://twitter.com/yoavweiss/status/1501823138786594820?s=20&amp;t=DTa7FR6DctSVgzU7zA6GRw\">a fix for sites using Web Workers is coming soon!</a></li>\n<li>Using an App Install Banner also makes a site ineligible, which affected smashingmagazine.com (we’ll get back to that momentarily), and again <a href=\"https://twitter.com/rakinazata/status/1501877483469115393?s=20&amp;t=DTa7FR6DctSVgzU7zA6GRw\">supporting App Banners is being actively worked on</a>.</li>\n</ul>\n<p>Those are some of the more common ones, but there are lots of reasons why a site may not be eligible. You can see the complete <a href=\"https://chromedevtools.github.io/devtools-protocol/tot/Page/#type-BackForwardCacheNotRestoredExplanationTree\">list of reasons for the Chrome source code</a>, with a bit <a href=\"https://docs.google.com/spreadsheets/d/1li0po_ETJAIybpaSX5rW_lUN62upQhY0tH4pR5UPt60/edit#gid=0\">more explanation in this sheet</a>.</p>\nBack/Forward Cache Testing Tool\n<p>Helpfully, rather than having to examine each one, the Chrome team added a test to Chrome Dev Tools under the Application tab:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0b2fa9b2-8438-484a-83b5-7bb73aecb83c/6-making-use-back-forward-cache.png\" /></p>\n<p>Clicking on that inviting little blue button will run the test and should hopefully give you a successful message:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2c1cfb4e-78bf-4ace-9d85-b9cdaa66d1c9/2-making-use-back-forward-cache.png\" /></p>\n<p>If you are getting an ineligibility message, with a reason then it’s well worth investigating if that reason can be resolved.</p>\n<p>Third-party scripts might be making your page ineligible, even if you don’t use those features directly in your code. As I mentioned above, <code>unload event listeners</code> are particularly common to some third-parties. As well as the above test showing this, there’s a Lighthouse test for this. Running a query on the HTTP Archive data <a href=\"https://docs.google.com/spreadsheets/d/17PiNHgYxs8TIQ9o3N5fHPgT-xWGxwUkS7qoA6qvZ5FY/edit#gid=100800185\">yielded a list of popular third-party scripts used by many sites</a> that use <code>unload event listeners</code>.</p>\n\n<p>I’ve heard the Chrome team has been reaching out to these companies to encourage them to solve this, and many of the scripts logged in the above spreadsheet are older versions, as many of the companies have indeed solved the issues. Facebook pixel, for example, is used by a lot of sites and has apparently recently resolved this issue, so I am expecting that to drop off soon if that is indeed the case.</p>\n<p>Site owners may also have power here: if you are using a third-party service that uses an <code>unload event listener</code>, then reach out to them to see if they have plans to remove this, to stop making your website slow — especially if it’s a service you are paying for! I know some discussions are underway with some of the other names on that list for precisely this reason, and I’ve helped provide some more information to one of the companies on that list to help prioritize this work, so am hopeful they are working on a fix.</p>\n<p>As I mentioned earlier, each browser has implemented the Back/Forward Cache separately, and the above test is only for Chromium-based browsers, so even if you pass that, you may still not be benefiting completely in the other browsers (or maybe you are, and it’s just Chrome that’s not using it!). Unfortunately, there is no easy way to debug this in Firefox and Safari, so my advice would be to concentrate on Chrome first using their tool and then hope that’s sufficient for the other browsers as they often are more permissive than Chrome. Manual testing may also show this, especially if you can slow down your network, but that is a little subjective, so can be prone to false positives and false negatives.</p>\nImpact On SmashingMagazine.com\n<p>As readers undoubtedly have noticed, the smashingmagazine.com website is already fast, and they’ve published a number of articles in the past on how they achieve this level of performance. In the last one, which I wrote, we documented how we spent a huge amount of time <a href=\"https://www.smashingmagazine.com/2021/12/core-web-vitals-case-study-smashing-magazine/\">investigating a performance issue that was holding us back from meeting the Core Web Vitals</a>.</p>\n<p>Thanks to that investigation we had crossed into the green zone and stayed there, so we were reasonably happy, as we were consistently under the 2.5-second limit for LCP in CrUX for at least 75% of our visitors. Not by much admittedly, as we were getting 2.4 seconds, but at least we were not going over it. But never ones to rest on our laurels, we’re always on the lookout for further improvements. They <a href=\"https://blog.speedvitals.com/delay-javascript/\">delayed some of their JavaScript</a> in January leading to some further improvements to an almost 2.2-second CrUX number.</p>\n<p>This website was initially failing that test due to the fact it had an App Install Banner. SmashingMazgazine.com is a PWA that prompts you to install it on the home screen for browsers that support that (Chrome on Android devices primarily). When I highlighted to the team in early March that this was holding them back from benefiting from the Back/Forward Cache that had recently been launched, they decided to remove some key parts of manifest.json to prevent the App Install Banner from showing, to see if this feature was costing them performance and the results were dramatic:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/44761708-936c-4269-95f6-43389796ffbd/5-making-use-back-forward-cache.png\" /></p>\n<p>We can see the impact of the December and January improvements were noticeable but started to tail off by the start of March, and then when we implemented the Back/Forward Cache fix the LCP numbers plummeted (in a good way!) all the way down to 1.7 seconds — the best number Smashing Magazine has ever seen since the Core Web Vitals initiative was launched.</p>\n<p>In fact, if we’d known this was coming, and the impact it would have, we may not have spent so much time on the other performance improvements they did last year! Though, personally, I am glad they did since it was an interesting case study.</p>\n<p>The above, was a custom chart created by measuring the CrUX API daily, but looking at the monthly <a href=\"https://github.com/rviscomi/crux-dash-launcher\">CrUX dashboard</a> (you can load the same for any URL) showed a similarly drastic improvement for LCP in the last two months, and the April numbers will shop a further improvement:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/db67966b-cc84-4a22-8870-5de7a79ea5a2/1-making-use-back-forward-cache.png\" /></p>\n<p>Across the web, CLS had a bigger improvement with the rollout of the Back/Forward Cache in Chrome, but Smashing saw the improvement in LCP as they had no CLS issues. When investigating the impact on your site look at all available metrics for any improvement.</p>\n<p>Of course, if your site was already eligible for Back/Forward Cache then you will have already got that performance boost in your Core Web Vitals data when this was rolled out in Chrome to your users — likely in December and January. But for those that are not, there is more web performance here available to you — so look into why you are not eligible.</p>\n<p> I honestly believe that sites that are ineligible for the Back/Forward Cache are giving up free web performance for their users, and making passing Core Web Vitals needlessly tough on themselves.</p>\n<p>Was there a downside to disabling the App Install Banner that was preventing this? That’s more difficult to judge. Certainly, we’ve had no complaints. Perhaps it’s even annoying some users less (I’m not an Android user, so can’t comment on whether it’s useful or annoying to have pop-ups on a site you visit encouraging you to install it). Hopefully, when Chrome fixes this blocker, Smashing can decide if they want both, but for now the clear benefits of the Back/Forward Cache mean they are prepared to give up this feature for those gains.</p>\n<p>Other sites, that are more app-like, may have a different opinion and forgo the Back/Forward Cache benefits in favor of those features. This is a judgment call each site needs to make for any Back/Forward Cache blocking features. You can also measure Back/Forward Cache navigations in your site Analytics using a Custom Dimension to see if there are a significant number of navigation and so an expected significant gain. Or perhaps A/B test this? There are also <a href=\"https://w3c.github.io/web-performance/meetings/2022/2022-03-31/index.html\">a couple of interesting proposals under discussion</a> to help measure some of this info to help websites make some of these decisions.</p>\nTest Your Website Today!\n<p>I strongly encourage sites to run the Back/Forward Cache test, understand any blockers leading to an unsuccessful test and seek to remove those blockers. It’s a simple test that literally only takes a couple of seconds, though the fix (if you are not eligible) might take longer! Also, remember to test different pages on your website in case they have different code and thus eligibility.</p>\n<p>If it’s due to your code, then look at whether it’s giving the benefits over this. If it’s third-party code, then raise it to them. And if it’s for some other reason, then <a href=\"https://bugs.chromium.org/\">let the Chrome team know it’s important to you</a> for them to solve it: Brower makers want user feedback to help prioritize their work.</p>\n<p>If you don’t do this, then you’re leaving noticeable web performance improvements on the table and making your site slower for users, and failing to capitalize on any SEO benefit at the same time.</p>\n<p><em>Many thanks to Philip Walton, Yoav Weiss, Dan Shappir, Annie Sullivan, Adrian Bece, and Giacomo Zecchini for reviewing the article for technical accuracy.</em></p>",
      "content_text": "First of all, it would be remiss of me to give the Chrome browser all the credit here, when the other two main browsers (Safari and Firefox) have had this concept for quite some time now, though there are some subtle differences in all three implementations.\nSo, Chrome was playing catch-up here. However, as the world’s most popular browser and the only browser feeding back the Core Web Vitals information for any search ranking boasting, Chrome getting this (finally, some might say) is important. Plus, they’ve created some more transparency about this, both in documentation and tooling. Not to mention the many other Chromium-based browsers (e.g. Edge, Opera, Brave) will now also have gotten this functionality too.\nWith that caveat out of the way, let’s get to the guts of the article: What is the Back/Forward Cache and why does it matter so much? As its name implies, this is a special cache used to remember the web page as you browse away from that web page, so if you browse back to it later, it can load a lot quicker.\nThink about the number of times you visit a home page, click on an article, then go back to the home page to view another article? Or you click back, then realize you forgot to make a note of something on that article, so click forward again. Similarly from cross-site navigation — think Google search results or the like and then clicking back. All those navigations can benefit from the Back/Forward Cache to instantly restore the page.\nDidn’t The HTTP Cache Do All That Anyway?\nBrowsers have lots of caches, the most well-known of which is the HTTP Cache that stores copies of downloaded resources on a local drive for later reuse. Ensuring your website caches most of its assets for future uses has long been touted as essential for web performance. Sadly, however, it is not yet universal, but there are plenty of other articles written about that.\nUsing the HTTP Cache can avoid the need to download the same resources over and over again. Going back to the example of visiting a home page and then going to an article page. There are likely lots of shared resources (site-wide CSS and JavaScript, logos, other images, etc.), so reusing them from that home page visit is a good saving. Similarly, before the Back/Forward Cache came along, being able to reuse these assets if going back to the home page was a good gain — even if it wasn’t instant.\nDownloading resources is a slow part of browsing the web no doubt, but there is a lot more to do as well as that: parse the HTML, see and fetch what resources you need (even if they can be gotten relatively quickly from the HTTP Cache), parse the CSS, layout the page, decode the images, run the oodles of JavaScript we so love to load our pages with… etc.\nWebPageTest is one of the few web performance testing tools that actually tests a reload of the page using a primed HTTP Cache — most of the other tools just flag if your HTTP resources are not explicitly set to be cached. So, running your site through WebPageTest will show the initial load takes some time, but the repeat view should be faster. But it still takes a little time, even if all the resources are being served from the cache. As an aside, that repeat view will likely not be fully representative anyway. Loading with an empty cache or a completely primed cache are the two extremes, but the reality is that you might have a semi-primed cache with some but not all of the resources cached already. Especially if you navigate from another page on the site.\nHere’s an experiment for you. In another tab, load https://www.smashingmagazine.com. Loads pretty quickly, doesn’t it? The Smashing team has done a lot to make a fast website, so even a fresh load (though this experiment may not be a completely fresh load if you came to this article from the home page). Now close the tab. Now open another new tab and load https://www.smashingmagazine.com again. That’s the reload with a fully primed HTTP cache from that initial load. Even faster yeah? But not quite instant. Now, in that tab, click on an article link from https://www.smashingmagazine.com and, once it’s loaded, click back — much faster yeah? Instant, some might say.\nYou can also disable the Back/Forward Cache in Chrome at chrome://flags/#back-forward-cache if you want to experiment more, but the above steps should hopefully be a sufficient enough test to give a rough feel for the potential speed gains.\nIt might not seem like that much of a difference, but repeat the experiment over a bad mobile connection, or using a heavier and slower website, and you’ll see a big difference. And if you browse a few articles on this site, returning to the home page each time, then the gains multiply.\nWhy is the Back/Forward Cache so much faster?\nThe Back/Forward Cache keeps a snapshot of the loaded page including the fully rendered page and the JavaScript heap. You really are returning to the state you left it in rather than just having all the resources you need to render the page.\nAdditionally, the Back/Forward Cache is an in-memory cache. The HTTP Cache is a disk cache. A disk cache is faster than having to fetch those resources from the network (though not always, oddly enough!), but there’s an extra boost from not even having to read them from disk. If you ever wondered why browsers need so much memory just to display a simple page — it’s partly for optimizations like this. And mostly, that’s a good thing.\nFinally, not all resources are allowed to be cached in the HTTP Cache. Many sites don’t cache the HTML document itself, for example, and only the resources. This allows the page to be updated without waiting for a cache expiry (subresources normally handle this with unique cache-busting URLs, but that can’t be used on the main document, as you don’t want to change the URL each time), but at the cost of the page having to be fetched each time. Unless you’re a real-time news website or similar, I always recommend caching the main document resource for at least a few minutes (or even better hours) to speed up repeat visits. Regardless, the Back/Forward Cache is not limited to this as it is restoring a page, rather than reloading a page — so again another reason why it can be faster. However, this isn’t quite a clear cut, and there is still work going on in this space in Chrome, though Safari has had this for a bit now.\nOK, But Is It Really That Much Faster For Most Web Browsing Or Are We Just Nitpicking Now?\nThe Core Web Vitals initiative gives us a way of seeing the impact on real user web browsing, and the Core Web Vitals Technology Report allows us to see these figures by site based on HTTP Archive monthly crawls. Some in the e-commerce web performance community noticed the unexplained improvement in January’s figures:\nCRUX data for Jan-22 is out. Let's see how various eCommerce platforms did this month. #webperf #perfmatters. Change in % of Origins worldwide having good CWVs (compared to last month)@LightspeedHQ - 18% up@ShopifyEng - 9% up@opencart - 9% up@squarespace - 5% up pic.twitter.com/wbnDdGeRWl— Rockey Nebhwani (@rnebhwani) February 9, 2022\n\nAnnie from the Chrome team confirmed this was due to the Back/Forward Cache rollout and was a bit surprised just how noticeable it was:\nThis is a bit surprising, but the improvement is user-visible; it is caused by the bfcache rollout (https://t.co/9raiXQaYwU).What's happening is that when a web page is restored from cache instead of fully loading, it skips all the layout shifts from load. Big CLS improvement!— Annie Sullivan (@anniesullie) February 9, 2022\n\nAlthough it is restoring the page from a previous state, as far as Core Web Vitals, as measured by Chrome, is concerned, this is still page navigation. So, the user experience of that load is still measured and counts as an additional page view — just with a much faster and more stable load!\nBe aware, however, that other analytics may not see this as a page load and need to take extra efforts to also measure these. So for some of your tooling you may even have noticed a drop in visitor count and performance as these fast repeat views (which were measured), became even faster restores (but which potentially aren't now measured), so your overall average page loads measured appear to have got slower. Again, I’ll refer you to Philip Walton’s article including a section on how bfcache affects analytics and performance measurement, for more information.\nI’ve another more dramatic example, closer to home to share, but first a little more background.\nDo I Need To Do Anything, Or Does My Site Just Get A Free Boost?\nWell, this isn’t just some puff piece for the Chrome team — especially since they were late to the party! There is an action for sites to take to ensure they are benefiting from this speed gain because there are a number of reasons you may not be.\nImplementing a Back/Forward Cache sounds simple, but there are a million things to consider that could go wrong. I’ve kept it reasonably light on technical details here (check out Philip Walton’s Back/forward cache article for more technical information), but there are many things that could go wrong with this.\nBrowser makers have to make sure it’s safe to just restore pages like this, and the problem is many sites are not written with the expectation that a page can be restored like this and think (not entirely unreasonably!) that when the page is navigated away from that the user isn’t coming back without a full page reload.\nFor example, some pages may register an unload event listener in JavaScript to perform some clean-up tasks under the assumption the user is finished with this page. That doesn’t work well if the page is then restored from the Back/Forward Cache. Now, to be honest, the unload event listener has been seen as a bad practice for a while now as it is not reliably fired (e.g. if the browser crashes, or the browser is backgrounded on a mobile and then killed), but the Back/Forward cache gives a more pressing reason why it should be avoided because browsers will not use the Back/Forward Cache if your page or any of its resources uses an unload event listener. \nThere are a number of other reasons why your page might not be eligible for the Back/Forward cache. Counterintuitively, for a web performance feature, some of these reasons are due to other web performance features:\n\nUnload listeners were (and in some cases still are) often used log data when the page was finished with. This is particularly useful for Real User Monitoring web performance tools — used by sites that obviously have an interest in ensuring the best performance! There are other better events now that should now be used instead that are compatible, including pagehide and freeze.\nUsing a dedicated worker to offload work from the main thread is another performance technique that at the moment makes the website ineligible for the Back/Forward cache. This is used by some popular platforms like Wix, but a fix for sites using Web Workers is coming soon!\nUsing an App Install Banner also makes a site ineligible, which affected smashingmagazine.com (we’ll get back to that momentarily), and again supporting App Banners is being actively worked on.\n\nThose are some of the more common ones, but there are lots of reasons why a site may not be eligible. You can see the complete list of reasons for the Chrome source code, with a bit more explanation in this sheet.\nBack/Forward Cache Testing Tool\nHelpfully, rather than having to examine each one, the Chrome team added a test to Chrome Dev Tools under the Application tab:\n\nClicking on that inviting little blue button will run the test and should hopefully give you a successful message:\n\nIf you are getting an ineligibility message, with a reason then it’s well worth investigating if that reason can be resolved.\nThird-party scripts might be making your page ineligible, even if you don’t use those features directly in your code. As I mentioned above, unload event listeners are particularly common to some third-parties. As well as the above test showing this, there’s a Lighthouse test for this. Running a query on the HTTP Archive data yielded a list of popular third-party scripts used by many sites that use unload event listeners.\n\nI’ve heard the Chrome team has been reaching out to these companies to encourage them to solve this, and many of the scripts logged in the above spreadsheet are older versions, as many of the companies have indeed solved the issues. Facebook pixel, for example, is used by a lot of sites and has apparently recently resolved this issue, so I am expecting that to drop off soon if that is indeed the case.\nSite owners may also have power here: if you are using a third-party service that uses an unload event listener, then reach out to them to see if they have plans to remove this, to stop making your website slow — especially if it’s a service you are paying for! I know some discussions are underway with some of the other names on that list for precisely this reason, and I’ve helped provide some more information to one of the companies on that list to help prioritize this work, so am hopeful they are working on a fix.\nAs I mentioned earlier, each browser has implemented the Back/Forward Cache separately, and the above test is only for Chromium-based browsers, so even if you pass that, you may still not be benefiting completely in the other browsers (or maybe you are, and it’s just Chrome that’s not using it!). Unfortunately, there is no easy way to debug this in Firefox and Safari, so my advice would be to concentrate on Chrome first using their tool and then hope that’s sufficient for the other browsers as they often are more permissive than Chrome. Manual testing may also show this, especially if you can slow down your network, but that is a little subjective, so can be prone to false positives and false negatives.\nImpact On SmashingMagazine.com\nAs readers undoubtedly have noticed, the smashingmagazine.com website is already fast, and they’ve published a number of articles in the past on how they achieve this level of performance. In the last one, which I wrote, we documented how we spent a huge amount of time investigating a performance issue that was holding us back from meeting the Core Web Vitals.\nThanks to that investigation we had crossed into the green zone and stayed there, so we were reasonably happy, as we were consistently under the 2.5-second limit for LCP in CrUX for at least 75% of our visitors. Not by much admittedly, as we were getting 2.4 seconds, but at least we were not going over it. But never ones to rest on our laurels, we’re always on the lookout for further improvements. They delayed some of their JavaScript in January leading to some further improvements to an almost 2.2-second CrUX number.\nThis website was initially failing that test due to the fact it had an App Install Banner. SmashingMazgazine.com is a PWA that prompts you to install it on the home screen for browsers that support that (Chrome on Android devices primarily). When I highlighted to the team in early March that this was holding them back from benefiting from the Back/Forward Cache that had recently been launched, they decided to remove some key parts of manifest.json to prevent the App Install Banner from showing, to see if this feature was costing them performance and the results were dramatic:\n\nWe can see the impact of the December and January improvements were noticeable but started to tail off by the start of March, and then when we implemented the Back/Forward Cache fix the LCP numbers plummeted (in a good way!) all the way down to 1.7 seconds — the best number Smashing Magazine has ever seen since the Core Web Vitals initiative was launched.\nIn fact, if we’d known this was coming, and the impact it would have, we may not have spent so much time on the other performance improvements they did last year! Though, personally, I am glad they did since it was an interesting case study.\nThe above, was a custom chart created by measuring the CrUX API daily, but looking at the monthly CrUX dashboard (you can load the same for any URL) showed a similarly drastic improvement for LCP in the last two months, and the April numbers will shop a further improvement:\n\nAcross the web, CLS had a bigger improvement with the rollout of the Back/Forward Cache in Chrome, but Smashing saw the improvement in LCP as they had no CLS issues. When investigating the impact on your site look at all available metrics for any improvement.\nOf course, if your site was already eligible for Back/Forward Cache then you will have already got that performance boost in your Core Web Vitals data when this was rolled out in Chrome to your users — likely in December and January. But for those that are not, there is more web performance here available to you — so look into why you are not eligible.\n I honestly believe that sites that are ineligible for the Back/Forward Cache are giving up free web performance for their users, and making passing Core Web Vitals needlessly tough on themselves.\nWas there a downside to disabling the App Install Banner that was preventing this? That’s more difficult to judge. Certainly, we’ve had no complaints. Perhaps it’s even annoying some users less (I’m not an Android user, so can’t comment on whether it’s useful or annoying to have pop-ups on a site you visit encouraging you to install it). Hopefully, when Chrome fixes this blocker, Smashing can decide if they want both, but for now the clear benefits of the Back/Forward Cache mean they are prepared to give up this feature for those gains.\nOther sites, that are more app-like, may have a different opinion and forgo the Back/Forward Cache benefits in favor of those features. This is a judgment call each site needs to make for any Back/Forward Cache blocking features. You can also measure Back/Forward Cache navigations in your site Analytics using a Custom Dimension to see if there are a significant number of navigation and so an expected significant gain. Or perhaps A/B test this? There are also a couple of interesting proposals under discussion to help measure some of this info to help websites make some of these decisions.\nTest Your Website Today!\nI strongly encourage sites to run the Back/Forward Cache test, understand any blockers leading to an unsuccessful test and seek to remove those blockers. It’s a simple test that literally only takes a couple of seconds, though the fix (if you are not eligible) might take longer! Also, remember to test different pages on your website in case they have different code and thus eligibility.\nIf it’s due to your code, then look at whether it’s giving the benefits over this. If it’s third-party code, then raise it to them. And if it’s for some other reason, then let the Chrome team know it’s important to you for them to solve it: Brower makers want user feedback to help prioritize their work.\nIf you don’t do this, then you’re leaving noticeable web performance improvements on the table and making your site slower for users, and failing to capitalize on any SEO benefit at the same time.\nMany thanks to Philip Walton, Yoav Weiss, Dan Shappir, Annie Sullivan, Adrian Bece, and Giacomo Zecchini for reviewing the article for technical accuracy.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/98883c6e-253d-4285-aa86-09da18d3b935/performance-game-changer-back-forward-cache.jpg",
      "date_published": "2022-05-09T10:30:00.000Z",
      "date_modified": "2022-05-09T10:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/give-effective-feedback-remotely/",
      "url": "https://smashingmagazine.com/2022/05/give-effective-feedback-remotely/",
      "title": "How To Give Effective Feedback Remotely",
      "summary": "Let’s explore how to give and receive better feedback when working remotely — feedback that is actionable, specific, kind, and that won’t set you on edge. We’ll start by explaining when feedback sessions don’t work and how to prevent it.",
      "content_html": "<p>We need more good feedback in our world, and I don’t just mean the type of feedback that celebrates your good work. I’m talking about feedback that is actionable, specific, and kind; feedback that does not set us on edge or make us fall into an anxious spiral; feedback that helps us collaborate more effectively. The kind of feedback that is actually <em>really hard</em> to do when working remotely.</p>\n<p>In this article, I’ll discuss a few ways to get around that difficulty. We’ll start by learning what causes feedback sessions to get off track, how to prevent this from happening, and what to do when this happens.</p>\n<p>This article is targeted toward designers and developers who are currently working remotely or are planning to switch to remote work.</p>\nImagine...\n<p>You’re part of a remote design team in a small company that is currently having you focus on revising their to-do app’s design based on some customer feedback and some ideas that the company wants to validate. During your presentation to the company, someone interrupts you. With their camera off, they say: “Wait, why are we wasting time doing this? The existing page is fine. The older colors and layout were better and this new <em>thing</em> feels clunky. Just put the sign-up call to action at the top and be done with it.”</p>\n<p>You’ve been doing this for a few years, so this isn’t new to, you but you still feel like you got the wind knocked out of you. You get flushed and a little angry, because this person hasn’t always been so unfriendly to you before, and you don’t want to look bad in front of the leadership. You start to stumble over your words, which you think makes you look bad. Now you’re in a downward spiral. </p>\nWhy Does Negative Feedback Elicit Such Strong Responses?\n<p>Mostly for two reasons:</p>\n<ol>\n<li>We put a lot of ourselves into what we do, and so it’s natural, that when confronted with negative feedback, we would take it personally. That’s totally understandable and human.</li>\n<li>Our brain perceives critical feedback and arguments in the same way it did thousands of years ago. We’ve gone from a decentralized, hunter-gatherer society to a modern-day society so quickly (evolutionarily speaking, of course) that our brain hasn’t been able to keep pace with the changes. So, while we’re generally a lot less likely to be <em>physically attacked</em> at work today, our brains still perceive disagreements <em>just as if</em> we’re about to be. This is the reason why oftentimes the person who disagrees with you on a really hot design issue at work may appear to you in the exact same way as a caveman about to bean you with a rock to take your food.</li>\n</ol>\n<h3>Our Brain’s Structure</h3>\n<p>Understanding how we route around this problem requires a brief discussion on how our brains perceive conflict. So, let’s dive into some neuroscience! </p>\n<p>We’ll first discuss the three main levels of our brain:</p>\n<ul>\n<li>the neocortex (where our rational, thinking brain lives),</li>\n<li>the limbic brain (where our emotions and feelings live),</li>\n<li>the reptilian brain (where our basic biological, survival programs live).</li>\n</ul>\n<p>When we are threatened, something called the amygdala (which is our brain’s “smoke detector”) sounds the alarm and does two things: it produces cortisol (a stress hormone) and diverts the blood flow from the neocortex to the lower levels of our brain. This means at this moment the part of our brain that thinks and reasons isn’t getting enough blood, so we become the real-life equivalent of the <a href=\"https://en.wikipedia.org/wiki/Hulk\">Incredible Hulk</a>: just pure fight, flight, or freeze (only without the torn clothes and green skin). In his book <a href=\"http://www.amazon.com/Emotional-Intelligence-Matter-More-Than/dp/055338371X\"><em>Emotional Intelligence</em></a>, Daniel Goleman calls this “<a href=\"https://en.wikipedia.org/wiki/Amygdala_hijack\">amygdala hijacking</a>.” It’s responsible for almost all of our conflicts going awry.</p>\n<blockquote>“An amygdala hijack is an emotional response that is immediate, overwhelming, and out of measure with the actual stimulus, because it has triggered a much more significant emotional threat. The term was coined by Daniel Goleman in his 1996 book <strong>Emotional Intelligence: Why It Can Matter More Than IQ.</strong>”<br /><br />— <a href=\"https://en.wikipedia.org/wiki/Amygdala_hijack\">Wikipedia</a></blockquote>\n\n<h3>Psychological Safety</h3>\n<p>You want the receiver of the feedback to feel comfortable enough to hear what you have to say without triggering their amygdala response, and you need to feel comfortable enough to say it. This is called <em>psychological safety</em>, and it is defined like this:</p>\n<blockquote>“Psychological safety is being able to show and employ one’s self without fear of negative consequences of self-image, status or career (Kahn 1990, p. 708). It can be defined as a shared belief that the team is safe for interpersonal risk-taking. In psychologically safe teams, team members feel accepted and respected. It is also the most studied enabling condition in <a href=\"https://en.wikipedia.org/wiki/Group_dynamics\">group dynamics</a> and <a href=\"https://en.wikipedia.org/wiki/Team_learning\">team learning</a> research.”<br /><br />— <a href=\"https://en.wikipedia.org/wiki/Psychological_safety\">Wikipedia</a></blockquote>\n\n<p>The tools that follow will help build and maintain psychological safety by signaling that it’s not a harmful situation. Remember, when you lose safety, it’s because someone’s survival circuits kicked in. Better put, psychological safety is the underpinning of all good conversations.</p>\n<p>When there isn’t safety, resentment builds, feedback gets conveniently ignored, and people tend to clam up and not give real, helpful feedback.</p>\nHow Can We Avoid It Going Sideways?\n<p>We’ll learn how to give high-fidelity feedback, share actionable and specific insights, as well as how to give a little conversational “first aid” by making refocusing statements.</p>\n<h3>Give High Fidelity Feedback</h3>\n<p>Having a conflict when collaborating remotely causes us to lose what I call “high fidelity conversation,” leaving everyone at a disadvantage. Here’s my definition:</p>\n<blockquote><strong>High fidelity conversation</strong><br />It is a conversation in which all participants have access to the full range of human communication, including tone of voice as well as non-verbal cues, such as body language and tone.</blockquote>\n\n<p>As more and more teams work remotely, we lose out on vital conversational cues, such as body language and tone of voice, leaving us in the dark about what someone truly means when they speak. Let’s dig into why this is difficult so that we can frame up an appropriate response.</p>\n<p>To start, let’s go over the different levels of conversational fidelity we can have and discuss what we lose in remote work communications:</p>\n<ul>\n<li><strong>In-person</strong>, which gives us the full range of verbal and non-verbal cues, such as body language, tone of voice, and the full range of their voice.</li>\n<li><strong>Video</strong>, which loses most of the body language due to cropping and the fidelity of people’s voices (video chat apps often compress audio).</li>\n<li><strong>Phone</strong>, which loses out on all non-verbal cues.</li>\n<li><strong>Text</strong>, which loses out on all non-verbal cues <em>and</em> the tone of voice.</li>\n<li><strong>Email</strong>, which loses out on everything else, including the synchronous communication (read: Slack, various chat apps, SMS messages, etc.) and leaves you only with the transcript of what people say.</li>\n</ul>\n<p>The goal for these tough conversations is to have them in <strong>as high a fidelity</strong> as you possibly can. While email and Slack have dramatically reduced the friction for communication, it’s come at the expense of clarity and thoughtfulness. It’s far easier to send a half-baked email that leaves too much open to interpretation (remember the last email — or email thread — you got that was a forwarded email with just <em>“thoughts?”</em> included on a single line?). Plus, you’re at the mercy of the reader’s mood, state of mind, or distractions they experience, which could contribute to the missing key parts of your message.</p>\n<p>When we lose conversational fidelity, our brain’s survival circuits activate and fill in all the gaps in the communication with negative assumptions, leaving us prone to misinterpret someone’s message. </p>\n<p>There are times, however, when real-time communication isn’t an option, especially for fully remote companies with people spread all across the world. In that case, consider using a tool like <a href=\"https://www.loom.com\">Loom</a> to give your feedback, or you could even record an audio message on your phone and upload that. In doing so, you still retain your tone and give them some body language to work off of. </p>\n<p>Failing that, you’ll need to work a little harder to ensure things are taken well. Remember, you’re losing a lot of fidelity here, so you’ll need to compensate. Here are two of the best tips:</p>\n<ol>\n<li><strong>Be very clear with your language.</strong><br />Humans’ brains like to fill in the gaps with negative assumptions.</li>\n<li><strong>Use emoji. 😊</strong><br />Because <a href=\"https://www.wired.com/2014/02/brain-smiley-emoticon-science/\">our brains perceive emoji in the same way that it does a real human’s reaction</a>. Don’t overuse them, but know they’re a helpful tool if people can’t see your real face.</li>\n</ol>\n<h3>Ask For (And Give) Actionable Feedback On Specific Areas</h3>\n<p>When we start projects, we establish objectives and goals we want to achieve. Feedback sessions have exactly the same needs. So, when you gather people for feedback, be specific. Here’s a helpful guide:</p>\n<h4>Don’t ask:</h4>\n<ul>\n<li>What do you think?</li>\n<li>Thoughts?</li>\n</ul>\n<h4>Do ask:</h4>\n<ul>\n<li>I’d like feedback on the grid system, and particularly on the following elements of...</li>\n<li>This technically passes our contrast guideline tests, but it feels somewhat wrong. What do you think?</li>\n</ul>\n<p>We often mistake a client’s, a manager’s, or a stakeholder’s desire to contribute to your discussion for <em>direction</em>. But it’s not always so — generally, these people just want to <em>help you</em> solve the user experience or user interface design problems.</p>\n<p>I’ve found Asana’s method to be particularly helpful here — you need to bucket the feedback into three buckets: <strong>do</strong>, <strong>try</strong>, and <strong>consider</strong>.</p>\n<blockquote>“A while back at Asana we noticed teams were laser-focused on shipping and would carefully ask if each piece of feedback was “launch blocking” at our launch reviews. Often non-blocking feedback would be brushed aside even if it was relatively cheap and would really improve the quality of the product. We reflected on what was happening and realized that we didn’t have clear language or norms on how to give or respond to feedback. And so, the Do, Try, Consider framework was born.”<br /><br />— “<a href=\"https://jackiebo.medium.com/do-try-consider-how-we-give-product-feedback-at-asana-db9bc754cc4a\">Do, Try, Consider — How we give product feedback at Asana</a>” by Jackie Bavaro</blockquote>\n\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/37cb3e77-953b-4e46-9fb2-bbff722b576e/2-give-effective-feedback-remotely.png\" /></p>\n<p>When giving feedback, you should give the person something to explore or try. For example, instead of “Put the sign-up call to action here,” try “What other layouts might help us achieve our goal?”</p>\n<p>Every piece of feedback should also be directly related to a goal, whether that’s the design being on-brand, responding to someone’s feedback, and so on. And if you aren’t seeing a way to be more specific, consider asking the <em>other person</em> to ask what specific type of feedback <em>they’re</em> looking for. </p>\n<p>Here’s how a feedback session could work:</p>\n<p>Invite people to have several minutes of quiet ideation, adding sticky notes to a virtual board. Once the solo time expires, group the similar sticky notes and then discuss each group individually, bucketing them accordingly.</p>\n<p>Here’s a little <a href=\"https://www.figma.com/community/file/1103730337624845214/Feedback-Template\">template</a> that I made:</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/6b89972c-a1c5-4b18-9ea4-32b118e5fdc5/figma-feedback-template.png\" /></p>\n<p>And here’s how this could look like in action:</p>\n<blockquote><strong>Person A:</strong> “Hey Person B, here’s the latest prototype. I’d like to get feedback on the navigation structure for this app because I’m feeling a little tension with where the account settings are currently located. I’m also not sure about whether or not this design iteration is fully in line with the new brand look that we’re rolling out next quarter.”<br /><br /><strong>Person B:</strong> “The account settings should definitely be not so front-and-center, I think we have to put them under ‘Profile’ to match the website UX. Also, I expected to see the buttons in our brand’s shade of blue and not the shade that you have used. Can we change the color?”<br /><br /><strong>Person A:</strong> “Okay, let’s talk about the blue first. We didn’t have a matching shade that was also accessible (not enough color contrast), so I made a new one that was. Is this comment a must-do, try, or consider? Also, it sounds like repositioning the account settings is a must-do, is that right?”</blockquote>\n\n\n\n<h3>Be Kind</h3>\n<p>Before we continue, let’s discuss what I mean by being <strong>kind</strong>. I don’t mean that you should go around giving empty compliments to people or avoiding telling them things that aren’t quite right — both of these are ultimately harmful. What I intend by saying “be kind” is that you are direct with the other person. You have hard, direct conversations because you care. That’s true kindness. (And of course, <a href=\"https://twitter.com/timmisiak/status/1502330641412591617\">be polite</a>.)</p>\n<blockquote><p>More people need to learn that a polite suggestion as feedback is far more likely to get action than a snarky or unprofessional comment. And don't insult the people you're giving feedback to. We're all human.</p>— Tim Misiak (@timmisiak) <a href=\"https://twitter.com/timmisiak/status/1502330641412591617?ref_src=twsrc%5Etfw\">March 11, 2022</a></blockquote>\n\n<p>How you <strong>frame the feedback</strong> has a direct influence on how it will be received. For example, which do you think is the better type of feedback? </p>\n<ul>\n<li>“This blue is lame. Just not digging it, man.”</li>\n<li>“This blue isn’t in line with our brand guidelines. Good thinking on the accessibility angle, though. You should chat with marketing to make sure that we use the right color shade, and at the same time, we have enough color contrast to keep this UI element accessible.”</li>\n</ul>\n<p>I hope you chose the second option. 😄</p>\n<h3>When It Goes Sideways, Refocus</h3>\n<p>Despite our best efforts, conversations will still go sideways sometimes. Here, we’ll discuss the best way to perform some conversational “first aid” when things feel a little dicey. Enter what I call <strong>refocusing statements</strong>.</p>\n<blockquote>A <strong>refocusing statement</strong> is a statement that addresses the misinterpretation, reestablishes focus on your goal, and asks open-ended questions to ensure clarity.</blockquote>\n\n<p>Here’s what they look like:</p>\n<ol>\n<li>What you <em>aren’t</em> saying (the misunderstanding or misrepresentation).</li>\n<li>What you <em>are</em> saying (your personal or shared goal).</li>\n<li>An open-ended question that puts the conversation back in their court.</li>\n</ol>\n<p>Here are a few refocusing statements in action:</p>\n<blockquote>“I don’t intend to imply you’re not a skillful enough designer, I’m saying that this isn’t up to our team’s standards. We can &amp;mdash, and we want — to help you get there though.”<br /><br />“I’m not saying you have to do it my way. I know that you’ve got a lot more expertise in designing interfaces than I do. I just wanted to say that we need to consult with one another before sending the prototypes to the stakeholders because I’m responsible for doing the accessibility audits and don’t want any unnecessary back and forth to happen.”<br /><br />“It’s not that you aren’t welcome to contribute to the user interviews or you aren’t a part of our team, your expertise in this is essential. Rather I would say that the type of questions you asked could taint our user research. Can we talk about how to reframe those questions?”</blockquote>\n\n<p>By framing the statements like in these examples, we actively address someone’s humanity and experience, and at the same time, we shift the conversation in a way that overcomes the objection or misunderstanding.</p>\n<p><strong>Note</strong>: <em>Please, avoid ending these with “does this make sense?” These non-questions only serve to open the door for condescension.</em></p>\n<p>And of course, give credit where credit is due — the inspiration for the refocusing technique came from <a href=\"https://cruciallearning.com\">Crucial Learning</a>’s excellent “contrasting statement”, but I shaped it further to better fit my own practice.</p>\nConclusion\n<p>In closing, let’s briefly recap some of the key points that I made in the article:</p>\n<ul>\n<li>Society evolved quickly over the last few millennia, but our brains still “lag behind”, so we need to adopt a few new techniques to make giving and receiving feedback easier.</li>\n<li>If we can build and kindle psychological safety with our peers, giving feedback will be a much more effective process.</li>\n<li>We build psychological safety in part by having a <strong>high fidelity conversation</strong> — a conversation in which all participants have access to the full range of human communication, including tone of voice as well as non-verbal cues, such as body language and tone. (And if you cannot have a high fidelity conversation, then you’ll need to work a little harder to ensure things are taken well when communicating your feedback using <strong>text alone</strong> — remember to be very clear with your language and do use emoji.)</li>\n<li>Ask for (and give) feedback that’s actionable and specific. Use Asana’s methods to bucket the feedback into three separate “buckets”: <strong>do</strong>, <strong>try</strong>, and <strong>consider</strong>.</li>\n<li><strong>Be kind</strong>. How you frame the feedback has a direct influence on how it’s received.</li>\n<li>When it goes sideways, try using a <strong>refocusing statement</strong> — a statement which <em>addresses the misinterpretation</em>, <em>reestablishes focus on your goal</em>, and <em>asks open-ended questions</em> to ensure clarity.</li>\n</ul>",
      "content_text": "We need more good feedback in our world, and I don’t just mean the type of feedback that celebrates your good work. I’m talking about feedback that is actionable, specific, and kind; feedback that does not set us on edge or make us fall into an anxious spiral; feedback that helps us collaborate more effectively. The kind of feedback that is actually really hard to do when working remotely.\nIn this article, I’ll discuss a few ways to get around that difficulty. We’ll start by learning what causes feedback sessions to get off track, how to prevent this from happening, and what to do when this happens.\nThis article is targeted toward designers and developers who are currently working remotely or are planning to switch to remote work.\nImagine...\nYou’re part of a remote design team in a small company that is currently having you focus on revising their to-do app’s design based on some customer feedback and some ideas that the company wants to validate. During your presentation to the company, someone interrupts you. With their camera off, they say: “Wait, why are we wasting time doing this? The existing page is fine. The older colors and layout were better and this new thing feels clunky. Just put the sign-up call to action at the top and be done with it.”\nYou’ve been doing this for a few years, so this isn’t new to, you but you still feel like you got the wind knocked out of you. You get flushed and a little angry, because this person hasn’t always been so unfriendly to you before, and you don’t want to look bad in front of the leadership. You start to stumble over your words, which you think makes you look bad. Now you’re in a downward spiral. \nWhy Does Negative Feedback Elicit Such Strong Responses?\nMostly for two reasons:\n\nWe put a lot of ourselves into what we do, and so it’s natural, that when confronted with negative feedback, we would take it personally. That’s totally understandable and human.\nOur brain perceives critical feedback and arguments in the same way it did thousands of years ago. We’ve gone from a decentralized, hunter-gatherer society to a modern-day society so quickly (evolutionarily speaking, of course) that our brain hasn’t been able to keep pace with the changes. So, while we’re generally a lot less likely to be physically attacked at work today, our brains still perceive disagreements just as if we’re about to be. This is the reason why oftentimes the person who disagrees with you on a really hot design issue at work may appear to you in the exact same way as a caveman about to bean you with a rock to take your food.\n\nOur Brain’s Structure\nUnderstanding how we route around this problem requires a brief discussion on how our brains perceive conflict. So, let’s dive into some neuroscience! \nWe’ll first discuss the three main levels of our brain:\n\nthe neocortex (where our rational, thinking brain lives),\nthe limbic brain (where our emotions and feelings live),\nthe reptilian brain (where our basic biological, survival programs live).\n\nWhen we are threatened, something called the amygdala (which is our brain’s “smoke detector”) sounds the alarm and does two things: it produces cortisol (a stress hormone) and diverts the blood flow from the neocortex to the lower levels of our brain. This means at this moment the part of our brain that thinks and reasons isn’t getting enough blood, so we become the real-life equivalent of the Incredible Hulk: just pure fight, flight, or freeze (only without the torn clothes and green skin). In his book Emotional Intelligence, Daniel Goleman calls this “amygdala hijacking.” It’s responsible for almost all of our conflicts going awry.\n“An amygdala hijack is an emotional response that is immediate, overwhelming, and out of measure with the actual stimulus, because it has triggered a much more significant emotional threat. The term was coined by Daniel Goleman in his 1996 book Emotional Intelligence: Why It Can Matter More Than IQ.”— Wikipedia\n\nPsychological Safety\nYou want the receiver of the feedback to feel comfortable enough to hear what you have to say without triggering their amygdala response, and you need to feel comfortable enough to say it. This is called psychological safety, and it is defined like this:\n“Psychological safety is being able to show and employ one’s self without fear of negative consequences of self-image, status or career (Kahn 1990, p. 708). It can be defined as a shared belief that the team is safe for interpersonal risk-taking. In psychologically safe teams, team members feel accepted and respected. It is also the most studied enabling condition in group dynamics and team learning research.”— Wikipedia\n\nThe tools that follow will help build and maintain psychological safety by signaling that it’s not a harmful situation. Remember, when you lose safety, it’s because someone’s survival circuits kicked in. Better put, psychological safety is the underpinning of all good conversations.\nWhen there isn’t safety, resentment builds, feedback gets conveniently ignored, and people tend to clam up and not give real, helpful feedback.\nHow Can We Avoid It Going Sideways?\nWe’ll learn how to give high-fidelity feedback, share actionable and specific insights, as well as how to give a little conversational “first aid” by making refocusing statements.\nGive High Fidelity Feedback\nHaving a conflict when collaborating remotely causes us to lose what I call “high fidelity conversation,” leaving everyone at a disadvantage. Here’s my definition:\nHigh fidelity conversationIt is a conversation in which all participants have access to the full range of human communication, including tone of voice as well as non-verbal cues, such as body language and tone.\n\nAs more and more teams work remotely, we lose out on vital conversational cues, such as body language and tone of voice, leaving us in the dark about what someone truly means when they speak. Let’s dig into why this is difficult so that we can frame up an appropriate response.\nTo start, let’s go over the different levels of conversational fidelity we can have and discuss what we lose in remote work communications:\n\nIn-person, which gives us the full range of verbal and non-verbal cues, such as body language, tone of voice, and the full range of their voice.\nVideo, which loses most of the body language due to cropping and the fidelity of people’s voices (video chat apps often compress audio).\nPhone, which loses out on all non-verbal cues.\nText, which loses out on all non-verbal cues and the tone of voice.\nEmail, which loses out on everything else, including the synchronous communication (read: Slack, various chat apps, SMS messages, etc.) and leaves you only with the transcript of what people say.\n\nThe goal for these tough conversations is to have them in as high a fidelity as you possibly can. While email and Slack have dramatically reduced the friction for communication, it’s come at the expense of clarity and thoughtfulness. It’s far easier to send a half-baked email that leaves too much open to interpretation (remember the last email — or email thread — you got that was a forwarded email with just “thoughts?” included on a single line?). Plus, you’re at the mercy of the reader’s mood, state of mind, or distractions they experience, which could contribute to the missing key parts of your message.\nWhen we lose conversational fidelity, our brain’s survival circuits activate and fill in all the gaps in the communication with negative assumptions, leaving us prone to misinterpret someone’s message. \nThere are times, however, when real-time communication isn’t an option, especially for fully remote companies with people spread all across the world. In that case, consider using a tool like Loom to give your feedback, or you could even record an audio message on your phone and upload that. In doing so, you still retain your tone and give them some body language to work off of. \nFailing that, you’ll need to work a little harder to ensure things are taken well. Remember, you’re losing a lot of fidelity here, so you’ll need to compensate. Here are two of the best tips:\n\nBe very clear with your language.Humans’ brains like to fill in the gaps with negative assumptions.\nUse emoji. 😊Because our brains perceive emoji in the same way that it does a real human’s reaction. Don’t overuse them, but know they’re a helpful tool if people can’t see your real face.\n\nAsk For (And Give) Actionable Feedback On Specific Areas\nWhen we start projects, we establish objectives and goals we want to achieve. Feedback sessions have exactly the same needs. So, when you gather people for feedback, be specific. Here’s a helpful guide:\nDon’t ask:\n\nWhat do you think?\nThoughts?\n\nDo ask:\n\nI’d like feedback on the grid system, and particularly on the following elements of...\nThis technically passes our contrast guideline tests, but it feels somewhat wrong. What do you think?\n\nWe often mistake a client’s, a manager’s, or a stakeholder’s desire to contribute to your discussion for direction. But it’s not always so — generally, these people just want to help you solve the user experience or user interface design problems.\nI’ve found Asana’s method to be particularly helpful here — you need to bucket the feedback into three buckets: do, try, and consider.\n“A while back at Asana we noticed teams were laser-focused on shipping and would carefully ask if each piece of feedback was “launch blocking” at our launch reviews. Often non-blocking feedback would be brushed aside even if it was relatively cheap and would really improve the quality of the product. We reflected on what was happening and realized that we didn’t have clear language or norms on how to give or respond to feedback. And so, the Do, Try, Consider framework was born.”— “Do, Try, Consider — How we give product feedback at Asana” by Jackie Bavaro\n\n\nWhen giving feedback, you should give the person something to explore or try. For example, instead of “Put the sign-up call to action here,” try “What other layouts might help us achieve our goal?”\nEvery piece of feedback should also be directly related to a goal, whether that’s the design being on-brand, responding to someone’s feedback, and so on. And if you aren’t seeing a way to be more specific, consider asking the other person to ask what specific type of feedback they’re looking for. \nHere’s how a feedback session could work:\nInvite people to have several minutes of quiet ideation, adding sticky notes to a virtual board. Once the solo time expires, group the similar sticky notes and then discuss each group individually, bucketing them accordingly.\nHere’s a little template that I made:\n\nAnd here’s how this could look like in action:\nPerson A: “Hey Person B, here’s the latest prototype. I’d like to get feedback on the navigation structure for this app because I’m feeling a little tension with where the account settings are currently located. I’m also not sure about whether or not this design iteration is fully in line with the new brand look that we’re rolling out next quarter.”Person B: “The account settings should definitely be not so front-and-center, I think we have to put them under ‘Profile’ to match the website UX. Also, I expected to see the buttons in our brand’s shade of blue and not the shade that you have used. Can we change the color?”Person A: “Okay, let’s talk about the blue first. We didn’t have a matching shade that was also accessible (not enough color contrast), so I made a new one that was. Is this comment a must-do, try, or consider? Also, it sounds like repositioning the account settings is a must-do, is that right?”\n\n\n\nBe Kind\nBefore we continue, let’s discuss what I mean by being kind. I don’t mean that you should go around giving empty compliments to people or avoiding telling them things that aren’t quite right — both of these are ultimately harmful. What I intend by saying “be kind” is that you are direct with the other person. You have hard, direct conversations because you care. That’s true kindness. (And of course, be polite.)\nMore people need to learn that a polite suggestion as feedback is far more likely to get action than a snarky or unprofessional comment. And don't insult the people you're giving feedback to. We're all human.— Tim Misiak (@timmisiak) March 11, 2022\n\nHow you frame the feedback has a direct influence on how it will be received. For example, which do you think is the better type of feedback? \n\n“This blue is lame. Just not digging it, man.”\n“This blue isn’t in line with our brand guidelines. Good thinking on the accessibility angle, though. You should chat with marketing to make sure that we use the right color shade, and at the same time, we have enough color contrast to keep this UI element accessible.”\n\nI hope you chose the second option. 😄\nWhen It Goes Sideways, Refocus\nDespite our best efforts, conversations will still go sideways sometimes. Here, we’ll discuss the best way to perform some conversational “first aid” when things feel a little dicey. Enter what I call refocusing statements.\nA refocusing statement is a statement that addresses the misinterpretation, reestablishes focus on your goal, and asks open-ended questions to ensure clarity.\n\nHere’s what they look like:\n\nWhat you aren’t saying (the misunderstanding or misrepresentation).\nWhat you are saying (your personal or shared goal).\nAn open-ended question that puts the conversation back in their court.\n\nHere are a few refocusing statements in action:\n“I don’t intend to imply you’re not a skillful enough designer, I’m saying that this isn’t up to our team’s standards. We can &mdash, and we want — to help you get there though.”“I’m not saying you have to do it my way. I know that you’ve got a lot more expertise in designing interfaces than I do. I just wanted to say that we need to consult with one another before sending the prototypes to the stakeholders because I’m responsible for doing the accessibility audits and don’t want any unnecessary back and forth to happen.”“It’s not that you aren’t welcome to contribute to the user interviews or you aren’t a part of our team, your expertise in this is essential. Rather I would say that the type of questions you asked could taint our user research. Can we talk about how to reframe those questions?”\n\nBy framing the statements like in these examples, we actively address someone’s humanity and experience, and at the same time, we shift the conversation in a way that overcomes the objection or misunderstanding.\nNote: Please, avoid ending these with “does this make sense?” These non-questions only serve to open the door for condescension.\nAnd of course, give credit where credit is due — the inspiration for the refocusing technique came from Crucial Learning’s excellent “contrasting statement”, but I shaped it further to better fit my own practice.\nConclusion\nIn closing, let’s briefly recap some of the key points that I made in the article:\n\nSociety evolved quickly over the last few millennia, but our brains still “lag behind”, so we need to adopt a few new techniques to make giving and receiving feedback easier.\nIf we can build and kindle psychological safety with our peers, giving feedback will be a much more effective process.\nWe build psychological safety in part by having a high fidelity conversation — a conversation in which all participants have access to the full range of human communication, including tone of voice as well as non-verbal cues, such as body language and tone. (And if you cannot have a high fidelity conversation, then you’ll need to work a little harder to ensure things are taken well when communicating your feedback using text alone — remember to be very clear with your language and do use emoji.)\nAsk for (and give) feedback that’s actionable and specific. Use Asana’s methods to bucket the feedback into three separate “buckets”: do, try, and consider.\nBe kind. How you frame the feedback has a direct influence on how it’s received.\nWhen it goes sideways, try using a refocusing statement — a statement which addresses the misinterpretation, reestablishes focus on your goal, and asks open-ended questions to ensure clarity.\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9fd70453-99c5-4d6f-9abe-1a19a52d217b/give-effective-feedback-remotely.jpg",
      "date_published": "2022-05-06T09:30:00.000Z",
      "date_modified": "2022-05-06T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/resilience-flexibility-immediacy-headless-systems/",
      "url": "https://smashingmagazine.com/2022/05/resilience-flexibility-immediacy-headless-systems/",
      "title": "Resilience, Flexibility And Immediacy: Working With Headless Systems",
      "summary": "When deploying websites, there’s rarely a one-size-fits-all solution. Some websites benefit from server-rendered pages, some prefer statically generating content upfront. In this article, Stefan explains how a CMS such as [Storyblok](https://www.storyblok.com/) can help you make your site more resilient without losing the flexibility to deliver time-relevant content.",
      "content_html": "<p>This article is a sponsored by <a href=\"https://www.storyblok.com/\">Storyblok</a></p>\n<p>In the last couple of years, our industry has figured out how to make use of cloud infrastructure and flexible deployments in the best way possible. We use services that give us continuous integration without headaches and serve static files without us managing anything. And adding the right framework to the mix, those services blur the line between static files, dynamic updates, and serverless APIs.</p>\n<p>In all of this, one fundamental piece is often left out: <strong>storing data</strong>. This raises the question, “Where does our content come from?” Well, a headless content management system might just be what you need.</p>\nThe Mighty Monolith And Opinions\n<p>In order to understand why we get so many benefits out of architectures that involve headless systems, we need to understand how things worked with a more traditional approach: <strong>monolithic architectures</strong>.</p>\n<p>Not so long ago, monolithic content management systems were the jack-of-all-trades for your web content delivery concerns. They came along with:</p>\n<ul>\n<li>a database (or required a very specific one),</li>\n<li>the logic to read, change, and store data,</li>\n<li>user interfaces for content administration,</li>\n<li>logic to render all your content in deliverable formats such as HTML or JSON,</li>\n<li>the ability to upload, store, and deliver assets like images and static files,</li>\n<li>sometimes even an editor for design,</li>\n<li>a routing logic to map readable URLs to actual data in your system.</li>\n</ul>\n<p>That’s a lot of tasks! Furthermore, a monolithic CMS more often than not was very opinionated in its choice of tools and flavors. For example, if you were lucky, you got a template engine to define the markup you wanted to produce and had absolute control over it. It might not have been as featureful as you wanted it to be, but it at least was better than mixing PHP code with HTML tags.</p>\n<p>Being this opinionated left you as a developer with two choices:</p>\n<ol>\n<li><strong>Submit to the system.</strong><br />Learn all its intricacies inside out, become an expert, and don’t deviate from the standard. Treat a CMS as a framework with all the benefits and downsides that come with them. Be super productive if you follow the rules. Avoid anything that doesn’t play well with the opinions of your tool of choice. This can go well for a long time. But you become very inflexible if there are changes in requirements. Not only if you need a different front-end to deploy that is to be designed differently than your tool allows, but also if you end up needing to scale out your servers because of increased traffic, or you need to establish stricter security because of new attack vectors you can’t mitigate. Don’t get me wrong, people who produce and develop monolithic CMS know about those challenges and work on them. It’s still not your choice if you want change.</li>\n<li><strong>Work around the system.</strong><br />This is arguably worse than following a framework blindly. If you work around a system, try to integrate functionality via plug-ins, shift responsibility to attached systems on the side, try to hack something in the core to get things done your way (yes, this happens as well), you end up frankensteining your solution until it’s unrecognizable anymore. While this gives you flexibility when your product managers want to crank out features, it will fall back on you sometime in the future. Don’t do this.</li>\n</ol>\n<p>None of these choices is something we want to have. And it all happens because we mix responsibilities in one single solution: How we define, maintain, and store content is mixed with the creation of views.</p>\n<p>The following chart shows what happens if we want to see content produced by a traditional, server-side rendered system.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f9af0ee6-c92e-4c04-b6f5-50e6c35f3509/6-resilience-flexibility-immediacy-headless-systems.png\" /></p>\n<ol>\n<li>A client, maybe a browser, requests a website from a server via a URL;</li>\n<li>A router resolves the URL and maps it to some input parameters that the system can understand;</li>\n<li>It asks a rendering component to render content based on said input parameters;</li>\n<li>Then, in return, it needs to ask the data storage if this content is available;</li>\n<li>One pierce through the layer cake, and you get your content back;</li>\n<li>The renderer renders it into HTML;</li>\n<li>The routing layer can send a response to the client.</li>\n</ol>\n<p>Every communication between the components of this layered architecture is subject to the opinions of its creator. In monolithic architectures, these are the content management system’s opinions. If you want to change them, you have to go the extra mile.</p>\nThe Promise Of Headless Architectures\n<p>And this is exactly where headless content management systems come in. A headless CMS gives you easy reading access to the data. Everything else can be designed according to your opinions. </p>\n<p>You decide how to resolve routing. On the client? On a web proxy? In a Node.js server? Your choice. You decide how and where to render content. Again, on the client? With blade templates in PHP on the server? A serverless function on AWS Lambda written in Go that spits out JSON? Your choice.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f7cb24de-812f-4387-9740-f68b13950b5e/4-resilience-flexibility-immediacy-headless-systems.png\" /></p>\n<p>Chopping of the head gives you as a developer the freedom to decide what is the right technology for your situation. From a single page application to a traditional server-side rendered website or pre-built sites in continuous integration. </p>\n<p>Suddenly you also get the freedom to update “the head” as many times as you like and as often as you need. You can deploy it to different servers with different scaling possibilities. Remix, Nuxt, Laravel, 11ty… They couldn’t be more different in how they work, and how they’re supposed to be deployed. Your CMS stays the same.</p>\n<p> Headless CMS not only solve the technology lock-in problem, but they are also a chance to raise the availability and stability of your website. With a traditional, monolithic architecture, everything is tightly coupled.</p>\n<p>An unknown error in your render logic might cause the same kind of problems as if your database has no room to write anymore. By attaching a headless content management system moves a potential source of problems away from others. Suddenly, the boundary becomes clearer — and we can even go further.</p>\n<p>What if we cannot only define the error boundary much better? What if we can react to potential errors much better because of all the ways we are able to consume data?</p>\nJamstack And Static Sites\n<p>Jamstack means publishing static sites. It’s the opposite of a pull architecture, where each request means fresh content from the database, instead, we push out all our content at once, pre-rendered, in static files, ready to be served.</p>\n<p>This comes with <strong>a ton of benefits</strong>. Jamstack sites are easy to deploy. All your web server needs to be able to do is serve static files. Web servers are really good at serving static sites! Security-wise, Jamstack pages are a fortress. You actively cut all ties to systems that require authentication or handle sensitive data. <strong>Web servers serve in read-only mode</strong>. Some setups from popular providers even create an immutable copy of your site. No possibility to change anything on this disk.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/9be2fdf3-f52a-4bb2-a36c-547a4b0d06f2/5-resilience-flexibility-immediacy-headless-systems.png\" /></p>\n<p>All you need is a static site generator, and if you want to scale, a build server. Services like Netlify and Vercel build static sites for you. Content updates happen at build time. The static site generator pulls the entire necessary content from a headless CMS once.</p>\n<p>See this example with Storyblok and Next.js:</p>\n<pre><code>import {\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story }) {\n  // Let's show what we got.\n  return &lt;StoryblokComponent blok={story.content} /&gt;;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Here, we are loading all data for static generation.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'draft',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n  };\n}</code></pre>\n\n<p>Once the website is done building, all ties are cut. Your website runs without any connection to a content management system. From an operations point of view, this is fantastic. Not only did we introduce an error boundary and reduced channels to other systems, but we also cut off communication entirely because we don’t need it anymore. </p>\n<p><strong>Updates to your content require a rebuild</strong>. A CMS like Storyblok offers you to call a webhook once the publish button has been pressed. Thankfully, hosts like Vercel offer to create webhooks that rebuild your site.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8a8f5db7-935a-4682-9836-247dc041e493/2-resilience-flexibility-immediacy-headless-systems.png\" /></p>\n<p>It’s not all hunky-dory, though. While Jamstack sites have undeniable benefits, they also come with some problems. The bigger your site is, the slower your builds can be. If you have to have mission-critical updates, and some companies do, it might be unacceptable to wait a couple of minutes until you see an update. Heck, <a href=\"https://www.smashingmagazine.com/2016/08/using-a-static-site-generator-at-scale-lessons-learned/\">I’ve seen projects taking up to 30 minutes to publish new content</a>. This is way too long if you need to react quickly.</p>\nDeployment Free Updates\n<p>If we think back to how monolithic content management systems dealt with retrieving content, we see that there was just one spot where the content was actually queried. Thanks to a headless CMS that gives you APIs to fetch data, we can now <strong>fetch content from multiple places</strong>.</p>\n<p>We can use this to maneuver around some limitations we get when using Jamstack when we need to wait for a build to get an update. We can see the deployed static files as a robust, available baseline to serve our content from. For critical parts of our website, where real-time updates are of essence, we fetch data dynamically from our CMS.</p>\n<p>This can be parts of your website, but also the entire content of an entire page. The following example shows how this can be done using Storyblok and Next.js:</p>\n<pre><code>import {\n  useStoryblok,\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story: initialStory }) {\n  // We are fetching new data from our CMS.\n  let story = useStoryblok(\"react\", { version: \"draft\" });\n\n  // If data isn't available, yet, we show the original static data.\n  if (!story.content) {\n    story = initialStory;\n  }\n\n  return &lt;StoryblokComponent blok={story.content} /&gt;;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Here, we are loading all data for static generation.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'draft',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n  };\n}</code></pre>\n\n<p>Next.js ergonomic APIs allow us to pinpoint the exact locations where we want to have data dynamically with a static fallback. And we increase our data accessing points.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/bf4ad617-1aff-4d59-a1fe-53462db09def/1-resilience-flexibility-immediacy-headless-systems.png\" /></p>\n<p>Press releases, news articles, and everything that needs to be published within a certain time frame can be done dynamically on the client-side — <strong>without losing the benefits of static site generation</strong>. You still can redeploy your website, but publishing at an exact point in time becomes an afterthought. Let the build run as long as it needs.</p>\n<p>Not only do you get fast updates. If the connection to your CMS breaks for whatever reason, users are still able to see the old content. There’s no arguing that this is definitely better than seeing no content at all.</p>\n<p>There are many more use cases for a model like this. Updates on time-critical pages are one thing but think of different modes for your site. You publish statically generated pages fetching all recent data at once at build time. You have a preview mode for your content creators and editors to see what they’re currently working on hosted someplace else.</p>\n<pre><code>import {\n  useStoryblok,\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story: initialStory, preview }) {\n  if (preview) {\n    // Load draft articles in preview mode.\n    let story = useStoryblok(\"react\", { version: \"draft\" });\n    return &lt;StoryblokComponent blok={story.content} /&gt;;\n  }\n\n  return &lt;StoryblokComponent blok={initialStory.content} /&gt;;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Load published data in build mode.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'published',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n  };\n}</code></pre>\n\n<p>Nice! Give your editors some taste of what they’re actually working on!</p>\nIncremental Static Updates\n<p>Fetching time-sensitive data on the client-side is one idea to update your page without a full rebuild. It’s great if you want to have fast updates, but you might see a huge switch between the pre-built. If your hosting solution allows it, tools like Next.js allow you to incrementally update content after a certain retention period.</p>\n<p>This <a href=\"https://www.smashingmagazine.com/2021/04/incremental-static-regeneration-nextjs/\">article on Smashing Magazine by Lee Robinson</a> goes into incremental static regeneration in full detail. <strong>The story in a nutshell</strong>: The web server serves statically generated content. You define how long this content is supposed to be valid. If at the time of serving this period has elapsed, Next.js triggers a serverless function that renders the desired page new and overwrites the original page with the newly generated HTML. Quite a task, for you it’s just one line of code you need to add.</p>\n<pre><code>import {\n  useStoryblok,\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story: initialStory }) {\n  // We are fetching new data from our CMS.\n  let story = useStoryblok(\"react\", { version: \"draft\" });\n\n  // If data isn't available, yet, we show the original static data.\n  if (!story.content) {\n    story = initialStory;\n  }\n\n  return &lt;StoryblokComponent blok={story.content} /&gt;;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Here, we are loading all data for static generation.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'draft',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n    revalidate: 3600 // Check back after 1 hour if there's new content.\n  };\n}</code></pre>\n\n<p>Now we have three points where we access our headless CMS from:</p>\n<ol>\n<li>Once a build for all available content.</li>\n<li>For time-sensitive data on the client-side. Fallback to the original content.</li>\n<li>In a serverless function for every page we want to update incrementally.</li>\n</ol>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e5ea36f4-3ac9-44bb-81d0-123ac5fba3f8/3-resilience-flexibility-immediacy-headless-systems.png\" /></p>\nSoft Coupling\n<p>All three connection points work for different time frames.</p>\n<ol>\n<li><strong>Real-time client-side data fetching</strong> has the shortest life span and gives you the most recent content.</li>\n<li><strong>Incrementally generated static pages</strong> have a longer life span and give you content that is of a certain age.</li>\n<li><strong>Build-time generated static pages</strong> have the longest life span and are as recent as you configure them. Their life span is significantly shorter if you rebuild on every content update, it’s longer if you only rebuild at code changes.</li>\n</ol>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ebe46190-543d-417a-9d1b-714bc5516d11/7-resilience-flexibility-immediacy-headless-systems.png\" /></p>\n<p>But by adding all the connection points to our CMS, something else has changed. We coupled ourselves more often to an external system than before, but every connection is allowed to fail.</p>\n<p>If a real-time update on the client-side fails for whatever reason, we still see the content of the incrementally generated page. If this connection didn’t work, we see what we generated on build time.</p>\n<p><strong>Note</strong>: <em>The examples above use Next.js mostly because Next.js allows us to get all that benefit with very little to do for us developers. Especially with the hooks from Storyblok data fetching becomes a single line of code. The same principles of soft coupling can be applied to other sites and frameworks as well.</em></p>\n<p>Let’s say you generate all your content on the server-side using Express.js. The following route would fetch content with every request to the server:</p>\n<pre><code>app.get('/*', function (req, res) {\n  var path = url.parse(req.url).pathname;\n  console.log(path);\n  path = path == '/' ? 'home' : path;\n\n  Storyblok.get(`cdn/stories${path}`, {\n    version: 'draft',\n  })\n    .then((response) =&gt; {\n      // Render content to HTML.\n      res.render({\n        story: response.data.story,\n      });\n    })\n    .catch((error) =&gt; {\n      res.send(error);\n    });\n});</code></pre>\n\n<p>If the bridge to our CMS fails, so does delivering our content. Adding another connection point serves cached content first and does updates in the background.</p>\n<pre><code>app.get('/*', function (req, res) {\n  var path = url.parse(req.url).pathname;\n  console.log(path);\n  path = path == '/' ? 'home' : path;\n\n  // Loading the cached content.\n  let content = contentMap.get(path);\n  if (content) {\n    Storyblok.get(`cdn/stories${path}`, {\n      version: 'draft',\n    }).then((response) =&gt; {\n      // Update in the background.\n      contentMap.set(path, response);\n    });\n\n    return res.send(content);\n  }\n\n  // Fetching the real content.\n  Storyblok.get(`cdn/stories${path}`, {\n    version: 'draft',\n  })\n    .then((response) =&gt; {\n      contentMap.set(path, response);\n      res.send({\n        story: response.data.story,\n      });\n    })\n    .catch((error) =&gt; {\n      res.send(error);\n    });\n});</code></pre>\n\n<p>And with some added metadata on revalidation, we can even check for updates after a certain period of time:</p>\n<pre><code>app.get('/*', function (req, res) {\n  var path = url.parse(req.url).pathname;\n  console.log(path);\n  path = path == '/' ? 'home' : path;\n\n  // Loading the cached content.\n  let content = contentMap.get(path);\n  if (content) {\n    // Check if the revalidation window has elapsed.\n    if (content.fetchedDate + content.revalidate &lt; Date.now())\n      Storyblok.get(`cdn/stories${path}`, {\n        version: 'draft',\n      }).then((response) =&gt; {\n        contentMap.set(path, {\n          response,\n          fetchedDate: content.fetchedDate,\n          revalidate: content.revalidate,\n        });\n      });\n\n    return res.send(content.response);\n  }\n\n  // Fetching the real content.\n  Storyblok.get(`cdn/stories${path}`, {\n    version: 'draft',\n  })\n    .then((response) =&gt; {\n      // Store with some metadata for revalidation.\n      contentMap.set(path, {\n        response,\n        fetchedDate: Date.now(),\n        revalidate: 3600000, //in ms\n      });\n      res.send({\n        story: response.data.story,\n      });\n    })\n    .catch((error) =&gt; {\n      res.send(error);\n    });\n});</code></pre>\n\n<p>Add this with some client-side caching using <a href=\"https://web.dev/stale-while-revalidate/\"><code>stale-while-revalidate</code></a> to add an extra fallback for your revisiting users.</p>\nBottom Line\n<p>Headless content management systems allow you to add a clear boundary between the content you deliver and the content that is being maintained by others. This clear separation lets a CMS focus on content <em>management</em> again, instead of blurring the line between content and its design.</p>\n<p>But it’s not only that. When deploying websites, there’s rarely a one-size-fits-all solution. Some websites benefit from server-rendered pages, some prefer statically generating content upfront. <strong>A headless CMS works with all approaches</strong>, allowing you to mix and match depending on your needs.</p>\n<p>We just played through one possibility of adding a headless CMS to our stack and connecting it from various sources to make our site more resilient without losing the flexibility to deliver time-relevant content. And that’s just one of many.</p>",
      "content_text": "This article is a sponsored by Storyblok\nIn the last couple of years, our industry has figured out how to make use of cloud infrastructure and flexible deployments in the best way possible. We use services that give us continuous integration without headaches and serve static files without us managing anything. And adding the right framework to the mix, those services blur the line between static files, dynamic updates, and serverless APIs.\nIn all of this, one fundamental piece is often left out: storing data. This raises the question, “Where does our content come from?” Well, a headless content management system might just be what you need.\nThe Mighty Monolith And Opinions\nIn order to understand why we get so many benefits out of architectures that involve headless systems, we need to understand how things worked with a more traditional approach: monolithic architectures.\nNot so long ago, monolithic content management systems were the jack-of-all-trades for your web content delivery concerns. They came along with:\n\na database (or required a very specific one),\nthe logic to read, change, and store data,\nuser interfaces for content administration,\nlogic to render all your content in deliverable formats such as HTML or JSON,\nthe ability to upload, store, and deliver assets like images and static files,\nsometimes even an editor for design,\na routing logic to map readable URLs to actual data in your system.\n\nThat’s a lot of tasks! Furthermore, a monolithic CMS more often than not was very opinionated in its choice of tools and flavors. For example, if you were lucky, you got a template engine to define the markup you wanted to produce and had absolute control over it. It might not have been as featureful as you wanted it to be, but it at least was better than mixing PHP code with HTML tags.\nBeing this opinionated left you as a developer with two choices:\n\nSubmit to the system.Learn all its intricacies inside out, become an expert, and don’t deviate from the standard. Treat a CMS as a framework with all the benefits and downsides that come with them. Be super productive if you follow the rules. Avoid anything that doesn’t play well with the opinions of your tool of choice. This can go well for a long time. But you become very inflexible if there are changes in requirements. Not only if you need a different front-end to deploy that is to be designed differently than your tool allows, but also if you end up needing to scale out your servers because of increased traffic, or you need to establish stricter security because of new attack vectors you can’t mitigate. Don’t get me wrong, people who produce and develop monolithic CMS know about those challenges and work on them. It’s still not your choice if you want change.\nWork around the system.This is arguably worse than following a framework blindly. If you work around a system, try to integrate functionality via plug-ins, shift responsibility to attached systems on the side, try to hack something in the core to get things done your way (yes, this happens as well), you end up frankensteining your solution until it’s unrecognizable anymore. While this gives you flexibility when your product managers want to crank out features, it will fall back on you sometime in the future. Don’t do this.\n\nNone of these choices is something we want to have. And it all happens because we mix responsibilities in one single solution: How we define, maintain, and store content is mixed with the creation of views.\nThe following chart shows what happens if we want to see content produced by a traditional, server-side rendered system.\n\n\nA client, maybe a browser, requests a website from a server via a URL;\nA router resolves the URL and maps it to some input parameters that the system can understand;\nIt asks a rendering component to render content based on said input parameters;\nThen, in return, it needs to ask the data storage if this content is available;\nOne pierce through the layer cake, and you get your content back;\nThe renderer renders it into HTML;\nThe routing layer can send a response to the client.\n\nEvery communication between the components of this layered architecture is subject to the opinions of its creator. In monolithic architectures, these are the content management system’s opinions. If you want to change them, you have to go the extra mile.\nThe Promise Of Headless Architectures\nAnd this is exactly where headless content management systems come in. A headless CMS gives you easy reading access to the data. Everything else can be designed according to your opinions. \nYou decide how to resolve routing. On the client? On a web proxy? In a Node.js server? Your choice. You decide how and where to render content. Again, on the client? With blade templates in PHP on the server? A serverless function on AWS Lambda written in Go that spits out JSON? Your choice.\n\nChopping of the head gives you as a developer the freedom to decide what is the right technology for your situation. From a single page application to a traditional server-side rendered website or pre-built sites in continuous integration. \nSuddenly you also get the freedom to update “the head” as many times as you like and as often as you need. You can deploy it to different servers with different scaling possibilities. Remix, Nuxt, Laravel, 11ty… They couldn’t be more different in how they work, and how they’re supposed to be deployed. Your CMS stays the same.\n Headless CMS not only solve the technology lock-in problem, but they are also a chance to raise the availability and stability of your website. With a traditional, monolithic architecture, everything is tightly coupled.\nAn unknown error in your render logic might cause the same kind of problems as if your database has no room to write anymore. By attaching a headless content management system moves a potential source of problems away from others. Suddenly, the boundary becomes clearer — and we can even go further.\nWhat if we cannot only define the error boundary much better? What if we can react to potential errors much better because of all the ways we are able to consume data?\nJamstack And Static Sites\nJamstack means publishing static sites. It’s the opposite of a pull architecture, where each request means fresh content from the database, instead, we push out all our content at once, pre-rendered, in static files, ready to be served.\nThis comes with a ton of benefits. Jamstack sites are easy to deploy. All your web server needs to be able to do is serve static files. Web servers are really good at serving static sites! Security-wise, Jamstack pages are a fortress. You actively cut all ties to systems that require authentication or handle sensitive data. Web servers serve in read-only mode. Some setups from popular providers even create an immutable copy of your site. No possibility to change anything on this disk.\n\nAll you need is a static site generator, and if you want to scale, a build server. Services like Netlify and Vercel build static sites for you. Content updates happen at build time. The static site generator pulls the entire necessary content from a headless CMS once.\nSee this example with Storyblok and Next.js:\nimport {\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story }) {\n  // Let's show what we got.\n  return <StoryblokComponent blok={story.content} />;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Here, we are loading all data for static generation.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'draft',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n  };\n}\n\nOnce the website is done building, all ties are cut. Your website runs without any connection to a content management system. From an operations point of view, this is fantastic. Not only did we introduce an error boundary and reduced channels to other systems, but we also cut off communication entirely because we don’t need it anymore. \nUpdates to your content require a rebuild. A CMS like Storyblok offers you to call a webhook once the publish button has been pressed. Thankfully, hosts like Vercel offer to create webhooks that rebuild your site.\n\nIt’s not all hunky-dory, though. While Jamstack sites have undeniable benefits, they also come with some problems. The bigger your site is, the slower your builds can be. If you have to have mission-critical updates, and some companies do, it might be unacceptable to wait a couple of minutes until you see an update. Heck, I’ve seen projects taking up to 30 minutes to publish new content. This is way too long if you need to react quickly.\nDeployment Free Updates\nIf we think back to how monolithic content management systems dealt with retrieving content, we see that there was just one spot where the content was actually queried. Thanks to a headless CMS that gives you APIs to fetch data, we can now fetch content from multiple places.\nWe can use this to maneuver around some limitations we get when using Jamstack when we need to wait for a build to get an update. We can see the deployed static files as a robust, available baseline to serve our content from. For critical parts of our website, where real-time updates are of essence, we fetch data dynamically from our CMS.\nThis can be parts of your website, but also the entire content of an entire page. The following example shows how this can be done using Storyblok and Next.js:\nimport {\n  useStoryblok,\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story: initialStory }) {\n  // We are fetching new data from our CMS.\n  let story = useStoryblok(\"react\", { version: \"draft\" });\n\n  // If data isn't available, yet, we show the original static data.\n  if (!story.content) {\n    story = initialStory;\n  }\n\n  return <StoryblokComponent blok={story.content} />;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Here, we are loading all data for static generation.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'draft',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n  };\n}\n\nNext.js ergonomic APIs allow us to pinpoint the exact locations where we want to have data dynamically with a static fallback. And we increase our data accessing points.\n\nPress releases, news articles, and everything that needs to be published within a certain time frame can be done dynamically on the client-side — without losing the benefits of static site generation. You still can redeploy your website, but publishing at an exact point in time becomes an afterthought. Let the build run as long as it needs.\nNot only do you get fast updates. If the connection to your CMS breaks for whatever reason, users are still able to see the old content. There’s no arguing that this is definitely better than seeing no content at all.\nThere are many more use cases for a model like this. Updates on time-critical pages are one thing but think of different modes for your site. You publish statically generated pages fetching all recent data at once at build time. You have a preview mode for your content creators and editors to see what they’re currently working on hosted someplace else.\nimport {\n  useStoryblok,\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story: initialStory, preview }) {\n  if (preview) {\n    // Load draft articles in preview mode.\n    let story = useStoryblok(\"react\", { version: \"draft\" });\n    return <StoryblokComponent blok={story.content} />;\n  }\n\n  return <StoryblokComponent blok={initialStory.content} />;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Load published data in build mode.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'published',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n  };\n}\n\nNice! Give your editors some taste of what they’re actually working on!\nIncremental Static Updates\nFetching time-sensitive data on the client-side is one idea to update your page without a full rebuild. It’s great if you want to have fast updates, but you might see a huge switch between the pre-built. If your hosting solution allows it, tools like Next.js allow you to incrementally update content after a certain retention period.\nThis article on Smashing Magazine by Lee Robinson goes into incremental static regeneration in full detail. The story in a nutshell: The web server serves statically generated content. You define how long this content is supposed to be valid. If at the time of serving this period has elapsed, Next.js triggers a serverless function that renders the desired page new and overwrites the original page with the newly generated HTML. Quite a task, for you it’s just one line of code you need to add.\nimport {\n  useStoryblok,\n  useStoryblokApi,\n  StoryblokComponent,\n} from '@storyblok/react';\n\nexport default function Home({ story: initialStory }) {\n  // We are fetching new data from our CMS.\n  let story = useStoryblok(\"react\", { version: \"draft\" });\n\n  // If data isn't available, yet, we show the original static data.\n  if (!story.content) {\n    story = initialStory;\n  }\n\n  return <StoryblokComponent blok={story.content} />;\n}\n\nexport async function getStaticProps({ preview = false }) {\n  // Here, we are loading all data for static generation.\n  const storyblokApi = useStoryblokApi();\n  let { data } = await storyblokApi.get(`cdn/stories/react`, {\n    version: 'draft',\n  });\n\n\n  return {\n    props: {\n      story: data ? data.story : false,\n      preview,\n    },\n    revalidate: 3600 // Check back after 1 hour if there's new content.\n  };\n}\n\nNow we have three points where we access our headless CMS from:\n\nOnce a build for all available content.\nFor time-sensitive data on the client-side. Fallback to the original content.\nIn a serverless function for every page we want to update incrementally.\n\n\nSoft Coupling\nAll three connection points work for different time frames.\n\nReal-time client-side data fetching has the shortest life span and gives you the most recent content.\nIncrementally generated static pages have a longer life span and give you content that is of a certain age.\nBuild-time generated static pages have the longest life span and are as recent as you configure them. Their life span is significantly shorter if you rebuild on every content update, it’s longer if you only rebuild at code changes.\n\n\nBut by adding all the connection points to our CMS, something else has changed. We coupled ourselves more often to an external system than before, but every connection is allowed to fail.\nIf a real-time update on the client-side fails for whatever reason, we still see the content of the incrementally generated page. If this connection didn’t work, we see what we generated on build time.\nNote: The examples above use Next.js mostly because Next.js allows us to get all that benefit with very little to do for us developers. Especially with the hooks from Storyblok data fetching becomes a single line of code. The same principles of soft coupling can be applied to other sites and frameworks as well.\nLet’s say you generate all your content on the server-side using Express.js. The following route would fetch content with every request to the server:\napp.get('/*', function (req, res) {\n  var path = url.parse(req.url).pathname;\n  console.log(path);\n  path = path == '/' ? 'home' : path;\n\n  Storyblok.get(`cdn/stories${path}`, {\n    version: 'draft',\n  })\n    .then((response) => {\n      // Render content to HTML.\n      res.render({\n        story: response.data.story,\n      });\n    })\n    .catch((error) => {\n      res.send(error);\n    });\n});\n\nIf the bridge to our CMS fails, so does delivering our content. Adding another connection point serves cached content first and does updates in the background.\napp.get('/*', function (req, res) {\n  var path = url.parse(req.url).pathname;\n  console.log(path);\n  path = path == '/' ? 'home' : path;\n\n  // Loading the cached content.\n  let content = contentMap.get(path);\n  if (content) {\n    Storyblok.get(`cdn/stories${path}`, {\n      version: 'draft',\n    }).then((response) => {\n      // Update in the background.\n      contentMap.set(path, response);\n    });\n\n    return res.send(content);\n  }\n\n  // Fetching the real content.\n  Storyblok.get(`cdn/stories${path}`, {\n    version: 'draft',\n  })\n    .then((response) => {\n      contentMap.set(path, response);\n      res.send({\n        story: response.data.story,\n      });\n    })\n    .catch((error) => {\n      res.send(error);\n    });\n});\n\nAnd with some added metadata on revalidation, we can even check for updates after a certain period of time:\napp.get('/*', function (req, res) {\n  var path = url.parse(req.url).pathname;\n  console.log(path);\n  path = path == '/' ? 'home' : path;\n\n  // Loading the cached content.\n  let content = contentMap.get(path);\n  if (content) {\n    // Check if the revalidation window has elapsed.\n    if (content.fetchedDate + content.revalidate < Date.now())\n      Storyblok.get(`cdn/stories${path}`, {\n        version: 'draft',\n      }).then((response) => {\n        contentMap.set(path, {\n          response,\n          fetchedDate: content.fetchedDate,\n          revalidate: content.revalidate,\n        });\n      });\n\n    return res.send(content.response);\n  }\n\n  // Fetching the real content.\n  Storyblok.get(`cdn/stories${path}`, {\n    version: 'draft',\n  })\n    .then((response) => {\n      // Store with some metadata for revalidation.\n      contentMap.set(path, {\n        response,\n        fetchedDate: Date.now(),\n        revalidate: 3600000, //in ms\n      });\n      res.send({\n        story: response.data.story,\n      });\n    })\n    .catch((error) => {\n      res.send(error);\n    });\n});\n\nAdd this with some client-side caching using stale-while-revalidate to add an extra fallback for your revisiting users.\nBottom Line\nHeadless content management systems allow you to add a clear boundary between the content you deliver and the content that is being maintained by others. This clear separation lets a CMS focus on content management again, instead of blurring the line between content and its design.\nBut it’s not only that. When deploying websites, there’s rarely a one-size-fits-all solution. Some websites benefit from server-rendered pages, some prefer statically generating content upfront. A headless CMS works with all approaches, allowing you to mix and match depending on your needs.\nWe just played through one possibility of adding a headless CMS to our stack and connecting it from various sources to make our site more resilient without losing the flexibility to deliver time-relevant content. And that’s just one of many.",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/f290e32b-b1fa-42d0-989e-21a751f27d00/resilience-flexibility-immediacy-headless-systems.jpg",
      "date_published": "2022-05-05T09:30:00.000Z",
      "date_modified": "2022-05-05T09:30:00.000Z"
    },
    {
      "id": "https://smashingmagazine.com/2022/05/designing-better-language-selector/",
      "url": "https://smashingmagazine.com/2022/05/designing-better-language-selector/",
      "title": "Designing A Better Language Selector",
      "summary": "How difficult can it be to design a bulletproof language selector? It’s not as straightforward as one might think. We need to avoid redirects, decouple our language and country presets, allow for overrides, and use non-modal windows. Let’s dive in!",
      "content_html": "<p>Imagine that you’ve just arrived in Tokyo. Full of impatience and excitement, you are just about to hit the road, yet there it comes: an <strong>urgent warning</strong> from your mobile provider, nudging you to top up your dwindling balance. With some justified concern, you go to the website, just to be redirected to the <strong>Japanese version of the site</strong>. You can’t read Japanese just yet, yet there is no obvious option to change the location, and there is no option to change the language either.</p>\n<p>As the data keeps dwindling, you juggle between auto-translation and your limited VPN options — just to run out of data in the middle of the session. The language selector is somewhere there, yet it’s disguised between cryptic symbols and mysterious icons, nowhere to be found on the spot.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7ad18cfe-12b4-4fb4-81bb-9695dc0cb9d9/1-designing-better-language-selector.png\" /></p>\n<p>Chances are high that at some point you had a similar experience as well. As designers, we can of course make language selectors <strong>more obvious and noticeable</strong>, yet most of the time, the appearance of a component is only a part of the problem.</p>\n<p>Too often, when we design interfaces, we subconsciously embed our <strong>personal assumptions</strong>, biases and expectations into our work. Of course, we can’t possibly consider all exceptions and all edge cases, along with all happy or unhappy coincidences. So we focus on the most common situations, eventually breaking a beautifully orchestrated user experience entirely for some of our disgruntled users.</p>\n<p>Can we fix it? Absolutely! We just need to decouple presets, allow for overrides and allow users to specify their intent. But before we dive in, let’s explore what options we have in front of us.</p>\nThe Fine Little Details Of A Language Selector\n<p>Usually, we know when we need a language selector. Every multi-lingual website will need one, and this definitely holds true for public services and companies residing in countries with multiple national languages. It is also necessary for <strong>global brands</strong>, organizations and the hospitality industry — as well as eCommerce where goods might be paid in various currencies and shipped to various destinations around the world.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d021f79c-3c78-4f37-9d53-7ffa1418b5ba/2-designing-better-language-selector.png\" /></p>\n<p>Where do we place a language selector? Well, users have their usual suspects of course. In my experience, when asked to change a country or language, a vast majority of users will immediately <strong>head to the header of the page first</strong>, and if they can’t find it there, they’ll jump all the way to the bottom of the page and scout the footer next.</p>\n<p>As for indicators of country selection, flags actually do work fairly well, and if users can’t spot them, they seek other icons that might represent a language in one way or the other — such as the globe icon or a “translation” icon. Obviously, when it comes to translations of articles or specific pages, users rely on the <a href=\"https://learnui.design/blog/the-3-laws-of-locality.html\">laws of locality</a> and search for a selection of language next to the title of the article. So far so good.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/cc54664b-cd80-4df1-b01b-9355d1dc5fb0/3-designing-better-language-selector.png\" /></p>\n<p>Design-wise, however, there are plenty of intricate details that we need to account for. Surely the selector on its own will live somewhere in the footer of the page, and it is also very likely to make its appearance in the header as well. However, we could also <strong>auto-redirect users</strong> based on their location and <strong>auto-detect language</strong> based on the browser’s preferences, or prompt a modal window and ask users to select a region first. We could be using text labels or abbreviations, icons or flags, native or custom dropdowns, preferences panes or sidebars, toggles, or standalone pages.</p>\n<p>As we will see, many of these solutions have usability issues on their own; and if we want to <strong>maximize clarity and reduce ambiguity</strong>, we need to come up with a proper strategy of how to label and group languages, how to present them, and how to make the language selector obvious to users — without running into a wild mixture of accessibility and auto-translation problems down the line.</p>\n<p>Let’s start with something that is probably obvious, but worth stating nevertheless — auto-redirects might be helpful, but they often cause more frustration and annoyance than a help.</p>\nAvoid Auto-Redirects\n<p>Many websites rely on redirects based on <strong>user’s location (IP) or browser’s language</strong>. However, if a person is located in Tokyo, it doesn’t necessarily imply that they fluently read Japanese. And if their preferred locale is Dutch, it doesn’t mean that they want to deliver physical items to the Netherlands. In the same way, if the preferred locale is French, yet it isn’t available on the site, a user might encounter a fallback language that isn’t necessarily the language that they are most comfortable with.</p>\n<p><strong>We can’t confidently infer users’ preferences</strong> without asking them first. That doesn’t mean that we should avoid redirects at all costs though. If a user happens to be connecting to a US website from Germany, it‘s perfectly reasonable to nudge them towards a German website. But if they happen to be connecting to a German website with an English locale preferred, it would be confusing to redirect them to the UK or US version of the site — even though it might very well be the user’s intent in some rare cases.</p>\n<p>In general, <strong>redirects based on location</strong> are probably more instructive than redirects based on the browser’s language, but they are error-prone, too.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/daed8803-d2c8-4d9e-a963-e0391faef8cf/4-designing-better-language-selector.png\" /></p>\n<p>On the very first visit, <a href=\"https://www.dyson.be/fr\">Dyson.com</a> nudges visitors to select the preferred region and language in the header on the page. Users can dismiss the bar and locate the language selector in the footer of the page again.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7863bbe0-79d5-4084-8066-680ca9beb278/58-designing-better-language-selector.png\" /></p>\n<p><a href=\"http://backcountry.com/\">Backcountry</a>, a US company for outdoor gear and clothing, automatically redirects its users to another site. Since 2018, the website is no longer available outside the U.S. as an answer to the GDPR regulations. Without a VPN, it’s <strong>impossible to reach the website</strong>, for example, to purchase and deliver a gift for a friend located in the U.S.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/22c0525d-38ff-4c10-b652-8205f06aa8e6/59-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.audi.com/de.html\">Audi</a> automatically redirects users to a country deemed as a <strong>best fit</strong>. However, users can choose their country by clicking on the language selector in the right upper corner. On click, a modal shows up with autocomplete and a disabled “Continue” button.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/de3b13bb-641e-499a-9573-8b411b12a37e/60-designing-better-language-selector.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/99550a32-ad47-466d-b310-8630920b517a/61-designing-better-language-selector.png\" /></p>\n<p>A global <a href=\"https://www.bmw.com/\">BMW website</a> doesn’t automatically redirect users to any website. Instead, you can locate the <strong>“BMW in your country” option</strong> in the right upper corner of the header. It opens a modal with all the options listed, along with the prominent button at the top “BMW in your country”, which, on click, redirects users to the website considered to be the best fit for them. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/99f66be3-fee3-4d15-a887-4ebe11a23725/62-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.ikea.com/\">IKEA</a>, without an automatic redirect, but with a very large country selector that understands <strong>domains, endonyms and languages</strong> of the largest countries in the world. The “Go shopping” button might be the biggest button in the world and might deserve a spot in the World Guinness Records Book. Unfortunately, on the site, you can change the country, but not always the language.</p>\n<p>While <strong>polite nudging is reasonable</strong>, automatic redirects are not. Once we start moving users from one site to another without asking them at all, we start baking our assumptions into the design, and that’s usually a red flag. We shouldn’t be surprised by increased levels of frustration and abandonment as a result. Ironically, this data is rarely tracked or known as the abandonment is happening on the “other” website, with different departments and teams on the other side of the globe.</p>\n<p>Either way, whether we want to nudge users towards a different website, or we absolutely need to use an auto-redirect, it’s definitely a good idea to always allow users to <strong>override redirects</strong> with manual preferences. This requires us to tame our assumptions and decouple our presets.</p>\nDecouple Location and Language Presets\n<p>Many websites rely on an assumption that <strong>location, language and currency</strong> are usually tightly coupled. After all, if a user chooses a location in Germany, they are very likely to prefer the German language and see prices in Euro. However, this is based on assumptions that work for many people, but <strong>break the experience entirely</strong> for others.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8c54d2c5-531a-4f7d-a0c2-de938e96d559/6-designing-better-language-selector.png\" /></p>\n<p>For example, if you want to purchase sneakers on <a href=\"https://www.adidas.de/\">Adidas</a> from Germany but deliver them to your friend in Poland, you need to be able to make sense of the Polish language when checking out. You can either choose the German language with delivery to Germany or the Polish language with delivery to Poland. It’s impossible to select the English language with delivery options to Poland, for example. In other words, <strong>both language and location are tightly coupled</strong>.</p>\n<p>As it turns out, there are plenty of scenarios where this assumption doesn’t work:</p>\n<ul>\n<li>A person is using a <strong>German VPN</strong>, but not be located in Germany nor understands German;</li>\n<li>A person is connecting from Germany, but be <strong>visiting for a few days</strong>, and they might not speak nor read German at all;</li>\n<li>A person is living in Germany, access a website in German, but prefers to pay with a company’s credit card in USD, rather than in EUR;</li>\n<li>A person is living in Germany might want to deliver an item from an American store to an <strong>American friend</strong>, but keeps getting redirected to a German website;</li>\n<li>A person is connecting from the USA but needs to be able to provide a VAT number because the product will be purchased by a German office with a <strong>German credit card</strong>.</li>\n</ul>\n<p>Of course, we might consider all these situations to be <strong>very rare edge cases</strong> and dismiss them. But first, we need to track how many people actually experience such issues and end up leaving as a result. In practice, especially for global brands, these numbers might be more significant than one might think.</p>\n<p>These problems appear because we frame common situations in tightly coupled and rather <strong>inflexible presets</strong>. Surely presets are useful as default options, but they break down when defaults aren’t good enough. That’s why it’s usually a good idea to decouple all presets, and allow users to make standalone choices.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4487f1b3-80ff-4582-84fb-e8cda00968d9/7-designing-better-language-selector.png\" /></p>\n<p>On <a href=\"https://mondraker.com/es/es\">Mondraker</a>, users <strong>select location and language separately</strong>. All countries are grouped into tabs, and at the bottom users can choose the language of their preference. A very similar design, but a quite different approach. A downside: labeling all countries in a selected language is probably not as effective as using corresponding native labels instead.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/63fa1fc9-56ea-49b7-9c8e-9ac4fd171227/monese.jpg\" /></p>\n<p><a href=\"https://monese.com/gb/en\">Monese</a> shows <strong>two tabs</strong> in the right upper corner of the header. Users can switch between language and country, defining preferences for each separately.</p>\n<p>User preferences don’t have to be limited by country and language alone. We can allow users to <strong>customize further parts of the UI</strong>, from currency and auto-translation to units of measurement and date formatting.</p>\nAllow Users To Set Custom Preferences\n<p>For many sites, language and location are just the first important attributes that convey what website might be a good fit for a customer. However, to deliver value to users, we might want to go a little bit beyond that.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b68d4436-0398-4961-873d-303fc190a6d9/9-designing-better-language-selector.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/487e522a-d728-4cf2-aae0-272c7e91c2d1/10-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.revolve.com/\">Revolve.com</a> uses <strong>language, country and currency presets</strong> based on the user’s IP and their browser’s locale. However, users can override these presets with custom preferences. They can choose a country for shipping, the language on the site and the currency. The hint for preferences is located in the header, with a combination of a language abbreviation, flag and a currency indicator.</p>\n<p>These details are enough to <strong>show all products with the final price</strong> that includes delivery costs to their country and in the currency that’s most familiar to them. That’s what the perfect decoupling of location, language and currency is.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a3e27ccb-60b3-4c08-9062-a3b35e1d5fce/11-designing-better-language-selector.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1b34af0e-c9e1-4155-acc6-085a697362a2/12-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.airbnb.com/\">AirBnB</a> suggests languages and regions in groups, but also allows users to adjust their preferences and choose a language and region of their choice. Additionally, users can <strong>opt-in to automatically translate descriptions</strong> and reviews to English. The modal is prompted by a tap on the globe icon in the right upper corner of the header.</p>\n<p>Once the settings are set, users can jump from one location to another, <strong>compare prices in the same currency</strong> and see reviews automatically translate to a language that they might understand better. That’s undoubtedly a win for the users.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2fd37bf3-01e8-4dcc-a584-b715c599e310/13-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://de.iherb.com\">iHerb</a> goes the extra mile by providing a whole range of additional preferences for their users. Not only can users choose their language, preferred currency and shipping destination (and specify it with ZIP code for US destinations) — they can also choose <strong>preferred units of measure</strong> and check available payment methods and available shipping methods. Bonus points for smart autocomplete input rather than a not-so-good old-fashioned <a href=\"https://www.fuckdropdowns.com/\">&lt;select&gt;-dropdown</a>. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/63d0d8f5-bbd2-4695-8a12-dc860e99218b/14-designing-better-language-selector.png\" /></p>\n<p>Some slightly different preferences can be defined on the <a href=\"https://www.ssga.com/de/en_gb/institutional/etfs/funds/spdr-sp-500-ucits-etf-dist-spy5-gy\">State Street of Global Advisors</a>. On the first visit, a modal window appears explaining to users some of the assumptions that the interface is making about the location and their interests. Within the modal window, users can change a location, <strong>specify their role</strong> and choose a preferred type of site for their visit. </p>\n<p>In general, these are some of the useful adjustments that we could allow users to specify to customize the entire experience for them:</p>\n<ul>\n<li>Shipping location</li>\n<li>Preferred currency</li>\n<li>Units of measure</li>\n<li><strong>Time/date formatting</strong></li>\n<li>Time zones preferences</li>\n<li><strong>Level of experience</strong></li>\n</ul>\n<p>The question, of course, is how to <strong>surface all these settings to the user</strong> — in a separate settings page, as a sidebar, in the header, or the footer? One disputable option is to show the settings in a modal or non-modal window upon entry to the site.</p>\nA Case For Non-Modal Dialogs\n<p>Admittedly, modal windows are <a href=\"https://www.nngroup.com/articles/modal-nonmodal-dialog/\">rarely a good idea</a>. They are disruptive and annoying as they require immediate attention. However, they are appropriate when we need to draw the user’s attention to important details — be it loss of data, mutually exclusive preferences or critical errors.</p>\n<p>Some of the websites listed above <strong>prompt a modal window</strong> on the very first visit, asking users to specify their intent and their preferences before using the site. On others, default presets are silently applied, with an option to adjust them if needed — sometimes in a modal, and sometimes on a dedicated page.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2597d68b-0e79-4751-868c-b79d879d5980/15-designing-better-language-selector.png\" /></p>\n<p>While modal windows will always be noticed, <a href=\"https://youtu.be/mAiNdU1go1A?t=3744\">usability tests show</a> that they are often <strong>instinctively dismissed</strong>, sometimes even before users realize what content they contain. On the other hand, users often don’t pay attention to any accessory navigation such as choice of currency, measurements or shipping location as they are very much focused on products. It’s only if the change of the language is necessary that they might notice that further settings can be adjusted as well.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d8ba0d6d-628e-4520-9bc8-af8bc993dc20/16-designing-better-language-selector.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a4caba1d-fcb7-4ff4-ad75-47f42d539173/17-designing-better-language-selector.png\" /></p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e9130a99-6bdf-4e6b-9f9c-ef4dbf900cb7/18-designing-better-language-selector.png\" /></p>\n<p>Rather than using one modal with tabs, <a href=\"https://booking.com/\">Booking</a> uses <strong>separate buttons</strong> in the header for currency and language. The interface infers some settings from the user and applies them directly, with an option to override these settings. Rather than using a <code>&lt;select&gt;</code>-dropdown, which is often the slowest form component, all options are <strong>displayed in plain text</strong>, hence being searchable by in-browser search.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/1f97dfc6-f254-45b4-88c1-1765459a05a2/19-designing-better-language-selector.png\" /></p>\n<p>For comparison, <a href=\"https://www.skyscanner.com/\">Skyscanner</a> allows users to prompt all customization options with one large button, grouping all options in a few drop-downs. Also, the interface always allows users to fall back to the English language if they’ve accidentally made a mistake.</p>\n<p><strong>Which option is better?</strong> Ultimately, this will of course be decided by usability tests. In this particular case, showing a modal window upon entry might not be a bad idea since it provides tangible value to users — a value that they might not be able to spot otherwise. However, there might be an alternative option that could work even better — using a <strong>non-modal dialog</strong> instead.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/24eb7a65-0ad6-456d-bda6-0625d946b318/20-designing-better-language-selector.png\" /></p>\n<p>Upon website entry on <a href=\"https://www.patagonia.com/home/\">Patagonia</a>, a <strong>sticky non-modal dialog</strong> appears in the left bottom corner. Users can choose location and language and save their preferences as a cookie. They can also always bring the selection back by accessing the preferences bar in the footer. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2bccba3f-eb0e-49dd-8258-d01d982a35be/22-designing-better-language-selector.png\" /></p>\n<p>In the mock-up above, the important <strong>content isn’t blocked by the modal</strong>; users can scroll, navigate, select and copy-paste. However, the preference pane appears in the bottom right section of the screen. It can also be collapsed or minimized, but it does require an action from the user. It is a little bit more intrusive than when silently placed in the global navigation, but is easier to discover as well.</p>\n<p>If you aren’t certain about the best option for your project, consider adding a link in the navigation bar first. Measure <a href=\"https://www.smashingmagazine.com/2022/04/boosting-ux-with-design-kpis/\">design KPIs</a> and test how they change with a non-modal option — a much <strong>less intruding and more friendly</strong> option — and ultimately a modal. Chances are high that the modals might perform better than one might think.</p>\nClick-Through Menus For Countries\n<p>Large corporations know the problem too well: navigating dozens of options in a <strong>small overlay</strong>, or even a large modal is quite cumbersome and requires a <strong>healthy dose of scrolling</strong>. So it’s not very surprising that often websites present all available options on separate pages, broken down by regions and sometimes illustrated with country flags.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/91c91e45-b876-47dc-b9c8-9f25920d0dff/23-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.revolut.com/en-DE/change-country\">Revolut</a> displays all available options on a separate, dedicated page. The countries are <strong>written in the English language</strong>, organized in groups and listed alphabetically. However, the page doesn’t only showcase available locations, but also locations that aren’t available yet. For this particular case, it might be a good idea to allow users to filter — e.g. hide all unavailable locations, perhaps with a toggle or tab above the list.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/47815086-19ca-40f8-becc-3976efb7bdfd/24-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.logitech.com/en-us/change-location.html\">Logitech</a> displays most <strong>languages in their local format</strong> — e.g. “Deutschland” for Germany, and “中文” for China. This eliminates the assumption that the user needs to understand English to find the country or language of their choice. On the page, all countries (and available languages) are grouped by geography and displayed across columns, making it easier for users to discover them.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e6455e05-dd05-40e9-b569-2285d5875d5c/25-designing-better-language-selector.png\" /></p>\n<p>Rather than displaying all available options on one long page, <a href=\"https://dell.com/\">Dell</a> breaks countries by regions within <strong>tabs</strong>. No flags are being used, making the scanning a bit more difficult. Countries and languages are combined. In this case, less scrolling is required to find a location that would fit users best.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/e2fd9092-d5d1-48f7-ae55-970c7b2feb2b/26-designing-better-language-selector.png\" /></p>\n<p>Not all tabs are alike though. <a href=\"https://www.cisco.com/\">Cisco</a> uses a small overlay with <strong>vertical tabs</strong>, rather than horizontal ones. This makes the selection very compact, and the solution very straightforward. It’s worth noting that the main disadvantage of tabs is that they make the content inaccessible with an in-browser search (well, <a href=\"https://twitter.com/addyosmani/status/1520459804656824320\">for now</a>). The user always has to select a region first.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/738ff172-4cea-464e-88c4-b90673eda4cc/27-designing-better-language-selector.png\" /></p>\n<p>Another option, of course, is to group the countries with a <strong>vertical accordion</strong>, as it’s done on <a href=\"https://www.edreams.gr/\">eDreams</a>, for example. You might need a bit more vertical space as a result, but all options can be scanned from top to bottom in one go.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/93e870cc-5400-4dac-a225-899021f3eb0e/63-designing-better-language-selector.png\" /></p>\n<p>A slightly different kind of country selector on <a href=\"https://www.oracle.com/index.html\">Oracle</a>: a <strong>click-through overlay menu</strong>, with all countries grouped, rather than displaying a standalone page. That’s a very compact and straightforward solution.</p>\n<p>If you need to display a wide range of languages, explore if you can group and display them on a single page. If it’s getting too overwhelming, consider grouping them within accordions or tabs — assuming that tabs appear like tabs and don’t contain cryptic labels. Or even better: provide users with poignant autocomplete suggestions.</p>\nShow Autocomplete Suggestions\n<p>Getting autocomplete right isn’t an easy task. This is especially difficult if we are dealing with multiple pieces of information at once, i.e. both country and language. For it to work well, we need to <strong>support frequent abbreviations</strong>, <a href=\"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_and_their_capitals_in_native_languages\">endonyms</a>, and shorthands for all available options. And then, of course, our autocomplete suggestions should display both countries and languages, with an option to choose one option or another. Plus, we also might want to consider the support of multiple “primary” languages (English, French, Spanish, to name a few). Thats’ not easy at all!</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/24fff3ea-2a49-4bbd-bcdc-37e92bb4b365/64-designing-better-language-selector.png\" /></p>\n<p>On <a href=\"https://frame.work/de/en/locale/edit\">Framework</a>, users can select country and language separately, both with autocomplete, with the <strong>most frequent options highlighted</strong> on focus. There is no need to scroll through the list of countries to find the preferred option. While this might be perfectly enough for some scenarios, it might not be sufficient in a situation when the user’s country isn’t available in the list. Instead, we could indicate the <strong>closest locations</strong> to the preferred option, rather than guiding a user to a dead end.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/92d45ad8-c24b-4bb3-b5fb-a07e6a0bbb3c/30-designing-better-language-selector.png\" /></p>\n<p>In the mock-up above, <strong>“4 locations nearby”</strong> could open an accordion, highlighting the closest locations next to Lithuania (<em>Lietuva),</em> indented.  This pattern might not be applicable when a user is trying to open a new bank account, but it might be useful when a user is looking for a particular office in their country, but can’t locate it.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/83e6d480-3ce5-4715-ab00-292445d969ea/31-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://wise.com\">Wise</a> also includes autocomplete for language settings. If the same language appears in multiple items, the autocomplete specifies what country it refers to. All language options are presented in their local format.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d7f1725a-990b-43f6-9cc5-f57473c57e8b/32-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.porsche.com/\">Porsche</a> uses an accordion along with autocomplete as a page overlay. The interface supports abbreviations and indicates available options with flag icons.</p>\n<p>Undoubtedly autocomplete is a great addition to language selection. However, when testing it, explore how people use autocomplete, and what they are actually typing to find their country. Sometimes the <strong>fine-tuning of making autocomplete work</strong> for many different languages might be an effort way too underestimated and way too time-consuming. </p>\nGrouping Countries\n<p>Not every location or language has to represent with a separate entry in the language selector. If multiple countries are speaking the same language, what if indicated by grouping countries within one option?</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4044800c-6c28-484d-b5ab-0ece50411fd8/33-designing-better-language-selector.png\" /></p>\n<p>Daniel Marchini has come up with an <a href=\"https://dribbble.com/shots/2386084-Language-Selection-Modal/attachments/9275096?mode=media\">interesting concept</a> of <strong>grouping flags within a single selection</strong>. If the content will appear exactly the same for multiple countries, is it really necessary to show them separately? For example, the Portuguese language is displayed as an option for Portugal and Brazil, while the Spanish language is highlighted for Mexico and Spain. Obviously, not all countries could be grouped this way, but if you target users from specific countries, this might be worth a shot.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/b4218426-66cd-40d0-b95d-daf126ba15ef/34-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.airwallex.com/eu\">Airwallex</a>’s country selector groups all European countries as “European Union”. The service is available in the <strong>entire European Union</strong>, so it’s not necessary to select an individual country. However, if you have a slightly longer list of options, and you are looking for an option to open a bank account in the Netherlands, you might need a bit of time to realize that the Netherlands is assumed as a country within the European Union.</p>\nUse Flags For Countries, Text Labels For Languages\n<p>When designing a country selector, it feels almost natural to think about the flags they are represented by. After all, compared to just plain text, it should be much easier for users to locate the icon that they can immediately recognize. This is indeed true, however, as James Offer has suggested in his wonderful blog on <a href=\"http://www.flagsarenotlanguages.com/blog/\">Flags are not languages</a>, flags are specific to countries, but <strong>languages often cross borders</strong>.</p>\n<p>We can find French-speaking people in Canada, Vietnam, Senegal, Switzerland, and many other countries. It would be inaccurate to assume that all users from these countries associate their choice of language with a French flag. </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/a8c6a273-46ac-404c-9329-5717c41ba600/36-designing-better-language-selector.png\" /></p>\n<p>In the article “<a href=\"https://uxdesign.cc/my-take-on-language-selectors-945caceb58f7\">My Take On Language Selectors</a>”, Zsolt Szilvai shows an interesting example of such a conundrum. During the usability tests of an application designed for the UAE, many people found the fact that the Arabic language was visualized with one single flag, as it is used in many countries and cannot be identified with any particular flag alone.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/11512b03-5609-47ad-a9af-a0c40fdb9a7d/65-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.curve.com/\">Curve.com</a> opts in for a default international version which is available in English. There are a few other options available as well but one might wonder about the difference between “International (English)” and “English (United States)”. When flags are used to indicate languages, it can quickly become a little bit confusing.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8b7e3224-7d89-4954-8e69-4b374c42cc5e/39-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.backmarket.com/\">Backmarket</a> includes a <strong>list of flags in the footer</strong> of the page to indicate local sites of the marketplace. When we want to drive users to specific local websites, we can safely use flags that best represent countries, rather than languages. Many sites also just add links in the footer instead, making language labels easier to find with an in-browser search.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4b843148-26fe-4727-8711-62c516c5c937/40-designing-better-language-selector.png\" /></p>\n<p>Flags for countries, and plain text for languages. Everything seems to be about right on <a href=\"https://www.bol.com/nl/nl/\">Bol.com</a>. The country selector (with a flag) is located in the right upper corner, where most users expect it.</p>\n<p>To avoid misunderstandings, make sure that you use flags if your users need to select a <strong>specific country</strong>. However, if you’re providing users with a choice of a <strong>specific language</strong>, then flags are probably not going to work well. There, an autocomplete with all available countries and labels for languages written next to them might work better.</p>\n<p>This of course brings up a question: how should these labels actually be written? In English or in a language’s local format?</p>\nLabel Languages Locally\n<p>Assumptions are error-prone, and if it goes for combinations of currency, language and location, this holds true for how we label languages as well. We shouldn’t assume that a user will be speaking one of the languages we choose to see as a default option. Instead, when users select a language, usually it’s better to always use the name of the language <strong>in its local format</strong>.</p>\n<p>So rather than offering a choice of <em>German</em> and <em>Chinese</em>, assuming that users understand English, we can label these options as <em>Deutsch</em> and <em>中文</em>.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d6bc7abb-fd85-4e41-8e7e-42cb254543f7/41-designing-better-language-selector.png\" /></p>\n<p>But if the languages are labeled locally, somebody who happens to be in China might be experiencing issues switching to a slightly more familiar language. Surely flags would help to locate a button that would allow for that, but we could also <strong>prefix the selected language with a label</strong>, for example, “Language” to make it easier to spot the selector. Or we could just add a link saying “English” in the header. This of course relies on assumptions we are making, but it might be easier than hopping through the navigation bar and view-source with fingers crossed.  </p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/00ebb517-4ae3-4b08-9b7c-6b9e8f6a8e6b/66-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://booking.com/\">Booking</a> provides a hint to indicate that users can change the language in a local language. If you prefer to show a hint on hover, that’s one of the very few cases where one might consider using a language that many users would understand, and it could be English.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/8e25fc2d-cf29-4872-a2be-08deea0c49b3/45-designing-better-language-selector.png\" /></p>\nThe Globe and Translate Icons\n<p>Since flags can be somewhat problematic, what would be a reasonable alternative to them? As briefly mentioned at the beginning of the article, we can also use icons such as “Globe” or “Translate” to indicate the choice of locales. There is as well an <a href=\"http://www.languageicon.org/\">official language icon</a>, which is free to use, but unfortunately is still not as recognizable as the other icons.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/97a39647-f975-4089-88e1-4f110ee3f7cb/47-designing-better-language-selector.png\" /></p>\n<p>Surely not everybody will be able to understand the icon in combination with a word that they can barely decipher, but if it’s prominently located in the header or the footer, the chance to be discovered are significantly higher.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/efbe04fc-8e61-4471-9fa8-5381431ead89/48-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://www.tomorrow.one/en-EU/\">Tomorrow.one</a> displays a large drop-down selector with a globe icon in the footer of each page. It’s not available in the header on the site. Because pages aren’t very long, that’s probably not a big problem, but users might give up if they have to embark on a long-running scrolling marathon, or if the <a href=\"https://www.smashingmagazine.com/2022/03/designing-better-infinite-scroll/\">infinite scroll</a> prevents them from reaching the footer.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/4aa08b40-3b51-4b17-9c62-925d6b443ac9/49-designing-better-language-selector.png\" /></p>\n<p>On <a href=\"https://www.atlassian.com/it/software/jira\">Atlassian</a>, the language selector is tucked at the very end of the page in the footer, with a globe icon indicating the selection. However, if the user with a different browser language preference enters the site, it <strong>suggests changing the language</strong> at the very top of the page, with a globe icon appearing there, too.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ac61ad17-d208-494e-8d06-599185c32658/51-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://monday.com/lang/ko/\">Monday.com</a> keeps the language selection at the very top of the page, in the left upper corner. All options are presented in <strong>three columns</strong>, with the current selection highlighted in blue.</p>\n\n<p>While flags are easier to recognize, icons can work as an alternative option as well, especially if you need to provide users with language options, rather than choices for location. Even if the selection is provided in the header, it’s a safe bet to also place it at the bottom to ensure that users can find it when they need to. </p>\nAvoid Language Shorthands or Initials\n<p>Another interesting problem that Zsolt Szilvai has <a href=\"https://uxdesign.cc/my-take-on-language-selectors-945caceb58f7shows\">discovered</a> in testing is related to the use <strong>abbreviations, initials or shorthands</strong> to indicate a particular language. When we are running out of space in navigation, we could be using “EN” for English, or “DE” for Germany, or “UA” for Ukraine. Indeed, these shorthands are often well-understood, but they bring surprising results when a user’s browser auto-translates all websites in a particular language.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/d5613484-7ffd-4d5c-9efa-ee7c323c51be/decathlon.png\" /></p>\n<p>Not only does it often result in broken menus and surprising layouts; <strong>browsers also translate language shorthands</strong>, producing an interface that might be very difficult to make sense of. However, were the shorthands avoided in favor of the full local name of the language, the user wouldn’t have to deal with these issues at all. Instead, the translator would help them find a language that would work better for them.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/2e234f38-b784-42f4-81f7-c246166608b0/56-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://n26.com/en-eu\">N26.de</a> uses a shorthand “EN” for “English”. The selected language is <strong>disabled in the list of options</strong>, but it’s probably a good idea to increase the color contrast a little. As users scroll down the page, the header remains sticky, so there is really no need to display the language selector in the footer as well.</p>\n<p><img src=\"https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ac7ed3ac-091e-4c3e-a198-c2a8e4924553/57-designing-better-language-selector.png\" /></p>\n<p><a href=\"https://wise.com/\">Wise</a> uses shorthands for language selection in the right upper corner, but displays the <strong>languages in full</strong> on click, with a noticeable focus style to indicate where a user currently is. This avoids the problem of auto-translation that often turns abbreviations into seemingly random strings.</p>\nWrapping Up\n<p>The country and language selector might appear like a quite trivial design challenge, but there are plenty of fine details that make or break the experience. When designing one, always <strong>decouple presets</strong> and reduce assumptions about groups that are likely to go together. Users expect the language selector to be located in the header or the footer of each page, and they often watch out for flags, “Globe” or “Translate” icons to find it.</p>\n<p>If you have just a few languages, a drop-down overlay might be perfectly enough. If you need 10–15 languages, perhaps it’s worth exploring the option of a non-modal overlay with autocomplete. If there are even more options to display, consider using a standalone page, with countries grouped into tabs or accordions.</p>\nLanguage Selector Checklist\n<p>As usual, here’s a general checklist of a few <strong>important guidelines to consider</strong> when designing a better language selector:</p>\n<ul>\n<li><strong>Nudge users</strong>, but avoid auto-redirects.</li>\n<li>Decouple presets, be it location, language, or anything else.</li>\n<li>Allow users to set <strong>custom preferences</strong> (currency, time zones, units of measure).</li>\n<li>Consider using a <strong>non-modal dialog</strong>.</li>\n<li>Organize countries and languages in sections, tabs, and accordions.</li>\n<li>Provide input with <strong>autocomplete suggestions</strong>.</li>\n<li>Use flags for countries, but avoid them for languages.</li>\n<li>Consider the <em>Globe</em> and <em>Translate</em> icons instead of flags.</li>\n<li><strong>Label languages locally</strong>, e.g. <em>Deutsch</em> instead of <em>German</em>.</li>\n<li>Avoid language shorthands or initials.</li>\n<li>For accessibility reasons, make sure the country selector appears in the header as well as in the footer, and is keyboard-accessible.</li>\n</ul>\nMeet Smart Interface Design Patterns\n<p>If you are interested in similar insights around UX, take a look at <a href=\"https://smart-interface-design-patterns.com/\"><strong>Smart Interface Design Patterns</strong></a>, our shiny new <strong>7h-video course</strong> with 100s of practical examples from real-life projects. Plenty of design patterns and guidelines on everything from accordions and dropdowns to complex tables and intricate web forms — with 5 new segments added every year. <em>Just sayin’!</em> <a href=\"https://www.youtube.com/watch?v=aSP5oR9g-ss\">Check a free preview</a>.</p>\n<a href=\"https://smart-interface-design-patterns.com/\"><img src=\"https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/7cc4e1de-6921-474e-a3fb-db4789fc13dd/b4024b60-e627-177d-8bff-28441f810462.jpeg\" /></a>Meet <a href=\"https://smart-interface-design-patterns.com/\">Smart Interface Design Patterns</a>, our new video course on interface design &amp; UX.\n\n<div><a href=\"https://smart-interface-design-patterns.com/\">Jump to the video course →</a></div>\n\n<p></p><p>100 design patterns &amp; real-life \nexamples.<br />7h-video course + live UX training. <a href=\"https://www.youtube.com/watch?v=aSP5oR9g-ss\">Free preview</a>.</p>\nResources\n<ul>\n<li><a href=\"http://www.flagsarenotlanguages.com/blog/\">Flags are not languages</a>, a blog by James Offer</li>\n<li><a href=\"https://uxdesign.cc/my-take-on-language-selectors-945caceb58f7\">“My take on language selectors”</a> + <a href=\"https://uxdesign.cc/designing-language-selectors-that-work-well-with-assistive-technology-c645a16e73e7\">accessible implementation details</a>, by Zsolt Szilvai</li>\n<li><a href=\"https://medium.com/nyc-design/ux-practice-skyscanners-language-selector-276167b4ed84\">UX practice: Skyscanner’s language selector</a></li>\n<li><a href=\"https://www.robertjelenic.com/language-switching-ui-ux-on-multilingual-sites/\">Language switching UI/UX on multilingual sites</a>, by Robert Jelenic</li>\n<li><a href=\"https://www.robertjelenic.com/language-switching-ui-ux-on-multilingual-sites/\">Best practices for presenting website language selection</a></li>\n<li><a href=\"https://share-design.kr/en/article/ui-ux-design/1\">UI/UX design of a language selector</a></li>\n<li><a href=\"https://ux.siemens-healthineers.com/ui-marcom/components/language-selection/usage/index.html\">Interesting language selector patterns on Siemens Design System</a></li>\n<li><a href=\"https://usersnap.com/blog/design-language-switch/\">Designing a language switch: Examples and best practices</a>, by Thomas Peham</li>\n</ul>\nRelated Articles\n<p>If you find this article useful, here’s an overview of similar articles we’ve published over the years — and a few more are coming your way.</p>\n<ul>\n<li><a href=\"https://www.smashingmagazine.com/2022/03/designing-better-infinite-scroll/\">Designing A Better Infinite Scroll</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2022/04/designing-better-breadcrumbs/\">Designing Better Breadcrumbs</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2022/04/designing-better-carousel-ux/\">Designing A Better Carousel UX</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2017/06/designing-perfect-accordion-checklist/\">Designing A Better Accordion</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2018/02/designing-a-perfect-responsive-configurator/\">Designing A Better Responsive Configurator</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2021/05/frustrating-design-patterns-birthday-picker/\">Designing A Better Birthday Picker</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2017/07/designing-perfect-date-time-picker/\">Designing A Better Date and Time Picker</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2017/08/designing-perfect-feature-comparison-table/\">Designing A Better Feature Comparison</a></li>\n<li><a href=\"https://www.smashingmagazine.com/2017/07/designing-perfect-slider/\">Designing A Better Slider</a></li>\n<li>“<a href=\"https://www.smashingmagazine.com/printed-books/form-design-patterns/\">Form Design Patterns Book</a>,” written by Adam Silver</li>\n</ul>",
      "content_text": "Imagine that you’ve just arrived in Tokyo. Full of impatience and excitement, you are just about to hit the road, yet there it comes: an urgent warning from your mobile provider, nudging you to top up your dwindling balance. With some justified concern, you go to the website, just to be redirected to the Japanese version of the site. You can’t read Japanese just yet, yet there is no obvious option to change the location, and there is no option to change the language either.\nAs the data keeps dwindling, you juggle between auto-translation and your limited VPN options — just to run out of data in the middle of the session. The language selector is somewhere there, yet it’s disguised between cryptic symbols and mysterious icons, nowhere to be found on the spot.\n\nChances are high that at some point you had a similar experience as well. As designers, we can of course make language selectors more obvious and noticeable, yet most of the time, the appearance of a component is only a part of the problem.\nToo often, when we design interfaces, we subconsciously embed our personal assumptions, biases and expectations into our work. Of course, we can’t possibly consider all exceptions and all edge cases, along with all happy or unhappy coincidences. So we focus on the most common situations, eventually breaking a beautifully orchestrated user experience entirely for some of our disgruntled users.\nCan we fix it? Absolutely! We just need to decouple presets, allow for overrides and allow users to specify their intent. But before we dive in, let’s explore what options we have in front of us.\nThe Fine Little Details Of A Language Selector\nUsually, we know when we need a language selector. Every multi-lingual website will need one, and this definitely holds true for public services and companies residing in countries with multiple national languages. It is also necessary for global brands, organizations and the hospitality industry — as well as eCommerce where goods might be paid in various currencies and shipped to various destinations around the world.\n\nWhere do we place a language selector? Well, users have their usual suspects of course. In my experience, when asked to change a country or language, a vast majority of users will immediately head to the header of the page first, and if they can’t find it there, they’ll jump all the way to the bottom of the page and scout the footer next.\nAs for indicators of country selection, flags actually do work fairly well, and if users can’t spot them, they seek other icons that might represent a language in one way or the other — such as the globe icon or a “translation” icon. Obviously, when it comes to translations of articles or specific pages, users rely on the laws of locality and search for a selection of language next to the title of the article. So far so good.\n\nDesign-wise, however, there are plenty of intricate details that we need to account for. Surely the selector on its own will live somewhere in the footer of the page, and it is also very likely to make its appearance in the header as well. However, we could also auto-redirect users based on their location and auto-detect language based on the browser’s preferences, or prompt a modal window and ask users to select a region first. We could be using text labels or abbreviations, icons or flags, native or custom dropdowns, preferences panes or sidebars, toggles, or standalone pages.\nAs we will see, many of these solutions have usability issues on their own; and if we want to maximize clarity and reduce ambiguity, we need to come up with a proper strategy of how to label and group languages, how to present them, and how to make the language selector obvious to users — without running into a wild mixture of accessibility and auto-translation problems down the line.\nLet’s start with something that is probably obvious, but worth stating nevertheless — auto-redirects might be helpful, but they often cause more frustration and annoyance than a help.\nAvoid Auto-Redirects\nMany websites rely on redirects based on user’s location (IP) or browser’s language. However, if a person is located in Tokyo, it doesn’t necessarily imply that they fluently read Japanese. And if their preferred locale is Dutch, it doesn’t mean that they want to deliver physical items to the Netherlands. In the same way, if the preferred locale is French, yet it isn’t available on the site, a user might encounter a fallback language that isn’t necessarily the language that they are most comfortable with.\nWe can’t confidently infer users’ preferences without asking them first. That doesn’t mean that we should avoid redirects at all costs though. If a user happens to be connecting to a US website from Germany, it‘s perfectly reasonable to nudge them towards a German website. But if they happen to be connecting to a German website with an English locale preferred, it would be confusing to redirect them to the UK or US version of the site — even though it might very well be the user’s intent in some rare cases.\nIn general, redirects based on location are probably more instructive than redirects based on the browser’s language, but they are error-prone, too.\n\nOn the very first visit, Dyson.com nudges visitors to select the preferred region and language in the header on the page. Users can dismiss the bar and locate the language selector in the footer of the page again.\n\nBackcountry, a US company for outdoor gear and clothing, automatically redirects its users to another site. Since 2018, the website is no longer available outside the U.S. as an answer to the GDPR regulations. Without a VPN, it’s impossible to reach the website, for example, to purchase and deliver a gift for a friend located in the U.S.\n\nAudi automatically redirects users to a country deemed as a best fit. However, users can choose their country by clicking on the language selector in the right upper corner. On click, a modal shows up with autocomplete and a disabled “Continue” button.\n\n\nA global BMW website doesn’t automatically redirect users to any website. Instead, you can locate the “BMW in your country” option in the right upper corner of the header. It opens a modal with all the options listed, along with the prominent button at the top “BMW in your country”, which, on click, redirects users to the website considered to be the best fit for them. \n\nIKEA, without an automatic redirect, but with a very large country selector that understands domains, endonyms and languages of the largest countries in the world. The “Go shopping” button might be the biggest button in the world and might deserve a spot in the World Guinness Records Book. Unfortunately, on the site, you can change the country, but not always the language.\nWhile polite nudging is reasonable, automatic redirects are not. Once we start moving users from one site to another without asking them at all, we start baking our assumptions into the design, and that’s usually a red flag. We shouldn’t be surprised by increased levels of frustration and abandonment as a result. Ironically, this data is rarely tracked or known as the abandonment is happening on the “other” website, with different departments and teams on the other side of the globe.\nEither way, whether we want to nudge users towards a different website, or we absolutely need to use an auto-redirect, it’s definitely a good idea to always allow users to override redirects with manual preferences. This requires us to tame our assumptions and decouple our presets.\nDecouple Location and Language Presets\nMany websites rely on an assumption that location, language and currency are usually tightly coupled. After all, if a user chooses a location in Germany, they are very likely to prefer the German language and see prices in Euro. However, this is based on assumptions that work for many people, but break the experience entirely for others.\n\nFor example, if you want to purchase sneakers on Adidas from Germany but deliver them to your friend in Poland, you need to be able to make sense of the Polish language when checking out. You can either choose the German language with delivery to Germany or the Polish language with delivery to Poland. It’s impossible to select the English language with delivery options to Poland, for example. In other words, both language and location are tightly coupled.\nAs it turns out, there are plenty of scenarios where this assumption doesn’t work:\n\nA person is using a German VPN, but not be located in Germany nor understands German;\nA person is connecting from Germany, but be visiting for a few days, and they might not speak nor read German at all;\nA person is living in Germany, access a website in German, but prefers to pay with a company’s credit card in USD, rather than in EUR;\nA person is living in Germany might want to deliver an item from an American store to an American friend, but keeps getting redirected to a German website;\nA person is connecting from the USA but needs to be able to provide a VAT number because the product will be purchased by a German office with a German credit card.\n\nOf course, we might consider all these situations to be very rare edge cases and dismiss them. But first, we need to track how many people actually experience such issues and end up leaving as a result. In practice, especially for global brands, these numbers might be more significant than one might think.\nThese problems appear because we frame common situations in tightly coupled and rather inflexible presets. Surely presets are useful as default options, but they break down when defaults aren’t good enough. That’s why it’s usually a good idea to decouple all presets, and allow users to make standalone choices.\n\nOn Mondraker, users select location and language separately. All countries are grouped into tabs, and at the bottom users can choose the language of their preference. A very similar design, but a quite different approach. A downside: labeling all countries in a selected language is probably not as effective as using corresponding native labels instead.\n\nMonese shows two tabs in the right upper corner of the header. Users can switch between language and country, defining preferences for each separately.\nUser preferences don’t have to be limited by country and language alone. We can allow users to customize further parts of the UI, from currency and auto-translation to units of measurement and date formatting.\nAllow Users To Set Custom Preferences\nFor many sites, language and location are just the first important attributes that convey what website might be a good fit for a customer. However, to deliver value to users, we might want to go a little bit beyond that.\n\n\nRevolve.com uses language, country and currency presets based on the user’s IP and their browser’s locale. However, users can override these presets with custom preferences. They can choose a country for shipping, the language on the site and the currency. The hint for preferences is located in the header, with a combination of a language abbreviation, flag and a currency indicator.\nThese details are enough to show all products with the final price that includes delivery costs to their country and in the currency that’s most familiar to them. That’s what the perfect decoupling of location, language and currency is.\n\n\nAirBnB suggests languages and regions in groups, but also allows users to adjust their preferences and choose a language and region of their choice. Additionally, users can opt-in to automatically translate descriptions and reviews to English. The modal is prompted by a tap on the globe icon in the right upper corner of the header.\nOnce the settings are set, users can jump from one location to another, compare prices in the same currency and see reviews automatically translate to a language that they might understand better. That’s undoubtedly a win for the users.\n\niHerb goes the extra mile by providing a whole range of additional preferences for their users. Not only can users choose their language, preferred currency and shipping destination (and specify it with ZIP code for US destinations) — they can also choose preferred units of measure and check available payment methods and available shipping methods. Bonus points for smart autocomplete input rather than a not-so-good old-fashioned <select>-dropdown. \n\nSome slightly different preferences can be defined on the State Street of Global Advisors. On the first visit, a modal window appears explaining to users some of the assumptions that the interface is making about the location and their interests. Within the modal window, users can change a location, specify their role and choose a preferred type of site for their visit. \nIn general, these are some of the useful adjustments that we could allow users to specify to customize the entire experience for them:\n\nShipping location\nPreferred currency\nUnits of measure\nTime/date formatting\nTime zones preferences\nLevel of experience\n\nThe question, of course, is how to surface all these settings to the user — in a separate settings page, as a sidebar, in the header, or the footer? One disputable option is to show the settings in a modal or non-modal window upon entry to the site.\nA Case For Non-Modal Dialogs\nAdmittedly, modal windows are rarely a good idea. They are disruptive and annoying as they require immediate attention. However, they are appropriate when we need to draw the user’s attention to important details — be it loss of data, mutually exclusive preferences or critical errors.\nSome of the websites listed above prompt a modal window on the very first visit, asking users to specify their intent and their preferences before using the site. On others, default presets are silently applied, with an option to adjust them if needed — sometimes in a modal, and sometimes on a dedicated page.\n\nWhile modal windows will always be noticed, usability tests show that they are often instinctively dismissed, sometimes even before users realize what content they contain. On the other hand, users often don’t pay attention to any accessory navigation such as choice of currency, measurements or shipping location as they are very much focused on products. It’s only if the change of the language is necessary that they might notice that further settings can be adjusted as well.\n\n\n\nRather than using one modal with tabs, Booking uses separate buttons in the header for currency and language. The interface infers some settings from the user and applies them directly, with an option to override these settings. Rather than using a <select>-dropdown, which is often the slowest form component, all options are displayed in plain text, hence being searchable by in-browser search.\n\nFor comparison, Skyscanner allows users to prompt all customization options with one large button, grouping all options in a few drop-downs. Also, the interface always allows users to fall back to the English language if they’ve accidentally made a mistake.\nWhich option is better? Ultimately, this will of course be decided by usability tests. In this particular case, showing a modal window upon entry might not be a bad idea since it provides tangible value to users — a value that they might not be able to spot otherwise. However, there might be an alternative option that could work even better — using a non-modal dialog instead.\n\nUpon website entry on Patagonia, a sticky non-modal dialog appears in the left bottom corner. Users can choose location and language and save their preferences as a cookie. They can also always bring the selection back by accessing the preferences bar in the footer. \n\nIn the mock-up above, the important content isn’t blocked by the modal; users can scroll, navigate, select and copy-paste. However, the preference pane appears in the bottom right section of the screen. It can also be collapsed or minimized, but it does require an action from the user. It is a little bit more intrusive than when silently placed in the global navigation, but is easier to discover as well.\nIf you aren’t certain about the best option for your project, consider adding a link in the navigation bar first. Measure design KPIs and test how they change with a non-modal option — a much less intruding and more friendly option — and ultimately a modal. Chances are high that the modals might perform better than one might think.\nClick-Through Menus For Countries\nLarge corporations know the problem too well: navigating dozens of options in a small overlay, or even a large modal is quite cumbersome and requires a healthy dose of scrolling. So it’s not very surprising that often websites present all available options on separate pages, broken down by regions and sometimes illustrated with country flags.\n\nRevolut displays all available options on a separate, dedicated page. The countries are written in the English language, organized in groups and listed alphabetically. However, the page doesn’t only showcase available locations, but also locations that aren’t available yet. For this particular case, it might be a good idea to allow users to filter — e.g. hide all unavailable locations, perhaps with a toggle or tab above the list.\n\nLogitech displays most languages in their local format — e.g. “Deutschland” for Germany, and “中文” for China. This eliminates the assumption that the user needs to understand English to find the country or language of their choice. On the page, all countries (and available languages) are grouped by geography and displayed across columns, making it easier for users to discover them.\n\nRather than displaying all available options on one long page, Dell breaks countries by regions within tabs. No flags are being used, making the scanning a bit more difficult. Countries and languages are combined. In this case, less scrolling is required to find a location that would fit users best.\n\nNot all tabs are alike though. Cisco uses a small overlay with vertical tabs, rather than horizontal ones. This makes the selection very compact, and the solution very straightforward. It’s worth noting that the main disadvantage of tabs is that they make the content inaccessible with an in-browser search (well, for now). The user always has to select a region first.\n\nAnother option, of course, is to group the countries with a vertical accordion, as it’s done on eDreams, for example. You might need a bit more vertical space as a result, but all options can be scanned from top to bottom in one go.\n\nA slightly different kind of country selector on Oracle: a click-through overlay menu, with all countries grouped, rather than displaying a standalone page. That’s a very compact and straightforward solution.\nIf you need to display a wide range of languages, explore if you can group and display them on a single page. If it’s getting too overwhelming, consider grouping them within accordions or tabs — assuming that tabs appear like tabs and don’t contain cryptic labels. Or even better: provide users with poignant autocomplete suggestions.\nShow Autocomplete Suggestions\nGetting autocomplete right isn’t an easy task. This is especially difficult if we are dealing with multiple pieces of information at once, i.e. both country and language. For it to work well, we need to support frequent abbreviations, endonyms, and shorthands for all available options. And then, of course, our autocomplete suggestions should display both countries and languages, with an option to choose one option or another. Plus, we also might want to consider the support of multiple “primary” languages (English, French, Spanish, to name a few). Thats’ not easy at all!\n\nOn Framework, users can select country and language separately, both with autocomplete, with the most frequent options highlighted on focus. There is no need to scroll through the list of countries to find the preferred option. While this might be perfectly enough for some scenarios, it might not be sufficient in a situation when the user’s country isn’t available in the list. Instead, we could indicate the closest locations to the preferred option, rather than guiding a user to a dead end.\n\nIn the mock-up above, “4 locations nearby” could open an accordion, highlighting the closest locations next to Lithuania (Lietuva), indented.  This pattern might not be applicable when a user is trying to open a new bank account, but it might be useful when a user is looking for a particular office in their country, but can’t locate it.\n\nWise also includes autocomplete for language settings. If the same language appears in multiple items, the autocomplete specifies what country it refers to. All language options are presented in their local format.\n\nPorsche uses an accordion along with autocomplete as a page overlay. The interface supports abbreviations and indicates available options with flag icons.\nUndoubtedly autocomplete is a great addition to language selection. However, when testing it, explore how people use autocomplete, and what they are actually typing to find their country. Sometimes the fine-tuning of making autocomplete work for many different languages might be an effort way too underestimated and way too time-consuming. \nGrouping Countries\nNot every location or language has to represent with a separate entry in the language selector. If multiple countries are speaking the same language, what if indicated by grouping countries within one option?\n\nDaniel Marchini has come up with an interesting concept of grouping flags within a single selection. If the content will appear exactly the same for multiple countries, is it really necessary to show them separately? For example, the Portuguese language is displayed as an option for Portugal and Brazil, while the Spanish language is highlighted for Mexico and Spain. Obviously, not all countries could be grouped this way, but if you target users from specific countries, this might be worth a shot.\n\nAirwallex’s country selector groups all European countries as “European Union”. The service is available in the entire European Union, so it’s not necessary to select an individual country. However, if you have a slightly longer list of options, and you are looking for an option to open a bank account in the Netherlands, you might need a bit of time to realize that the Netherlands is assumed as a country within the European Union.\nUse Flags For Countries, Text Labels For Languages\nWhen designing a country selector, it feels almost natural to think about the flags they are represented by. After all, compared to just plain text, it should be much easier for users to locate the icon that they can immediately recognize. This is indeed true, however, as James Offer has suggested in his wonderful blog on Flags are not languages, flags are specific to countries, but languages often cross borders.\nWe can find French-speaking people in Canada, Vietnam, Senegal, Switzerland, and many other countries. It would be inaccurate to assume that all users from these countries associate their choice of language with a French flag. \n\nIn the article “My Take On Language Selectors”, Zsolt Szilvai shows an interesting example of such a conundrum. During the usability tests of an application designed for the UAE, many people found the fact that the Arabic language was visualized with one single flag, as it is used in many countries and cannot be identified with any particular flag alone.\n\nCurve.com opts in for a default international version which is available in English. There are a few other options available as well but one might wonder about the difference between “International (English)” and “English (United States)”. When flags are used to indicate languages, it can quickly become a little bit confusing.\n\nBackmarket includes a list of flags in the footer of the page to indicate local sites of the marketplace. When we want to drive users to specific local websites, we can safely use flags that best represent countries, rather than languages. Many sites also just add links in the footer instead, making language labels easier to find with an in-browser search.\n\nFlags for countries, and plain text for languages. Everything seems to be about right on Bol.com. The country selector (with a flag) is located in the right upper corner, where most users expect it.\nTo avoid misunderstandings, make sure that you use flags if your users need to select a specific country. However, if you’re providing users with a choice of a specific language, then flags are probably not going to work well. There, an autocomplete with all available countries and labels for languages written next to them might work better.\nThis of course brings up a question: how should these labels actually be written? In English or in a language’s local format?\nLabel Languages Locally\nAssumptions are error-prone, and if it goes for combinations of currency, language and location, this holds true for how we label languages as well. We shouldn’t assume that a user will be speaking one of the languages we choose to see as a default option. Instead, when users select a language, usually it’s better to always use the name of the language in its local format.\nSo rather than offering a choice of German and Chinese, assuming that users understand English, we can label these options as Deutsch and 中文.\n\nBut if the languages are labeled locally, somebody who happens to be in China might be experiencing issues switching to a slightly more familiar language. Surely flags would help to locate a button that would allow for that, but we could also prefix the selected language with a label, for example, “Language” to make it easier to spot the selector. Or we could just add a link saying “English” in the header. This of course relies on assumptions we are making, but it might be easier than hopping through the navigation bar and view-source with fingers crossed.  \n\nBooking provides a hint to indicate that users can change the language in a local language. If you prefer to show a hint on hover, that’s one of the very few cases where one might consider using a language that many users would understand, and it could be English.\n\nThe Globe and Translate Icons\nSince flags can be somewhat problematic, what would be a reasonable alternative to them? As briefly mentioned at the beginning of the article, we can also use icons such as “Globe” or “Translate” to indicate the choice of locales. There is as well an official language icon, which is free to use, but unfortunately is still not as recognizable as the other icons.\n\nSurely not everybody will be able to understand the icon in combination with a word that they can barely decipher, but if it’s prominently located in the header or the footer, the chance to be discovered are significantly higher.\n\nTomorrow.one displays a large drop-down selector with a globe icon in the footer of each page. It’s not available in the header on the site. Because pages aren’t very long, that’s probably not a big problem, but users might give up if they have to embark on a long-running scrolling marathon, or if the infinite scroll prevents them from reaching the footer.\n\nOn Atlassian, the language selector is tucked at the very end of the page in the footer, with a globe icon indicating the selection. However, if the user with a different browser language preference enters the site, it suggests changing the language at the very top of the page, with a globe icon appearing there, too.\n\nMonday.com keeps the language selection at the very top of the page, in the left upper corner. All options are presented in three columns, with the current selection highlighted in blue.\n\nWhile flags are easier to recognize, icons can work as an alternative option as well, especially if you need to provide users with language options, rather than choices for location. Even if the selection is provided in the header, it’s a safe bet to also place it at the bottom to ensure that users can find it when they need to. \nAvoid Language Shorthands or Initials\nAnother interesting problem that Zsolt Szilvai has discovered in testing is related to the use abbreviations, initials or shorthands to indicate a particular language. When we are running out of space in navigation, we could be using “EN” for English, or “DE” for Germany, or “UA” for Ukraine. Indeed, these shorthands are often well-understood, but they bring surprising results when a user’s browser auto-translates all websites in a particular language.\n\nNot only does it often result in broken menus and surprising layouts; browsers also translate language shorthands, producing an interface that might be very difficult to make sense of. However, were the shorthands avoided in favor of the full local name of the language, the user wouldn’t have to deal with these issues at all. Instead, the translator would help them find a language that would work better for them.\n\nN26.de uses a shorthand “EN” for “English”. The selected language is disabled in the list of options, but it’s probably a good idea to increase the color contrast a little. As users scroll down the page, the header remains sticky, so there is really no need to display the language selector in the footer as well.\n\nWise uses shorthands for language selection in the right upper corner, but displays the languages in full on click, with a noticeable focus style to indicate where a user currently is. This avoids the problem of auto-translation that often turns abbreviations into seemingly random strings.\nWrapping Up\nThe country and language selector might appear like a quite trivial design challenge, but there are plenty of fine details that make or break the experience. When designing one, always decouple presets and reduce assumptions about groups that are likely to go together. Users expect the language selector to be located in the header or the footer of each page, and they often watch out for flags, “Globe” or “Translate” icons to find it.\nIf you have just a few languages, a drop-down overlay might be perfectly enough. If you need 10–15 languages, perhaps it’s worth exploring the option of a non-modal overlay with autocomplete. If there are even more options to display, consider using a standalone page, with countries grouped into tabs or accordions.\nLanguage Selector Checklist\nAs usual, here’s a general checklist of a few important guidelines to consider when designing a better language selector:\n\nNudge users, but avoid auto-redirects.\nDecouple presets, be it location, language, or anything else.\nAllow users to set custom preferences (currency, time zones, units of measure).\nConsider using a non-modal dialog.\nOrganize countries and languages in sections, tabs, and accordions.\nProvide input with autocomplete suggestions.\nUse flags for countries, but avoid them for languages.\nConsider the Globe and Translate icons instead of flags.\nLabel languages locally, e.g. Deutsch instead of German.\nAvoid language shorthands or initials.\nFor accessibility reasons, make sure the country selector appears in the header as well as in the footer, and is keyboard-accessible.\n\nMeet Smart Interface Design Patterns\nIf you are interested in similar insights around UX, take a look at Smart Interface Design Patterns, our shiny new 7h-video course with 100s of practical examples from real-life projects. Plenty of design patterns and guidelines on everything from accordions and dropdowns to complex tables and intricate web forms — with 5 new segments added every year. Just sayin’! Check a free preview.\nMeet Smart Interface Design Patterns, our new video course on interface design & UX.\n\nJump to the video course →\n\n100 design patterns & real-life \nexamples.7h-video course + live UX training. Free preview.\nResources\n\nFlags are not languages, a blog by James Offer\n“My take on language selectors” + accessible implementation details, by Zsolt Szilvai\nUX practice: Skyscanner’s language selector\nLanguage switching UI/UX on multilingual sites, by Robert Jelenic\nBest practices for presenting website language selection\nUI/UX design of a language selector\nInteresting language selector patterns on Siemens Design System\nDesigning a language switch: Examples and best practices, by Thomas Peham\n\nRelated Articles\nIf you find this article useful, here’s an overview of similar articles we’ve published over the years — and a few more are coming your way.\n\nDesigning A Better Infinite Scroll\nDesigning Better Breadcrumbs\nDesigning A Better Carousel UX\nDesigning A Better Accordion\nDesigning A Better Responsive Configurator\nDesigning A Better Birthday Picker\nDesigning A Better Date and Time Picker\nDesigning A Better Feature Comparison\nDesigning A Better Slider\n“Form Design Patterns Book,” written by Adam Silver\n",
      "image": "http://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/ec0dac36-90ba-4295-b51b-f095fb2d90ff/designing-better-language-selector.jpg",
      "date_published": "2022-05-04T10:00:00.000Z",
      "date_modified": "2022-05-04T10:00:00.000Z"
    }
  ],
  "description": "Recent content in Articles on Smashing Magazine — For Web Designers And Developers",
  "home_page_url": "https://www.smashingmagazine.com/",
  "icon": "https://www.smashingmagazine.com/images/favicon/app-icon-512x512.png",
  "_extGeneratorVersion": "0.0.3"
}