{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Logic Magazine",
  "feed_url": "https://logicmag.io/rss.xml",
  "items": [
    {
      "id": "https://logicmag.io/beacons/organizing-as-joy-an-ocean-hill-brownsville-story-with-tranae-moran-and",
      "url": "https://logicmag.io/beacons/organizing-as-joy-an-ocean-hill-brownsville-story-with-tranae-moran-and",
      "title": "Organizing as Joy: An Ocean-Hill Brownsville Story, with Tranae Moran and Fabian Rogers",
      "summary": "A conversation about dismantling surveillance the Brooklyn way.",
      "content_html": "<p><i>In the fall of 2018, the residents of Atlantic Plaza Towers, a rent-stabilized apartment complex in Brownsville, Brooklyn, received an alarming notice from their landlord stating that the key fob system to enter the building was to be replaced with facial recognition technology. More than 130 residents opposed Nelson Management Group’s plan to install the facial recognition system and mandate photographs for mailbox key replacements. Atlantic Plaza Towers resident Tranae Moran led the fight, then celebrated the successful defeat of Nelson Management’s plan by founding the Ocean Hill-Brownsville Alliance (OBA). Fabian Rogers, a former floor captain at Atlantic Towers—a volunteer position that involves helping residents in an emergency—has followed Tranae to OBA in order to continue educating their community about the dangers of biometrics and elevate the joy of the Ocean Hill-Brownsville neighborhood. Issue editor J. Khadijah Abdurahman spoke to Moran and Rogers about what they’ve learned through their organizing work, and how the anti-surveillance struggle fits into the broader fight for environmental justice, social housing, and community reinvestment.</i></p>\n<p><b>Can you start us off with the basics? What would you like readers to know about who you are and the work you’ve been engaged with since the peak of resistance against facial recognition in Atlantic Plaza Towers?</b></p>\n<p>Tranae Moran (TM): I am a community organizer and community outreach specialist, and my nine-to-five is working with the City’s Tenant Support Unit. I founded the Ocean Hill-Brownsville Alliance (OBA) after assisting the Atlantic Plaza Towers Tenants Association in pushing back against facial recognition technology. After we succeeded in preventing the installation of facial recognition technology in our apartment complex, I wanted to continue the work of educating people about biometric collecting systems and just general tenants rights. I didn’t want to take up too much space in the Tenants Association, so I started the OBA in order to push that initiative forward. So, here we are. </p>\n<p>Fabian Rogers (FR): Technically, I think Tranae usually throws the title of cofounder my way, but I’m more of a participant. I’m kind of like an assistant aide of sorts to the Ocean Hill-Brownsville Alliance. But, you know, Tranae would beg to differ, of course. Also, I was a floor captain from Atlantic Plaza Towers, but currently I work as a constituent advocate for New York State Senator Jabari Brisport’s office out here in my Senate District 25. Tranae and I have been able to change the trajectory of our careers, essentially, just from organizing, at no cost at all—just kind of pushing forward until folks finally told us we can make a profit from it. </p>\n<p>TM: I don’t want to say a profit; I would rather say make a living out of it. People from our community don’t think of civic engagement and community work as an actual career. No one thinks that just by helping the community, you can make a living doing that. So, this was a very eye-opening experience for both Fabian and I, because we found ourselves doing passion work but ended up making some real impact, and were able to use our lived experience through that to start a career in community work.</p>\n<p><b>A lot of articles feature the fight and the resistance that the Atlantic Towers community waged against the implementation of facial recognition technology. I was wondering if you could set the stage for us: What does Brownsville and Ocean Hill look like? What is your relationship to the community and how did that set the stage for this successful battle? </b></p>\n<p>TM: What does Brownsville look like? Brownsville looks like a multitude of things. It’s a very vibrant and resilient neighborhood with a legacy of activism. When the time comes, we are able to come together and make some waves. Just Atlantic Towers specifically, we are a tight-knit community. We’ve been here for generations: elderly folks, young people—it’s just a little bit of everyone. Our Tenants Association is a direct reflection of that: we have municipal workers, we have people who work for MTA, we have lawyers, we have real estate agents, we have teachers, nurses, caregivers. So it’s a very diverse group of people with expertise in different spaces, which means, if we have the right foundation, we can make a lot of positive movement.</p>\n<p>There’s a lot of focus on the negative things that happen in Brownsville. I always say to people, I don’t see a lot of this stuff that you guys say is happening here. It could just be because I am from here and I identify what many other people wouldn’t consider as joy! I know people come to Brownsville and may be a bit taken aback, but I just took a walk to go buy a new pair of headphones because the ones I purchased didn’t work out so well and I’m just like, this is such a joyful neighborhood. Yes, we have things happen, but what neighborhood doesn’t have things going on? </p>\n<p>I want to magnify the joy that is present here while giving folks the information they need in order to navigate and not be taken advantage of, because there is gentrification coming here in Brownsville and not everyone has the same access to information. OBA is stepping in to assist with the flow of information. </p>\n<p>FR: The other thing to understand is the resiliency and the persistence of Black and brown folks within this community in particular. Fighting back against the narrative that you’re a product of your environment—a lot of Ocean Hill-Brownsville-ites are more than what their environment is. At the same time, a lot of their environment is that which they can’t control. Health disparities come from the fact that Brownsville was industrialized and those remnants of industrialization play a role in environmental violence. Things that you can’t see that make it seem as though Black and brown folks are just born with respiratory issues, when it’s really the environment that we’re living in that plays a large role as opposed to our habits and things like that. </p>\n<p>When folks find out about the more invisible things like air quality being bad, or illegal projects affecting the health of Ocean Hill-Brownsville, a lot of times folks become activists and advocates for the community. People live, love, and learn in this community. I think that that’s a staple as to why the culture of Ocean Hill-Brownsville continues to persist despite gentrification and other disparities.</p>\n<p>TM: Brownsville is made up of the highest concentration of public housing buildings in New York. They are not a priority to the city, if you ask me. There is a lot of neglect happening in these neighborhoods. This neighborhood is a food desert. We don’t have markets. Fresh fruits and vegetables are not easy to find. I mean, we do have a beautiful network of community gardens and local people who contribute their time and energy to those gardens, and help to make our community a more vibrant place. But as far as the city coming in to do cleanups and things like that, we don’t see much of that happening. </p>\n<p>Are we creating community spaces for people to take up space in and do whatever it is that they want to do? That is not being done, which is why OBA is committed to creating space for joy, imagination, and vision in Brownsville. Because of the things that people have been through, a lot of them are numb and we have to wake them up first—liven them up with some joy again and de-stressing activities through art—before we can focus on fighting biometric information collecting or the things that take a bit more time for understanding. </p>\n<h1><b>Not Just Playing Candy Crush</b></h1>\n<p><b>I don’t know if this is your experience, but it’s something I definitely complain about in academic or institutional spaces, when they want to bring in “community,” the currency is “impacted people.” They want you to share a little bit of your trauma, your individual story, and then talk about “organizing”—organizing is anything that’s not writing a paper in the way that they speak. And then they’re done with you, and you can go back to whence you came from until they want to trot you back out again for the pictures and stuff. I’m not even interested in critiquing that. Rather, I want to ask, what does the conversation look like across ourselves and across neighborhood intimacies? </b></p>\n<p><b>It definitely has stood out to me how OBA has been a collective effort. It’s you leading the fight Tranae, but it’s not like you are the sole hero. Even how you conceptualize what the problem is and how you situate it into both the joyous community and the environmental factors or ecologies of various types of violences that people are subjected to. I really appreciated that. I remember reading all about OBA in 2019, and now we are about to be in 2022 and you guys haven’t just been chillin’ playing Candy Crush. What is the state of OBA organizing, not just with Covid, but over this length of time? What has been like, “Yo, I’m never doing that again,” or “This is what has been really hard,” or however you’d like to reflect on that passage of time? </b></p>\n<p>TM: We have been refocusing what OBA wants to do. At first, the main thought was that we need to get information out about biometric collecting systems. We need to inform our community about the dangers and why they need to be aware of their surroundings. That is still a major theme in OBA but this has just been a very stressful time, so we have been trying to find ways to make an impact that don’t ask for too much energy from our community. They are exerting themselves in so many different ways, with work, with kids going back to school, and just with navigating life post-vaccines becoming available. </p>\n<p>We partnered with AI For the People last summer for OBA’s first public outdoor event on Juneteenth. The community appreciated the music, food, and information about all of the invisible harms. Many people didn’t know about the topics we covered, including the fact that National Grid runs a fracked gas pipeline through Brownsville. Leaks in that pipeline can expose people to cancer-causing and radioactive gas. As Fabian just mentioned, we are already dealing with environmental issues in Brownsville. There is a large community of people who have asthma here and respiratory problems, and now things are being done that will potentially cause more harm to the health of the people in this community. </p>\n<p>FR: We’ve been trying to connect dots between different struggles going on between housing justice, environmental justice, and surveillance with Housing Organizers for People Empowerment (HOPE), AI For the People, and Brownsville Green Justice. For example, pointing out how our landlord trying to install facial recognition into our building plays into the grand scheme of housing injustice. Anti-surveillance includes pushing for social housing or housing access vouchers for homeless folks and things like that. </p>\n<p>National Grid is building a fracked gas pipeline in Brownsville. It’s one of many different corporate entities monopolizing essential utilities for all New York housing. It’s reliant on the fossil fuel industry and so they make money by building new infrastructure, not necessarily through gas flowing. This means they have to find ways to circumvent New York state law and other state laws in order to continue building infrastructure. And they end up picking Black and brown communities that don’t come off as active or as in tune with what’s going on, or seem to have a sense of wanting to push back. National Grid fails to inform the community and then the community has to be reactive, so you suddenly see a community activate and want to inform themselves, understand what’s going on, and push back against corporate BS. </p>\n<h1><b>(Re)active Situations</b></h1>\n<p><b>Do you see anti-surveillance organizing as a strategy of abolition or defunding the police? How do you situate privacy issues relative to the other issues emerging in the community? </b></p>\n<p>FR: Sometimes it’s not necessarily focusing on surveillance rights, but just looking at how we deal with corporate enterprises. How do you look at a biometrics company like StoneLock that tried to install its facial recognition system in Atlantic Towers? How do you look at the shenanigans that they pulled off and compare it to the strategies that National Grid is putting in place to try to give folks in Brownsville and Ocean Hill a hard time, in terms of trying to build new infrastructure that will then impact folks’ lives for the sake of a profit that they don’t need?</p>\n<p>In partnership with the Surveillance Technology Oversight Project, I’ve gotten tapped into different anti-surveillance groups, including the G.A.N.G.S. Coalition (Grassroots Advocates for Neighborhood Groups &amp; Solutions). They are trying to dispel the myths embedded in gang databases by reframing the issue for disenfranchised communities that are riddled with gang and community violence as a lack of opportunity, a lack of funding, a lack of resources that makes folks desperate and have to take risks in order to make a consistent living. </p>\n<p>When you dispel the idea of “folks out here just trying to create trouble” and you look deeper into it, it forces you to question the tactics that the NYPD uses in order to build a database to help with their so-called policing. With this gang database in particular, it’s a database built off of police bias. It’s not built off of fact. It’s not built off of factual information. </p>\n<p>When I think of justice, I always try to simplify it to the essential issue. What’s the essential device that allows this issue to proliferate in said communities, and how do we tap into communities to try to address quality of life issues? How do we tap into communities to be able to empower themselves to be the force to stop those pejorative relationships? If you get caught up in the monotony, you’ll lose sight of the fact that a lot of times these corporate enterprises are using the same strategies. It’s a very cookie-cutter system, but because it’s in a different sort of industry, you don’t think of it as such.</p>\n<p>For me and Tranae and other folks that were on our side in terms of surveillance and data privacy advocacy, we had to think about technology in a different way. We had to think about these issues as a housing issue. You often have to think outside of the context of what you’re put in to really be able to dissect the issue and be able to address it, and then be able to translate it to allow folks to feel as though they can be informed, they can be empowered. And then from there, they can be partners and allies, and oftentimes can be leaders.</p>\n<p>TM: We are very reactive when things happen because there are no conversations being held with our community about changes being made. That flow of information seems to not flow to us in the way that it should, which is where I want OBA to be able to step in. I want us to be a hub. A lot of these technology companies, real estate developers, and all kinds of folks who are just making their way over to Brownsville claim that they can’t find anyone to talk to. I’m just like, there’s so many community organizations doing work in Brownsville. How could you not find anyone to talk to and get insights from? So, you decided to still push forward with whatever this project was, without speaking to anyone in the community or trying to have a town hall or anything, despite the fact that we are very open to all of those things? </p>\n<p>Why aren’t these companies speaking to the community-based organizations? I want OBA to be a hub where they know they can come here and speak with community members who have expertise in different areas, so that we’re not just like, “Oh, what the heck is that? We never heard of this. What are you doing here?” Instead, it’s like, “Oh no, we had conversations with these people. We let them know that we wanted this and that to happen, and this is what we don’t want to see.” Those conversations don’t happen. It’s always a too little, too late kind of situation for us, and I want to change that. </p>\n<p>I want us to be involved in the conversations that are being had about the space that we occupy. Like, we live here. There are people here that have a brain and they have wants and needs, and they want to see different things in their community. When Fabian was speaking about gangs, how kids end up in those situations is that they want to go outside, but we don’t have green fields for them to sit in the grass and look at the sky and just ponder. We don’t have spaces like that. They come outside of their homes into all kinds of confusion. Young people have to navigate through these communities, digesting what they see and that’s how they learn. And it’s not always the greatest thing when they don’t have someone, or an organization, there to explain to them what they’re experiencing, so that they can make better and more informed decisions about how they want to navigate through the community. </p>\n<h1><b>Housing and (De)Funding The Police</b></h1>\n<p><b>As far as the gang database, who gets categorized as a gang? You mentioned that National Grid is putting poisonous gas under the ground, affecting a lot of people. Nobody is calling them a gang, right? But if you’re fifteen years old, Black, with certain colors on, you’re more likely to be identified as a gang member. </b></p>\n<p><b>Tranae, you mentioned the density of housing projects in Brownsville. People don’t seem to understand that you have a high density of projects, but you also have middle-class home ownership and residents with white-collar jobs. So, even when we talk about community, people within the community have very different relationships to the intensity of surveillance and policing. I also know from my experience, caseworkers live in Brownsville, so there’s people who sit in a lot of different places and have different relationships to policing. How are you thinking through class differences and funding relationships as you organize in Ocean Hill-Brownsville? </b></p>\n<p>TM: In Ocean Hill, there’s a larger amount of home ownership than there is down in Brownsville, which I’ve found to be one of the dividing factors. This is one of the reasons why OBA started and why we have this name—I wanted to bring the two communities together because we are separated due to the infrastructure of Brownsville and the density of the housing projects. We have the same issues, but the intensity of those issues is greater in Brownsville. Ocean Hill will probably be gentrified way faster than down in Brownsville. It’s happening at the same time, but the changes are happening a lot quicker in Ocean Hill. </p>\n<p>I’m not finding that everyone wants to defund the police here. The police have actually been very supportive of OBA, thus far, in our events and organizing outdoors. I think it’s about the people and not just police in general, because we have been met with folks not being happy about our presence outside. For example, business owners have called the police but when the police arrive, they’re actually helpful and they like what they see us doing, which is creating space for imagination and joy, and providing information on these invisible harms: facial recognition, surveillance, and fracked gas pipelines in Brooklyn. </p>\n<p>We want to focus on meeting people where they are, and not on specific topics such as defunding the police, because everyone doesn’t share that vision and we are not trying to divide the community more than it may be already. Everyone has to navigate however it works for their specific family unit. I feel like everyone has that capacity as long as they have the information to do it. </p>\n<p>We have not been accepting funding from many organizations. One, because we’re still laying down the foundations for OBA. With the climate of community organizing and community work, and these corporations wanting to put money into the community with whatever other agendas they have going on, I have been trying to be very careful about who we are accepting funding from. We have organizations like National Grid, who are doing great events in our community, but at the same time, they’re running a fracked gas pipeline in Brownsville. They were handing out hot dogs. First of all, why are you giving people hot dogs, anyway? They’re smiling and in community and giving away all these things but, at the same time, they’re being a double. They have these construction workers digging in front of your apartment building, putting all kinds of nonsense into the ground. And they are just going to leave and say, “Okay, we had a great event while you’re dealing with respiratory problems” and who knows what other kinds of health issues because of the things that they’re doing in the community. </p>\n<p>FR: An example of resistance we’ve encountered is from homeowners, because Amazon’s Ring doorbell and similar surveillance technologies are marketed to them as basic home protection. One approach that I’ve found helpful is pointing out the corporate relations between a product and possible policing. For instance, Amazon partners with and donates to police departments, and so by buying into the Ring system, you may be indirectly paying into an unnecessary police budget. Trying to build that sort of conversation helps folks understand the bigger picture as to what goes on. </p>\n<p>“Defund the police,” in particular, has always been an interesting conversation because people think, like, “Oh, we’re going to take the badges and weapons away from the police.” It’s like, no, folks just want to defund the police’s excessive budget and refund the community for how strapped it’s been for resources. I’m always a stickler for making simple phrases that can open up a bigger conversation. When folks get very defensive about something like “defund the police,” for instance, I’m like, “Well, I think you should look at it in the context that it’s only half the phrase. It’s more of ‘defund the police,’ ‘refund the community.’” We <i>all</i> make the big arguments about how strapped our community has been since the 1970s.</p>\n<p>Reaganomics and trickle-down theory started to trickle away the resources that helped working-class blue-collar communities push through by having supportive programs, trade schools, and alternatives to what’s out there. So, we should be thinking about how the police are asked to be a Swiss Army Knife when their training doesn’t allow them to be. A police officer isn’t a mental health expert. That’s just a fact, unless they had that background beforehand and then they became a police officer.</p>\n<p>Folks say “defund the police” because we’ve bolstered a couple of different economies rather than the community. If we see that the police have bolstered their pockets, maybe it’s a chance to look at how we can stop the excessive spending and start to think about how to funnel back money into the community. That’s what happened pre-Reaganomics, trickle-down theory, and things like that. That all gets lost in the chaos of folks getting caught up in a phrase like “defund the police” or “Black Lives Matter.” It’s always the monotony of getting caught up in the moment of a phrase that feels triggering, rather than unpacking the history and the impact and the side effects of systemic changes that end up de-establishing what a community can provide for itself and for others.</p>",
      "content_text": "In the fall of 2018, the residents of Atlantic Plaza Towers, a rent-stabilized apartment complex in Brownsville, Brooklyn, received an alarming notice from their landlord stating that the key fob system to enter the building was to be replaced with facial recognition technology. More than 130 residents opposed Nelson Management Group’s plan to install the facial recognition system and mandate photographs for mailbox key replacements. Atlantic Plaza Towers resident Tranae Moran led the fight, then celebrated the successful defeat of Nelson Management’s plan by founding the Ocean Hill-Brownsville Alliance (OBA). Fabian Rogers, a former floor captain at Atlantic Towers—a volunteer position that involves helping residents in an emergency—has followed Tranae to OBA in order to continue educating their community about the dangers of biometrics and elevate the joy of the Ocean Hill-Brownsville neighborhood. Issue editor J. Khadijah Abdurahman spoke to Moran and Rogers about what they’ve learned through their organizing work, and how the anti-surveillance struggle fits into the broader fight for environmental justice, social housing, and community reinvestment.\nCan you start us off with the basics? What would you like readers to know about who you are and the work you’ve been engaged with since the peak of resistance against facial recognition in Atlantic Plaza Towers?\nTranae Moran (TM): I am a community organizer and community outreach specialist, and my nine-to-five is working with the City’s Tenant Support Unit. I founded the Ocean Hill-Brownsville Alliance (OBA) after assisting the Atlantic Plaza Towers Tenants Association in pushing back against facial recognition technology. After we succeeded in preventing the installation of facial recognition technology in our apartment complex, I wanted to continue the work of educating people about biometric collecting systems and just general tenants rights. I didn’t want to take up too much space in the Tenants Association, so I started the OBA in order to push that initiative forward. So, here we are. \nFabian Rogers (FR): Technically, I think Tranae usually throws the title of cofounder my way, but I’m more of a participant. I’m kind of like an assistant aide of sorts to the Ocean Hill-Brownsville Alliance. But, you know, Tranae would beg to differ, of course. Also, I was a floor captain from Atlantic Plaza Towers, but currently I work as a constituent advocate for New York State Senator Jabari Brisport’s office out here in my Senate District 25. Tranae and I have been able to change the trajectory of our careers, essentially, just from organizing, at no cost at all—just kind of pushing forward until folks finally told us we can make a profit from it. \nTM: I don’t want to say a profit; I would rather say make a living out of it. People from our community don’t think of civic engagement and community work as an actual career. No one thinks that just by helping the community, you can make a living doing that. So, this was a very eye-opening experience for both Fabian and I, because we found ourselves doing passion work but ended up making some real impact, and were able to use our lived experience through that to start a career in community work.\nA lot of articles feature the fight and the resistance that the Atlantic Towers community waged against the implementation of facial recognition technology. I was wondering if you could set the stage for us: What does Brownsville and Ocean Hill look like? What is your relationship to the community and how did that set the stage for this successful battle? \nTM: What does Brownsville look like? Brownsville looks like a multitude of things. It’s a very vibrant and resilient neighborhood with a legacy of activism. When the time comes, we are able to come together and make some waves. Just Atlantic Towers specifically, we are a tight-knit community. We’ve been here for generations: elderly folks, young people—it’s just a little bit of everyone. Our Tenants Association is a direct reflection of that: we have municipal workers, we have people who work for MTA, we have lawyers, we have real estate agents, we have teachers, nurses, caregivers. So it’s a very diverse group of people with expertise in different spaces, which means, if we have the right foundation, we can make a lot of positive movement.\nThere’s a lot of focus on the negative things that happen in Brownsville. I always say to people, I don’t see a lot of this stuff that you guys say is happening here. It could just be because I am from here and I identify what many other people wouldn’t consider as joy! I know people come to Brownsville and may be a bit taken aback, but I just took a walk to go buy a new pair of headphones because the ones I purchased didn’t work out so well and I’m just like, this is such a joyful neighborhood. Yes, we have things happen, but what neighborhood doesn’t have things going on? \nI want to magnify the joy that is present here while giving folks the information they need in order to navigate and not be taken advantage of, because there is gentrification coming here in Brownsville and not everyone has the same access to information. OBA is stepping in to assist with the flow of information. \nFR: The other thing to understand is the resiliency and the persistence of Black and brown folks within this community in particular. Fighting back against the narrative that you’re a product of your environment—a lot of Ocean Hill-Brownsville-ites are more than what their environment is. At the same time, a lot of their environment is that which they can’t control. Health disparities come from the fact that Brownsville was industrialized and those remnants of industrialization play a role in environmental violence. Things that you can’t see that make it seem as though Black and brown folks are just born with respiratory issues, when it’s really the environment that we’re living in that plays a large role as opposed to our habits and things like that. \nWhen folks find out about the more invisible things like air quality being bad, or illegal projects affecting the health of Ocean Hill-Brownsville, a lot of times folks become activists and advocates for the community. People live, love, and learn in this community. I think that that’s a staple as to why the culture of Ocean Hill-Brownsville continues to persist despite gentrification and other disparities.\nTM: Brownsville is made up of the highest concentration of public housing buildings in New York. They are not a priority to the city, if you ask me. There is a lot of neglect happening in these neighborhoods. This neighborhood is a food desert. We don’t have markets. Fresh fruits and vegetables are not easy to find. I mean, we do have a beautiful network of community gardens and local people who contribute their time and energy to those gardens, and help to make our community a more vibrant place. But as far as the city coming in to do cleanups and things like that, we don’t see much of that happening. \nAre we creating community spaces for people to take up space in and do whatever it is that they want to do? That is not being done, which is why OBA is committed to creating space for joy, imagination, and vision in Brownsville. Because of the things that people have been through, a lot of them are numb and we have to wake them up first—liven them up with some joy again and de-stressing activities through art—before we can focus on fighting biometric information collecting or the things that take a bit more time for understanding. \nNot Just Playing Candy Crush\nI don’t know if this is your experience, but it’s something I definitely complain about in academic or institutional spaces, when they want to bring in “community,” the currency is “impacted people.” They want you to share a little bit of your trauma, your individual story, and then talk about “organizing”—organizing is anything that’s not writing a paper in the way that they speak. And then they’re done with you, and you can go back to whence you came from until they want to trot you back out again for the pictures and stuff. I’m not even interested in critiquing that. Rather, I want to ask, what does the conversation look like across ourselves and across neighborhood intimacies? \nIt definitely has stood out to me how OBA has been a collective effort. It’s you leading the fight Tranae, but it’s not like you are the sole hero. Even how you conceptualize what the problem is and how you situate it into both the joyous community and the environmental factors or ecologies of various types of violences that people are subjected to. I really appreciated that. I remember reading all about OBA in 2019, and now we are about to be in 2022 and you guys haven’t just been chillin’ playing Candy Crush. What is the state of OBA organizing, not just with Covid, but over this length of time? What has been like, “Yo, I’m never doing that again,” or “This is what has been really hard,” or however you’d like to reflect on that passage of time? \nTM: We have been refocusing what OBA wants to do. At first, the main thought was that we need to get information out about biometric collecting systems. We need to inform our community about the dangers and why they need to be aware of their surroundings. That is still a major theme in OBA but this has just been a very stressful time, so we have been trying to find ways to make an impact that don’t ask for too much energy from our community. They are exerting themselves in so many different ways, with work, with kids going back to school, and just with navigating life post-vaccines becoming available. \nWe partnered with AI For the People last summer for OBA’s first public outdoor event on Juneteenth. The community appreciated the music, food, and information about all of the invisible harms. Many people didn’t know about the topics we covered, including the fact that National Grid runs a fracked gas pipeline through Brownsville. Leaks in that pipeline can expose people to cancer-causing and radioactive gas. As Fabian just mentioned, we are already dealing with environmental issues in Brownsville. There is a large community of people who have asthma here and respiratory problems, and now things are being done that will potentially cause more harm to the health of the people in this community. \nFR: We’ve been trying to connect dots between different struggles going on between housing justice, environmental justice, and surveillance with Housing Organizers for People Empowerment (HOPE), AI For the People, and Brownsville Green Justice. For example, pointing out how our landlord trying to install facial recognition into our building plays into the grand scheme of housing injustice. Anti-surveillance includes pushing for social housing or housing access vouchers for homeless folks and things like that. \nNational Grid is building a fracked gas pipeline in Brownsville. It’s one of many different corporate entities monopolizing essential utilities for all New York housing. It’s reliant on the fossil fuel industry and so they make money by building new infrastructure, not necessarily through gas flowing. This means they have to find ways to circumvent New York state law and other state laws in order to continue building infrastructure. And they end up picking Black and brown communities that don’t come off as active or as in tune with what’s going on, or seem to have a sense of wanting to push back. National Grid fails to inform the community and then the community has to be reactive, so you suddenly see a community activate and want to inform themselves, understand what’s going on, and push back against corporate BS. \n(Re)active Situations\nDo you see anti-surveillance organizing as a strategy of abolition or defunding the police? How do you situate privacy issues relative to the other issues emerging in the community? \nFR: Sometimes it’s not necessarily focusing on surveillance rights, but just looking at how we deal with corporate enterprises. How do you look at a biometrics company like StoneLock that tried to install its facial recognition system in Atlantic Towers? How do you look at the shenanigans that they pulled off and compare it to the strategies that National Grid is putting in place to try to give folks in Brownsville and Ocean Hill a hard time, in terms of trying to build new infrastructure that will then impact folks’ lives for the sake of a profit that they don’t need?\nIn partnership with the Surveillance Technology Oversight Project, I’ve gotten tapped into different anti-surveillance groups, including the G.A.N.G.S. Coalition (Grassroots Advocates for Neighborhood Groups & Solutions). They are trying to dispel the myths embedded in gang databases by reframing the issue for disenfranchised communities that are riddled with gang and community violence as a lack of opportunity, a lack of funding, a lack of resources that makes folks desperate and have to take risks in order to make a consistent living. \nWhen you dispel the idea of “folks out here just trying to create trouble” and you look deeper into it, it forces you to question the tactics that the NYPD uses in order to build a database to help with their so-called policing. With this gang database in particular, it’s a database built off of police bias. It’s not built off of fact. It’s not built off of factual information. \nWhen I think of justice, I always try to simplify it to the essential issue. What’s the essential device that allows this issue to proliferate in said communities, and how do we tap into communities to try to address quality of life issues? How do we tap into communities to be able to empower themselves to be the force to stop those pejorative relationships? If you get caught up in the monotony, you’ll lose sight of the fact that a lot of times these corporate enterprises are using the same strategies. It’s a very cookie-cutter system, but because it’s in a different sort of industry, you don’t think of it as such.\nFor me and Tranae and other folks that were on our side in terms of surveillance and data privacy advocacy, we had to think about technology in a different way. We had to think about these issues as a housing issue. You often have to think outside of the context of what you’re put in to really be able to dissect the issue and be able to address it, and then be able to translate it to allow folks to feel as though they can be informed, they can be empowered. And then from there, they can be partners and allies, and oftentimes can be leaders.\nTM: We are very reactive when things happen because there are no conversations being held with our community about changes being made. That flow of information seems to not flow to us in the way that it should, which is where I want OBA to be able to step in. I want us to be a hub. A lot of these technology companies, real estate developers, and all kinds of folks who are just making their way over to Brownsville claim that they can’t find anyone to talk to. I’m just like, there’s so many community organizations doing work in Brownsville. How could you not find anyone to talk to and get insights from? So, you decided to still push forward with whatever this project was, without speaking to anyone in the community or trying to have a town hall or anything, despite the fact that we are very open to all of those things? \nWhy aren’t these companies speaking to the community-based organizations? I want OBA to be a hub where they know they can come here and speak with community members who have expertise in different areas, so that we’re not just like, “Oh, what the heck is that? We never heard of this. What are you doing here?” Instead, it’s like, “Oh no, we had conversations with these people. We let them know that we wanted this and that to happen, and this is what we don’t want to see.” Those conversations don’t happen. It’s always a too little, too late kind of situation for us, and I want to change that. \nI want us to be involved in the conversations that are being had about the space that we occupy. Like, we live here. There are people here that have a brain and they have wants and needs, and they want to see different things in their community. When Fabian was speaking about gangs, how kids end up in those situations is that they want to go outside, but we don’t have green fields for them to sit in the grass and look at the sky and just ponder. We don’t have spaces like that. They come outside of their homes into all kinds of confusion. Young people have to navigate through these communities, digesting what they see and that’s how they learn. And it’s not always the greatest thing when they don’t have someone, or an organization, there to explain to them what they’re experiencing, so that they can make better and more informed decisions about how they want to navigate through the community. \nHousing and (De)Funding The Police\nAs far as the gang database, who gets categorized as a gang? You mentioned that National Grid is putting poisonous gas under the ground, affecting a lot of people. Nobody is calling them a gang, right? But if you’re fifteen years old, Black, with certain colors on, you’re more likely to be identified as a gang member. \nTranae, you mentioned the density of housing projects in Brownsville. People don’t seem to understand that you have a high density of projects, but you also have middle-class home ownership and residents with white-collar jobs. So, even when we talk about community, people within the community have very different relationships to the intensity of surveillance and policing. I also know from my experience, caseworkers live in Brownsville, so there’s people who sit in a lot of different places and have different relationships to policing. How are you thinking through class differences and funding relationships as you organize in Ocean Hill-Brownsville? \nTM: In Ocean Hill, there’s a larger amount of home ownership than there is down in Brownsville, which I’ve found to be one of the dividing factors. This is one of the reasons why OBA started and why we have this name—I wanted to bring the two communities together because we are separated due to the infrastructure of Brownsville and the density of the housing projects. We have the same issues, but the intensity of those issues is greater in Brownsville. Ocean Hill will probably be gentrified way faster than down in Brownsville. It’s happening at the same time, but the changes are happening a lot quicker in Ocean Hill. \nI’m not finding that everyone wants to defund the police here. The police have actually been very supportive of OBA, thus far, in our events and organizing outdoors. I think it’s about the people and not just police in general, because we have been met with folks not being happy about our presence outside. For example, business owners have called the police but when the police arrive, they’re actually helpful and they like what they see us doing, which is creating space for imagination and joy, and providing information on these invisible harms: facial recognition, surveillance, and fracked gas pipelines in Brooklyn. \nWe want to focus on meeting people where they are, and not on specific topics such as defunding the police, because everyone doesn’t share that vision and we are not trying to divide the community more than it may be already. Everyone has to navigate however it works for their specific family unit. I feel like everyone has that capacity as long as they have the information to do it. \nWe have not been accepting funding from many organizations. One, because we’re still laying down the foundations for OBA. With the climate of community organizing and community work, and these corporations wanting to put money into the community with whatever other agendas they have going on, I have been trying to be very careful about who we are accepting funding from. We have organizations like National Grid, who are doing great events in our community, but at the same time, they’re running a fracked gas pipeline in Brownsville. They were handing out hot dogs. First of all, why are you giving people hot dogs, anyway? They’re smiling and in community and giving away all these things but, at the same time, they’re being a double. They have these construction workers digging in front of your apartment building, putting all kinds of nonsense into the ground. And they are just going to leave and say, “Okay, we had a great event while you’re dealing with respiratory problems” and who knows what other kinds of health issues because of the things that they’re doing in the community. \nFR: An example of resistance we’ve encountered is from homeowners, because Amazon’s Ring doorbell and similar surveillance technologies are marketed to them as basic home protection. One approach that I’ve found helpful is pointing out the corporate relations between a product and possible policing. For instance, Amazon partners with and donates to police departments, and so by buying into the Ring system, you may be indirectly paying into an unnecessary police budget. Trying to build that sort of conversation helps folks understand the bigger picture as to what goes on. \n“Defund the police,” in particular, has always been an interesting conversation because people think, like, “Oh, we’re going to take the badges and weapons away from the police.” It’s like, no, folks just want to defund the police’s excessive budget and refund the community for how strapped it’s been for resources. I’m always a stickler for making simple phrases that can open up a bigger conversation. When folks get very defensive about something like “defund the police,” for instance, I’m like, “Well, I think you should look at it in the context that it’s only half the phrase. It’s more of ‘defund the police,’ ‘refund the community.’” We all make the big arguments about how strapped our community has been since the 1970s.\nReaganomics and trickle-down theory started to trickle away the resources that helped working-class blue-collar communities push through by having supportive programs, trade schools, and alternatives to what’s out there. So, we should be thinking about how the police are asked to be a Swiss Army Knife when their training doesn’t allow them to be. A police officer isn’t a mental health expert. That’s just a fact, unless they had that background beforehand and then they became a police officer.\nFolks say “defund the police” because we’ve bolstered a couple of different economies rather than the community. If we see that the police have bolstered their pockets, maybe it’s a chance to look at how we can stop the excessive spending and start to think about how to funnel back money into the community. That’s what happened pre-Reaganomics, trickle-down theory, and things like that. That all gets lost in the chaos of folks getting caught up in a phrase like “defund the police” or “Black Lives Matter.” It’s always the monotony of getting caught up in the moment of a phrase that feels triggering, rather than unpacking the history and the impact and the side effects of systemic changes that end up de-establishing what a community can provide for itself and for others.",
      "date_published": "2022-02-22T15:04:00.000Z",
      "date_modified": "2022-02-22T15:04:00.000Z",
      "_plugin": {
        "pageFilename": "4b9e48fedf02d80ac93b35e11a9c1d0a56687f37cb752d9b8fbdffdd146e0f96.html"
      }
    },
    {
      "id": "https://logicmag.io/beacons/family-units",
      "url": "https://logicmag.io/beacons/family-units",
      "title": "Family Units",
      "summary": "The communities behind the data annotation work that powers AI.",
      "content_html": "<p>Since the early months of the Covid-19 pandemic, María’s house has been run like a factory. Every day, her family of six synchronizes their routines so two people are always behind a computer. María, her husband Rodrigo, and their children, Daniela (20), Andrés (18), and Camila (13) are among the unknown number of Venezuelans who, after years of political and economic crisis exacerbated by the pandemic, now try to make a living by annotating data through crowdsourcing platforms. Using two Canaima laptops, which the Hugo Chavéz government provided a decade ago for school children, they tag images and videos, transcribe text and audio, search for information online, and send videos and pictures of themselves to developers at companies and research institutions in Europe and North America. The developers use this data to train machine learning algorithms, like the ones that do facial recognition, moderate content, and guide self-driving cars.</p>\n<p>The family’s activities all revolve around data production because this is their only source of income and, according to María, they have to “focus on the same objective to survive.” She and Rodrigo do most of the work, although she also takes care of many domestic duties. Camila, Andrés, and Daniela work part time on data annotation while attending high school and university. Only María’s youngest child, Sebastián (7) is able to focus exclusively on school. Although most crowdsourcing platforms’ terms of use state that each account must be run by a single adult, often the only hard requirement to set up an account is for someone to prove that they are at least eighteen years old by taking pictures of an identification card and their face, and praying that a third-party facial recognition verification system called Onfido detects a match.</p>\n<p>The platform the family works for pays them a few cents per task, in cryptocurrency. They are only allowed to transfer the money to their online wallet once they have made at least the equivalent of ten dollars. After working every day of the week, they usually earn around twice that much, but recently they have barely made the minimum. “Last week, we couldn’t cash in,” Maria told me. “We couldn’t even make five dollars in total.” Her family dreads the day when the tasks will stop coming, the computer breaks, or they will lose access to the internet and electricity. Ofelia, another data annotation worker, who has diabetes, depends entirely on the platform to purchase insulin. “I would die without this income,” she told me. “I would literally die.”</p>\n<p>Income from data annotation is essential to Ophelia, María’s family, and the other Venezuelans who do this work because hyperinflation has made the official monthly minimum wage in the country worth only a few dollars, which is not enough to afford staple foods to survive even a week. That has rendered most jobs paid in bolivars, the national currency, unsustainable. After years of economic mismanagement due to government corruption and its economic dependency on oil, Venezuela has a goods and services shortage and has inflation levels that are consistently among the highest in the world. This situation, combined with its existing internet infrastructure, has made the country an appealing target of crowdsourcing platforms. In the absence of a robust social safety net, workers often see these platforms as their most reliable source of income in US dollars. </p>\n<p>Before the pandemic, María and her family were migrants in neighboring Colombia for a year. María worked at a beauty salon while her husband Rodrigo worked selling coffees in the streets. The children all studied in the public education system. These were difficult but more stable times for the family. When the pandemic hit, María lost her job and, with deserted streets, Rodrigo couldn’t find many clients. With no other choice, they decided to return to Venezuela. “Here we had to look for options, and a friend recommended the platform to us,” Maria said. When the pandemic stopped in-person teaching, it meant that her three eldest children were stuck at home too, and could also perform data annotation work. In dozens of interviews with platform workers in Latin America, many of whom are or were migrants, I have heard similar stories: they were collectivizing platform labor across their household members, with teenage children doing more and more work after the onset of the pandemic. </p>\n<p>In these ways, the political and economic crisis in Venezuela, as well as the pandemic and remote schooling, have turned out to be productive for data annotation platforms, their clients, and the venture capitalists that back them. (These crises have also generated profits for companies selling information to carceral states: Onfido, the identity verification company used by electronic wallets, shares the identity and facial recognition data it collects with the United Kingdom police.) The thousands of companies and research institutions that develop artificial intelligence are using platforms to find cheap outsourced labor, especially from low-income economies, for global markets in which data and labor are sold as commodities. One of the results is a race to the bottom in which wages get lower and lower as competition between platforms—and their ability to find pools of ready labor even among people living in refugee camps—goes up.</p>\n<p>The invisibility of the workers in this process, and the myth of “one user, one account,” which permeates the technology industry, are at the center of many tech companies’ business models; in many cases, they pretend that their products are entirely automated and devoid of human intervention. In fact, the most popular data-annotation platform in the United States and India, Amazon Mechanical Turk, is named after an eighteenth-century automaton that deceived spectators by seeming to play chess autonomously while concealing a human player inside. From the clients’ perspective, workers are just users or, even worse, less than robots: “To be successful at this job, you have to think like a machine,” said one of the platform administrators to Cecilia, a worker I interviewed.</p>\n<p>Once we see through the single-user facade, we can begin to appreciate the ways in which workers and their networks have gamed data annotation platforms and collaborated to mitigate the crises they face. These survival tactics can be important resources for other workers and communities facing similar exploitation. At the same time, though, these tactics indirectly serve to prop up the neocolonial labor practices of the platforms, their clients, and venture capital. In order to challenge these larger forces, we not only need to hold companies and research institutions accountable for the value they extract from “indivisibilized” workers. More importantly, we need to support emerging community-based alternatives to data annotation platforms—alternatives built by the people actually subject to this highly extractive form of work.</p>\n<h1><b>Survival Tactics</b></h1>\n<p>In the suburbs of Valencia, in Carabobo State, data-annotation workers like Alfredo must increasingly rely on their own efforts to survive. “Our water comes from a pump,” Alfredo told me recently. “Every block of houses has a well, and every day the community designates someone to operate the pump to fill those wells.” The country’s ongoing economic and political crisis has caused the state and traditional businesses to become less present and effective in peoples’ lives; with little support from their local institutions or from employers, workers have increasingly had to rely on families and local communities for survival. Many of these communities manage water and waste disposal locally as common goods and services. These community-based services are necessary so workers can be ready for work, but not always robust or safe; for example, workers in communities that have had to resort to private waste incineration have been poisoned by smoke pollution. </p>\n<p>Community support is also critical online, where workers share resources and organize with others through social media platforms like Facebook and Discord. Originally, the data-annotation platforms themselves created internal online groups to communicate with workers; however, these groups were heavily policed by moderators from the platforms. On one occasion, Roberto, a Black Venezuelan, wondered why Onfido’s AI could not manage to match his face and ID to validate his account. The moderators responded by expelling him from the online group. “I was astonished,” he told me. “I was expelled for asking a question!” </p>\n<p>This kind of policing prompted many workers to form their own groups. Through my interviews, I found groups where workers would seek help learning how to complete tasks, complain about the platforms, and, on one occasion, organize a strike: members of a major Facebook group for data-annotation workers in Venezuela tried to convince their peers not to work for a few days, inspired by colleagues in the Philippines who, according to the organizers, successfully improved their wages by refusing to work. Despite the organizers’ efforts, most workers and their families were so dependent on the platform income that they couldn’t join the strike. </p>\n<p>Through my interviews, I also found that some workers are part of smaller, closed groups on text-based apps like Telegram. These groups have a few dozen members with fees of a few dollars per month. (It was through Rogelio, the administrator of one of these groups, that I interviewed María and her family.) These sort of online professional associations were built for workers to help each other, to generate trust, and to access currency traders, who exchange virtual dollars and cryptocurrency for bolivars. In these groups, workers share resources, like bots that alert them when tasks are available, and guides that explain how to solve tasks more efficiently. I was told that one group pooled their savings to pay a programmer in Spain to code one of these bots for them. </p>\n<p>Workers also use the groups to buy and sell accounts on the data-annotation platforms. New platform workers are not allowed by the platforms to perform many annotation tasks, and it takes a great investment of time to gain access to the best work. As a result, there is an informal market for the highest, “level 3” accounts, which are sometimes sold individually for roughly ten US dollars, or in packages of at least as many as ten.</p>\n<p>Online worker groups can also transcend the virtual—for example, when a fellow member cannot work from home and needs a place to go, or when a member tries to take advantage of another one. A worker named Rodolfo told me about a colleague who refused to pay after receiving login details for ten platform accounts. “Hopefully, the moderators have personal information of every single member, including addresses,” he told me. “They contacted the seller physically and realized that she had lost access to electricity and couldn’t complete the transaction.” Trust in his fellow workers is essential in a context where online scams are common.</p>\n<p>These forms of community support are vital to workers, but they also put the onus on workers to make the data platforms’ business models sustainable. But even then, workers are disposable: when a platform can no longer drive down wages in a particular country, they can simply look to other places and other crises.</p>\n<h1><b>Beyond the Visible</b></h1>\n<p>Since platforms are not usually physically and administratively present in the countries where workers are located, they can relocate quickly. I have conducted quantitative research on the web traffic of ninety-three crowdsourcing platforms and shown that some of those present in Venezuela are now targeting workers in Kenya. This repeats the same model used by non-data-annotation gig work apps, such as Uber, which launch in a country with incentives that make workers dependent on the platform and then remove those incentives once they create dependency. </p>\n<p>Making workers and their communities more visible may be one way to demand these platforms change their business models. But pointing out the collective exploitation at the heart of data annotation should also be used to pressure the platforms’ clients, including developers, management, and individual researchers, as well as investors, shareholders, and university administrators. In order to do this, we need more efforts to document the origins of datasets, third-party audits on AI models to assess their compliance with local and international labor standards, and assessments of the working conditions of platforms.</p>\n<p>However, as the scholar Noopur Raval argues, making workers and their communities visible is not enough. Since the economic incentives for platforms and their clients will remain, major actors in the data-annotation pipeline need to be directed to change their practices through regulation. In addition, in the place of exploitative multinational gig work platforms, companies and research institutions that require annotation need to support local initiatives from unionization to cooperative ownership of locally created platforms.</p>\n<p>In fact, there is a burgeoning ecosystem of platform companies owned and managed by workers. These companies have the potential to be more sustainable alternatives to the mainstream gig economy platforms. The Platform Cooperative Consortium lists 506 co-op projects in thirty-three countries. Many have emerged in sectors like ride-hailing and delivery, but the market for cooperative data annotation remains untapped. It is also worth mentioning that local impact sourcing companies, where data annotation occurs on-site by employed workers, could represent a more reliable alternative, in terms of data quality and labor conditions, than many platforms currently in the market. Ultimately, only solutions that recognize the communal nature of work and economic justice can have transformative effects on the lives of workers like María and her family. Inequality in platform labor is not an issue of individual workers, but networks of people who resist the paradox of a technology that innovates for some by exploiting others.</p>",
      "content_text": "Since the early months of the Covid-19 pandemic, María’s house has been run like a factory. Every day, her family of six synchronizes their routines so two people are always behind a computer. María, her husband Rodrigo, and their children, Daniela (20), Andrés (18), and Camila (13) are among the unknown number of Venezuelans who, after years of political and economic crisis exacerbated by the pandemic, now try to make a living by annotating data through crowdsourcing platforms. Using two Canaima laptops, which the Hugo Chavéz government provided a decade ago for school children, they tag images and videos, transcribe text and audio, search for information online, and send videos and pictures of themselves to developers at companies and research institutions in Europe and North America. The developers use this data to train machine learning algorithms, like the ones that do facial recognition, moderate content, and guide self-driving cars.\nThe family’s activities all revolve around data production because this is their only source of income and, according to María, they have to “focus on the same objective to survive.” She and Rodrigo do most of the work, although she also takes care of many domestic duties. Camila, Andrés, and Daniela work part time on data annotation while attending high school and university. Only María’s youngest child, Sebastián (7) is able to focus exclusively on school. Although most crowdsourcing platforms’ terms of use state that each account must be run by a single adult, often the only hard requirement to set up an account is for someone to prove that they are at least eighteen years old by taking pictures of an identification card and their face, and praying that a third-party facial recognition verification system called Onfido detects a match.\nThe platform the family works for pays them a few cents per task, in cryptocurrency. They are only allowed to transfer the money to their online wallet once they have made at least the equivalent of ten dollars. After working every day of the week, they usually earn around twice that much, but recently they have barely made the minimum. “Last week, we couldn’t cash in,” Maria told me. “We couldn’t even make five dollars in total.” Her family dreads the day when the tasks will stop coming, the computer breaks, or they will lose access to the internet and electricity. Ofelia, another data annotation worker, who has diabetes, depends entirely on the platform to purchase insulin. “I would die without this income,” she told me. “I would literally die.”\nIncome from data annotation is essential to Ophelia, María’s family, and the other Venezuelans who do this work because hyperinflation has made the official monthly minimum wage in the country worth only a few dollars, which is not enough to afford staple foods to survive even a week. That has rendered most jobs paid in bolivars, the national currency, unsustainable. After years of economic mismanagement due to government corruption and its economic dependency on oil, Venezuela has a goods and services shortage and has inflation levels that are consistently among the highest in the world. This situation, combined with its existing internet infrastructure, has made the country an appealing target of crowdsourcing platforms. In the absence of a robust social safety net, workers often see these platforms as their most reliable source of income in US dollars. \nBefore the pandemic, María and her family were migrants in neighboring Colombia for a year. María worked at a beauty salon while her husband Rodrigo worked selling coffees in the streets. The children all studied in the public education system. These were difficult but more stable times for the family. When the pandemic hit, María lost her job and, with deserted streets, Rodrigo couldn’t find many clients. With no other choice, they decided to return to Venezuela. “Here we had to look for options, and a friend recommended the platform to us,” Maria said. When the pandemic stopped in-person teaching, it meant that her three eldest children were stuck at home too, and could also perform data annotation work. In dozens of interviews with platform workers in Latin America, many of whom are or were migrants, I have heard similar stories: they were collectivizing platform labor across their household members, with teenage children doing more and more work after the onset of the pandemic. \nIn these ways, the political and economic crisis in Venezuela, as well as the pandemic and remote schooling, have turned out to be productive for data annotation platforms, their clients, and the venture capitalists that back them. (These crises have also generated profits for companies selling information to carceral states: Onfido, the identity verification company used by electronic wallets, shares the identity and facial recognition data it collects with the United Kingdom police.) The thousands of companies and research institutions that develop artificial intelligence are using platforms to find cheap outsourced labor, especially from low-income economies, for global markets in which data and labor are sold as commodities. One of the results is a race to the bottom in which wages get lower and lower as competition between platforms—and their ability to find pools of ready labor even among people living in refugee camps—goes up.\nThe invisibility of the workers in this process, and the myth of “one user, one account,” which permeates the technology industry, are at the center of many tech companies’ business models; in many cases, they pretend that their products are entirely automated and devoid of human intervention. In fact, the most popular data-annotation platform in the United States and India, Amazon Mechanical Turk, is named after an eighteenth-century automaton that deceived spectators by seeming to play chess autonomously while concealing a human player inside. From the clients’ perspective, workers are just users or, even worse, less than robots: “To be successful at this job, you have to think like a machine,” said one of the platform administrators to Cecilia, a worker I interviewed.\nOnce we see through the single-user facade, we can begin to appreciate the ways in which workers and their networks have gamed data annotation platforms and collaborated to mitigate the crises they face. These survival tactics can be important resources for other workers and communities facing similar exploitation. At the same time, though, these tactics indirectly serve to prop up the neocolonial labor practices of the platforms, their clients, and venture capital. In order to challenge these larger forces, we not only need to hold companies and research institutions accountable for the value they extract from “indivisibilized” workers. More importantly, we need to support emerging community-based alternatives to data annotation platforms—alternatives built by the people actually subject to this highly extractive form of work.\nSurvival Tactics\nIn the suburbs of Valencia, in Carabobo State, data-annotation workers like Alfredo must increasingly rely on their own efforts to survive. “Our water comes from a pump,” Alfredo told me recently. “Every block of houses has a well, and every day the community designates someone to operate the pump to fill those wells.” The country’s ongoing economic and political crisis has caused the state and traditional businesses to become less present and effective in peoples’ lives; with little support from their local institutions or from employers, workers have increasingly had to rely on families and local communities for survival. Many of these communities manage water and waste disposal locally as common goods and services. These community-based services are necessary so workers can be ready for work, but not always robust or safe; for example, workers in communities that have had to resort to private waste incineration have been poisoned by smoke pollution. \nCommunity support is also critical online, where workers share resources and organize with others through social media platforms like Facebook and Discord. Originally, the data-annotation platforms themselves created internal online groups to communicate with workers; however, these groups were heavily policed by moderators from the platforms. On one occasion, Roberto, a Black Venezuelan, wondered why Onfido’s AI could not manage to match his face and ID to validate his account. The moderators responded by expelling him from the online group. “I was astonished,” he told me. “I was expelled for asking a question!” \nThis kind of policing prompted many workers to form their own groups. Through my interviews, I found groups where workers would seek help learning how to complete tasks, complain about the platforms, and, on one occasion, organize a strike: members of a major Facebook group for data-annotation workers in Venezuela tried to convince their peers not to work for a few days, inspired by colleagues in the Philippines who, according to the organizers, successfully improved their wages by refusing to work. Despite the organizers’ efforts, most workers and their families were so dependent on the platform income that they couldn’t join the strike. \nThrough my interviews, I also found that some workers are part of smaller, closed groups on text-based apps like Telegram. These groups have a few dozen members with fees of a few dollars per month. (It was through Rogelio, the administrator of one of these groups, that I interviewed María and her family.) These sort of online professional associations were built for workers to help each other, to generate trust, and to access currency traders, who exchange virtual dollars and cryptocurrency for bolivars. In these groups, workers share resources, like bots that alert them when tasks are available, and guides that explain how to solve tasks more efficiently. I was told that one group pooled their savings to pay a programmer in Spain to code one of these bots for them. \nWorkers also use the groups to buy and sell accounts on the data-annotation platforms. New platform workers are not allowed by the platforms to perform many annotation tasks, and it takes a great investment of time to gain access to the best work. As a result, there is an informal market for the highest, “level 3” accounts, which are sometimes sold individually for roughly ten US dollars, or in packages of at least as many as ten.\nOnline worker groups can also transcend the virtual—for example, when a fellow member cannot work from home and needs a place to go, or when a member tries to take advantage of another one. A worker named Rodolfo told me about a colleague who refused to pay after receiving login details for ten platform accounts. “Hopefully, the moderators have personal information of every single member, including addresses,” he told me. “They contacted the seller physically and realized that she had lost access to electricity and couldn’t complete the transaction.” Trust in his fellow workers is essential in a context where online scams are common.\nThese forms of community support are vital to workers, but they also put the onus on workers to make the data platforms’ business models sustainable. But even then, workers are disposable: when a platform can no longer drive down wages in a particular country, they can simply look to other places and other crises.\nBeyond the Visible\nSince platforms are not usually physically and administratively present in the countries where workers are located, they can relocate quickly. I have conducted quantitative research on the web traffic of ninety-three crowdsourcing platforms and shown that some of those present in Venezuela are now targeting workers in Kenya. This repeats the same model used by non-data-annotation gig work apps, such as Uber, which launch in a country with incentives that make workers dependent on the platform and then remove those incentives once they create dependency. \nMaking workers and their communities more visible may be one way to demand these platforms change their business models. But pointing out the collective exploitation at the heart of data annotation should also be used to pressure the platforms’ clients, including developers, management, and individual researchers, as well as investors, shareholders, and university administrators. In order to do this, we need more efforts to document the origins of datasets, third-party audits on AI models to assess their compliance with local and international labor standards, and assessments of the working conditions of platforms.\nHowever, as the scholar Noopur Raval argues, making workers and their communities visible is not enough. Since the economic incentives for platforms and their clients will remain, major actors in the data-annotation pipeline need to be directed to change their practices through regulation. In addition, in the place of exploitative multinational gig work platforms, companies and research institutions that require annotation need to support local initiatives from unionization to cooperative ownership of locally created platforms.\nIn fact, there is a burgeoning ecosystem of platform companies owned and managed by workers. These companies have the potential to be more sustainable alternatives to the mainstream gig economy platforms. The Platform Cooperative Consortium lists 506 co-op projects in thirty-three countries. Many have emerged in sectors like ride-hailing and delivery, but the market for cooperative data annotation remains untapped. It is also worth mentioning that local impact sourcing companies, where data annotation occurs on-site by employed workers, could represent a more reliable alternative, in terms of data quality and labor conditions, than many platforms currently in the market. Ultimately, only solutions that recognize the communal nature of work and economic justice can have transformative effects on the lives of workers like María and her family. Inequality in platform labor is not an issue of individual workers, but networks of people who resist the paradox of a technology that innovates for some by exploiting others.",
      "date_published": "2022-02-08T13:54:22.000Z",
      "date_modified": "2022-02-08T13:54:22.000Z",
      "_plugin": {
        "pageFilename": "66d64770df06ed2cda7e6be6f0f3a222a6875c79e36bb2ad02466497b7a943ab.html"
      }
    },
    {
      "id": "https://logicmag.io/beacons/dark-matter",
      "url": "https://logicmag.io/beacons/dark-matter",
      "title": "Beyond Dark Matter",
      "summary": "A tween zine about time traveling and overthrowing master technologies.",
      "content_html": "<p><b><i>Beyond Dark Matter </i></b>is a tween zine about time traveling and overthrowing master technologies featuring Gem, a young student who is always on the go, Ms. Johnson, an elder who runs the local community kitchen and Archie, a retired postal service worker and handyman who volunteers at the community kitchen.\n\nThis zine is based on <a href=\"https://netabomani.com/darkmatter/\">Dark matter objects: Technologies of capture and things that can’t be held</a>.</p>\n<p></p>\n<div style=\"position:relative;padding-top:max(60%,326px);height:0;width:100%\"><iframe sandbox=\"allow-top-navigation allow-top-navigation-by-user-activation allow-downloads allow-scripts allow-same-origin allow-popups allow-modals allow-popups-to-escape-sandbox\" allowfullscreen=\"true\" style=\"position:absolute;border:none;width:100%;height:100%;left:0;right:0;top:0;bottom:0;\" src=\"https://e.issuu.com/embed.html?d=web-spread-beyond-dark-matter&pageLayout=singlePage&u=logicmagazine\"></iframe></div>\n<p></p>\n<p></p>",
      "content_text": "Beyond Dark Matter is a tween zine about time traveling and overthrowing master technologies featuring Gem, a young student who is always on the go, Ms. Johnson, an elder who runs the local community kitchen and Archie, a retired postal service worker and handyman who volunteers at the community kitchen.\n\nThis zine is based on Dark matter objects: Technologies of capture and things that can’t be held.\n\n\n\n",
      "date_published": "2022-02-04T01:50:33.000Z",
      "date_modified": "2022-02-14T14:20:26.000Z",
      "_plugin": {
        "pageFilename": "6e127b355eb668d7f34e8728f7134dab575a8638f93922bc195e521a702edbb6.html"
      }
    },
    {
      "id": "https://logicmag.io/beacons/holding-to-account-safiya-umoja-noble-and-meredith-whittaker",
      "url": "https://logicmag.io/beacons/holding-to-account-safiya-umoja-noble-and-meredith-whittaker",
      "title": "Holding to Account: Safiya Umoja Noble and Meredith Whittaker on Duties of Care and Resistance to Big Tech",
      "summary": "Critique and capture in the strange space of “AI ethics.”",
      "content_html": "<p><i>The tech industry is a monopolizing force, and one of the many things it monopolizes is the means for producing knowledge about it. In the platform era, the machinery of the internet is locked behind closed doors, creating problems for researchers. Companies like Facebook aren’t keen to share data or the other computational resources needed to develop a complete picture of how large algorithmic systems work (and whom they work for). And these companies’ endless amounts of money give them plenty of other ways to derail critical research, in particular by exercising influence over academia and the other places where knowledge about the tech industry is made, as well as by co-opting or silencing individual researchers.</i></p>\n<p><i>Given these obstacles, how can researchers both inside and outside of tech companies do the difficult work of research, critique, and resistance?</i></p>\n<p><i>To discuss this and other related questions, issue editor J. Khadijah Abdurahman talked with two leading critical scholars of technology. Dr. Safiya Umoja Noble is a MacArthur Genius Fellowship recipient and an Associate Professor of Gender Studies and African American Studies at UCLA, where she serves as the cofounder and director of the UCLA Center for Critical Internet Inquiry. She is also the author of the seminal book debunking technologies as neutral artifacts of progress, </i>Algorithms of Oppression: How Search Engines Reinforce Racism.<i> Meredith Whittaker is the Faculty Director and cofounder of the AI Now Institute, and a Minderoo Research Professor at NYU. She resigned from Google after organizing with her coworkers against the company’s efforts to build military AI and its failure to address rampant discrimination and sexual abuse. Abdurahman spoke with Noble and Whittaker about how to do critical tech research, and how to insist on transformative justice practices as we try to dismantle technologies of oppression.</i></p>\n<hr />\n<p><b><i>Beacons</i></b><b> was conceived of in the wake of Dr. Timnit Gebru’s high-profile firing from Google. Similarly, the impetus for this interview was the systematic firing of Black women from academia and industries—those who were essentially fulfilling their duties and showing up as their full selves. On one hand, there’s a question of what is to be done about institutional and corporate power—but the bright lines dictating who are the villains in a David and Goliath story let us off the hook in terms of internal cultures of accountability. Are there different ways to relate to one another and be accountable, as we respond to institutional repression? How are each of you thinking about these questions as we’re approaching the one year anniversary of Dr. Gebru’s firing?</b></p>\n<p>Safiya Umoja Noble (SN): The question about how do we hold ourselves accountable is really important. I know that there is always a series of conversations happening among people who work in the field of AI and ethics, which is a big tent of people holding competitive and often diametrically opposed ideas. You have, for example, companies like Google that consider themselves leaders in ethical AI; and then you have the women, the people of color, the LGBTQ scholars, the activists, and the journalists who for two decades have been trying to make their issues about the immorality or the politics of various types of technologies legible. </p>\n<p>That legibility has also led to an intense capture by people who are not interested in the radical reimagining of or resistance to these technologies, or in the way that these technologies are reshaping society, consolidating power in the hands of a few, and making the world more socially, politically, and economically unequal. So, it’s interesting to have this conversation on the almost anniversary of the firing of Dr. Gebru from Google. Because watching her ascent to that position of leadership and then her firing, when she named the racist technologies and environmentally consequential technologies that Google is developing, is symbolic of the nefarious intent or willful ignoring of the core issues at stake. It’s symbolic because there are in fact thousands of people who have been organizing for a long time around these issues, trying to ensure that these conversations about AI ethics still keep their kind of political importance and are not just completely defanged and depoliticized. I don’t know, Meredith. What do you think? </p>\n<p>Meredith Whittaker (MW): There are so many ways I can approach this. It’s very personal because Timnit is someone—along with Meg Mitchell and others—who stood up for me when Google pushed me out. So I’m also seeing an attack on support structures within these organizations and an attack on the people with the courage to call out bad behavior. I think Timnit’s firing was an inflection point that you captured in “On the Moral Collapse of AI Ethics,” Khadijah. When you published that piece in the wake of her firing, it laid bare the stakes and failures we’re confronting.</p>\n<p>Before Timnit’s firing, there’d been enough people who were willing to—mainly in the name of civility politics—give Google the benefit of the doubt. Then the company fired Timnit, someone who had been outspoken about the racism inside of Google <i>and</i> who had been doing research that was exposing fundamental problems with Google’s business practices. Timnit called out racism <i>and</i> her work showed that the large language models at the core of Google’s current product and profit strategy are biased, environmentally harmful, and an overall problem. It was when criticism of Google’s racist culture and criticism of its harmful business practices converged that Google retaliated, in what I saw as an almost reflexive reaction. It was clear that leadership just “had enough,” and went on to make an astonishing string of unforced errors. The corporate immune system kicked into gear: “Okay, fuck it, we’re going to make a really bad PR move, which we calculate we’re powerful enough to withstand. What we can’t withstand any longer is the tension of ‘supporting’ AI ethics on one side, and selling biased, extractive, unverified AI on the other; of doing diversity and inclusion PR on one side, and discriminating against Black women on the other.” </p>\n<p>Google’s firing of Timnit reverberated through the AI ethics space for many reasons. One, I think, is because the space is so co-opted and so unwilling to look at who pays us, at who our community is—insofar as we are a community. And suddenly, unexpectedly, the field was faced with big existential questions, which in many cases challenged people’s comfortable status quo: can we work with Google and other tech corporations? What are the limits corporate funders actually put on our research, on the research we review as part of our conference program committee roles, on the research of the corporate-employed collaborators we co-author with? Many in the space were largely avoiding these questions which, we should note, are standard in many other fields.</p>\n<p>This moment also illuminated some of the ways that the field is configured. People use the word community—the AI ethics community, or whatever—but a lot of times “community” is just a bunch of people a funder paid to fly somewhere, or a group of folks whose employers are willing to fund them to go to the same conference. The people in these “communities” may have vastly divergent politics and motivations, and these communities are certainly predominantly white, and often very exclusionary. I may be sitting next to someone who’s funded by the Koch Foundation, who believes Facebook is a net good. But we’re both narrated under this umbrella of “community,” and we’re all usually nice and civil to each other because clarifying political commitments in these circumstances has material stakes, and could get you kicked out of the “community.” To put it bluntly, as the leader of an organization, I have to go back home and I have to make sure my people have jobs and health insurance, that I have health insurance, that my family is supported. Of course, there’ll be certain things I do feel I can agitate or call out. But I also have a duty of care that I may be jeopardizing if I go too far, and I feel this tension constantly. </p>\n<p>Amy Westervelt has a really good podcast called <i>Drilled</i>, and the first season traces the history of Exxon. At one point the company was genuinely trying to support and understand climate science and climate change, trying to get ahead of it and figure out how its business model could adapt, to potentially provision other sources of non-fossil energy. This approach got traction until the company refused to adapt their business model to the science and doubled down, which initiated a slow process of Exxon pushing climate scientists out of the company, and then turning to climate denial; for example, funding anti-climate heterodox “scientists” and related misinformation campaigns. </p>\n<p>We’re in a similar phase in the AI ethics space. Initially, big companies accommodated the ethical implications of AI research, but when it challenged their culture and their business model, they started pushing us out, denigrating us and our research. This is happening right now. But as researchers weathering this transition, we haven’t had that real talk about things like, “Whose money do we take?” Or: “Why is so much so-called tech criticism funded by the companies whose tech is purportedly being criticized?” We’re in the process of a rude awakening. It’s like a limb coming back to life after being asleep—it’s painful for a lot of people. </p>\n<h1><b>Open Letters to the Apocalypse</b></h1>\n<p><b>Part of what I was thinking through when I wrote “On the Moral Collapse of AI Ethics” was—and I’m saying this as someone who has written my own open letter—what to do with this asymmetry between writing an open letter and the stakes of techno capitalism. The open letter that I spend a lot of time thinking about is the Franck Report of June 1945, which was signed by several prominent nuclear physicists who had worked on the Manhattan Project. They delivered it to the White House, saying “Maybe we should just let the Japanese come over and see our capability, and not drop the atomic bomb?” Then, as we all know, in August 1945, you have first Hiroshima and then Nagasaki.</b></p>\n<p><b>So we’re facing these tremendous stakes and also have to contend with the civility politics you both alluded to. How do we negotiate the obvious villains of centralized corporate computing capital, while also this negotiation among ourselves? Who is the resistance? How do we identify what that means? What does the coalition look like and how do we start thinking about some of those bright lines? </b></p>\n<p>SN: Well, one of the challenges is that not everybody who is working on these issues relates to themselves as community organizers, or relates to each other inside a politics of accountability, shared responsibility, protection, and support, or has committed to a process of hashing out hard conversations, strategies, and ideas about how to move forward. You see this most profoundly in the fairness, accountability, transparency efforts and movement under ACM—the Association for Computing Machinery, an international educational and scientific computing society—which has really, from its inception, marginalized the more radical political critiques of systems and has sought to pursue perfecting technology and to champion techno-solutionism. Though they might more recently be grafting on a Black feminist quote to open a paper, they’re still seeking to address the fairness questions around tech in terms of <i>better</i> algorithms or <i>better</i> AI. </p>\n<p>That’s really different from what others of us are doing, those of us who think some of these technologies should not exist—to your point, Khadijah, that we shouldn’t have the Manhattan Projects of AI today. And then when we look up and see that the whole world has been reorganized through these ubiquitous technology deployments, in every single industry and every sector that are, in essence, snake oil or have profound civil and human and sovereign rights implications. That’s actually a completely different project to be working on in the world. </p>\n<p>Part of the challenge here is that researchers have been socialized in academia to be apolitical or to think of themselves as scientists and not as people who have values imbued into the work that they’re doing. That is also part of the problem that we’re trying to contend with around the making of these technologies that are also allegedly neutral and just tools. This is part of the reason why we need feminists and why we need people who are committed and connected to social movements around the world to contextualize our work and to make sense of what it’s working in service of. That’s really important. </p>\n<p>MW: AI is an umbrella marketing term. It’s not a term of art that describes a specific technique. Companies apply the name AI to data-centric approaches generally, and you never quite know what you’re buying if you’re licensing an “AI” system. </p>\n<p>The AI boom of the last decade was not the result of a major scientific innovation in algorithmic techniques. It was a recognition that with massive amounts of data and computing power, you can make old techniques do things they couldn’t do before. The ascent of AI was predicated on concentrated tech company power and resources which had, as their driving force, the surveillance business model. </p>\n<p>One thing we rarely discuss is how AI research and development’s dependence on corporate resources worked—and continues to work—to shape and in some cases co-opt knowledge production. In other words, to “do AI” as defined in the current “bigger is better” paradigm, you increasingly need resources that are controlled by these handful of companies. You need access to really expensive cloud compute, you need access to data that is hard and sometimes impossible to get. You can’t just go to the data market and buy it—you often need to get access from the data’s creators or collectors, who are often the tech companies. It’s fair to say that academic computer science disciplines underwent a kind of soft-capture, in which as a condition of doing “cutting edge” AI research, over the last decade they became increasingly dependent on corporate resources, and corporate largesse. </p>\n<p>This dynamic led to practices like dual affiliation, where professors work at a tech company but have a professorial title and produce research under their university affiliation. It’s led to tech companies moving whole corporate labs into the middle of universities—like Amazon’s machine vision lab at Caltech. We have a structural imbrication between a massive, consolidated industry and knowledge production about what that industry does. And this compromised entanglement has bled into the fairness and ethics space, in many cases without anyone commenting on it. There are many forces working against our recognition of how captured the technical disciplines are at this time, and how easy it is for them to extend this capture into fairness, ethics, and other disciplinary pursuits focused on the consequences and politics of tech. </p>\n<p>To pick one example, Amazon is underwriting half of the National Science Foundation’s Fairness in Artificial Intelligence grants. And while a few people called this out, the fields concerned went on to apply for this funding, and uncritically applauded colleagues who received it. Whole labs are reliant on Amazon, Google, Facebook, Microsoft funding, and if you raise questions about it you’re endangering your ability to support your postdocs, your ability to obtain future funding, your standing with your dean. Or, you’re endangering your colleagues in these same ways. Dissecting the particularities of what it means to be able to do research on AI and related technologies, and how dependent this work often is on corporate resources, is a project that I think can help develop a clearer political-economic read of tech and the tech industry overall, and reveal the capital interests that are propelling research and knowledge production into tech and its implications. </p>\n<p>SN: This is a critical area especially during the time of Covid-19, when we saw how fragile so many of our public institutions are. We really feel that at a place like UCLA, where teaching assistants aren’t paid adequately, it’s extremely expensive to get an undergraduate degree, and the pressures to deliver public education are intense. Many, many systems are broken, and it is very painful to work under those kinds of broken systems. </p>\n<p>Meredith, I recognize this tech sector political economy you’re describing. They are capturing not only scholars but policymakers who, in essence, use public money to subsidize the entire industry, both through the research efforts at the National Science Foundation and also by making it impossible for democratic public institutions to flourish, because they don’t pay their fair share. They offshore their profits, and they don’t reinvest them back into communities where they do business in extremely exploitative ways. They just expect the public to underwrite it through tax refunds. How in the world can companies like Apple get tax refunds except through pure corruption? As we struggle in our communities with and in our institutions, we have to identify why those conditions are present. We have to recognize who has monopolized all of the resources and we have to examine the narrative about what’s happening with those resources.</p>\n<p><b>I want to ask you about social media and “cancel culture.” In July 2020, </b><b><i>Harper’s</i></b><b> published “A Letter on Justice and Open Debate,” signed by a number of prominent people, including Noam Chomsky and J.K. Rowling. The letter criticized “an intolerant climate” on the Left, and in particular, “an intolerance of opposing views, a vogue for public shaming and ostracism, and the tendency to dissolve complex policy issues in a blinding moral certainty.” The following month, in August 2020, </b><b><i>The Atlantic</i></b><b> published a piece by Anne Applebaum called “The New Puritans,” that used Nathaniel Hawthorne’s </b><b><i>The Scarlet Letter</i></b><b> to criticize social media “mob justice.” The irony of invoking the white woman’s public humiliation for being pregnant out of wedlock is that the book was published more than a decade before the Civil War. Black and Indigenous peoples’ ongoing bondage and claims to liberation are as unnamed in the book as they are in today’s epistles of moral panic.</b></p>\n<p><b>But how do we negotiate this issue? Is calling people out on Twitter our only mode of addressing power dynamics in the AI ethics space? How can we put forward a vision that is constructive and not just reactive, even though our operational capacity is so low, even though we’re all exhausted, grieving, and torn into so many different directions? What is our vision for transformative justice in the context of knowledge production?</b></p>\n<p>MW: Look, I have a lot to say here. First, I think there’s a visibility bias: people see when calls for accountability and redress spill into the public. They rarely see the agonizing work of trying to hold harmful people and institutions accountable behind the scenes. Work that’s too often not only unrewarded, but actively punished. Like many people, I have engaged in a number of accountability processes that didn’t end with Twitter callouts and are not visible to the public. In my experience, Twitter is always a last resort. There are failures upon failures upon failures within these institutions and with the way power moves within them, all of which happen before someone is going to take to Twitter or call on social media as a witness. Timnit taking to Twitter didn’t save her job. </p>\n<p>Buried in the moral panic around “cancel culture” is a burning question about how you hold power to account when you’re in an institution that will punish you for doing so. What do you do when your wellbeing and duties of care dictate that you confront and curtail harmful behavior, but you know that any such attempt risks your livelihood and institutional and professional standing? Institutions protect power. Universities don’t want to touch a star professor who’s bringing in press and grants; tech companies have every incentive to coddle the person architecting the algorithm that is going to make them a shit ton of money. These corporations and corporate universities are structured to protect flows of capital and, by extension, to protect the people who enable them. There are infrastructures in place—including HR and most Title IX offices—to make sure that those who enable the interests of capital are elevated and to make sure that it’s as painful as possible for the people who might report anything. </p>\n<p>This is the backdrop against which we’re trying to figure out how we, as people within these environments, protect ourselves and each other. In my view, the answer to this question doesn’t start with building a better HR, or hiring a diversity consultant. It’s rooted in solidarity, mutual care, and in a willingness to understand ourselves as committed to our own and others’ wellbeing over our commitments to institutional standing or professional identity. </p>\n<p>That’s also a question of how we can be accountable ourselves. Especially as people who have institutional power, and who may experience favorable treatment from the same people who harm those with less power. In other words, the more power we have the less we can rely on our experience of people and institutions as an accurate barometer, because there’s every incentive to act the sycophant. This means we need to actually listen to, elevate, believe, and act on the accounts of those with less power, especially Black people and historically marginalized people for whom institutional abuse is compounded. And we need to be willing to put their safety and wellbeing above our institutional and professional standing. This is very hard, but in my view it’s the floor. If you can’t do it, then you shouldn’t be in a position of leadership. </p>\n<p>SN: I relate so much to all the things you’re saying. I think we’re in a long struggle around creating systems of mutual care, aid, and support, and that is very difficult. Most of the environments that we’re trying to build those systems within, like academia, are hostile to trying to get work done and get people supported properly. Having said that, we have to keep building these networked communities. We have to be agile and we have to think about how we’re going to create more space for others to do their work. </p>\n<p>In my own experience and my own career, I have felt at many times completely unsupported. I have felt like if I could just expand the circle at some point in my career so that more people could be supported, that would be something. The question is, to what degree can we institutionalize that so that all of the possibilities don’t hinge on one person in one space or place, but that we remake entire systems? We want those systems to last and not rely on any one particular person. That’s difficult work and we need to be sharing ideas about how to do that. </p>\n<p>But the problems that we’re working on are very big problems in the world and in our communities. I think about abolitionist traditions: you know, how did a handful of people change the world? Millions of Americans got up every day and made pancakes and went to work while people were being human-trafficked right in front of them and enslaved, beaten, lynched, and harmed on the regular. How did abolitionists, in the face of those conditions, abolish the transatlantic slave trade or change the laws around the enslavement of African peoples? How did others resist the expansion into First Nations and Indigenous peoples’ lands? There weren’t millions of people working on these issues. It was, relative to the population, a very small number of people who worked on those things. </p>\n<p>I guess I feel heartened by the fact that if enough people can be coordinated, a lot of change can happen. That is why we have to study history and study social movements to figure out how they did it and how to make it last. Especially for those of us right now living through the rollback of the Civil Rights Movement, we know that those changes can also be precarious. We have to figure out how to make them last. </p>\n<h1><b>On Some Global Tech Resistance</b></h1>\n<p><b>Academia is coming for our lives, so much of our time is swallowed up into institutional administrative overhead, and also we’re facing major stakes that are global. It’s so difficult to even stay on top of our own “domain expertise,” so how do we facilitate transnational solidarity? How do we think about this work as global? What are the points of connections you identify around intellectually, and politically, in your own work? What kind of infrastructure represents the next steps that could be taken to bolster this kind of transnational research?</b></p>\n<p>SN: We have to keep our diasporic commitments intact while we’re doing our work. And of course, we sit here in the heart of the American technology empire. We have a responsibility where we are in this location to press on these companies and on governments to ease exploitation around the world. Many of us understand these questions because we come from internal colonies of the United States, which is one of the ways that sociologists have talked about Black people’s experience in the Americas. Our work is connected materially to other people’s lives around the world. </p>\n<p>We have to be in community. We have to be in conversation. And we also have to recognize what our piece of the puzzle is ours to work on. While it is true, yes, we’re just individual people, together we’re a lot of people and we can shift the zeitgeist and make the immorality of what the tech sector is doing—through all its supply chains around the world—more legible. It’s our responsibility to do that as best we can. </p>\n<p>MW: Yeah, I agree. I’m a white lady raised in LA. I had to educate myself on so much that I didn’t understand, and that process is humbling and ongoing. </p>\n<p>My voice doesn’t need to be the center of every conversation. But, okay, if I have a little power and a little standing maybe I can move capital, maybe I can ask people what they need and see what I can do to get it to them, to support and nurture their expertise and organizing and approaches, which may be completely unfamiliar to me, and may not need any advice or insight from me. I’m thinking of the ACM Conference on Fairness, Accountability, and Transparency (FAccT). Briefly, it’s a computer-science focused conference exploring fairness in algorithms. Over the years, we have seen increasing calls to examine algorithmic and other technologies in the context of racial capitalism and structural inequality, accompanied by warnings about the insufficiency of narrow FAccT-style technical approaches to the problems of algorithms and tech. So, what was the response? From many people, it wasn’t a re-evaluation of the field, but instead a move to absorb. Like, “Oh, well, how about we bolt an Audre Lorde quote to this computational social science paper.” This response continues to place computer science at the center, with racial justice as seasoning. Even though there are, of course, Black feminist conferences that could use some funding, and that have been deep in these topics for decades before FAccT. So my question is, why is the instinct always to absorb into the core instead of diffuse the resources to those already doing the work? </p>\n<p><b>I mean, I fuck with that. We need allyship in the form of funneling actual, material support out of these Western institutions.</b></p>",
      "content_text": "The tech industry is a monopolizing force, and one of the many things it monopolizes is the means for producing knowledge about it. In the platform era, the machinery of the internet is locked behind closed doors, creating problems for researchers. Companies like Facebook aren’t keen to share data or the other computational resources needed to develop a complete picture of how large algorithmic systems work (and whom they work for). And these companies’ endless amounts of money give them plenty of other ways to derail critical research, in particular by exercising influence over academia and the other places where knowledge about the tech industry is made, as well as by co-opting or silencing individual researchers.\nGiven these obstacles, how can researchers both inside and outside of tech companies do the difficult work of research, critique, and resistance?\nTo discuss this and other related questions, issue editor J. Khadijah Abdurahman talked with two leading critical scholars of technology. Dr. Safiya Umoja Noble is a MacArthur Genius Fellowship recipient and an Associate Professor of Gender Studies and African American Studies at UCLA, where she serves as the cofounder and director of the UCLA Center for Critical Internet Inquiry. She is also the author of the seminal book debunking technologies as neutral artifacts of progress, Algorithms of Oppression: How Search Engines Reinforce Racism. Meredith Whittaker is the Faculty Director and cofounder of the AI Now Institute, and a Minderoo Research Professor at NYU. She resigned from Google after organizing with her coworkers against the company’s efforts to build military AI and its failure to address rampant discrimination and sexual abuse. Abdurahman spoke with Noble and Whittaker about how to do critical tech research, and how to insist on transformative justice practices as we try to dismantle technologies of oppression.\n\nBeacons was conceived of in the wake of Dr. Timnit Gebru’s high-profile firing from Google. Similarly, the impetus for this interview was the systematic firing of Black women from academia and industries—those who were essentially fulfilling their duties and showing up as their full selves. On one hand, there’s a question of what is to be done about institutional and corporate power—but the bright lines dictating who are the villains in a David and Goliath story let us off the hook in terms of internal cultures of accountability. Are there different ways to relate to one another and be accountable, as we respond to institutional repression? How are each of you thinking about these questions as we’re approaching the one year anniversary of Dr. Gebru’s firing?\nSafiya Umoja Noble (SN): The question about how do we hold ourselves accountable is really important. I know that there is always a series of conversations happening among people who work in the field of AI and ethics, which is a big tent of people holding competitive and often diametrically opposed ideas. You have, for example, companies like Google that consider themselves leaders in ethical AI; and then you have the women, the people of color, the LGBTQ scholars, the activists, and the journalists who for two decades have been trying to make their issues about the immorality or the politics of various types of technologies legible. \nThat legibility has also led to an intense capture by people who are not interested in the radical reimagining of or resistance to these technologies, or in the way that these technologies are reshaping society, consolidating power in the hands of a few, and making the world more socially, politically, and economically unequal. So, it’s interesting to have this conversation on the almost anniversary of the firing of Dr. Gebru from Google. Because watching her ascent to that position of leadership and then her firing, when she named the racist technologies and environmentally consequential technologies that Google is developing, is symbolic of the nefarious intent or willful ignoring of the core issues at stake. It’s symbolic because there are in fact thousands of people who have been organizing for a long time around these issues, trying to ensure that these conversations about AI ethics still keep their kind of political importance and are not just completely defanged and depoliticized. I don’t know, Meredith. What do you think? \nMeredith Whittaker (MW): There are so many ways I can approach this. It’s very personal because Timnit is someone—along with Meg Mitchell and others—who stood up for me when Google pushed me out. So I’m also seeing an attack on support structures within these organizations and an attack on the people with the courage to call out bad behavior. I think Timnit’s firing was an inflection point that you captured in “On the Moral Collapse of AI Ethics,” Khadijah. When you published that piece in the wake of her firing, it laid bare the stakes and failures we’re confronting.\nBefore Timnit’s firing, there’d been enough people who were willing to—mainly in the name of civility politics—give Google the benefit of the doubt. Then the company fired Timnit, someone who had been outspoken about the racism inside of Google and who had been doing research that was exposing fundamental problems with Google’s business practices. Timnit called out racism and her work showed that the large language models at the core of Google’s current product and profit strategy are biased, environmentally harmful, and an overall problem. It was when criticism of Google’s racist culture and criticism of its harmful business practices converged that Google retaliated, in what I saw as an almost reflexive reaction. It was clear that leadership just “had enough,” and went on to make an astonishing string of unforced errors. The corporate immune system kicked into gear: “Okay, fuck it, we’re going to make a really bad PR move, which we calculate we’re powerful enough to withstand. What we can’t withstand any longer is the tension of ‘supporting’ AI ethics on one side, and selling biased, extractive, unverified AI on the other; of doing diversity and inclusion PR on one side, and discriminating against Black women on the other.” \nGoogle’s firing of Timnit reverberated through the AI ethics space for many reasons. One, I think, is because the space is so co-opted and so unwilling to look at who pays us, at who our community is—insofar as we are a community. And suddenly, unexpectedly, the field was faced with big existential questions, which in many cases challenged people’s comfortable status quo: can we work with Google and other tech corporations? What are the limits corporate funders actually put on our research, on the research we review as part of our conference program committee roles, on the research of the corporate-employed collaborators we co-author with? Many in the space were largely avoiding these questions which, we should note, are standard in many other fields.\nThis moment also illuminated some of the ways that the field is configured. People use the word community—the AI ethics community, or whatever—but a lot of times “community” is just a bunch of people a funder paid to fly somewhere, or a group of folks whose employers are willing to fund them to go to the same conference. The people in these “communities” may have vastly divergent politics and motivations, and these communities are certainly predominantly white, and often very exclusionary. I may be sitting next to someone who’s funded by the Koch Foundation, who believes Facebook is a net good. But we’re both narrated under this umbrella of “community,” and we’re all usually nice and civil to each other because clarifying political commitments in these circumstances has material stakes, and could get you kicked out of the “community.” To put it bluntly, as the leader of an organization, I have to go back home and I have to make sure my people have jobs and health insurance, that I have health insurance, that my family is supported. Of course, there’ll be certain things I do feel I can agitate or call out. But I also have a duty of care that I may be jeopardizing if I go too far, and I feel this tension constantly. \nAmy Westervelt has a really good podcast called Drilled, and the first season traces the history of Exxon. At one point the company was genuinely trying to support and understand climate science and climate change, trying to get ahead of it and figure out how its business model could adapt, to potentially provision other sources of non-fossil energy. This approach got traction until the company refused to adapt their business model to the science and doubled down, which initiated a slow process of Exxon pushing climate scientists out of the company, and then turning to climate denial; for example, funding anti-climate heterodox “scientists” and related misinformation campaigns. \nWe’re in a similar phase in the AI ethics space. Initially, big companies accommodated the ethical implications of AI research, but when it challenged their culture and their business model, they started pushing us out, denigrating us and our research. This is happening right now. But as researchers weathering this transition, we haven’t had that real talk about things like, “Whose money do we take?” Or: “Why is so much so-called tech criticism funded by the companies whose tech is purportedly being criticized?” We’re in the process of a rude awakening. It’s like a limb coming back to life after being asleep—it’s painful for a lot of people. \nOpen Letters to the Apocalypse\nPart of what I was thinking through when I wrote “On the Moral Collapse of AI Ethics” was—and I’m saying this as someone who has written my own open letter—what to do with this asymmetry between writing an open letter and the stakes of techno capitalism. The open letter that I spend a lot of time thinking about is the Franck Report of June 1945, which was signed by several prominent nuclear physicists who had worked on the Manhattan Project. They delivered it to the White House, saying “Maybe we should just let the Japanese come over and see our capability, and not drop the atomic bomb?” Then, as we all know, in August 1945, you have first Hiroshima and then Nagasaki.\nSo we’re facing these tremendous stakes and also have to contend with the civility politics you both alluded to. How do we negotiate the obvious villains of centralized corporate computing capital, while also this negotiation among ourselves? Who is the resistance? How do we identify what that means? What does the coalition look like and how do we start thinking about some of those bright lines? \nSN: Well, one of the challenges is that not everybody who is working on these issues relates to themselves as community organizers, or relates to each other inside a politics of accountability, shared responsibility, protection, and support, or has committed to a process of hashing out hard conversations, strategies, and ideas about how to move forward. You see this most profoundly in the fairness, accountability, transparency efforts and movement under ACM—the Association for Computing Machinery, an international educational and scientific computing society—which has really, from its inception, marginalized the more radical political critiques of systems and has sought to pursue perfecting technology and to champion techno-solutionism. Though they might more recently be grafting on a Black feminist quote to open a paper, they’re still seeking to address the fairness questions around tech in terms of better algorithms or better AI. \nThat’s really different from what others of us are doing, those of us who think some of these technologies should not exist—to your point, Khadijah, that we shouldn’t have the Manhattan Projects of AI today. And then when we look up and see that the whole world has been reorganized through these ubiquitous technology deployments, in every single industry and every sector that are, in essence, snake oil or have profound civil and human and sovereign rights implications. That’s actually a completely different project to be working on in the world. \nPart of the challenge here is that researchers have been socialized in academia to be apolitical or to think of themselves as scientists and not as people who have values imbued into the work that they’re doing. That is also part of the problem that we’re trying to contend with around the making of these technologies that are also allegedly neutral and just tools. This is part of the reason why we need feminists and why we need people who are committed and connected to social movements around the world to contextualize our work and to make sense of what it’s working in service of. That’s really important. \nMW: AI is an umbrella marketing term. It’s not a term of art that describes a specific technique. Companies apply the name AI to data-centric approaches generally, and you never quite know what you’re buying if you’re licensing an “AI” system. \nThe AI boom of the last decade was not the result of a major scientific innovation in algorithmic techniques. It was a recognition that with massive amounts of data and computing power, you can make old techniques do things they couldn’t do before. The ascent of AI was predicated on concentrated tech company power and resources which had, as their driving force, the surveillance business model. \nOne thing we rarely discuss is how AI research and development’s dependence on corporate resources worked—and continues to work—to shape and in some cases co-opt knowledge production. In other words, to “do AI” as defined in the current “bigger is better” paradigm, you increasingly need resources that are controlled by these handful of companies. You need access to really expensive cloud compute, you need access to data that is hard and sometimes impossible to get. You can’t just go to the data market and buy it—you often need to get access from the data’s creators or collectors, who are often the tech companies. It’s fair to say that academic computer science disciplines underwent a kind of soft-capture, in which as a condition of doing “cutting edge” AI research, over the last decade they became increasingly dependent on corporate resources, and corporate largesse. \nThis dynamic led to practices like dual affiliation, where professors work at a tech company but have a professorial title and produce research under their university affiliation. It’s led to tech companies moving whole corporate labs into the middle of universities—like Amazon’s machine vision lab at Caltech. We have a structural imbrication between a massive, consolidated industry and knowledge production about what that industry does. And this compromised entanglement has bled into the fairness and ethics space, in many cases without anyone commenting on it. There are many forces working against our recognition of how captured the technical disciplines are at this time, and how easy it is for them to extend this capture into fairness, ethics, and other disciplinary pursuits focused on the consequences and politics of tech. \nTo pick one example, Amazon is underwriting half of the National Science Foundation’s Fairness in Artificial Intelligence grants. And while a few people called this out, the fields concerned went on to apply for this funding, and uncritically applauded colleagues who received it. Whole labs are reliant on Amazon, Google, Facebook, Microsoft funding, and if you raise questions about it you’re endangering your ability to support your postdocs, your ability to obtain future funding, your standing with your dean. Or, you’re endangering your colleagues in these same ways. Dissecting the particularities of what it means to be able to do research on AI and related technologies, and how dependent this work often is on corporate resources, is a project that I think can help develop a clearer political-economic read of tech and the tech industry overall, and reveal the capital interests that are propelling research and knowledge production into tech and its implications. \nSN: This is a critical area especially during the time of Covid-19, when we saw how fragile so many of our public institutions are. We really feel that at a place like UCLA, where teaching assistants aren’t paid adequately, it’s extremely expensive to get an undergraduate degree, and the pressures to deliver public education are intense. Many, many systems are broken, and it is very painful to work under those kinds of broken systems. \nMeredith, I recognize this tech sector political economy you’re describing. They are capturing not only scholars but policymakers who, in essence, use public money to subsidize the entire industry, both through the research efforts at the National Science Foundation and also by making it impossible for democratic public institutions to flourish, because they don’t pay their fair share. They offshore their profits, and they don’t reinvest them back into communities where they do business in extremely exploitative ways. They just expect the public to underwrite it through tax refunds. How in the world can companies like Apple get tax refunds except through pure corruption? As we struggle in our communities with and in our institutions, we have to identify why those conditions are present. We have to recognize who has monopolized all of the resources and we have to examine the narrative about what’s happening with those resources.\nI want to ask you about social media and “cancel culture.” In July 2020, Harper’s published “A Letter on Justice and Open Debate,” signed by a number of prominent people, including Noam Chomsky and J.K. Rowling. The letter criticized “an intolerant climate” on the Left, and in particular, “an intolerance of opposing views, a vogue for public shaming and ostracism, and the tendency to dissolve complex policy issues in a blinding moral certainty.” The following month, in August 2020, The Atlantic published a piece by Anne Applebaum called “The New Puritans,” that used Nathaniel Hawthorne’s The Scarlet Letter to criticize social media “mob justice.” The irony of invoking the white woman’s public humiliation for being pregnant out of wedlock is that the book was published more than a decade before the Civil War. Black and Indigenous peoples’ ongoing bondage and claims to liberation are as unnamed in the book as they are in today’s epistles of moral panic.\nBut how do we negotiate this issue? Is calling people out on Twitter our only mode of addressing power dynamics in the AI ethics space? How can we put forward a vision that is constructive and not just reactive, even though our operational capacity is so low, even though we’re all exhausted, grieving, and torn into so many different directions? What is our vision for transformative justice in the context of knowledge production?\nMW: Look, I have a lot to say here. First, I think there’s a visibility bias: people see when calls for accountability and redress spill into the public. They rarely see the agonizing work of trying to hold harmful people and institutions accountable behind the scenes. Work that’s too often not only unrewarded, but actively punished. Like many people, I have engaged in a number of accountability processes that didn’t end with Twitter callouts and are not visible to the public. In my experience, Twitter is always a last resort. There are failures upon failures upon failures within these institutions and with the way power moves within them, all of which happen before someone is going to take to Twitter or call on social media as a witness. Timnit taking to Twitter didn’t save her job. \nBuried in the moral panic around “cancel culture” is a burning question about how you hold power to account when you’re in an institution that will punish you for doing so. What do you do when your wellbeing and duties of care dictate that you confront and curtail harmful behavior, but you know that any such attempt risks your livelihood and institutional and professional standing? Institutions protect power. Universities don’t want to touch a star professor who’s bringing in press and grants; tech companies have every incentive to coddle the person architecting the algorithm that is going to make them a shit ton of money. These corporations and corporate universities are structured to protect flows of capital and, by extension, to protect the people who enable them. There are infrastructures in place—including HR and most Title IX offices—to make sure that those who enable the interests of capital are elevated and to make sure that it’s as painful as possible for the people who might report anything. \nThis is the backdrop against which we’re trying to figure out how we, as people within these environments, protect ourselves and each other. In my view, the answer to this question doesn’t start with building a better HR, or hiring a diversity consultant. It’s rooted in solidarity, mutual care, and in a willingness to understand ourselves as committed to our own and others’ wellbeing over our commitments to institutional standing or professional identity. \nThat’s also a question of how we can be accountable ourselves. Especially as people who have institutional power, and who may experience favorable treatment from the same people who harm those with less power. In other words, the more power we have the less we can rely on our experience of people and institutions as an accurate barometer, because there’s every incentive to act the sycophant. This means we need to actually listen to, elevate, believe, and act on the accounts of those with less power, especially Black people and historically marginalized people for whom institutional abuse is compounded. And we need to be willing to put their safety and wellbeing above our institutional and professional standing. This is very hard, but in my view it’s the floor. If you can’t do it, then you shouldn’t be in a position of leadership. \nSN: I relate so much to all the things you’re saying. I think we’re in a long struggle around creating systems of mutual care, aid, and support, and that is very difficult. Most of the environments that we’re trying to build those systems within, like academia, are hostile to trying to get work done and get people supported properly. Having said that, we have to keep building these networked communities. We have to be agile and we have to think about how we’re going to create more space for others to do their work. \nIn my own experience and my own career, I have felt at many times completely unsupported. I have felt like if I could just expand the circle at some point in my career so that more people could be supported, that would be something. The question is, to what degree can we institutionalize that so that all of the possibilities don’t hinge on one person in one space or place, but that we remake entire systems? We want those systems to last and not rely on any one particular person. That’s difficult work and we need to be sharing ideas about how to do that. \nBut the problems that we’re working on are very big problems in the world and in our communities. I think about abolitionist traditions: you know, how did a handful of people change the world? Millions of Americans got up every day and made pancakes and went to work while people were being human-trafficked right in front of them and enslaved, beaten, lynched, and harmed on the regular. How did abolitionists, in the face of those conditions, abolish the transatlantic slave trade or change the laws around the enslavement of African peoples? How did others resist the expansion into First Nations and Indigenous peoples’ lands? There weren’t millions of people working on these issues. It was, relative to the population, a very small number of people who worked on those things. \nI guess I feel heartened by the fact that if enough people can be coordinated, a lot of change can happen. That is why we have to study history and study social movements to figure out how they did it and how to make it last. Especially for those of us right now living through the rollback of the Civil Rights Movement, we know that those changes can also be precarious. We have to figure out how to make them last. \nOn Some Global Tech Resistance\nAcademia is coming for our lives, so much of our time is swallowed up into institutional administrative overhead, and also we’re facing major stakes that are global. It’s so difficult to even stay on top of our own “domain expertise,” so how do we facilitate transnational solidarity? How do we think about this work as global? What are the points of connections you identify around intellectually, and politically, in your own work? What kind of infrastructure represents the next steps that could be taken to bolster this kind of transnational research?\nSN: We have to keep our diasporic commitments intact while we’re doing our work. And of course, we sit here in the heart of the American technology empire. We have a responsibility where we are in this location to press on these companies and on governments to ease exploitation around the world. Many of us understand these questions because we come from internal colonies of the United States, which is one of the ways that sociologists have talked about Black people’s experience in the Americas. Our work is connected materially to other people’s lives around the world. \nWe have to be in community. We have to be in conversation. And we also have to recognize what our piece of the puzzle is ours to work on. While it is true, yes, we’re just individual people, together we’re a lot of people and we can shift the zeitgeist and make the immorality of what the tech sector is doing—through all its supply chains around the world—more legible. It’s our responsibility to do that as best we can. \nMW: Yeah, I agree. I’m a white lady raised in LA. I had to educate myself on so much that I didn’t understand, and that process is humbling and ongoing. \nMy voice doesn’t need to be the center of every conversation. But, okay, if I have a little power and a little standing maybe I can move capital, maybe I can ask people what they need and see what I can do to get it to them, to support and nurture their expertise and organizing and approaches, which may be completely unfamiliar to me, and may not need any advice or insight from me. I’m thinking of the ACM Conference on Fairness, Accountability, and Transparency (FAccT). Briefly, it’s a computer-science focused conference exploring fairness in algorithms. Over the years, we have seen increasing calls to examine algorithmic and other technologies in the context of racial capitalism and structural inequality, accompanied by warnings about the insufficiency of narrow FAccT-style technical approaches to the problems of algorithms and tech. So, what was the response? From many people, it wasn’t a re-evaluation of the field, but instead a move to absorb. Like, “Oh, well, how about we bolt an Audre Lorde quote to this computational social science paper.” This response continues to place computer science at the center, with racial justice as seasoning. Even though there are, of course, Black feminist conferences that could use some funding, and that have been deep in these topics for decades before FAccT. So my question is, why is the instinct always to absorb into the core instead of diffuse the resources to those already doing the work? \nI mean, I fuck with that. We need allyship in the form of funneling actual, material support out of these Western institutions.",
      "date_published": "2022-02-01T14:59:42.000Z",
      "date_modified": "2022-02-01T14:59:42.000Z",
      "_plugin": {
        "pageFilename": "fa020ffec0a121bdf0a996fcc7494d1c75cb43da901b98578ce79f5df2467095.html"
      }
    },
    {
      "id": "https://logicmag.io/beacons/the-oversight-bloc",
      "url": "https://logicmag.io/beacons/the-oversight-bloc",
      "title": "The Oversight Bloc",
      "summary": "An investigation into how tech workers and community organizers fought the San Diego surveillance state.",
      "content_html": "<p>In July 2019, one of us, Khalid Alexander, received a tip from a fellow San Diego community organizer. “You should be paying attention to the city’s new streetlights.” The message continued, “Apparently, they have cameras attached to them.” Alexander lived in one of the many predominantly Black and brown neighborhoods in San Diego that was under constant police surveillance, including by “gang suppression units” that watch, harass, and document residents. He feared that streetlights with cameras on them could supercharge these efforts.</p>\n<p>Two weeks later, Alexander showed up at a public library for a forum about the streetlights program (which the city named the Smart Streetlights Program). The only other people at the meeting were the presenters: a police captain, a city staffer, and an executive from General Electric (GE), the company that produced the new streetlights. Their presentation began with an infomercial for the technology, a city-wide network of thousands of LED streetlights mounted with cameras that recorded video around-the-clock. The footage was uploaded to the cloud, where city agencies could use software to count cars, pedestrians, and who knows what else. According to the police captain, the smart streetlights were already being used to solve crimes.</p>\n<p>Alexander left the presentation shocked and concerned. Five years earlier, police had rounded up thirty-three Black and brown men from San Diego and charged them with fifty years to life in prison for gang crimes simply because they were included in a police surveillance database called CalGang. The Smart Streetlights would make this kind of state violence more likely—other networked surveillance programs in cities such as Chicago and Los Angeles had led to similar raids—and yet none of the city’s larger civil rights organizations seemed to be visibly fighting the project. The community was going to have to organize resistance to the streetlights itself.</p>\n<p>Alexander’s first call was to the Tech Workers Coalition (TWC). Much of the technology incorporated into the new streetlights was foreign to him, and he wanted to better understand how it might be used. He also reached out to activists from communities he knew were likely to be targeted by the surveillance—homeless advocates, immigration rights organizers, police abolitionists—and invited them to the next streetlights community forum. At that meeting, held a month later, Alexander and his fellow activists managed to pack the house.</p>\n<p>This was the beginning of a two-year grassroots campaign to rein in the Smart Streetlights Program. By connecting surveillance to a wider set of issues than policing alone, the organizers were able to create a coalition wide enough to win. A lynchpin of their success was not only building a traditional coalition of community organizations from around the city, but also bringing in new allies: workers from the companies and research institutions building these technologies. The methods might be a model for other struggles against surveillance and carceral technologies in cities around the country.</p>\n<h1><b>The New Bacon</b></h1>\n<p>The infomercial Alexander was shown at the first community forum boasted that the data produced by the Smart Streetlights were “the new bacon”—they went with anything and could serve almost any purpose that agencies with access to the data could imagine. The other one of us, Lilly Irani, an organizer with TWC, listened to the presentation at the second community forum and realized that surveillance was only one part of what the streetlights could be used for.</p>\n<p>Community members at the forum immediately raised concerns about the technology’s ability to further criminalize San Diego residents. Black and brown-led organizations worried about heightened racial profiling using video streams. Refugee advocates worried that the streetlights could intensify the criminalization of Muslims by using software to analyze behavior near mosques. Homeless rights groups predicted the city would use the streetlights to more quickly find encampments to sweep. Border activists worried the streetlights could help track and deport people by being integrated with systems such as those developed for the Department of Homeland Security by Palantir.</p>\n<p>A police officer at the forum assured the crowd that the cameras did not record private property, but a computer engineer from TWC was able to force the officer to clarify that the cameras <i>did</i> record private property, which was then scrubbed from the data by a software program. What the city called the “sensors” on the streetlights also included microphones that could record people’s voices without their knowledge. The officer said the microphones were currently disabled, but admitted that they might be used for gunshot detection in the future. When a community member asked how long the streetlights were going to collect information, a city staffer replied that it was “undetermined”; the officer tried to reassure the crowd that “the answer is probably never.”</p>\n<p>Activists recognized that what the city and law enforcement said it was doing (and planning to do) with the program was beside the point. San Diego has long been an innovator in police surveillance networks. The county’s Automated Regional Justice Information System, which shares surveillance data between more than sixty-five law enforcement agencies, has been in place since the 1980s. More recently, the county had provided facial recognition devices to law enforcement agencies across the southwestern border region until the state passed a moratorium on such devices and the Electronic Freedom Foundation sued to have the moratorium enforced. For years, the San Diego Police Department shared data from its automated license plate readers with Border Patrol to help the federal agency track, detain, and deport migrants, until the practice was exposed by journalists. When it came to the streetlights, the hard part was already done: more than three thousand units were installed across the city. Expanding what that hardware could help officials do would only be a few software updates away. As the officer admitted, the sensors weren’t even covered by civil codes the way similar technologies, such as automatic license plate readers, were.</p>\n<p>And it wasn’t only city and law enforcement agencies that might deploy the technology. All of the data generated by the streetlights would be made publicly available, albeit in an ostensibly anonymized form. A city staffer at the forum explained that this would allow “civic entrepreneurs” to use the data to build businesses to improve the city, including an app to help people find parking downtown. Irani knew this was code for gentrification—the city would give or even sell data harvested from the public, without its consent, to tech companies that would use the data to reshape the city in ways that favored wealthier white communities and pushed Black, brown, and poor people out of San Diego. Irani and Alexander later discovered through a public records request that the city had used Federal Community Development Block Grants, meant for projects that benefit low-income neighborhoods, to fund the streetlights.</p>\n<p>This range of concerns about how the technology might be used in the future became the basis for the grassroots campaign. Within a month, thirty community and activist groups had joined together in what became the Transparent and Responsible Use of Surveillance Technology San Diego (TRUST SD) Coalition. It grew quickly, in part, because people recognized that the Smart Streetlights surveillance infrastructure spanned the city and could bring anyone into the law enforcement dragnet. The campaign also relied on the working relationships that Alexander had built over years of organizing with different communities.</p>\n<p>Tech workers, too, were an essential part of the coalition. They joined because they did not want to build tools of state violence and oppression. In many public contests over technology, experts from industry and the state dominate conversations by wielding technical knowledge that communities cannot counter. In this coalition, however, the technical expertise of tech workers allowed organizers to counter official claims about what the Smart Streetlights technology could or couldn’t do, and helped them understand how the surveillance applications they feared could in fact be built on top of the existing network. The alliance with tech workers neutralized the city’s advantage.</p>\n<h1><b>Organizing the Lab Rats</b></h1>\n<p>The coalition decided to focus on three goals. Articulating these was crucial to keeping the various political and ideological factions within the coalition from splintering over other issues. First, it called for an immediate moratorium on streetlight acquisition, installation, and operation. This would end the immediate threats that the streetlights posed while organizers lobbied for more radical changes to public policy.</p>\n<p>Those changes to public policy were the coalition’s second goal. Organizers sought public participation in the creation of legally enforceable policies over all surveillance technologies used by the city, not just the streetlights. A wide range of technologies beyond the streetlights—known and unknown—made up the surveillance dragnet of San Diego. Worse, surveillance tech could come to the city through donations to the Police Officer Association or through free trials like those offered by facial recognition company Clearview AI. This meant that the City Council did not always have to approve the technologies and the public had no way to see what was in use, unless someone peppered city departments with scattershot public records requests. Council members had not even discussed the Smart Streetlights Program publicly before they signed off on it; that was two years before communities realized a mass surveillance technology was even on the table. Communities needed a legal infrastructure that would alert them to surveillance technologies before they were approved. Rather than playing whack-a-mole to stop individual technologies, the coalition sought transparency, oversight, and City Council authority over <i>all</i> city surveillance technology, existing and future.</p>\n<p>Finally, the coalition demanded public records showing how the streetlights had already been used and accessed. As organizers studied these records, they discovered that the city had considered monetizing the data and had even explored providing a livestream to the police. These discoveries informed the coalition’s activism and provided fodder for breaking news stories that added momentum to the campaign.</p>\n<p>Because the mayor had championed the program, organizers would need a veto-proof majority of council members to support the moratorium and the policy changes we were fighting for. So the campaign worked to build public pressure on the city council through press conferences, newspaper opinion pieces, public events, and direct lobbying. Organizers broadened their discussion of the issue beyond criminalization to larger concerns about the dangerous power of big tech to engage liberal and conservative elected officials in different ways. In one opinion piece, they argued that San Diego residents had been turned into “lab rats for innovation.”</p>\n<p>The Mayor’s Office and city officials tried to dismiss the campaign as a small handful of activists with hidden agendas. They also attempted to frame it as ignorant of the technical dimensions of the streetlight program. In November 2019, a tech worker who had experience working on artificial intelligence contracts read the contract the city had signed with GE, and discovered that the city had signed over to the company ownership of the data produced by the streetlights. The data were stored on GE’s servers, and the city merely accessed them through a subscription, which meant the city lacked final say over what the company could do with the data. An anonymous city staffer responded by calling the coalition’s findings “insane lies,” but ultimately the city could not undermine the credibility of tech workers who had built or worked closely on smart cities hardware, artificial intelligence models, and similar technologies.</p>\n<p>Over the following months, members of the coalition lobbied city council members and found them increasingly at odds with the mayor and the city attorney over the scope and legal framework of the Streetlights Program. In order to channel that frustration into a tactical win, organizers followed a two-pronged approach. First, they expanded their attempts to put public pressure on these elected officials. They held town halls, screenings of the film <i>The Feeling of Being Watched</i>—about government surveillance of Muslim communities in Chicago—and workshops at which we taught community members and activists about the technology and brought them into the organizing efforts. They also did direct outreach to community leaders and journalists.</p>\n<p>The second prong was to write a “surveillance technology transparency and oversight” ordinance. The coalition would hand the draft legislation over to a champion on the city council, who could then present it as a “common sense” solution they could claim as a legislative victory. Organizers adapted their ordinance from ones already in place in Oakland and Seattle. It required city departments to create use policies and impact reports to gain Council approval for any new technology with surveillance capabilities. It emphasized oversight over all such technologies, not just those used by the police. The LED streetlights, after all, had been acquired in the name of energy savings and innovation, obscuring the technology’s connections to law enforcement. The ordinance also created a Privacy Advisory Board to support the City Council with recommendations on specific technology acquisition proposals. Board seats were reserved for representatives from “equity-focused organizations” serving communities impacted by surveillance, as well as information technology and civil liberties experts; anyone with financial ties to companies selling surveillance technologies was disqualified. </p>\n<p>Organizers wrote the ordinance to appeal to a wide range of constituencies. Fiscal conservatives liked it because they wanted to reduce government spending. (The streetlight program, budgeted at $30 million over a decade, was already seeing cost overruns.) Liberals who believed in deliberative process appreciated that the ordinance created an independent body to advise the city council and included civil rights oversight. More radical organizing communities recognized that they needed the ordinance in order to find out about new technologies if they were to have any chance of organizing against them.</p>\n<p>The coalition was lucky to find a champion on the Council who was willing to take the ordinance through committees and do the behind-the-scenes work to get it passed. The Councilmember, formerly a civil rights attorney at the ACLU, also had close relationships with people in the coalition. Meanwhile, organizers kept pressure on the city to shut down the streetlights and adopt the ordinance by organizing people to show up at council meetings and the mayor’s office, and led telephone and email campaigns ahead of crucial votes.</p>\n<p>The coalition also seized upon Covid-related budget cuts to defund the streetlights. Mid-pandemic, Irani assembled a dystopian hackathon with coalition-aligned students to prototype creepy examples of what the streetlight technology could already do. Irani thought the demos would help persuade the Council of potential harms, but the most important outcome turned out to be the discovery that the streetlights didn’t deliver the promised data for city planning. The coalition alerted an investigative journalist, who broke the story in April 2020. By May, the city was proposing Covid budget cuts. The mayor had put library hours on the chopping block but saved the streetlights. The coalition worked with the progressive Community Budget Alliance to mobilize residents to email and call council members and demand they defund the streetlights. San Diego Climate Action also joined the effort, since the lights, operated under the Sustainability Department budget, had redirected funds to a broken, greenwashing surveillance system. In the end, the Council refused to fund the system. </p>\n<h1><b>Tools for Struggle</b></h1>\n<p>In May 2020, the mayor made a last ditch attempt to hand over control of the surveillance system to the police and fund it using an obscure budget pool that City Council didn’t control. The coalition was able to show through old legal memos that this funding strategy was likely illegal and held a press conference to make the point. The mayor fought organizers for months, but finally, in September, he surprised everyone by announcing that the Smart Streetlight sensors and networks would be turned off until an ordinance was created to oversee the surveillance technologies run by the city. </p>\n<p>In November 2020, a year after the campaign began, the Council unanimously approved the oversight ordinance. The ordinance makes visible technologies that usually operate out of public view, mounted on light poles and cop cars, or running in the circuits and servers of hardware, software, and data brokerages. It slows down technology acquisition and gives communities time to learn and organize resistance. It puts community members with negative experiences of surveillance in a role where they can build knowledge about technologies and educate others. Though some argue that such ordinances create legitimacy for surveillance technologies, they also create a mechanism for people to organize refusal where there currently is none. </p>\n<p>But ordinances like these are not a panacea. They are tools for struggle and refusal, but do not guarantee resistance to surveillance. Without vigilant organizing, including alliances with technologists and elected officials, even community advisory boards may rubber stamp policies and legitimize surveillance technologies. This struggle also shows how cities do not control the technology of companies they contract with. As the coalition in San Diego worked to get the ordinance passed, it put the fear in city council members by explaining how the NYPD lost control of its data to Palantir. Then, the same thing happened to San Diego. With defunding, the city lost access to the streetlights’ surveillance feed. But the cameras continue to record. GE sold off the streetlight network to another company, which sold it to a Florida-based firm called Ubicquia. Ubicquia refuses to stop recording even though the city can no longer access the data. But even this did not stop the police from removing the camera and harddrive in one case to access and share the video. </p>\n<p>Paradoxically, it was the process of organizing for the ordinance that strengthened the coalition’s political capacity to challenge emerging surveillance technologies. By political capacity, we mean relationships among community members who trust one another, can teach each other, and can work together; we mean the time that people can spend researching, calling into council, occupying the mayor’s office, strategizing, and running educational forums. More people means more time spent doing these things, and more relationships with people who will get involved in the movement. </p>\n<p>In advocating for the ordinance, Irani and Alexander talked to a wide range of people, from anti-racism activists to former soldiers. Each person had different reasons to fear surveillance. People who showed up out of fear of big tech or privacy violations also learned about the criminalization of marginalized San Diegans. Anti-criminalization activists learned a lot about technology and its potential role in further entrenching the carceral state. Many of the people engaged by the coalition took their first steps from awareness to action. But the coalition’s work to resist and refuse mass surveillance doesn’t end with the ordinance. It begins in earnest once the ordinance is in place.</p>",
      "content_text": "In July 2019, one of us, Khalid Alexander, received a tip from a fellow San Diego community organizer. “You should be paying attention to the city’s new streetlights.” The message continued, “Apparently, they have cameras attached to them.” Alexander lived in one of the many predominantly Black and brown neighborhoods in San Diego that was under constant police surveillance, including by “gang suppression units” that watch, harass, and document residents. He feared that streetlights with cameras on them could supercharge these efforts.\nTwo weeks later, Alexander showed up at a public library for a forum about the streetlights program (which the city named the Smart Streetlights Program). The only other people at the meeting were the presenters: a police captain, a city staffer, and an executive from General Electric (GE), the company that produced the new streetlights. Their presentation began with an infomercial for the technology, a city-wide network of thousands of LED streetlights mounted with cameras that recorded video around-the-clock. The footage was uploaded to the cloud, where city agencies could use software to count cars, pedestrians, and who knows what else. According to the police captain, the smart streetlights were already being used to solve crimes.\nAlexander left the presentation shocked and concerned. Five years earlier, police had rounded up thirty-three Black and brown men from San Diego and charged them with fifty years to life in prison for gang crimes simply because they were included in a police surveillance database called CalGang. The Smart Streetlights would make this kind of state violence more likely—other networked surveillance programs in cities such as Chicago and Los Angeles had led to similar raids—and yet none of the city’s larger civil rights organizations seemed to be visibly fighting the project. The community was going to have to organize resistance to the streetlights itself.\nAlexander’s first call was to the Tech Workers Coalition (TWC). Much of the technology incorporated into the new streetlights was foreign to him, and he wanted to better understand how it might be used. He also reached out to activists from communities he knew were likely to be targeted by the surveillance—homeless advocates, immigration rights organizers, police abolitionists—and invited them to the next streetlights community forum. At that meeting, held a month later, Alexander and his fellow activists managed to pack the house.\nThis was the beginning of a two-year grassroots campaign to rein in the Smart Streetlights Program. By connecting surveillance to a wider set of issues than policing alone, the organizers were able to create a coalition wide enough to win. A lynchpin of their success was not only building a traditional coalition of community organizations from around the city, but also bringing in new allies: workers from the companies and research institutions building these technologies. The methods might be a model for other struggles against surveillance and carceral technologies in cities around the country.\nThe New Bacon\nThe infomercial Alexander was shown at the first community forum boasted that the data produced by the Smart Streetlights were “the new bacon”—they went with anything and could serve almost any purpose that agencies with access to the data could imagine. The other one of us, Lilly Irani, an organizer with TWC, listened to the presentation at the second community forum and realized that surveillance was only one part of what the streetlights could be used for.\nCommunity members at the forum immediately raised concerns about the technology’s ability to further criminalize San Diego residents. Black and brown-led organizations worried about heightened racial profiling using video streams. Refugee advocates worried that the streetlights could intensify the criminalization of Muslims by using software to analyze behavior near mosques. Homeless rights groups predicted the city would use the streetlights to more quickly find encampments to sweep. Border activists worried the streetlights could help track and deport people by being integrated with systems such as those developed for the Department of Homeland Security by Palantir.\nA police officer at the forum assured the crowd that the cameras did not record private property, but a computer engineer from TWC was able to force the officer to clarify that the cameras did record private property, which was then scrubbed from the data by a software program. What the city called the “sensors” on the streetlights also included microphones that could record people’s voices without their knowledge. The officer said the microphones were currently disabled, but admitted that they might be used for gunshot detection in the future. When a community member asked how long the streetlights were going to collect information, a city staffer replied that it was “undetermined”; the officer tried to reassure the crowd that “the answer is probably never.”\nActivists recognized that what the city and law enforcement said it was doing (and planning to do) with the program was beside the point. San Diego has long been an innovator in police surveillance networks. The county’s Automated Regional Justice Information System, which shares surveillance data between more than sixty-five law enforcement agencies, has been in place since the 1980s. More recently, the county had provided facial recognition devices to law enforcement agencies across the southwestern border region until the state passed a moratorium on such devices and the Electronic Freedom Foundation sued to have the moratorium enforced. For years, the San Diego Police Department shared data from its automated license plate readers with Border Patrol to help the federal agency track, detain, and deport migrants, until the practice was exposed by journalists. When it came to the streetlights, the hard part was already done: more than three thousand units were installed across the city. Expanding what that hardware could help officials do would only be a few software updates away. As the officer admitted, the sensors weren’t even covered by civil codes the way similar technologies, such as automatic license plate readers, were.\nAnd it wasn’t only city and law enforcement agencies that might deploy the technology. All of the data generated by the streetlights would be made publicly available, albeit in an ostensibly anonymized form. A city staffer at the forum explained that this would allow “civic entrepreneurs” to use the data to build businesses to improve the city, including an app to help people find parking downtown. Irani knew this was code for gentrification—the city would give or even sell data harvested from the public, without its consent, to tech companies that would use the data to reshape the city in ways that favored wealthier white communities and pushed Black, brown, and poor people out of San Diego. Irani and Alexander later discovered through a public records request that the city had used Federal Community Development Block Grants, meant for projects that benefit low-income neighborhoods, to fund the streetlights.\nThis range of concerns about how the technology might be used in the future became the basis for the grassroots campaign. Within a month, thirty community and activist groups had joined together in what became the Transparent and Responsible Use of Surveillance Technology San Diego (TRUST SD) Coalition. It grew quickly, in part, because people recognized that the Smart Streetlights surveillance infrastructure spanned the city and could bring anyone into the law enforcement dragnet. The campaign also relied on the working relationships that Alexander had built over years of organizing with different communities.\nTech workers, too, were an essential part of the coalition. They joined because they did not want to build tools of state violence and oppression. In many public contests over technology, experts from industry and the state dominate conversations by wielding technical knowledge that communities cannot counter. In this coalition, however, the technical expertise of tech workers allowed organizers to counter official claims about what the Smart Streetlights technology could or couldn’t do, and helped them understand how the surveillance applications they feared could in fact be built on top of the existing network. The alliance with tech workers neutralized the city’s advantage.\nOrganizing the Lab Rats\nThe coalition decided to focus on three goals. Articulating these was crucial to keeping the various political and ideological factions within the coalition from splintering over other issues. First, it called for an immediate moratorium on streetlight acquisition, installation, and operation. This would end the immediate threats that the streetlights posed while organizers lobbied for more radical changes to public policy.\nThose changes to public policy were the coalition’s second goal. Organizers sought public participation in the creation of legally enforceable policies over all surveillance technologies used by the city, not just the streetlights. A wide range of technologies beyond the streetlights—known and unknown—made up the surveillance dragnet of San Diego. Worse, surveillance tech could come to the city through donations to the Police Officer Association or through free trials like those offered by facial recognition company Clearview AI. This meant that the City Council did not always have to approve the technologies and the public had no way to see what was in use, unless someone peppered city departments with scattershot public records requests. Council members had not even discussed the Smart Streetlights Program publicly before they signed off on it; that was two years before communities realized a mass surveillance technology was even on the table. Communities needed a legal infrastructure that would alert them to surveillance technologies before they were approved. Rather than playing whack-a-mole to stop individual technologies, the coalition sought transparency, oversight, and City Council authority over all city surveillance technology, existing and future.\nFinally, the coalition demanded public records showing how the streetlights had already been used and accessed. As organizers studied these records, they discovered that the city had considered monetizing the data and had even explored providing a livestream to the police. These discoveries informed the coalition’s activism and provided fodder for breaking news stories that added momentum to the campaign.\nBecause the mayor had championed the program, organizers would need a veto-proof majority of council members to support the moratorium and the policy changes we were fighting for. So the campaign worked to build public pressure on the city council through press conferences, newspaper opinion pieces, public events, and direct lobbying. Organizers broadened their discussion of the issue beyond criminalization to larger concerns about the dangerous power of big tech to engage liberal and conservative elected officials in different ways. In one opinion piece, they argued that San Diego residents had been turned into “lab rats for innovation.”\nThe Mayor’s Office and city officials tried to dismiss the campaign as a small handful of activists with hidden agendas. They also attempted to frame it as ignorant of the technical dimensions of the streetlight program. In November 2019, a tech worker who had experience working on artificial intelligence contracts read the contract the city had signed with GE, and discovered that the city had signed over to the company ownership of the data produced by the streetlights. The data were stored on GE’s servers, and the city merely accessed them through a subscription, which meant the city lacked final say over what the company could do with the data. An anonymous city staffer responded by calling the coalition’s findings “insane lies,” but ultimately the city could not undermine the credibility of tech workers who had built or worked closely on smart cities hardware, artificial intelligence models, and similar technologies.\nOver the following months, members of the coalition lobbied city council members and found them increasingly at odds with the mayor and the city attorney over the scope and legal framework of the Streetlights Program. In order to channel that frustration into a tactical win, organizers followed a two-pronged approach. First, they expanded their attempts to put public pressure on these elected officials. They held town halls, screenings of the film The Feeling of Being Watched—about government surveillance of Muslim communities in Chicago—and workshops at which we taught community members and activists about the technology and brought them into the organizing efforts. They also did direct outreach to community leaders and journalists.\nThe second prong was to write a “surveillance technology transparency and oversight” ordinance. The coalition would hand the draft legislation over to a champion on the city council, who could then present it as a “common sense” solution they could claim as a legislative victory. Organizers adapted their ordinance from ones already in place in Oakland and Seattle. It required city departments to create use policies and impact reports to gain Council approval for any new technology with surveillance capabilities. It emphasized oversight over all such technologies, not just those used by the police. The LED streetlights, after all, had been acquired in the name of energy savings and innovation, obscuring the technology’s connections to law enforcement. The ordinance also created a Privacy Advisory Board to support the City Council with recommendations on specific technology acquisition proposals. Board seats were reserved for representatives from “equity-focused organizations” serving communities impacted by surveillance, as well as information technology and civil liberties experts; anyone with financial ties to companies selling surveillance technologies was disqualified. \nOrganizers wrote the ordinance to appeal to a wide range of constituencies. Fiscal conservatives liked it because they wanted to reduce government spending. (The streetlight program, budgeted at $30 million over a decade, was already seeing cost overruns.) Liberals who believed in deliberative process appreciated that the ordinance created an independent body to advise the city council and included civil rights oversight. More radical organizing communities recognized that they needed the ordinance in order to find out about new technologies if they were to have any chance of organizing against them.\nThe coalition was lucky to find a champion on the Council who was willing to take the ordinance through committees and do the behind-the-scenes work to get it passed. The Councilmember, formerly a civil rights attorney at the ACLU, also had close relationships with people in the coalition. Meanwhile, organizers kept pressure on the city to shut down the streetlights and adopt the ordinance by organizing people to show up at council meetings and the mayor’s office, and led telephone and email campaigns ahead of crucial votes.\nThe coalition also seized upon Covid-related budget cuts to defund the streetlights. Mid-pandemic, Irani assembled a dystopian hackathon with coalition-aligned students to prototype creepy examples of what the streetlight technology could already do. Irani thought the demos would help persuade the Council of potential harms, but the most important outcome turned out to be the discovery that the streetlights didn’t deliver the promised data for city planning. The coalition alerted an investigative journalist, who broke the story in April 2020. By May, the city was proposing Covid budget cuts. The mayor had put library hours on the chopping block but saved the streetlights. The coalition worked with the progressive Community Budget Alliance to mobilize residents to email and call council members and demand they defund the streetlights. San Diego Climate Action also joined the effort, since the lights, operated under the Sustainability Department budget, had redirected funds to a broken, greenwashing surveillance system. In the end, the Council refused to fund the system. \nTools for Struggle\nIn May 2020, the mayor made a last ditch attempt to hand over control of the surveillance system to the police and fund it using an obscure budget pool that City Council didn’t control. The coalition was able to show through old legal memos that this funding strategy was likely illegal and held a press conference to make the point. The mayor fought organizers for months, but finally, in September, he surprised everyone by announcing that the Smart Streetlight sensors and networks would be turned off until an ordinance was created to oversee the surveillance technologies run by the city. \nIn November 2020, a year after the campaign began, the Council unanimously approved the oversight ordinance. The ordinance makes visible technologies that usually operate out of public view, mounted on light poles and cop cars, or running in the circuits and servers of hardware, software, and data brokerages. It slows down technology acquisition and gives communities time to learn and organize resistance. It puts community members with negative experiences of surveillance in a role where they can build knowledge about technologies and educate others. Though some argue that such ordinances create legitimacy for surveillance technologies, they also create a mechanism for people to organize refusal where there currently is none. \nBut ordinances like these are not a panacea. They are tools for struggle and refusal, but do not guarantee resistance to surveillance. Without vigilant organizing, including alliances with technologists and elected officials, even community advisory boards may rubber stamp policies and legitimize surveillance technologies. This struggle also shows how cities do not control the technology of companies they contract with. As the coalition in San Diego worked to get the ordinance passed, it put the fear in city council members by explaining how the NYPD lost control of its data to Palantir. Then, the same thing happened to San Diego. With defunding, the city lost access to the streetlights’ surveillance feed. But the cameras continue to record. GE sold off the streetlight network to another company, which sold it to a Florida-based firm called Ubicquia. Ubicquia refuses to stop recording even though the city can no longer access the data. But even this did not stop the police from removing the camera and harddrive in one case to access and share the video. \nParadoxically, it was the process of organizing for the ordinance that strengthened the coalition’s political capacity to challenge emerging surveillance technologies. By political capacity, we mean relationships among community members who trust one another, can teach each other, and can work together; we mean the time that people can spend researching, calling into council, occupying the mayor’s office, strategizing, and running educational forums. More people means more time spent doing these things, and more relationships with people who will get involved in the movement. \nIn advocating for the ordinance, Irani and Alexander talked to a wide range of people, from anti-racism activists to former soldiers. Each person had different reasons to fear surveillance. People who showed up out of fear of big tech or privacy violations also learned about the criminalization of marginalized San Diegans. Anti-criminalization activists learned a lot about technology and its potential role in further entrenching the carceral state. Many of the people engaged by the coalition took their first steps from awareness to action. But the coalition’s work to resist and refuse mass surveillance doesn’t end with the ordinance. It begins in earnest once the ordinance is in place.",
      "date_published": "2022-01-25T15:06:23.000Z",
      "date_modified": "2022-01-25T15:06:23.000Z",
      "_plugin": {
        "pageFilename": "dc0010e5d6b36f99f4d78c72fdfcb470278fc21764915afe7128335863367c5c.html"
      }
    },
    {
      "id": "https://logicmag.io/beacons/dis-info-studies-andre-brock-jr",
      "url": "https://logicmag.io/beacons/dis-info-studies-andre-brock-jr",
      "title": "(dis)Info Studies: André Brock, Jr. on Why People Do What They Do on the Internet",
      "summary": "A conversation about the unholy trinity of whiteness, modernity, and capitalism.",
      "content_html": "<p>The Black internet has a long history. It has multiple points of origin, as Charlton McIlwain has documented—from Afronet, a BBS network for Black users, to NetNoir, an AOL-based portal “devoted to Afrocentric material,” both of which launched in the mid-1990s. Today, the Black internet has entered the platform era, distributing its riches across Twitter and Instagram and YouTube.</p>\n<p>What would it mean to take the Black internet seriously? What would it mean to see Black digital practices (in all their diversity) not in pathological terms—as hailing from the wrong side of a “digital divide”—but as creative, joyful, affirming? What if the Black internet offers a standpoint from which the rest of the internet can be seen, and critiqued, more clearly?</p>\n<p>These are some of the questions that guide the work of André Brock, Jr., associate professor of Black Digital Studies at Georgia Institute of Technology and the author of <i>Distributed Blackness: African American Cybercultures</i>. In his work, Brock uses a methodology that he calls “critical technocultural discourse analysis” (CTDA). “It decenters the Western deficit perspective on minority technology use to instead prioritize the epistemological standpoint of underrepresented groups of technology users,” he writes, with the aim of conducting “a holistic analysis of an information technology artifact and its practices.” In other words, CTDA asks, why do people do what they do on the internet—especially when “people” are not just white, cis, heteronormative men? Central to CTDA is the idea of the “libidinal economy,” which originates with Freud, was further developed by the French philosopher Jean-François Lyotard, and has more recently been taken up by Fred Moten, Frank B. Wilderson III, and other Black thinkers. A libidinal-economic approach emphasizes the role of emotional and psychological intensities in driving anti-Blackness, rather than the more rationalist models of human behavior derived from political-economic approaches. Issue editor J. Khadijah Abdurahman sat down with Brock to trace the history of disinformation from Reconstruction to the present, and to discuss “the unholy trinity of whiteness, modernity, and capitalism.”</p>\n<hr />\n<p><b>How do you see the state of mis/disinformation research? What do you think is missing from the conversation? </b></p>\n<p>Disinformation is only perceived as bad when it serves to disrupt the interests of whiteness and white power. White power sounds strong, but it fits. During Reconstruction, the country found all sorts of creative ways to keep black folk from the polls, up to and including murder. That wasn’t a problem. Du Bois documented this extensively in <i>Black Reconstruction</i>, but misinformation against non-whites is typically a footnote in history texts and media reports as it serves the telos of American democracy.</p>\n<p>Similarly, when disinformation campaigns began to surface in the mid-2000s around Gamergate—or troll farms attacking Black Lives Matter activists—that wasn’t considered worthy of research. We still don’t have great academic research on Crystal Johnson and Blacktivist—two large internet troll farm campaigns that were trying to convince Black folk not to vote. What we do have, however, is a plethora of highly funded research incorporating both quantitative and computational evidence of how disinformation has affected white voters. </p>\n<p>For example, reporting on the 2016 presidential election first framed voters as having economic anxiety. They weren’t white—they were <i>economically anxious</i>. Then folk began to find out that economics wasn’t necessarily the cause they were rallying around. They were rallying around xenophobia, anti-intellectualism, and anti-big government. All those are things that white folk are concerned about. Misinformation research is largely conducted by white folk, and their concerns reify this anxiety about the disruptive power of social media and mass media against the interests of white folk. </p>\n<p><b>The object of inquiry of disinformation research has largely been whiteness and white anxiety. Maybe that reflects the classism of disinformation researchers, who are probably mostly trust-fund babies or the partners of people who work in Big Tech. They’re concerned with these “rabble-rousing” and “ignorant” white folks. The emphasis on QAnon is fascinating to me: it’s taken such a god-like center stage in much of the disinformation research. </b></p>\n<p><b>Reporting on Black vaccine hesitancy has focused on the Tuskegee experiment. Leaving aside the fact that Tuskegee was the complete inverse of what we’re seeing with the Covid-19 vaccine—in that it was an experiment where treatment for syphilis was </b><b><i>withheld</i></b><b>, or that the racial disparities in Covid-19 vaccination rates primarily reflects availability and access, not hesitancy—the reporting has omitted how many of the pandemic conspiracy theories circulating in Black communities are tied to anti-Semitic conspiracy theories. </b></p>\n<p><b>Do you remember that right in the beginning of the shelter-in-place orders, Nick Cannon came out repeating anti-Semitic shit from Farrakhan about the caucusoids descending from the mountains? Then Viacom suspended his show. Busta Rhymes came out and said something that was anti-vax in August 2021, echoing conspiracy theories from Milton William Cooper’s </b><b><i>Behold a Pale Horse</i></b><b>. The way that book in particular has had a chokehold on the Black entertainment industry is well known in our community. Yet it’s nowhere to be found in this academic discourse of rationality, universality, and mis/disinformation. </b></p>\n<p>Disinformation technologizes and scrubs movements of their xenophobic and racist antecedents to say they represent strictly an information misbehavior. Not a cultural misbehavior. That’s part of the problem. If you scrub racism and xenophobia from disinformation campaigns, what you have is what they would like to say: an attempt to overthrow a government through illegitimate means. But what if you add back in the racism? The better antecedent for QAnon is the John Birch Society, but that’s seen as too explicitly racist. </p>\n<p>Black folk have contended with internal disinformation forever. Busta is part of the the Five-Percent Nation, which has had a deep hold on New York rap forever, in terms of coercing patriarchal gender roles and influencing Black relationships to the state. But that was just Black folk being crazy, right? </p>\n<p>If you add back in the racism, it adds an entirely powerful libidinal element, in the sense that QAnoners are not overthrowing the government because it was <i>working for white people</i>, they’re overthrowing the government because <i>they felt that it was working too hard to entitle Black and brown folk</i>. Working too hard to give them things to which these white folk feel they don’t deserve. It’s an entitlement culture: we don’t want to give them things. We want them to learn how to work for it. That’s been an anti-Black statement since the 1860s. As soon as we got free, they were like, “Oh, well, these n***** don’t work. They’re lazy. We had to beat them in order to get them to work.” </p>\n<p>That libidinal economy of the digital seeks to continually restrict information transfer and exchange as an instrumental mode. And by that I mean, it’s strictly the message that’s being communicated, not any of the things which animate that message. So, for the libidinal economy of the <i>digital</i>, we look at <i>productive</i>. We look at <i>efficient</i>. We look at <i>time and space-spanning</i>, right? We look at collapsing traditional order in order to impose modern order. We look at “just in time” manufacturing, which now we understand is a huge problem because corporations sought to “reduce inefficiencies” like merchandise sitting in warehouses or eliminating jobs to demonstrate productivity to Wall Street. As a result we have empty shelves, halted production, and inflation now, but also higher levels of inequality and stress in the decades leading up to this moment.</p>\n<h1><b>Believing in Digital Divides</b></h1>\n<p><b>I want to just scroll back to the other question about disinformation for a second. There’s this obsession with how </b><b><i>other</i></b><b> people behave and what </b><b><i>their</i></b><b> beliefs are. This white, cis, heteronormative, middle-class idea that spaces are not “diverse enough” demonstrates to me how homogenous academic and media spaces are. </b></p>\n<p><b>I used to do a lot of restaurant work. You’d be working in the back of the house with this dude who’s forty-five from Bangladesh, somebody else who is undocumented from Russia, a seventeen-year-old washing dishes who only speaks Spanish, and then you’re serving these white customers. So, really, it’s the class of people being served who has a more insular view of the world, not the people in the back of the house—yet that’s the class we’re getting research from. The disinformation discourse is very abstracted away from the conditions, beliefs, and societies it seeks to describe. </b></p>\n<p><b>When I think about disinformation campaigns, I also think about the digital divide, one of the biggest trends in pathologizing Black people’s relationship to technology. Where’s the space to turn ethnography backwards, </b><b><i>onto</i></b><b> a field that has gotten a lot wrong?</b></p>\n<p>The digital divide stuff has shifted to “information communication technology for development,” or ICT4D. They’re looking at Africa, India, Pakistan, and other places, and saying, “They don’t have the same type of networks we have in the West. So, of course, they’re struggling to access the resources that we take for granted.” It’s just as problematic as it was when they were looking at Black folk here in the States because, like you said, it never turns the gaze around to ask what created these conditions. How and why do these conditions continue to persist? Instead, let’s be liberal and only look at the ways people will either resist or are hailed by these particular technological systems in a way that disadvantages them. </p>\n<p><b>As the president of the </b><b><i>Distributed Blackness: African American Cybercultures</i></b><b> stan club, the two main contributions of your book are, in my view, Critical Technocultural Discourse Analysis (CTDA) as a process through which to understand these technologies, and the importance of the libidinal economy. This largely seems to have gone unaccepted within the dominant research discourse. Is that your experience, or do you feel like people are engaging with your approach? </b></p>\n<p><i>[Ed.: The idea of “libidinal economy” originates with Freud, was further developed by the French philosopher Jean-François Lyotard, and more recently has been taken up by Frank B. Wilderson III, Fred Moten, and other Black thinkers. It emphasizes that emotional intensities, such as desire or antiblackness, drive “rational self interest” or political-economic modes of thinking.] </i></p>\n<p>The libidinal approach is still too new. I don’t have the impact on social science research yet because I’m still talking about Black people. That’s my mistake. I didn’t try to claim white people are bad. That wasn’t my concern. My concern was to say, “Look at how <i>joyous</i> Black people are,” which is a very different thing. </p>\n<p>I have to give a talk to Microsoft in a month and they’re like, “Well, can you present your book in a way that makes it palatable to white people?” Nah, I can’t. And it’s not going to happen because you need to learn about me as opposed to learning what I do to resist you, which are two totally different things.</p>\n<p>Data science and information science have long been and will continue to be resistant to theories like libidinal economy, but also to theories like critical race theory, because they are resistant to things which are not <i>of them</i>. They think about things which they can reach out and fix, like ethics. Or reach out and bring in, like the digital divide stuff. But they don’t ever want to engage with the question of how they benefit from certain structures, or how to fix the problems they’ve created. They don’t want to do that.</p>\n<p>So the libidinal economy has a ways to go. I’m really enthused by the uptake that it’s gotten among critical academics like yourself. Somebody said to me in my DMs the other day that it gives you a framework for understanding exactly what was going on, because we didn’t have words for it before. But white folks will always say racism is not in their heart—which is their own libidinal economy, right? They’ll never be encouraged to take it up, because to do so requires that they interrogate themselves and that’s not going to happen. </p>\n<p><b>Do you think Twitter is an accurate gauge for the Discourse™️? Do you have a sense of what readings are driving the adherence to rationalism? </b></p>\n<p>Twitter really is a space where people who don’t read books want to argue with people who write books. That’s tech too, right? I had these students coming through my classes at Georgia Tech who said, “We don’t read this kind of thing. They just tell us to make stuff. They train us how to make it. They’re not asking us to think about it.”</p>\n<p>Those are the people that Georgia Tech sends into Google, Amazon, Microsoft, and Netflix. The people who are trained not to think about things. Lewis Mumford talked about this not on a racial basis, but on a technical basis. He called it “techno-rationalism,” and he said no manufacturer wants a person who has a tendency to engage in anthropomorphic, quasi-rational thinking about the industry that we inhabit. They don’t want anybody to personalize it, because why would you personalize something that’s based on extraction?</p>\n<p>The only emotion that they valorize is the one where you don’t have a reaction to your extraction. That’s the way we train STEM graduates, and engineers specifically. Then they hear ethics and they’re like, “Oh yeah, I took a course on ethics.” Well, how many courses did you take in your program? Seventeen? I mean, of course you took an ethics class. How do you put critical race theory on top of that? How do you put the libidinal economy on top of that? The whole curriculum is designed not to introduce them to things about the world, much less critical texts. But that’s whiteness. It’s what Charles Mills calls “an epistemology of ignorance.” If they are born not to know, they don’t ever have to interrogate the conditions which led them to their success, because all they have to do is bask in the profit and the privilege. Oh, and enforce the denial of those profits and privileges to people who don’t look like them. </p>\n<p><b>To put it another way, part of my question about libidinal economy is: what is the why of rationality?</b></p>\n<p>Let me ask you a different question. Why has Marxism been taken up so strongly by information science and technology people, but not critical race theory? </p>\n<p><b>I know your resistance to political economy and I understand it to a degree. I don’t know if I read enough information science or things that are self-identified in that category to speak confidently about it. But, I’ll say, Ruha Benjamin put together her collection </b><b><i>Captivating Technology: Race, Carceral Technoscience, and Liberatory Imagination in Everyday Life </i></b><b>with scholars who are arguably taking up Black Marxism and the Black radical tradition, including R. Joshua Scannell and Andrea Miller, in a way that I find productive. I wouldn’t claim it’s critical race theory per se, but they’re definitely thinking with scholars like Katherine McKittrick and Sylvia Wynter when they’re writing about drones, for example. The end goal is not to be like, “Aaah, apocalypse coming, all the Black people gon’ die because drones is coming.” </b></p>\n<p><b>There is an evacuated critical race theory where people will cite Crenshaw, Lorde, and the Combahee River Collective—in that order—and have read none of them, understand none of them, and they’re just referencing in order to #decolonize for corporate diversity—</b></p>\n<p>—to just check off the boxes. </p>\n<h1><b>The Unholy Trinity</b></h1>\n<p><b>To me, there’s a connection between the epistemology of ignorance, philistinism or the refusal to read, whiteness, and techno-rationalism because, like you said, there are seventeen courses. There’s one week of ethics, sure—but those seventeen courses were about race too, in their refusal to address it as an explicit object, right?</b></p>\n<p>And not race broadly speaking, but white supremacy as a desire to control the nonwhite world and the natural world. I’ve been reading some good stuff recently, McKittrick specifically, and she writes about whiteness’ desire to control the world in hierarchical ways—to categorize it so that it can be placed in a hierarchy. That’s much more modernity than it is whiteness. But they’re hard to separate. You have the holy trinity, or the unholy trinity, of whiteness, modernity, and capitalism. Modernity wants to take us away from our folkways and traditions and make us more efficient and, as such, it extracts us from humans to numbers. Capitalism is like, “<i>Word</i>, because if we extract these people from their humanity, we can then exploit them for profit.” And then whiteness is like, “<i>Say, word</i>, because I was ready to extract these n***** anyway!”</p>\n<p>So, they all work together in concert and it’s really hard to untangle them. Which is the point of the libidinal economy for me, because it goes past modernity’s desire for numerical extraction and capital’s desire for labor. The strongest political economy critiques address capitalism’s desire to exploit humanity, the world, and its resources for profit. The libidinal economy goes past that to say, “Hey, there’s something about whiteness here.” There’s something <i>specifically</i> about anti-Blackness, because we could talk about China and Africa, right? China is not white. They don’t think of themselves as white. They do think of themselves as a sovereign in the world order and are intent on imposing their way of thinking about the world on the world. So, you see them making loans to African nations where they retain property rights over the properties they develop. And the African nations basically just get to host it. They get a little change from which they can skim off, you know, to make their families rich. But China <i>owns</i> all of that and, by extension, they are exploiting and extracting from the natural resources of the continent, for their own game. Is that anti-Black? Absolutely. Is that white? </p>\n<p><b>Well, it’s Han nationalist. I mean, the Uyghurs aren’t the only ones who aren’t Han. </b></p>\n<p>Right, the Uyghurs are not the only ones who aren’t Han. The entire country is made up of multiple ethnic minorities, but it’s strange how the Muslim ones get singled out for that. </p>\n<p><b>Well, also, I would like to abolish the word ethnicity.</b></p>\n<p>Noooo… [whimpers]</p>\n<p><b>No, the term ethnicity must die. You don’t understand, for us sitting in relationship to Ethiopia, they say ethnicity with a hard R. What really is an ethnic group? No, so I’m telling you straight up, Amhara supremacists, they’ll be like, “All those ethnic, ethno-nationalists, all this tribalism…” This is how they refer to Black Indigenous land claims because they want this universal category of Black that is defined by state-based nationalism, in a way that circumvents their own complicity in a system that produces benefit for them at the expense of the vast majority of people, in the wake of the slavery and colonization that happen in Ethiopia. And so, what is an ethnicity? Because the claims that you can make as an ethnic group are very different from the claims that you make as a nation. The former hails a kind of parochialism that I think is different. </b></p>\n<p>The reason why I want to hold on to ethnicity partially is that’s where I got my definition of race from for <i>Distributed Blackness</i>. I fell in love with the sociological explanation of ethnicity. In relationship to Quebec, Everett Cherrington Hughes said ethnicity is <i>not</i> a pattern of traits or behaviors that you can assign to a particular group. Instead, it’s what both the in-group and the outgroup agree that the in-group says does, believes, and behaves. So, it’s a discursive definition and, from there, I feel like it’s important we get the understanding that no ethnicity exists in isolation. It’s always in response to cultural, environmental, geographic, and political factors around them. </p>\n<p>So, China is really trying to do the political work of saying there are no ethnicities here, “We’re all one China.” But we can look back at the Freedmen here in Oklahoma who are fighting to be considered part of the Cherokee ethnic group because they got that oil money, and the Cherokee are like, “No, we’re going to go to science and say, ‘You’re not genetically Cherokee, you can’t get this money.’” But the Freedmen are like, “We were raised with you. We have children with you. We have ancestors with you. Therefore, we are part of this culture.” And that difference to me—between race and ethnicity—<i>that</i> is the really tricky thing. It’s always slippery, right? But it’s a boundary that I think makes sense in our world of signifying and meaning. </p>\n<p><b>I would say the same exact thing in my explanation of why the term ethnicity must die. The thing is, the work “ethnicity” does in America is perhaps different than in other parts of the world. The most contention is around the category of Hispanic, when they have you fill out demographic forms around race and the options presented are Hispanic or Black—what the fuck is Hispanic? Who agreed to even be from Spain? </b></p>\n<h1><b>What to do about Logic (and Kevin)?</b></h1>\n<p><b>Shout out to </b><b><i>Logic</i></b><b>. I’m appreciative that they let me hijack this shit, right? But I’ve definitely been thinking about what it means to hijack </b><b><i>Logic</i></b><b>, because “logic” has been so central to the dominant critique of mis/disinformation—that these ignorant, economically anxious white actors are illogical. They’re not pledging allegiance to science and are undermining the Enlightenment rationality that we fought for, that our forefathers fought for—though maybe they shouldn’t have committed genocide against Indigenous people and enslave the Blacks along the way. But they say, “We recognize that, we make an acknowledgment of past harm,” and now let’s focus on logic. So, how do we intervene in the context of this way of thinking about logic, enlightenment, and rationality? </b></p>\n<p>The best thing we can do is establish the validity of alternative epistemological standpoints. What I mean when I say that is that every culture approaches their version of reality differently. Whether it’s geographic, whether it’s genetic, whether it’s environmental, whether it’s political—they all approach it differently. And for the last five or six hundred years, we’ve been forced to endure a world that is structured by a white disavowal of their own embodied consciousness, disdain for women, and anti-Black racism. Those three things are the pillars of what whiteness is, so rationality is a disavowal of not just feelings but also a disavowal of the role that women have in the decision-making process, because women under rationality are considered hysterical. </p>\n<p>If you take women out of the decision-making process, you basically get the thoughts of white men. Under whiteness, white men are valued for their ability to resist their dark desires, their empathy, and their care, because they’re making “unemotional” decisions about how to apportion resources. That comes <i>directly</i> back into the data science that we’re arguing with and about, because, to them, the most elegant code is the code that is beautiful in its simplicity and its aesthetic minimalism. The most elegant code also does things to social situations that seem as if they are situations devoid of emotional resonance. </p>\n<p>So we could talk about social welfare algorithms where people are now being asked to fill out entire questionnaires about what type of toothpaste they use, because their answer to that question will be put into a database and used to calculate that they are not deserving of welfare benefits because they have too good a taste in toothpaste. How dare you have sensitive teeth? You don’t deserve Sensodyne, you better go get you some Arm &amp; Hammer toothpaste for a dollar! So it’s this continual asceticism, this denial of the pleasures, or even the denial of the experience of the visceral, of the libidinal. That is one of the core functions of whiteness. </p>\n<p>One of the most interesting trends during the early stages of the pandemic was that African countries were not experiencing Covid-19 at the same rates as white Western nations. And it turns out that it was because these folk, since they had lived with chronic deadly diseases for centuries, had built up protocols for infection control strategies. And there are other examples where people are doing fantastic things for themselves, of themselves, by themselves that are not beholden to a Western paradigm. </p>\n<p>But, to go back to an American context, how are we supposed to gain control over these information resources in order to institute a different epistemological standpoint? Because one of the other things that whiteness is good at is <i>denying</i> access to those resources, so that we can achieve—I hate the word sovereignty—some sort of valence of being part of this nation.</p>\n<p>One of the slickest things that I’ve seen over the last thirty years is how good conservative movements are at taking terms like woke and critical race theory, stripping them of all meaning, and then getting them used against us. That interpretive flexibility, I would argue, is whiteness’s greatest resource. And it works well for the libidinal economy of information because the digital itself is flexible. It can promote pieces of information in a way that strips them of their context and makes it seem like they’re universal, when, in actuality, they’re very particular. So whiteness and information technology work well hand-in-hand. Maybe by design. What would a Wakandan information technology look like? </p>\n<p><b>Could you talk a little about what you mean when you say that </b><b><i>Distributed Blackness </i></b><b>proposes a Morrisonian approach to technology? </b></p>\n<p>That’s Ruha Benjamin’s fault. Ruha interviewed me, and at the end of the conversation, she said, “This is a <i>Morrisonian</i> approach to information technology.” I was like, “What you mean? That’s too big. I can’t take that.” She’s like, “No, if you think about <i>Playing in the Dark</i>, where Morrison spends a lot of time in the first couple of chapters talking about ‘American Africanism,’ or a white identity premised on a negative, inverse relationship with Blackness. You’re making that same conversation—not about literature, but about technology.” </p>\n<p>What I’m trying to do is establish what Black people have always done. We have always had to watch the other carefully in order to not get eaten by the other or destroyed by the other. We have to know their ways. We have to know how they work and, in the process, from that outside perspective, what we do is we build a Black inquiry on an analysis of <i>invention</i>—because what’s more invented than whiteness? They made themselves up out of English, German, Italian, Dutch, Norwegian. They made themselves into this category called white—that’s an invention like a mothafucka’, right? But in the process of doing so, they had to center that invention against a Black body in order to make it legible. </p>\n<p>Charles Mills says Blackness is illumination. Y’all been telling us that we need to illuminate what Blackness is for y’all. But Blackness actually illuminates what modernity is. And that’s where I sit. I use my epistemological standpoint, my positionality in and of the world, to critique the world that brought me into being—that’s Morrison. If you think about <i>Sula</i>, if you think about <i>The Bluest Eye</i>, those are all positions, those are all texts interrogating the world from a particular standpoint that has already been destroyed or attempted to be destroyed. </p>\n<p>That shit is powerful to me. It’s not a position of abjectness. I’m not saying, “Oh, I’m on the other side of the digital divide and I’m trying to cross that bridge.” No, I peeped that bridge and it doesn’t take me anywhere that’s really necessary for me to go. And let me tell you how fucked up it was, what you did while you was tearing down the ecosystem and destroying the land, and destroying the people who owned that land before you, in order to make this bridge happen so that you could be more efficient and not have to go all the way around to the ford to ship your goods. </p>\n<p>So a Morrisonian approach—an American Africanism—is shorthand for basically saying, from this standpoint, from where you stand on the margins of white society, but in your fullness as a Black person (because Blackness is human, regardless of what Afro-pessimists say), what critiques have you made or can you make about whiteness and the world that whiteness has created? A shit-ton, a lot, right? And they’re critiques that white folk are not capable of making because this is their utopia. For all that they complain about it, this is the world that they wanted, the world that they got. </p>\n<p>Man, that look on your face. I’d pay money for that. </p>\n<p><b>So, where we at? Where do we locate this Black sense of place when we know that information science is already so dominated by whiteness? Where do we just stand still and where do we act? We got McKittrick writing </b><b><i>Dear Science and Other Stories</i></b><b>, Ruha Benjamin’s multiple books, and Simone Browne’s </b><b><i>Dark Matters</i></b><b>. But, on the whole, where is the Black study folk at? </b></p>\n<p>Black studies has not concerned itself with science in any real way. Black studies is more focused on the interpretation of texts, film, video, music, and the like. They have not focused on science at all. You have some historians who have done amazing work, but in general Black studies don’t care. </p>\n<p>What McKittrick does that’s really valuable is she talks passionately about how we understand ourselves not grounded in the ways the world told us we should be, but how we understand ourselves as what Black people do. She said Black knowing is feeling, and I was like, “You motherfucking right,” because there’s something about that embodied cognition. When the world is inflicted upon your body, then you listen to what your body says when it’s trying to tell you about the world. </p>\n<p>We lack the means of control or even dominance in these tech industries. The best we can do is get an interest convergence with well-meaning white people (WMWPs) and liberal folk to at least trouble their understandings of what the world they’re creating is—whether that’s Black feminist epistemology, whether that’s intersectionality, whether that’s critical race theory, any of those things, right? If we can get them to understand that the harms that they visit upon us are also inadvertently visited upon their children and their grandparents, then we’ll get some action. The problem is we created industries full of white men who don’t care about their momma. Have you seen the movie <i>We Need to Talk About Kevin? </i></p>\n<p><b>Yes.</b></p>\n<p>That’s the type of industry we’ve created right now. “I wonder what this bow and arrow will do? Oh, I’m sorry, Dad, I didn’t mean to kill them with it.” </p>\n<p>We’ve got three white men fighting to get higher into the low Earth orbit—not even in fucking space, just far enough from the planet so they can float. And their aims are celebrated by the mainstream press because they’re visions of a future where they can escape Blackness. As opposed to dealing with the harms that they’ve created with just-in-time manufacturing and two-day shipping and this surveillance culture that they have fostered under the guise of friendship and community. They don’t want to address those harms because those harms have made them a <i>shit ton of money.</i> </p>\n<p>Facebook is a good example. My students always grimace when I say the best way to understand Facebook is that it was a creation of a horny nineteen-year-old with more computing skills than social skills, and this was a way he could get to meet, in the abstract, the women he wanted to be with. Because that’s what Facebook was. It was a network that he built where people would submit pictures of themselves and he could select them at his leisure without them knowing that he was looking at them. Once you start from that understanding, Facebook’s extraction of personal data and sales to advertisers makes a lot more sense. It never has been about community. You can see how poorly they understand community with the way they moderate and run Facebook groups. It always has been about the extraction of something to satisfy the libidinal, whether it’s voyeurism or simply wanting to profit off of others.</p>",
      "content_text": "The Black internet has a long history. It has multiple points of origin, as Charlton McIlwain has documented—from Afronet, a BBS network for Black users, to NetNoir, an AOL-based portal “devoted to Afrocentric material,” both of which launched in the mid-1990s. Today, the Black internet has entered the platform era, distributing its riches across Twitter and Instagram and YouTube.\nWhat would it mean to take the Black internet seriously? What would it mean to see Black digital practices (in all their diversity) not in pathological terms—as hailing from the wrong side of a “digital divide”—but as creative, joyful, affirming? What if the Black internet offers a standpoint from which the rest of the internet can be seen, and critiqued, more clearly?\nThese are some of the questions that guide the work of André Brock, Jr., associate professor of Black Digital Studies at Georgia Institute of Technology and the author of Distributed Blackness: African American Cybercultures. In his work, Brock uses a methodology that he calls “critical technocultural discourse analysis” (CTDA). “It decenters the Western deficit perspective on minority technology use to instead prioritize the epistemological standpoint of underrepresented groups of technology users,” he writes, with the aim of conducting “a holistic analysis of an information technology artifact and its practices.” In other words, CTDA asks, why do people do what they do on the internet—especially when “people” are not just white, cis, heteronormative men? Central to CTDA is the idea of the “libidinal economy,” which originates with Freud, was further developed by the French philosopher Jean-François Lyotard, and has more recently been taken up by Fred Moten, Frank B. Wilderson III, and other Black thinkers. A libidinal-economic approach emphasizes the role of emotional and psychological intensities in driving anti-Blackness, rather than the more rationalist models of human behavior derived from political-economic approaches. Issue editor J. Khadijah Abdurahman sat down with Brock to trace the history of disinformation from Reconstruction to the present, and to discuss “the unholy trinity of whiteness, modernity, and capitalism.”\n\nHow do you see the state of mis/disinformation research? What do you think is missing from the conversation? \nDisinformation is only perceived as bad when it serves to disrupt the interests of whiteness and white power. White power sounds strong, but it fits. During Reconstruction, the country found all sorts of creative ways to keep black folk from the polls, up to and including murder. That wasn’t a problem. Du Bois documented this extensively in Black Reconstruction, but misinformation against non-whites is typically a footnote in history texts and media reports as it serves the telos of American democracy.\nSimilarly, when disinformation campaigns began to surface in the mid-2000s around Gamergate—or troll farms attacking Black Lives Matter activists—that wasn’t considered worthy of research. We still don’t have great academic research on Crystal Johnson and Blacktivist—two large internet troll farm campaigns that were trying to convince Black folk not to vote. What we do have, however, is a plethora of highly funded research incorporating both quantitative and computational evidence of how disinformation has affected white voters. \nFor example, reporting on the 2016 presidential election first framed voters as having economic anxiety. They weren’t white—they were economically anxious. Then folk began to find out that economics wasn’t necessarily the cause they were rallying around. They were rallying around xenophobia, anti-intellectualism, and anti-big government. All those are things that white folk are concerned about. Misinformation research is largely conducted by white folk, and their concerns reify this anxiety about the disruptive power of social media and mass media against the interests of white folk. \nThe object of inquiry of disinformation research has largely been whiteness and white anxiety. Maybe that reflects the classism of disinformation researchers, who are probably mostly trust-fund babies or the partners of people who work in Big Tech. They’re concerned with these “rabble-rousing” and “ignorant” white folks. The emphasis on QAnon is fascinating to me: it’s taken such a god-like center stage in much of the disinformation research. \nReporting on Black vaccine hesitancy has focused on the Tuskegee experiment. Leaving aside the fact that Tuskegee was the complete inverse of what we’re seeing with the Covid-19 vaccine—in that it was an experiment where treatment for syphilis was withheld, or that the racial disparities in Covid-19 vaccination rates primarily reflects availability and access, not hesitancy—the reporting has omitted how many of the pandemic conspiracy theories circulating in Black communities are tied to anti-Semitic conspiracy theories. \nDo you remember that right in the beginning of the shelter-in-place orders, Nick Cannon came out repeating anti-Semitic shit from Farrakhan about the caucusoids descending from the mountains? Then Viacom suspended his show. Busta Rhymes came out and said something that was anti-vax in August 2021, echoing conspiracy theories from Milton William Cooper’s Behold a Pale Horse. The way that book in particular has had a chokehold on the Black entertainment industry is well known in our community. Yet it’s nowhere to be found in this academic discourse of rationality, universality, and mis/disinformation. \nDisinformation technologizes and scrubs movements of their xenophobic and racist antecedents to say they represent strictly an information misbehavior. Not a cultural misbehavior. That’s part of the problem. If you scrub racism and xenophobia from disinformation campaigns, what you have is what they would like to say: an attempt to overthrow a government through illegitimate means. But what if you add back in the racism? The better antecedent for QAnon is the John Birch Society, but that’s seen as too explicitly racist. \nBlack folk have contended with internal disinformation forever. Busta is part of the the Five-Percent Nation, which has had a deep hold on New York rap forever, in terms of coercing patriarchal gender roles and influencing Black relationships to the state. But that was just Black folk being crazy, right? \nIf you add back in the racism, it adds an entirely powerful libidinal element, in the sense that QAnoners are not overthrowing the government because it was working for white people, they’re overthrowing the government because they felt that it was working too hard to entitle Black and brown folk. Working too hard to give them things to which these white folk feel they don’t deserve. It’s an entitlement culture: we don’t want to give them things. We want them to learn how to work for it. That’s been an anti-Black statement since the 1860s. As soon as we got free, they were like, “Oh, well, these n***** don’t work. They’re lazy. We had to beat them in order to get them to work.” \nThat libidinal economy of the digital seeks to continually restrict information transfer and exchange as an instrumental mode. And by that I mean, it’s strictly the message that’s being communicated, not any of the things which animate that message. So, for the libidinal economy of the digital, we look at productive. We look at efficient. We look at time and space-spanning, right? We look at collapsing traditional order in order to impose modern order. We look at “just in time” manufacturing, which now we understand is a huge problem because corporations sought to “reduce inefficiencies” like merchandise sitting in warehouses or eliminating jobs to demonstrate productivity to Wall Street. As a result we have empty shelves, halted production, and inflation now, but also higher levels of inequality and stress in the decades leading up to this moment.\nBelieving in Digital Divides\nI want to just scroll back to the other question about disinformation for a second. There’s this obsession with how other people behave and what their beliefs are. This white, cis, heteronormative, middle-class idea that spaces are not “diverse enough” demonstrates to me how homogenous academic and media spaces are. \nI used to do a lot of restaurant work. You’d be working in the back of the house with this dude who’s forty-five from Bangladesh, somebody else who is undocumented from Russia, a seventeen-year-old washing dishes who only speaks Spanish, and then you’re serving these white customers. So, really, it’s the class of people being served who has a more insular view of the world, not the people in the back of the house—yet that’s the class we’re getting research from. The disinformation discourse is very abstracted away from the conditions, beliefs, and societies it seeks to describe. \nWhen I think about disinformation campaigns, I also think about the digital divide, one of the biggest trends in pathologizing Black people’s relationship to technology. Where’s the space to turn ethnography backwards, onto a field that has gotten a lot wrong?\nThe digital divide stuff has shifted to “information communication technology for development,” or ICT4D. They’re looking at Africa, India, Pakistan, and other places, and saying, “They don’t have the same type of networks we have in the West. So, of course, they’re struggling to access the resources that we take for granted.” It’s just as problematic as it was when they were looking at Black folk here in the States because, like you said, it never turns the gaze around to ask what created these conditions. How and why do these conditions continue to persist? Instead, let’s be liberal and only look at the ways people will either resist or are hailed by these particular technological systems in a way that disadvantages them. \nAs the president of the Distributed Blackness: African American Cybercultures stan club, the two main contributions of your book are, in my view, Critical Technocultural Discourse Analysis (CTDA) as a process through which to understand these technologies, and the importance of the libidinal economy. This largely seems to have gone unaccepted within the dominant research discourse. Is that your experience, or do you feel like people are engaging with your approach? \n[Ed.: The idea of “libidinal economy” originates with Freud, was further developed by the French philosopher Jean-François Lyotard, and more recently has been taken up by Frank B. Wilderson III, Fred Moten, and other Black thinkers. It emphasizes that emotional intensities, such as desire or antiblackness, drive “rational self interest” or political-economic modes of thinking.] \nThe libidinal approach is still too new. I don’t have the impact on social science research yet because I’m still talking about Black people. That’s my mistake. I didn’t try to claim white people are bad. That wasn’t my concern. My concern was to say, “Look at how joyous Black people are,” which is a very different thing. \nI have to give a talk to Microsoft in a month and they’re like, “Well, can you present your book in a way that makes it palatable to white people?” Nah, I can’t. And it’s not going to happen because you need to learn about me as opposed to learning what I do to resist you, which are two totally different things.\nData science and information science have long been and will continue to be resistant to theories like libidinal economy, but also to theories like critical race theory, because they are resistant to things which are not of them. They think about things which they can reach out and fix, like ethics. Or reach out and bring in, like the digital divide stuff. But they don’t ever want to engage with the question of how they benefit from certain structures, or how to fix the problems they’ve created. They don’t want to do that.\nSo the libidinal economy has a ways to go. I’m really enthused by the uptake that it’s gotten among critical academics like yourself. Somebody said to me in my DMs the other day that it gives you a framework for understanding exactly what was going on, because we didn’t have words for it before. But white folks will always say racism is not in their heart—which is their own libidinal economy, right? They’ll never be encouraged to take it up, because to do so requires that they interrogate themselves and that’s not going to happen. \nDo you think Twitter is an accurate gauge for the Discourse™️? Do you have a sense of what readings are driving the adherence to rationalism? \nTwitter really is a space where people who don’t read books want to argue with people who write books. That’s tech too, right? I had these students coming through my classes at Georgia Tech who said, “We don’t read this kind of thing. They just tell us to make stuff. They train us how to make it. They’re not asking us to think about it.”\nThose are the people that Georgia Tech sends into Google, Amazon, Microsoft, and Netflix. The people who are trained not to think about things. Lewis Mumford talked about this not on a racial basis, but on a technical basis. He called it “techno-rationalism,” and he said no manufacturer wants a person who has a tendency to engage in anthropomorphic, quasi-rational thinking about the industry that we inhabit. They don’t want anybody to personalize it, because why would you personalize something that’s based on extraction?\nThe only emotion that they valorize is the one where you don’t have a reaction to your extraction. That’s the way we train STEM graduates, and engineers specifically. Then they hear ethics and they’re like, “Oh yeah, I took a course on ethics.” Well, how many courses did you take in your program? Seventeen? I mean, of course you took an ethics class. How do you put critical race theory on top of that? How do you put the libidinal economy on top of that? The whole curriculum is designed not to introduce them to things about the world, much less critical texts. But that’s whiteness. It’s what Charles Mills calls “an epistemology of ignorance.” If they are born not to know, they don’t ever have to interrogate the conditions which led them to their success, because all they have to do is bask in the profit and the privilege. Oh, and enforce the denial of those profits and privileges to people who don’t look like them. \nTo put it another way, part of my question about libidinal economy is: what is the why of rationality?\nLet me ask you a different question. Why has Marxism been taken up so strongly by information science and technology people, but not critical race theory? \nI know your resistance to political economy and I understand it to a degree. I don’t know if I read enough information science or things that are self-identified in that category to speak confidently about it. But, I’ll say, Ruha Benjamin put together her collection Captivating Technology: Race, Carceral Technoscience, and Liberatory Imagination in Everyday Life with scholars who are arguably taking up Black Marxism and the Black radical tradition, including R. Joshua Scannell and Andrea Miller, in a way that I find productive. I wouldn’t claim it’s critical race theory per se, but they’re definitely thinking with scholars like Katherine McKittrick and Sylvia Wynter when they’re writing about drones, for example. The end goal is not to be like, “Aaah, apocalypse coming, all the Black people gon’ die because drones is coming.” \nThere is an evacuated critical race theory where people will cite Crenshaw, Lorde, and the Combahee River Collective—in that order—and have read none of them, understand none of them, and they’re just referencing in order to #decolonize for corporate diversity—\n—to just check off the boxes. \nThe Unholy Trinity\nTo me, there’s a connection between the epistemology of ignorance, philistinism or the refusal to read, whiteness, and techno-rationalism because, like you said, there are seventeen courses. There’s one week of ethics, sure—but those seventeen courses were about race too, in their refusal to address it as an explicit object, right?\nAnd not race broadly speaking, but white supremacy as a desire to control the nonwhite world and the natural world. I’ve been reading some good stuff recently, McKittrick specifically, and she writes about whiteness’ desire to control the world in hierarchical ways—to categorize it so that it can be placed in a hierarchy. That’s much more modernity than it is whiteness. But they’re hard to separate. You have the holy trinity, or the unholy trinity, of whiteness, modernity, and capitalism. Modernity wants to take us away from our folkways and traditions and make us more efficient and, as such, it extracts us from humans to numbers. Capitalism is like, “Word, because if we extract these people from their humanity, we can then exploit them for profit.” And then whiteness is like, “Say, word, because I was ready to extract these n***** anyway!”\nSo, they all work together in concert and it’s really hard to untangle them. Which is the point of the libidinal economy for me, because it goes past modernity’s desire for numerical extraction and capital’s desire for labor. The strongest political economy critiques address capitalism’s desire to exploit humanity, the world, and its resources for profit. The libidinal economy goes past that to say, “Hey, there’s something about whiteness here.” There’s something specifically about anti-Blackness, because we could talk about China and Africa, right? China is not white. They don’t think of themselves as white. They do think of themselves as a sovereign in the world order and are intent on imposing their way of thinking about the world on the world. So, you see them making loans to African nations where they retain property rights over the properties they develop. And the African nations basically just get to host it. They get a little change from which they can skim off, you know, to make their families rich. But China owns all of that and, by extension, they are exploiting and extracting from the natural resources of the continent, for their own game. Is that anti-Black? Absolutely. Is that white? \nWell, it’s Han nationalist. I mean, the Uyghurs aren’t the only ones who aren’t Han. \nRight, the Uyghurs are not the only ones who aren’t Han. The entire country is made up of multiple ethnic minorities, but it’s strange how the Muslim ones get singled out for that. \nWell, also, I would like to abolish the word ethnicity.\nNoooo… [whimpers]\nNo, the term ethnicity must die. You don’t understand, for us sitting in relationship to Ethiopia, they say ethnicity with a hard R. What really is an ethnic group? No, so I’m telling you straight up, Amhara supremacists, they’ll be like, “All those ethnic, ethno-nationalists, all this tribalism…” This is how they refer to Black Indigenous land claims because they want this universal category of Black that is defined by state-based nationalism, in a way that circumvents their own complicity in a system that produces benefit for them at the expense of the vast majority of people, in the wake of the slavery and colonization that happen in Ethiopia. And so, what is an ethnicity? Because the claims that you can make as an ethnic group are very different from the claims that you make as a nation. The former hails a kind of parochialism that I think is different. \nThe reason why I want to hold on to ethnicity partially is that’s where I got my definition of race from for Distributed Blackness. I fell in love with the sociological explanation of ethnicity. In relationship to Quebec, Everett Cherrington Hughes said ethnicity is not a pattern of traits or behaviors that you can assign to a particular group. Instead, it’s what both the in-group and the outgroup agree that the in-group says does, believes, and behaves. So, it’s a discursive definition and, from there, I feel like it’s important we get the understanding that no ethnicity exists in isolation. It’s always in response to cultural, environmental, geographic, and political factors around them. \nSo, China is really trying to do the political work of saying there are no ethnicities here, “We’re all one China.” But we can look back at the Freedmen here in Oklahoma who are fighting to be considered part of the Cherokee ethnic group because they got that oil money, and the Cherokee are like, “No, we’re going to go to science and say, ‘You’re not genetically Cherokee, you can’t get this money.’” But the Freedmen are like, “We were raised with you. We have children with you. We have ancestors with you. Therefore, we are part of this culture.” And that difference to me—between race and ethnicity—that is the really tricky thing. It’s always slippery, right? But it’s a boundary that I think makes sense in our world of signifying and meaning. \nI would say the same exact thing in my explanation of why the term ethnicity must die. The thing is, the work “ethnicity” does in America is perhaps different than in other parts of the world. The most contention is around the category of Hispanic, when they have you fill out demographic forms around race and the options presented are Hispanic or Black—what the fuck is Hispanic? Who agreed to even be from Spain? \nWhat to do about Logic (and Kevin)?\nShout out to Logic. I’m appreciative that they let me hijack this shit, right? But I’ve definitely been thinking about what it means to hijack Logic, because “logic” has been so central to the dominant critique of mis/disinformation—that these ignorant, economically anxious white actors are illogical. They’re not pledging allegiance to science and are undermining the Enlightenment rationality that we fought for, that our forefathers fought for—though maybe they shouldn’t have committed genocide against Indigenous people and enslave the Blacks along the way. But they say, “We recognize that, we make an acknowledgment of past harm,” and now let’s focus on logic. So, how do we intervene in the context of this way of thinking about logic, enlightenment, and rationality? \nThe best thing we can do is establish the validity of alternative epistemological standpoints. What I mean when I say that is that every culture approaches their version of reality differently. Whether it’s geographic, whether it’s genetic, whether it’s environmental, whether it’s political—they all approach it differently. And for the last five or six hundred years, we’ve been forced to endure a world that is structured by a white disavowal of their own embodied consciousness, disdain for women, and anti-Black racism. Those three things are the pillars of what whiteness is, so rationality is a disavowal of not just feelings but also a disavowal of the role that women have in the decision-making process, because women under rationality are considered hysterical. \nIf you take women out of the decision-making process, you basically get the thoughts of white men. Under whiteness, white men are valued for their ability to resist their dark desires, their empathy, and their care, because they’re making “unemotional” decisions about how to apportion resources. That comes directly back into the data science that we’re arguing with and about, because, to them, the most elegant code is the code that is beautiful in its simplicity and its aesthetic minimalism. The most elegant code also does things to social situations that seem as if they are situations devoid of emotional resonance. \nSo we could talk about social welfare algorithms where people are now being asked to fill out entire questionnaires about what type of toothpaste they use, because their answer to that question will be put into a database and used to calculate that they are not deserving of welfare benefits because they have too good a taste in toothpaste. How dare you have sensitive teeth? You don’t deserve Sensodyne, you better go get you some Arm & Hammer toothpaste for a dollar! So it’s this continual asceticism, this denial of the pleasures, or even the denial of the experience of the visceral, of the libidinal. That is one of the core functions of whiteness. \nOne of the most interesting trends during the early stages of the pandemic was that African countries were not experiencing Covid-19 at the same rates as white Western nations. And it turns out that it was because these folk, since they had lived with chronic deadly diseases for centuries, had built up protocols for infection control strategies. And there are other examples where people are doing fantastic things for themselves, of themselves, by themselves that are not beholden to a Western paradigm. \nBut, to go back to an American context, how are we supposed to gain control over these information resources in order to institute a different epistemological standpoint? Because one of the other things that whiteness is good at is denying access to those resources, so that we can achieve—I hate the word sovereignty—some sort of valence of being part of this nation.\nOne of the slickest things that I’ve seen over the last thirty years is how good conservative movements are at taking terms like woke and critical race theory, stripping them of all meaning, and then getting them used against us. That interpretive flexibility, I would argue, is whiteness’s greatest resource. And it works well for the libidinal economy of information because the digital itself is flexible. It can promote pieces of information in a way that strips them of their context and makes it seem like they’re universal, when, in actuality, they’re very particular. So whiteness and information technology work well hand-in-hand. Maybe by design. What would a Wakandan information technology look like? \nCould you talk a little about what you mean when you say that Distributed Blackness proposes a Morrisonian approach to technology? \nThat’s Ruha Benjamin’s fault. Ruha interviewed me, and at the end of the conversation, she said, “This is a Morrisonian approach to information technology.” I was like, “What you mean? That’s too big. I can’t take that.” She’s like, “No, if you think about Playing in the Dark, where Morrison spends a lot of time in the first couple of chapters talking about ‘American Africanism,’ or a white identity premised on a negative, inverse relationship with Blackness. You’re making that same conversation—not about literature, but about technology.” \nWhat I’m trying to do is establish what Black people have always done. We have always had to watch the other carefully in order to not get eaten by the other or destroyed by the other. We have to know their ways. We have to know how they work and, in the process, from that outside perspective, what we do is we build a Black inquiry on an analysis of invention—because what’s more invented than whiteness? They made themselves up out of English, German, Italian, Dutch, Norwegian. They made themselves into this category called white—that’s an invention like a mothafucka’, right? But in the process of doing so, they had to center that invention against a Black body in order to make it legible. \nCharles Mills says Blackness is illumination. Y’all been telling us that we need to illuminate what Blackness is for y’all. But Blackness actually illuminates what modernity is. And that’s where I sit. I use my epistemological standpoint, my positionality in and of the world, to critique the world that brought me into being—that’s Morrison. If you think about Sula, if you think about The Bluest Eye, those are all positions, those are all texts interrogating the world from a particular standpoint that has already been destroyed or attempted to be destroyed. \nThat shit is powerful to me. It’s not a position of abjectness. I’m not saying, “Oh, I’m on the other side of the digital divide and I’m trying to cross that bridge.” No, I peeped that bridge and it doesn’t take me anywhere that’s really necessary for me to go. And let me tell you how fucked up it was, what you did while you was tearing down the ecosystem and destroying the land, and destroying the people who owned that land before you, in order to make this bridge happen so that you could be more efficient and not have to go all the way around to the ford to ship your goods. \nSo a Morrisonian approach—an American Africanism—is shorthand for basically saying, from this standpoint, from where you stand on the margins of white society, but in your fullness as a Black person (because Blackness is human, regardless of what Afro-pessimists say), what critiques have you made or can you make about whiteness and the world that whiteness has created? A shit-ton, a lot, right? And they’re critiques that white folk are not capable of making because this is their utopia. For all that they complain about it, this is the world that they wanted, the world that they got. \nMan, that look on your face. I’d pay money for that. \nSo, where we at? Where do we locate this Black sense of place when we know that information science is already so dominated by whiteness? Where do we just stand still and where do we act? We got McKittrick writing Dear Science and Other Stories, Ruha Benjamin’s multiple books, and Simone Browne’s Dark Matters. But, on the whole, where is the Black study folk at? \nBlack studies has not concerned itself with science in any real way. Black studies is more focused on the interpretation of texts, film, video, music, and the like. They have not focused on science at all. You have some historians who have done amazing work, but in general Black studies don’t care. \nWhat McKittrick does that’s really valuable is she talks passionately about how we understand ourselves not grounded in the ways the world told us we should be, but how we understand ourselves as what Black people do. She said Black knowing is feeling, and I was like, “You motherfucking right,” because there’s something about that embodied cognition. When the world is inflicted upon your body, then you listen to what your body says when it’s trying to tell you about the world. \nWe lack the means of control or even dominance in these tech industries. The best we can do is get an interest convergence with well-meaning white people (WMWPs) and liberal folk to at least trouble their understandings of what the world they’re creating is—whether that’s Black feminist epistemology, whether that’s intersectionality, whether that’s critical race theory, any of those things, right? If we can get them to understand that the harms that they visit upon us are also inadvertently visited upon their children and their grandparents, then we’ll get some action. The problem is we created industries full of white men who don’t care about their momma. Have you seen the movie We Need to Talk About Kevin? \nYes.\nThat’s the type of industry we’ve created right now. “I wonder what this bow and arrow will do? Oh, I’m sorry, Dad, I didn’t mean to kill them with it.” \nWe’ve got three white men fighting to get higher into the low Earth orbit—not even in fucking space, just far enough from the planet so they can float. And their aims are celebrated by the mainstream press because they’re visions of a future where they can escape Blackness. As opposed to dealing with the harms that they’ve created with just-in-time manufacturing and two-day shipping and this surveillance culture that they have fostered under the guise of friendship and community. They don’t want to address those harms because those harms have made them a shit ton of money. \nFacebook is a good example. My students always grimace when I say the best way to understand Facebook is that it was a creation of a horny nineteen-year-old with more computing skills than social skills, and this was a way he could get to meet, in the abstract, the women he wanted to be with. Because that’s what Facebook was. It was a network that he built where people would submit pictures of themselves and he could select them at his leisure without them knowing that he was looking at them. Once you start from that understanding, Facebook’s extraction of personal data and sales to advertisers makes a lot more sense. It never has been about community. You can see how poorly they understand community with the way they moderate and run Facebook groups. It always has been about the extraction of something to satisfy the libidinal, whether it’s voyeurism or simply wanting to profit off of others.",
      "date_published": "2022-01-18T15:57:51.000Z",
      "date_modified": "2022-01-18T15:57:51.000Z",
      "_plugin": {
        "pageFilename": "ccbe7f3bfeee5e8c716f25a8707c81c9681f3832909c82a0c16fc92356682940.html"
      }
    },
    {
      "id": "https://logicmag.io/beacons/technologies-of-black-freedoms-calling-on-black-studies-scholars-with-sa",
      "url": "https://logicmag.io/beacons/technologies-of-black-freedoms-calling-on-black-studies-scholars-with-sa",
      "title": "Technologies of Black Freedoms: Calling On Black Studies Scholars, with SA Smythe",
      "summary": "Refusing to see like a state.",
      "content_html": "<p><i>There’s been an increasing recognition of how racial regimes are mediated by digital technologies, particularly through things like computational policing practices that target communities of color and automated hiring platforms that exacerbate employment discrimination. But so far, the discourse about “algorithmic bias” largely treats race as an aftermath of technology, as a downstream effect. Further, it treats race as a problem—race is the way you add up the bad things that technology does to people. Race is a way to measure harm. </i></p>\n<p><i>Both premises need to be challenged. Racial regimes aren’t downstream of technology—they’re present from the very start. They centrally shape the design, development, and deployment of the computational systems that govern our lives. And the obsession with calculating race as a function of harmful impact institutionalizes Black people as objects of suffering without agency or political subjectivity that extends beyond advocating for social remedy. </i></p>\n<p><i>To overcome the limitations of the algorithmic bias discourse, we need to ask a completely different set of questions about technology, drawing on the traditions of black thought and black freedom-dreaming. To help formulate these questions, and begin to sketch some possible answers, issue editor J. Khadijah Abdurahman talked with SA Smythe, an assistant professor in the Gender Studies and African American Studies departments at UCLA. Smythe is a poet, translator, and scholar of black European literary and cultural studies and Black trans poetics, and is deeply invested in the coalitional project of black life, black study, and relishing nonbinary experiences across the diaspora. Abdurahman talked to Smythe about abolition organizing on Turtle Island, statecraft as reproduced in humanitarian technologies, and orienting toward “otherwise possibility.”</i></p>\n<p><i></i></p>\n<p><b>The joke I always make is that techno-capitalism puts people who have never taken the humanities in charge of humanity. In that vein, the driving motivation behind </b><i>Beacons</i><b> is thinking about how we “call in” Black studies and abolitionist organizers into this technology discourse. Even as I say that, I want to be careful to not reify technology as the property of white, cisgender male tech bros straight outta Silicon Valley because we are all already using, interacting, and modifying techniques and technologies all the time, right? </b></p>\n<p>This time that we are asymmetrically experiencing has been intense and overwhelming due to the convergence of so-called “crises,” which are of course interrelated. So, I’m really grateful to be taking up those questions in this format. I’ve felt insecure about how to jump in and have a conversation about “tech” even though it’s so pervasive and is foundational to much of our relationship to modern life/modernity. How do we think about technologies as various techniques, tools, or modalities for collective liberation or for black freedoms? How do we get humanists and humanities adjacent folks—especially people who engage in various black radical traditions and Black feminist practices—to think more urgently about Technology in the capital T sense? I’m not quite sure, but the invitation is key. Of course, as we’ve talked about this ongoing invitation, with scholars like Simone Browne, Katherine McKittrick, Safiya Noble, and Ruha Benjamin, plus many of the other folks in this issue who have been working against “algorithms of oppression,” data, and technologies of liberation through a Black feminist lens for some time—you’ve reminded me to answer and amplify this call.</p>\n<p>I’m thinking about the movement and solidarity work that I joined in the wake of the ongoing Covid-19 pandemic and global Black rebellions in the summer of 2020. For the Cops Off Campus Coalition organizing both regionally and locally across Turtle Island, 95 percent of our convening, strategizing, and public campaigning was unthinkable without Zoom, Google Hangouts, or Skype, and apps like Cryptee, Google Docs, Canva, and Lucidchart, inviting one another to amplify our campaigns and build shared demands across different time zones to mobilize people and share resources. This was of course true for the Black Abolition Futures political education group and political organizing spaces in Europe that I was able to re-enter while physically in the US. It’s challenging, trying to think about what we need to imagine liberation tools and technologies beyond our current capacities, particularly when we’re in movement work or, like you, directly confronting these questions of technology on a day to day basis, and considering what otherwise can materially mean and how to bring that to bear in our present. </p>\n<p>When we’re inundated with technologies perceived to be “our only hope” à la <i>Star Wars</i>, where that’s the last chance that we’ve got to get ourselves free; that’s where I think we need to take a second to pause and double down on an acknowledgment: that this is precisely the time where we must mobilize for something else beyond our current capacities. This is when I orient towards the replenishable resource of <i>otherwise possibility</i>, a framing I first came across in the work of Ashon Crawley. Anyone telling you that new technological expansion is our last chance, that there’s no other way, or that this is the easiest path if you want to do the work that you’ve set out to do, I think we all need to reflect and think about our intentions, aspirations, and who among us is really out of time. What options do we have access to or must create?</p>\n<h1><b>Smaller Scales and The Digital Sea</b></h1>\n<p><b>What stands out to me is the idea of </b><b><i>thinkability</i></b><b>. Mariame Kaba says this a lot in reference to abolition. You know, that organizers worked for a very, very long time. And you know, organizers, including incarcerated people and people who were formerly incarcerated, right? Because sometimes there’s a weird binary—the organizer becomes the one who is separate from incarcerated people. But they work to make the idea of abolition </b><b><i>thinkable</i></b><b>, something that people, in a decentralized way, practice in their own lives and in their own scholarship. </b></p>\n<p><b>When we’re thinking about tech, the idea that you need to be a Black Girl who Codes or have mastered JavaScript and HTML in order to enter into the conversation is hegemonic. On top of that, the kind of digital environments you mentioned relying on in your organization work for Cops Off Campus are so default, that it is very hard to even think about what a different wave would look like. </b></p>\n<p>Exactly this. And I’m thinking about scale—digital, corporeal, and geopolitical scale all entwined together. While holding the need for global political revolution and exchange, I wonder if we might make the scales smaller and have the kind of impact on the ground that might lead toward a shift in digital space. So to put it more concretely: What’s really great about certain kinds of mutual aid is that I can send money to someone right now in Senegal or in Tahiti. It’ll get there roughly at the same time. But I wonder what this means in terms of rapid gentrification and displacement and dispossession of Black, brown, and indigenous peoples. I’m wondering about the capacity for a digital that is the people’s right, belonging to the people on a smaller scale, and without western attachments to property. </p>\n<p>What would that look like—if that’s even a useful way to start thinking about it—so that it’s not governed or even governable by a large scale, monolithic, usually evil enterprise? On a smaller scale, say you live in apartment 5B and you need a babysitter, one of your kids has an ear infection. You have to run out and go take care of them real quick. You can’t bring the other kids with you because that will be too hard to manage alone. Is someone available in the building right now to babysit? It would be cool to think from smaller scale mutual interdependence that abolitionists talk a lot about, that doesn’t look like TaskRabbit, that doesn’t feed into the gig economy which provides care as service for compensation independent of human, communal investment and accountability. </p>\n<p>One instance that comes to mind is the Watch the Med Alarm Phone project, a self-organized hotline for refugees in distress in the Mediterranean Sea. For example, if you arrive at the Port of Tripoli in Libya and join a voyage attempting to cross the Mediterranean into Europe but the boat capsizes or something goes wrong, you could call the hotline which would then point rescue operations to your relative location and come to your aid. </p>\n<p>On the one hand, this is a project on a relatively small scale, which is unfortunate in this case because it should be the work of governments whose borders are leading to catastrophe. As Harsha Walia says, the border is the crisis. But you know, government neglect is what it is. There are no real mechanisms then, digital or otherwise, that are consistent and hold the community of those rendered refugees or asylum seekers making that treacherous journey. </p>\n<p>The ephemera of the large-scale digital space has made it such that, at the end of the task, of the act, there is nothing, you fall off of the cliff from support after the GoFundMe gets circulated. The lives are anonymized and lost in these spaces while we do the (to be clear, very necessary) work of redistributing wealth to the oppressed, away from the Global North, etc. So, I’m wondering what would happen if the digital realm (which feels to me really large and nebulous, like a sea in its own right) can come down to a smaller scale such that we can collectively navigate our way through. Or does that seem idealistic in a non-useful way, because someone will need to administer it and technology is not value neutral in terms of how it produces and exacerbates material asymmetry? </p>\n<p><b>I’m just pausing to think, because I’m like, “both and neither.” Both in the sense that yes, I think that we do need to find better relationships to administer mutual aid or social support through digital infrastructures. I’m not a nihilist or saying, “Cash App is corrupt,” therefore die slow. I think that it is what it is and we have to help our people. I’ve also been in situations, in my own life, where I needed people to help me. I’m not going to be so dogmatic to the point that I’m saying, “Now you are complicit with capitalism because you have a wage and you’re going to send it to me on this commercial app.” But, I guess the “neither” part is recognizing how these apps are infrastructure and are controlling us as populations. I mean, it’s not so linear like that. I think about the algorithmic flagging of fraudulent transactions resulting in any money being sent to Palestinians on these platforms being suspended and frozen without recourse.</b></p>\n<p><b>We are in a situation where we must have mutual aid. We must send money back home. We must send money to Texas when the state has failed to take care of people. But in that must, we’re relying on these apps or these infrastructures that were designed not in service of us. Not to produce that livability, right? So how do we think about whether there is something qualitatively new manifesting in these technologies? What is new about predictive policing? Before the prediction, policing was still bad, still needed to be abolished, right? Is it just automating that same practice or is something different happening? I think about Virginia Eubanks’ comparison between the 20th century brick-and-mortar poorhouse and the present day digital poorhouse that is using algorithms. She emphasizes how the former geographically co-located Eastern European immigrants and Black Americans together—which some argue laid the ground for the Poor People’s Movement—as compared to the algorithmic sorting of the digital poorhouse which preempts that kind of cross racial solidarity or physical proximity. I feel like the way political subjectivities are formed in relationship to a state’s (often concealed) control of people’s movement through space is a theme of your work on Blackness and migration. Are there connections that you’re making in thinking about these examples?</b></p>\n<p>That’s really helpful. I love examples since I really appreciate having something to hold on to. Your question about this distinction makes me think of Cedric Robinson’s concept of racial regimes—that which does not want to be revealed, but by the very nature of its revelation, speaks the truth about the mutability of racial representations as historically uncertain. This is why the system of racial capitalism and the flourishing of white supremacy is specifically one of the things that pretends it does not exist, that there is no hand there building on pre-existing cultural forms with new technologies that emerge to retrench those processes. In this way, “new” technology hides the original intent and how those aims differentially structure our realities.</p>\n<p>Last month, when Facebook apps all went down—a possible distraction from the testimony of the company’s whistleblower Frances Haugen before the US Senate—I felt this regime acutely. I was trying to help support planning and get information about my grandfather’s funeral in Jamaica, and I couldn’t reach any of my relatives in the Caribbean and across the diaspora, who all use WhatsApp as the primary mode of communication. For a lot of my family, like millions across the Global South, staying in touch internationally is far too expensive over landlines, and VoIP services like WhatsApp have filled this need. During the temporary crash, I couldn’t figure out how to send money to them. I couldn’t figure out where they were physically so that I could then try to find out which cousin or which uncle or family friend or local pastor had a landline that I could attempt to reach. At that moment, I realized WhatsApp, owned by Facebook, was completely determining my ability to connect with my family, to grieve and support and organize my community in real time, with material consequences.</p>\n<p>That’s just one personal example among millions, not even just in this particular incident, but consistently and recklessly when we think of, for example, Black trans sex workers being suppressed by the algorithms of most mainstream platforms. While OnlyFans began to ramp up this same suppression that Instagram did, taking down photos that have Cash App links on them, pop stars on the same apps, wearing similar amounts of clothing, are being promoted widely on all of our screens.</p>\n<h1><b>Fourteen Ninety-Two</b></h1>\n<p><b>My impression is that black study hasn’t taken up technology as a primary site of analysis. Do you see an opportunity for scholars like yourself to intervene in the discourse of techno-capitalism and liberation? </b></p>\n<p>Black studies folks who are not already invested in thinking through technology as an instrument of capitalism should get on board because, as I mentioned, we’re already thinking about things like racial regimes, hidden infrastructures, and what they do to our material conditions and the ability to survive, thrive, and resist. Bedour Alagraa’s work becomes really key to my thinking on this and so many other things when she talks about catastrophe, the “changing same<i>,” </i>and the retrenchment of shared articulations of our dispossession. </p>\n<p>First of all, we need to acknowledge that, right? Acknowledge that fact—that this is a different era, but it is an extension from the deadly worldmaking event of 1492 into what we’re perceiving as our present day. And so there are all of these different kinds of work that Black studies scholars are doing to think about the revelations of the coercive organization of our daily lives, conceiving of how we can even begin to think about resisting, about liberation, about freedom dreaming. I’m convinced it’s really important and the intersections are increasingly being laid bare during this phase of neoliberal late stage capitalism. </p>\n<p>What I’m trying to hold onto is precisely the ephemeral understanding that “now is not working.” What we’re knowing as “the now”—the conditions of Western oriented or ontologically Western Space-Time—is not working. And actually, we’ve been in the same moment since 1492. So one of the ways it’s not working is that we think it’s 2021 and that has consistent material implications. On the internet people are like, “It’s 2021. We shouldn’t be saying this joke anymore,” or “How is this still happening and it’s 2021?” And I’m like, this is because we never left 1492. We’re playing ourselves by thinking that the clock being offered to us is actually any measure of a real shift in the time that we (and by “we” I mean black people—Africa and its diasporas) have been hailed into—and even indoctrinated within—to be making these kinds of statements. To think <i>otherwise</i> is calling for a real kind of rupture from the status quo keeping us unfree. I’m talking myself into a bit of a circle because of that “both/and” that’s required, and because I would never say, “Well, no computers for anyone and so I can’t Venmo you some money for your urgent care.” Or like, now I don’t support Facebook, and I delete all of my little apps, so I can’t message my auntie in Trelawney or uncles in the mountains in Jamaica, can’t participate in mutual aid for Black trans kin, sex workers, and migrants in communities that I’m no longer physically living near but still accountable to? We need both.</p>\n<p>Breathing into <i>otherwise possibility</i> is to me a fundamental, ontological, ahistorical rupture—in the sense of capital “H” history being a Western epistemological framework. It is a total divestment from the current world order. That means that the way that we can organize ourselves (or we even dream about organizing ourselves) in relation to one another is actionable and realizable; not fixed, but possible and dynamic. </p>\n<p>I don’t think that enough of us are entertaining the possibility, because of a false binary where it’s like, “Well, I need to survive.” And I’m thinking that part of this survival is <i>orienting to this otherwise</i>—it’s not seeing your survival as just the next meal or where’s the next paycheck. That gets really hard to narrate without sounding like you’re just swimming in privilege, completely oblivious to the material conditions of people who <i>need</i> to know where the next check is coming from or how they can get together for that next meal. </p>\n<p>I find myself sort of trapped by my own seductions, by my own desires for us to collectively orient ourselves to a thing without sounding like I’m oblivious and not aware of what people need—to be, to <i>literally exist</i>. But also understanding that the current order and the current perceptions of an allegedly discrete and separate catastrophe or of some kind of linear arc toward something—as opposed to spinning the wheels, “the changing same” and a deep retrenchment or acceleration of accumulation by dispossession and being asymmetrically displaced—is not it.</p>\n<h1><b>Moving Beyond The State</b></h1>\n<p><b>I keep bringing up how algorithms are hegemonic, bringing to scale the movement of people through space and producing new kinds of divisions through classifying and sorting people. Because predictive policing is not just about expanding forms of community surveillance, it’s also a labor management tool. We see in welfare, automated decision systems are producing and managing resource scarcity, and then managing those subjectivities. Sometimes this is enacted in a very broad and decentralized way, and sometimes in an intensely violent way that is neither unclear nor metaphorical. From any given vantage point, we cannot see everything, so we need that multiplicity of perspectives. </b></p>\n<p><b>It’s well documented that predictive policing relies on dirty data sets embedded with the historic overrepresentation of Black and houseless people, thereby redirecting the police to the same geographic sites they’ve always over-policed. What Stop LAPD Spying Coalition and Free Radicals uniquely identified in their Algorithmic Ecology project, was that PredPol was not actually classifying the Skid Row residents as high risk, which is what the traditional argument of dirty data would lead us to believe. Rather than labeling the Skid Row encampments as “hot spots,” PredPol is classifying the </b><b><i>perimeters</i></b><b> of Skid Row as high risk. In practice, this means that the moment residents tried to move past these otherwise invisible borders, they would encounter higher rates of arrest and police contact. If the LAPD announced a brick-and-mortar wall was to be built as a border around Skid Row, people would riot, right? Academic researchers who primarily rely on privacy rights to critique these technologies eschew the collective or communal harms that resonate with people who are targeted. I worry that residents of Skid Row, abolitionist organizers, and others may disengage from resisting these technologies when it’s rendered unclear how the stakes are much greater than data privacy. </b></p>\n<p><b>Even if we can understand Black Marxism from Cedric Robinson and are engaged with Bedour around not just rearticulating the same modes of catastrophe, crisis, and linear march through history, we’re still not in the refugee camp. I’m not reifying standpoint epistemology, but literally we don’t have access to everything, even at this moment where massive amounts of content is constantly being produced, right? I’m thinking about this “not knowing” alongside the United Nations High Commissioner for Refugees (UNHCR) Special Rapporteur Philip Alston’s report on Human Rights Violations in the United States in 2017. Examining the coordinated housing entry system in L.A., he emphasized that experimentation with public sector adoption of automated decision systems happens on the most marginalized sections of society before being generalized to the rest of the population. We can trace policies mandating fingerprinting for welfare recipients during the Clinton era to Simone Browne’s seminal book, </b><b><i>Dark Matters</i></b><b>, explicating the proto-biometrics of the Middle Passage in the ledgers and branding of enslaved Black peoples. </b></p>\n<p><b>So, some of these technologies have </b><b><i>been</i></b><b> the situation—and at the same time as recognizing that historic lineage or sameness, we have to recognize what’s different in these new forms of surveillance and social control as they are being enacted onto broader swaths of the population. </b></p>\n<p><b>In tech, to a degree there is a sociopolitical critical analysis, it often coalesces around bias. When you get to geopolicy, the discourse becomes very reliant on statecraft and state terminology because states </b><b><i>actually</i></b><b> have an analysis of society. They </b><b><i>actually</i></b><b> have a sense of who different actors are and, in a vacuum of political or theoretical frameworks, state actors are ascending. What stands out to me so much in your work is a rejection of state terminology, particularly as I’m thinking about my family in Oromia in the southern region of Ethiopia and observing how advocates are making moral appeals to the UN or to the US State Department. Human Rights Watch branded a recent report on Eritrean refugees in Tigray with a satellite image from Maxar Technologies. This just stood out to me so much—not that I want to hearken back to the old days of the ’83 famine where they just put starving, nameless black people on the cover—but because this bird’s eye view that renders people into polygons, if they’re even seen at all, and even then it only allows for people to be seen en masse, there is no humanity within it. What does belonging mean in that context? Similar to WhatsApp, many people will justify use of satellite imagery citing it as the sole source of gathering visual evidence during a crisis.</b></p>\n<p>Neither of us is here to defend the ivory tower, <i>but</i> this is why we need black study. And I’m using that term the way Robin D.G. Kelley points us to, as distinct from Black studies. So not Black Studies™ as a hegemonic and ethnonationalist interdisciplinary framework that was heavily funded by the government, by the State, namely through the Ford Foundation from the discipline’s institutionalization in the Sixties. But black study as the deeply invested commitment to black people, black life, black possibility, and freedom dreaming, beyond institutions and in fact under siege by them. Collectively attending to black study would have us asking a very different set of questions, and perhaps being prepared to bring about very different answers. </p>\n<p>This premise about evidence and evidencing is something that black study has taught me to challenge and expose the underlying perceptions of. What am I understanding when we talk about this bird’s eye/drone’s eye/God’s eye perspective is a view of people rendered non-people. That framing is borne from a visual technology that James Scott describes in <i>Seeing Like a State</i>. In managing how and who we’re seeing, this particular apparatus instigates us into a certain organized affect, initiates into a socially reproduced hierarchy—this is effectively what citizenship, nationalism, and patriotism do.</p>\n<p>A patriot sees a flag burning and they are moved to defend the nation, as opposed to seeing a piece of cloth that they can walk over in the street, right? And that’s because of what it means to belong to the state. You might feel it as an extension of yourself as opposed to what it is, which is the other way around. And so, I think, that thinking with black study, thinking with Black thought, would actually have us question: What does it mean when we’re seeing non-people? What does it say about us if images of the oppressed masses are disseminated, and when we encounter them we can then go, “Oh, I get it, it’s really bad there.” Technologies of seeing and the epistemologies they are informed by need to be interrogated so that when we engage in movement work and defend our communities, we are not benefitting statecraft or reproducing an asymmetrical and oppressive world order.</p>\n<p>Sometimes I feel increasingly militant about not reproducing certain images as evidence because, I mean, we’ve all seen them, right? Black people drowned at sea, black people’s bodies washed up on shore or left out in the street for hours as in the case of Michael Brown and countless others, dozens of black people on, what I guess what passes for a boat with an infrastructure than cannot safely cross the Mediterranean, whose image gets printed on the cover of <i>The Telegraph</i> with the language of “the swarm” with an action shot of black people fleeing in Haiti or in Sudan. We know what gets made to matter and how. Black study reminds us whose narratives, whose stories have weight and amplifies the work that needs to be done without trafficking in the antiblack violence of dehumanizing erasure.</p>\n<p>In the campaign leading up to Brexit, there were these massive billboards of black people crowded and stacked on a road and referred to as swarms—distinctly animal and non-human language for people fleeing conditions that Britain and other imperial formations have historically wrought. The images featured migrant crossing routes in places like Afghanistan and Libya, but they were being used in the middle of the UK so that people could see it and go, “Oh, that’s what’s happening here, they’re coming across our border, encroaching on our lands.” It was falling into the mind of the white citizen subject being like, “This is happening here,” or “It has already happened here.” Sight as a visual technology, as a mechanism, is already being used and abused in ways that need to be interrogated. </p>\n<p>What I know from black study, and what I’ve experienced in my embodiment as a Black trans person and in solidarity with disability rights activists, is that seeing is not always believing, and to interrogate the privileges of sight. What you take through a visual medium and how you privilege that sense is rarely a tool for our liberation. So what then do we rely on instead? </p>\n<p>And so for me, the kind of belonging that I hail, in relation to our collective liberation, tries to make that pivot. If not, you and I belong to this nation state because we look similar or we sound similar, because we speak the same language, because we have certain kinds of perceived proximities that the state has organized us into. Instead, we can belong to a different set of commitments wherein I don’t need to visually see your suffering to actually acknowledge it. We can actually orient toward one another and the life we want to lead, so that it’s not born through a series of documents, either visual or textual in statistics, the way that the UNHCR also does, the way throughout Europe, or the way that Frontex manages us and the International Office of Migration also enumerates. Quite simply, it’s an orientation in which we collectively understand that statistics also codify our existence and extract our humanity.</p>\n<p>I don’t need to “see” evidence of the Oromo Genocide or see dead people up and down Ethiopia to know that we need to mobilize a collective response to the violence there. I have friends from Ethiopia. I have people who are in a place, telling me something is happening, and I know that they’re committed to their and our collective freedoms. So I don’t need to know that fourty-five Ethiopians were murdered today or ten or twenty or a hundred. I actually don’t need to quantify that severe loss with numbers and not names or lives or memories if I already understand that the ongoing colonial and imperial illogics are producing a reality deeper than a mere number. We don’t need to fall into the same traps of enumeration, quantification, and extraction for us to bear witness. Yet again, there is a “both/and” there, too. I understand why there are the petitions, I understand the enumerations, I understand the visualizing of these things, but I also find it to be a trap of visibility and representation, because then we’re not belonging to each other. We’re not trying to collectively belong to a possible <i>otherwise</i>. We’re actually belonging <i>into</i> the same metrics of statecraft that are causing our harm to begin with.</p>\n<p><b>A hundred percent. I don’t know if you self-identify as a group, but what I have specifically learned from you, Zoé Samudzi, and Bedour Alagraa is thinking critically about visual documentation and the desire of the audience to see or experience this sadistic yet orgiastic enjoyment of black suffering. This desire is both dehumanizing and demands bodies, which is not the same. I also appreciate your demand to distinguish black life and black bodies versus “myself.”</b></p>\n<p><b>We’re rejecting statecraft while sitting in the west and as diaspora. So I’m also thinking about people who are incarcerated or who are living in zones with an intensity of unrelenting violence, what does it mean for them to reject technologies of statecraft? What is </b><b><i>otherwise</i></b><b> for them? Going back to that Philip Alston point, you know, humanitarian technology is a site of pervasive experimentation. On one level, I appreciate that the UN is so transparent; they actually state in their internal documents something along the lines of “Thank God, unlike the EU, we don’t have GDPR, so we can experiment on these populations and try out these new things before they get generalized to everyone else.” How do we resist being brought into the only kind of relation remaining when we only see back home through a documentation of the suffering by NGOs or other humanitarian bodies, which does not allow for a kind of belonging with refugees or those categorized as “internally displaced?” How can we learn from and be in community with them when technologies of the state have become the throughway?</b></p>\n<p>I’m thinking right now of a really dope book, Eric Stanley’s <i>Atmospheres of Violence: Structuring Antagonism and the Trans/Queer Ungovernable</i>. Eric thinks a lot with Black trans feminists, as well as with Angela Davis, about what it means to become ungovernable. </p>\n<p>When I used to do work in relation to the UK border with migrant women in detention centers, with a greater physical number of people, we could get heard and things could get done. We could mobilize to stop planes—like those small European detention flights. We could shut shit down in this very material way responding to immediate political and physical needs.</p>\n<p>Part of my reticence with technology is with the sleekness and the smoothness of a user experience across platforms, which doesn’t map onto the beautiful incoherence of human subjectivity. There’s increased regulation in how we present ourselves online. Through this, we’re becoming increasingly governable. One thing to consider is actual revolution, which Fanon and many others have taught us is not pretty, not consistent. It’s not an isolated march or rally. I mean, it’s machetes, it’s fires. It’s ongoing violent struggle meeting the violence we’ve (asymmetrically) been subjected to, that we should think about turning to <i>yesterday</i>, already. I know that because of the global structures that we’ve been slated into and the ways that we relate and the things that we would already have to be giving up, revolution across the world holds different weight. I’m trying to be careful as I’m saying things, but it is something that I think a lot about: what is required and how do we prepare?</p>\n<p>And I’m thinking about how not to just think about it, but to be about it. How do we actually mobilize in the long game while our life spans are being shortened in real time, while being heavily surveilled and coercively governed, while a lot of our communities are being dispossessed and displaced in real time, and when ecological disasters and climate catastrophe means some of us are already out of time? And, here you go, I try not to talk myself out of the very answers that I think are really what’s to come, are really hard to break open and leap out of—in that Fanonian sense—out of the current world order toward some otherwise one. </p>\n<h1><b>Registering Gender</b></h1>\n<p><b>The discussion around gender that I have been exposed to feels very bureaucratic. Particularly, I’ve been thinking about being “assigned at birth.” Do you identify with the gender that you’re assigned at birth? From my understanding, this has to do with birth certificates. Ethiopia actually has one of the lowest rates of birth registration in the world. Most people don’t even get birth registration until they get their passport if they’re going to leave the country. But it’s something like 1.2-1.3 percent of all children acquire birth registration, even among the middle class. </b></p>\n<p><b>As I went down this Google rabbit hole, I was like, “Yo, this is dope,” because when you’re talking about black methodologies, of misspokenness and the broken pieces, this is the complete opposite of digital surveillance. </b><b><i>Everything</i></b><b> is about enumerating, I mean, talk about counting—that is the fundamental ontological principle, and it’s really disturbed when people do not participate in birth registration for statistical regimes. I don’t want to romanticize these small acts of bureaucratic refusal or present them as active political commitments to abolishing the gender binary. There definitely is homophobia and transphobia in Ethiopia—I don’t even know how much those words completely translate, not just the literal sexual translation, but in the way that people conceive of gender. I don’t want to make it sound like Ethiopia is in any way a paragon of sexual freedom or gender identity inclusiveness, but at the same time, there is a way that everything is not so linear. So as this gender binary is being enacted onto people through institutions, bureaucracies, and technologies, people are refusing it in different kinds of ways. How do we make sense of that, not just in relationship to resistance, but between each other? What does it mean to think about gender when there is not that same assigning?</b></p>\n<p>Gender is nothing if not bureaucratic. Gender is nothing if not a series of accruals and assignations on a global scale. But, and, also, there’s something to really delight in, I think, in terms of a refusal that doesn’t look binary. I’ve had conversations where it’s just like, “Look at all this gender. Gender comes from the West, so let’s say ‘no’ to gender, right?” And so it’s supposed to be a rejection outright. But the queer and trans people that I know and delight in and struggle with, we can relish our gender too, as well as our relationship to it. </p>\n<p>Let’s put it this way: gender is a series of attachments, much like belonging—which is probably why this relates to your question. So technology, perhaps if I can try to make a real quick but rough analogy, not as a process or a series of mechanisms through which you manage labor, bodies, time, and all of these sorts of constructs, but actually as a way of deepening attachments. I’d like to think of “trans” when I think about transnational politics and even transdisciplinary scholarship as a moving across borders drawing from how trans theorist Eva Hayward talks about trans being a series of attachments and modes of relating as opposed to across, because grammatically, trans is supposed to be across and then cis would be on the same side. Instead of crossing a border or staying on the same side of a border, of gender, of geography, and so on, it could instead be a series of attachments to that very <i>otherwise</i> set of possibilities that we’re trying to mobilize.</p>\n<p>To go back to your concrete example with the Ethiopian birth certificates, I think it’s a super cool note to end on, right, because you actually are talking about possibility. No, of course you’re not saying, “Ethiopia is the trans friendliest place on Earth” or whatever. But by nature of these minor refusals that accumulate into a set of possibilities, then we have possibilities there, right? Like 1.2 percent is nothing to sniff at. So now if I wanted to play with my gender or what I understood or perceived to be gender, away from this kind of assignation, and I’m a trans Ethiopian or a person who is—and there are different words to talk about gender variance in different geographical contexts—then I can make some room, make something else possible for myself. And so I can use the very refusal that the masses are enacting to make room for myself. </p>\n<p>And then when I’m carving up that space, because how we identify, and how we are identified is always already relational, then I’m making room for an “us” to thrive in that refusal. Again, I think that is linked to the becoming ungovernable that Stanley talks about, the moving in the wake of interminable catastrophe that Alagraa talks about, the thinking away from sort of genocidal politics of enumeration that Samudzi talks about. These are circulating conversations that black study has made, that precisely can be situated in thinking about technology. Now we’ve moved beyond “just” tech, and also to technologies of refusal and how to make those possibilities endure. </p>\n<hr />\n<p><i>A note to the reader from SA Smythe: In response to decades of Black resistance in the US, many publishers have adopted a “house style” where “Black” is capitalized when referring to Black Americans/USians. This conversation was initially recorded and then edited, but SA Smythe spoke with us about the distinction between Black/black in terms of the larger African diaspora and the continent, and what capitalization gestures toward for/as Western grammar. When referring to Black USians explicitly, they usually capitalize the word in response to those important struggles and conventions of naming. Transnationally, the debates/struggles around that aren’t consistent, and thus Smythe considers it useful to be mindful about making those conventions hegemonic from the US, and what that means for collective, global black liberation. For this reason, global black struggles outside of the US, black study (independent from the interdiscipline of Black Studies), etc., are not capitalized in this interview. As La Marr Jurelle Bruce once tweeted: “As long as you’re writing and uttering the word ‘B/black’ with love and toward liberation, we’re good.” That’s the spirit through which this conversation was held.</i></p>",
      "content_text": "There’s been an increasing recognition of how racial regimes are mediated by digital technologies, particularly through things like computational policing practices that target communities of color and automated hiring platforms that exacerbate employment discrimination. But so far, the discourse about “algorithmic bias” largely treats race as an aftermath of technology, as a downstream effect. Further, it treats race as a problem—race is the way you add up the bad things that technology does to people. Race is a way to measure harm. \nBoth premises need to be challenged. Racial regimes aren’t downstream of technology—they’re present from the very start. They centrally shape the design, development, and deployment of the computational systems that govern our lives. And the obsession with calculating race as a function of harmful impact institutionalizes Black people as objects of suffering without agency or political subjectivity that extends beyond advocating for social remedy. \nTo overcome the limitations of the algorithmic bias discourse, we need to ask a completely different set of questions about technology, drawing on the traditions of black thought and black freedom-dreaming. To help formulate these questions, and begin to sketch some possible answers, issue editor J. Khadijah Abdurahman talked with SA Smythe, an assistant professor in the Gender Studies and African American Studies departments at UCLA. Smythe is a poet, translator, and scholar of black European literary and cultural studies and Black trans poetics, and is deeply invested in the coalitional project of black life, black study, and relishing nonbinary experiences across the diaspora. Abdurahman talked to Smythe about abolition organizing on Turtle Island, statecraft as reproduced in humanitarian technologies, and orienting toward “otherwise possibility.”\n\nThe joke I always make is that techno-capitalism puts people who have never taken the humanities in charge of humanity. In that vein, the driving motivation behind Beacons is thinking about how we “call in” Black studies and abolitionist organizers into this technology discourse. Even as I say that, I want to be careful to not reify technology as the property of white, cisgender male tech bros straight outta Silicon Valley because we are all already using, interacting, and modifying techniques and technologies all the time, right? \nThis time that we are asymmetrically experiencing has been intense and overwhelming due to the convergence of so-called “crises,” which are of course interrelated. So, I’m really grateful to be taking up those questions in this format. I’ve felt insecure about how to jump in and have a conversation about “tech” even though it’s so pervasive and is foundational to much of our relationship to modern life/modernity. How do we think about technologies as various techniques, tools, or modalities for collective liberation or for black freedoms? How do we get humanists and humanities adjacent folks—especially people who engage in various black radical traditions and Black feminist practices—to think more urgently about Technology in the capital T sense? I’m not quite sure, but the invitation is key. Of course, as we’ve talked about this ongoing invitation, with scholars like Simone Browne, Katherine McKittrick, Safiya Noble, and Ruha Benjamin, plus many of the other folks in this issue who have been working against “algorithms of oppression,” data, and technologies of liberation through a Black feminist lens for some time—you’ve reminded me to answer and amplify this call.\nI’m thinking about the movement and solidarity work that I joined in the wake of the ongoing Covid-19 pandemic and global Black rebellions in the summer of 2020. For the Cops Off Campus Coalition organizing both regionally and locally across Turtle Island, 95 percent of our convening, strategizing, and public campaigning was unthinkable without Zoom, Google Hangouts, or Skype, and apps like Cryptee, Google Docs, Canva, and Lucidchart, inviting one another to amplify our campaigns and build shared demands across different time zones to mobilize people and share resources. This was of course true for the Black Abolition Futures political education group and political organizing spaces in Europe that I was able to re-enter while physically in the US. It’s challenging, trying to think about what we need to imagine liberation tools and technologies beyond our current capacities, particularly when we’re in movement work or, like you, directly confronting these questions of technology on a day to day basis, and considering what otherwise can materially mean and how to bring that to bear in our present. \nWhen we’re inundated with technologies perceived to be “our only hope” à la Star Wars, where that’s the last chance that we’ve got to get ourselves free; that’s where I think we need to take a second to pause and double down on an acknowledgment: that this is precisely the time where we must mobilize for something else beyond our current capacities. This is when I orient towards the replenishable resource of otherwise possibility, a framing I first came across in the work of Ashon Crawley. Anyone telling you that new technological expansion is our last chance, that there’s no other way, or that this is the easiest path if you want to do the work that you’ve set out to do, I think we all need to reflect and think about our intentions, aspirations, and who among us is really out of time. What options do we have access to or must create?\nSmaller Scales and The Digital Sea\nWhat stands out to me is the idea of thinkability. Mariame Kaba says this a lot in reference to abolition. You know, that organizers worked for a very, very long time. And you know, organizers, including incarcerated people and people who were formerly incarcerated, right? Because sometimes there’s a weird binary—the organizer becomes the one who is separate from incarcerated people. But they work to make the idea of abolition thinkable, something that people, in a decentralized way, practice in their own lives and in their own scholarship. \nWhen we’re thinking about tech, the idea that you need to be a Black Girl who Codes or have mastered JavaScript and HTML in order to enter into the conversation is hegemonic. On top of that, the kind of digital environments you mentioned relying on in your organization work for Cops Off Campus are so default, that it is very hard to even think about what a different wave would look like. \nExactly this. And I’m thinking about scale—digital, corporeal, and geopolitical scale all entwined together. While holding the need for global political revolution and exchange, I wonder if we might make the scales smaller and have the kind of impact on the ground that might lead toward a shift in digital space. So to put it more concretely: What’s really great about certain kinds of mutual aid is that I can send money to someone right now in Senegal or in Tahiti. It’ll get there roughly at the same time. But I wonder what this means in terms of rapid gentrification and displacement and dispossession of Black, brown, and indigenous peoples. I’m wondering about the capacity for a digital that is the people’s right, belonging to the people on a smaller scale, and without western attachments to property. \nWhat would that look like—if that’s even a useful way to start thinking about it—so that it’s not governed or even governable by a large scale, monolithic, usually evil enterprise? On a smaller scale, say you live in apartment 5B and you need a babysitter, one of your kids has an ear infection. You have to run out and go take care of them real quick. You can’t bring the other kids with you because that will be too hard to manage alone. Is someone available in the building right now to babysit? It would be cool to think from smaller scale mutual interdependence that abolitionists talk a lot about, that doesn’t look like TaskRabbit, that doesn’t feed into the gig economy which provides care as service for compensation independent of human, communal investment and accountability. \nOne instance that comes to mind is the Watch the Med Alarm Phone project, a self-organized hotline for refugees in distress in the Mediterranean Sea. For example, if you arrive at the Port of Tripoli in Libya and join a voyage attempting to cross the Mediterranean into Europe but the boat capsizes or something goes wrong, you could call the hotline which would then point rescue operations to your relative location and come to your aid. \nOn the one hand, this is a project on a relatively small scale, which is unfortunate in this case because it should be the work of governments whose borders are leading to catastrophe. As Harsha Walia says, the border is the crisis. But you know, government neglect is what it is. There are no real mechanisms then, digital or otherwise, that are consistent and hold the community of those rendered refugees or asylum seekers making that treacherous journey. \nThe ephemera of the large-scale digital space has made it such that, at the end of the task, of the act, there is nothing, you fall off of the cliff from support after the GoFundMe gets circulated. The lives are anonymized and lost in these spaces while we do the (to be clear, very necessary) work of redistributing wealth to the oppressed, away from the Global North, etc. So, I’m wondering what would happen if the digital realm (which feels to me really large and nebulous, like a sea in its own right) can come down to a smaller scale such that we can collectively navigate our way through. Or does that seem idealistic in a non-useful way, because someone will need to administer it and technology is not value neutral in terms of how it produces and exacerbates material asymmetry? \nI’m just pausing to think, because I’m like, “both and neither.” Both in the sense that yes, I think that we do need to find better relationships to administer mutual aid or social support through digital infrastructures. I’m not a nihilist or saying, “Cash App is corrupt,” therefore die slow. I think that it is what it is and we have to help our people. I’ve also been in situations, in my own life, where I needed people to help me. I’m not going to be so dogmatic to the point that I’m saying, “Now you are complicit with capitalism because you have a wage and you’re going to send it to me on this commercial app.” But, I guess the “neither” part is recognizing how these apps are infrastructure and are controlling us as populations. I mean, it’s not so linear like that. I think about the algorithmic flagging of fraudulent transactions resulting in any money being sent to Palestinians on these platforms being suspended and frozen without recourse.\nWe are in a situation where we must have mutual aid. We must send money back home. We must send money to Texas when the state has failed to take care of people. But in that must, we’re relying on these apps or these infrastructures that were designed not in service of us. Not to produce that livability, right? So how do we think about whether there is something qualitatively new manifesting in these technologies? What is new about predictive policing? Before the prediction, policing was still bad, still needed to be abolished, right? Is it just automating that same practice or is something different happening? I think about Virginia Eubanks’ comparison between the 20th century brick-and-mortar poorhouse and the present day digital poorhouse that is using algorithms. She emphasizes how the former geographically co-located Eastern European immigrants and Black Americans together—which some argue laid the ground for the Poor People’s Movement—as compared to the algorithmic sorting of the digital poorhouse which preempts that kind of cross racial solidarity or physical proximity. I feel like the way political subjectivities are formed in relationship to a state’s (often concealed) control of people’s movement through space is a theme of your work on Blackness and migration. Are there connections that you’re making in thinking about these examples?\nThat’s really helpful. I love examples since I really appreciate having something to hold on to. Your question about this distinction makes me think of Cedric Robinson’s concept of racial regimes—that which does not want to be revealed, but by the very nature of its revelation, speaks the truth about the mutability of racial representations as historically uncertain. This is why the system of racial capitalism and the flourishing of white supremacy is specifically one of the things that pretends it does not exist, that there is no hand there building on pre-existing cultural forms with new technologies that emerge to retrench those processes. In this way, “new” technology hides the original intent and how those aims differentially structure our realities.\nLast month, when Facebook apps all went down—a possible distraction from the testimony of the company’s whistleblower Frances Haugen before the US Senate—I felt this regime acutely. I was trying to help support planning and get information about my grandfather’s funeral in Jamaica, and I couldn’t reach any of my relatives in the Caribbean and across the diaspora, who all use WhatsApp as the primary mode of communication. For a lot of my family, like millions across the Global South, staying in touch internationally is far too expensive over landlines, and VoIP services like WhatsApp have filled this need. During the temporary crash, I couldn’t figure out how to send money to them. I couldn’t figure out where they were physically so that I could then try to find out which cousin or which uncle or family friend or local pastor had a landline that I could attempt to reach. At that moment, I realized WhatsApp, owned by Facebook, was completely determining my ability to connect with my family, to grieve and support and organize my community in real time, with material consequences.\nThat’s just one personal example among millions, not even just in this particular incident, but consistently and recklessly when we think of, for example, Black trans sex workers being suppressed by the algorithms of most mainstream platforms. While OnlyFans began to ramp up this same suppression that Instagram did, taking down photos that have Cash App links on them, pop stars on the same apps, wearing similar amounts of clothing, are being promoted widely on all of our screens.\nFourteen Ninety-Two\nMy impression is that black study hasn’t taken up technology as a primary site of analysis. Do you see an opportunity for scholars like yourself to intervene in the discourse of techno-capitalism and liberation? \nBlack studies folks who are not already invested in thinking through technology as an instrument of capitalism should get on board because, as I mentioned, we’re already thinking about things like racial regimes, hidden infrastructures, and what they do to our material conditions and the ability to survive, thrive, and resist. Bedour Alagraa’s work becomes really key to my thinking on this and so many other things when she talks about catastrophe, the “changing same,” and the retrenchment of shared articulations of our dispossession. \nFirst of all, we need to acknowledge that, right? Acknowledge that fact—that this is a different era, but it is an extension from the deadly worldmaking event of 1492 into what we’re perceiving as our present day. And so there are all of these different kinds of work that Black studies scholars are doing to think about the revelations of the coercive organization of our daily lives, conceiving of how we can even begin to think about resisting, about liberation, about freedom dreaming. I’m convinced it’s really important and the intersections are increasingly being laid bare during this phase of neoliberal late stage capitalism. \nWhat I’m trying to hold onto is precisely the ephemeral understanding that “now is not working.” What we’re knowing as “the now”—the conditions of Western oriented or ontologically Western Space-Time—is not working. And actually, we’ve been in the same moment since 1492. So one of the ways it’s not working is that we think it’s 2021 and that has consistent material implications. On the internet people are like, “It’s 2021. We shouldn’t be saying this joke anymore,” or “How is this still happening and it’s 2021?” And I’m like, this is because we never left 1492. We’re playing ourselves by thinking that the clock being offered to us is actually any measure of a real shift in the time that we (and by “we” I mean black people—Africa and its diasporas) have been hailed into—and even indoctrinated within—to be making these kinds of statements. To think otherwise is calling for a real kind of rupture from the status quo keeping us unfree. I’m talking myself into a bit of a circle because of that “both/and” that’s required, and because I would never say, “Well, no computers for anyone and so I can’t Venmo you some money for your urgent care.” Or like, now I don’t support Facebook, and I delete all of my little apps, so I can’t message my auntie in Trelawney or uncles in the mountains in Jamaica, can’t participate in mutual aid for Black trans kin, sex workers, and migrants in communities that I’m no longer physically living near but still accountable to? We need both.\nBreathing into otherwise possibility is to me a fundamental, ontological, ahistorical rupture—in the sense of capital “H” history being a Western epistemological framework. It is a total divestment from the current world order. That means that the way that we can organize ourselves (or we even dream about organizing ourselves) in relation to one another is actionable and realizable; not fixed, but possible and dynamic. \nI don’t think that enough of us are entertaining the possibility, because of a false binary where it’s like, “Well, I need to survive.” And I’m thinking that part of this survival is orienting to this otherwise—it’s not seeing your survival as just the next meal or where’s the next paycheck. That gets really hard to narrate without sounding like you’re just swimming in privilege, completely oblivious to the material conditions of people who need to know where the next check is coming from or how they can get together for that next meal. \nI find myself sort of trapped by my own seductions, by my own desires for us to collectively orient ourselves to a thing without sounding like I’m oblivious and not aware of what people need—to be, to literally exist. But also understanding that the current order and the current perceptions of an allegedly discrete and separate catastrophe or of some kind of linear arc toward something—as opposed to spinning the wheels, “the changing same” and a deep retrenchment or acceleration of accumulation by dispossession and being asymmetrically displaced—is not it.\nMoving Beyond The State\nI keep bringing up how algorithms are hegemonic, bringing to scale the movement of people through space and producing new kinds of divisions through classifying and sorting people. Because predictive policing is not just about expanding forms of community surveillance, it’s also a labor management tool. We see in welfare, automated decision systems are producing and managing resource scarcity, and then managing those subjectivities. Sometimes this is enacted in a very broad and decentralized way, and sometimes in an intensely violent way that is neither unclear nor metaphorical. From any given vantage point, we cannot see everything, so we need that multiplicity of perspectives. \nIt’s well documented that predictive policing relies on dirty data sets embedded with the historic overrepresentation of Black and houseless people, thereby redirecting the police to the same geographic sites they’ve always over-policed. What Stop LAPD Spying Coalition and Free Radicals uniquely identified in their Algorithmic Ecology project, was that PredPol was not actually classifying the Skid Row residents as high risk, which is what the traditional argument of dirty data would lead us to believe. Rather than labeling the Skid Row encampments as “hot spots,” PredPol is classifying the perimeters of Skid Row as high risk. In practice, this means that the moment residents tried to move past these otherwise invisible borders, they would encounter higher rates of arrest and police contact. If the LAPD announced a brick-and-mortar wall was to be built as a border around Skid Row, people would riot, right? Academic researchers who primarily rely on privacy rights to critique these technologies eschew the collective or communal harms that resonate with people who are targeted. I worry that residents of Skid Row, abolitionist organizers, and others may disengage from resisting these technologies when it’s rendered unclear how the stakes are much greater than data privacy. \nEven if we can understand Black Marxism from Cedric Robinson and are engaged with Bedour around not just rearticulating the same modes of catastrophe, crisis, and linear march through history, we’re still not in the refugee camp. I’m not reifying standpoint epistemology, but literally we don’t have access to everything, even at this moment where massive amounts of content is constantly being produced, right? I’m thinking about this “not knowing” alongside the United Nations High Commissioner for Refugees (UNHCR) Special Rapporteur Philip Alston’s report on Human Rights Violations in the United States in 2017. Examining the coordinated housing entry system in L.A., he emphasized that experimentation with public sector adoption of automated decision systems happens on the most marginalized sections of society before being generalized to the rest of the population. We can trace policies mandating fingerprinting for welfare recipients during the Clinton era to Simone Browne’s seminal book, Dark Matters, explicating the proto-biometrics of the Middle Passage in the ledgers and branding of enslaved Black peoples. \nSo, some of these technologies have been the situation—and at the same time as recognizing that historic lineage or sameness, we have to recognize what’s different in these new forms of surveillance and social control as they are being enacted onto broader swaths of the population. \nIn tech, to a degree there is a sociopolitical critical analysis, it often coalesces around bias. When you get to geopolicy, the discourse becomes very reliant on statecraft and state terminology because states actually have an analysis of society. They actually have a sense of who different actors are and, in a vacuum of political or theoretical frameworks, state actors are ascending. What stands out to me so much in your work is a rejection of state terminology, particularly as I’m thinking about my family in Oromia in the southern region of Ethiopia and observing how advocates are making moral appeals to the UN or to the US State Department. Human Rights Watch branded a recent report on Eritrean refugees in Tigray with a satellite image from Maxar Technologies. This just stood out to me so much—not that I want to hearken back to the old days of the ’83 famine where they just put starving, nameless black people on the cover—but because this bird’s eye view that renders people into polygons, if they’re even seen at all, and even then it only allows for people to be seen en masse, there is no humanity within it. What does belonging mean in that context? Similar to WhatsApp, many people will justify use of satellite imagery citing it as the sole source of gathering visual evidence during a crisis.\nNeither of us is here to defend the ivory tower, but this is why we need black study. And I’m using that term the way Robin D.G. Kelley points us to, as distinct from Black studies. So not Black Studies™ as a hegemonic and ethnonationalist interdisciplinary framework that was heavily funded by the government, by the State, namely through the Ford Foundation from the discipline’s institutionalization in the Sixties. But black study as the deeply invested commitment to black people, black life, black possibility, and freedom dreaming, beyond institutions and in fact under siege by them. Collectively attending to black study would have us asking a very different set of questions, and perhaps being prepared to bring about very different answers. \nThis premise about evidence and evidencing is something that black study has taught me to challenge and expose the underlying perceptions of. What am I understanding when we talk about this bird’s eye/drone’s eye/God’s eye perspective is a view of people rendered non-people. That framing is borne from a visual technology that James Scott describes in Seeing Like a State. In managing how and who we’re seeing, this particular apparatus instigates us into a certain organized affect, initiates into a socially reproduced hierarchy—this is effectively what citizenship, nationalism, and patriotism do.\nA patriot sees a flag burning and they are moved to defend the nation, as opposed to seeing a piece of cloth that they can walk over in the street, right? And that’s because of what it means to belong to the state. You might feel it as an extension of yourself as opposed to what it is, which is the other way around. And so, I think, that thinking with black study, thinking with Black thought, would actually have us question: What does it mean when we’re seeing non-people? What does it say about us if images of the oppressed masses are disseminated, and when we encounter them we can then go, “Oh, I get it, it’s really bad there.” Technologies of seeing and the epistemologies they are informed by need to be interrogated so that when we engage in movement work and defend our communities, we are not benefitting statecraft or reproducing an asymmetrical and oppressive world order.\nSometimes I feel increasingly militant about not reproducing certain images as evidence because, I mean, we’ve all seen them, right? Black people drowned at sea, black people’s bodies washed up on shore or left out in the street for hours as in the case of Michael Brown and countless others, dozens of black people on, what I guess what passes for a boat with an infrastructure than cannot safely cross the Mediterranean, whose image gets printed on the cover of The Telegraph with the language of “the swarm” with an action shot of black people fleeing in Haiti or in Sudan. We know what gets made to matter and how. Black study reminds us whose narratives, whose stories have weight and amplifies the work that needs to be done without trafficking in the antiblack violence of dehumanizing erasure.\nIn the campaign leading up to Brexit, there were these massive billboards of black people crowded and stacked on a road and referred to as swarms—distinctly animal and non-human language for people fleeing conditions that Britain and other imperial formations have historically wrought. The images featured migrant crossing routes in places like Afghanistan and Libya, but they were being used in the middle of the UK so that people could see it and go, “Oh, that’s what’s happening here, they’re coming across our border, encroaching on our lands.” It was falling into the mind of the white citizen subject being like, “This is happening here,” or “It has already happened here.” Sight as a visual technology, as a mechanism, is already being used and abused in ways that need to be interrogated. \nWhat I know from black study, and what I’ve experienced in my embodiment as a Black trans person and in solidarity with disability rights activists, is that seeing is not always believing, and to interrogate the privileges of sight. What you take through a visual medium and how you privilege that sense is rarely a tool for our liberation. So what then do we rely on instead? \nAnd so for me, the kind of belonging that I hail, in relation to our collective liberation, tries to make that pivot. If not, you and I belong to this nation state because we look similar or we sound similar, because we speak the same language, because we have certain kinds of perceived proximities that the state has organized us into. Instead, we can belong to a different set of commitments wherein I don’t need to visually see your suffering to actually acknowledge it. We can actually orient toward one another and the life we want to lead, so that it’s not born through a series of documents, either visual or textual in statistics, the way that the UNHCR also does, the way throughout Europe, or the way that Frontex manages us and the International Office of Migration also enumerates. Quite simply, it’s an orientation in which we collectively understand that statistics also codify our existence and extract our humanity.\nI don’t need to “see” evidence of the Oromo Genocide or see dead people up and down Ethiopia to know that we need to mobilize a collective response to the violence there. I have friends from Ethiopia. I have people who are in a place, telling me something is happening, and I know that they’re committed to their and our collective freedoms. So I don’t need to know that fourty-five Ethiopians were murdered today or ten or twenty or a hundred. I actually don’t need to quantify that severe loss with numbers and not names or lives or memories if I already understand that the ongoing colonial and imperial illogics are producing a reality deeper than a mere number. We don’t need to fall into the same traps of enumeration, quantification, and extraction for us to bear witness. Yet again, there is a “both/and” there, too. I understand why there are the petitions, I understand the enumerations, I understand the visualizing of these things, but I also find it to be a trap of visibility and representation, because then we’re not belonging to each other. We’re not trying to collectively belong to a possible otherwise. We’re actually belonging into the same metrics of statecraft that are causing our harm to begin with.\nA hundred percent. I don’t know if you self-identify as a group, but what I have specifically learned from you, Zoé Samudzi, and Bedour Alagraa is thinking critically about visual documentation and the desire of the audience to see or experience this sadistic yet orgiastic enjoyment of black suffering. This desire is both dehumanizing and demands bodies, which is not the same. I also appreciate your demand to distinguish black life and black bodies versus “myself.”\nWe’re rejecting statecraft while sitting in the west and as diaspora. So I’m also thinking about people who are incarcerated or who are living in zones with an intensity of unrelenting violence, what does it mean for them to reject technologies of statecraft? What is otherwise for them? Going back to that Philip Alston point, you know, humanitarian technology is a site of pervasive experimentation. On one level, I appreciate that the UN is so transparent; they actually state in their internal documents something along the lines of “Thank God, unlike the EU, we don’t have GDPR, so we can experiment on these populations and try out these new things before they get generalized to everyone else.” How do we resist being brought into the only kind of relation remaining when we only see back home through a documentation of the suffering by NGOs or other humanitarian bodies, which does not allow for a kind of belonging with refugees or those categorized as “internally displaced?” How can we learn from and be in community with them when technologies of the state have become the throughway?\nI’m thinking right now of a really dope book, Eric Stanley’s Atmospheres of Violence: Structuring Antagonism and the Trans/Queer Ungovernable. Eric thinks a lot with Black trans feminists, as well as with Angela Davis, about what it means to become ungovernable. \nWhen I used to do work in relation to the UK border with migrant women in detention centers, with a greater physical number of people, we could get heard and things could get done. We could mobilize to stop planes—like those small European detention flights. We could shut shit down in this very material way responding to immediate political and physical needs.\nPart of my reticence with technology is with the sleekness and the smoothness of a user experience across platforms, which doesn’t map onto the beautiful incoherence of human subjectivity. There’s increased regulation in how we present ourselves online. Through this, we’re becoming increasingly governable. One thing to consider is actual revolution, which Fanon and many others have taught us is not pretty, not consistent. It’s not an isolated march or rally. I mean, it’s machetes, it’s fires. It’s ongoing violent struggle meeting the violence we’ve (asymmetrically) been subjected to, that we should think about turning to yesterday, already. I know that because of the global structures that we’ve been slated into and the ways that we relate and the things that we would already have to be giving up, revolution across the world holds different weight. I’m trying to be careful as I’m saying things, but it is something that I think a lot about: what is required and how do we prepare?\nAnd I’m thinking about how not to just think about it, but to be about it. How do we actually mobilize in the long game while our life spans are being shortened in real time, while being heavily surveilled and coercively governed, while a lot of our communities are being dispossessed and displaced in real time, and when ecological disasters and climate catastrophe means some of us are already out of time? And, here you go, I try not to talk myself out of the very answers that I think are really what’s to come, are really hard to break open and leap out of—in that Fanonian sense—out of the current world order toward some otherwise one. \nRegistering Gender\nThe discussion around gender that I have been exposed to feels very bureaucratic. Particularly, I’ve been thinking about being “assigned at birth.” Do you identify with the gender that you’re assigned at birth? From my understanding, this has to do with birth certificates. Ethiopia actually has one of the lowest rates of birth registration in the world. Most people don’t even get birth registration until they get their passport if they’re going to leave the country. But it’s something like 1.2-1.3 percent of all children acquire birth registration, even among the middle class. \nAs I went down this Google rabbit hole, I was like, “Yo, this is dope,” because when you’re talking about black methodologies, of misspokenness and the broken pieces, this is the complete opposite of digital surveillance. Everything is about enumerating, I mean, talk about counting—that is the fundamental ontological principle, and it’s really disturbed when people do not participate in birth registration for statistical regimes. I don’t want to romanticize these small acts of bureaucratic refusal or present them as active political commitments to abolishing the gender binary. There definitely is homophobia and transphobia in Ethiopia—I don’t even know how much those words completely translate, not just the literal sexual translation, but in the way that people conceive of gender. I don’t want to make it sound like Ethiopia is in any way a paragon of sexual freedom or gender identity inclusiveness, but at the same time, there is a way that everything is not so linear. So as this gender binary is being enacted onto people through institutions, bureaucracies, and technologies, people are refusing it in different kinds of ways. How do we make sense of that, not just in relationship to resistance, but between each other? What does it mean to think about gender when there is not that same assigning?\nGender is nothing if not bureaucratic. Gender is nothing if not a series of accruals and assignations on a global scale. But, and, also, there’s something to really delight in, I think, in terms of a refusal that doesn’t look binary. I’ve had conversations where it’s just like, “Look at all this gender. Gender comes from the West, so let’s say ‘no’ to gender, right?” And so it’s supposed to be a rejection outright. But the queer and trans people that I know and delight in and struggle with, we can relish our gender too, as well as our relationship to it. \nLet’s put it this way: gender is a series of attachments, much like belonging—which is probably why this relates to your question. So technology, perhaps if I can try to make a real quick but rough analogy, not as a process or a series of mechanisms through which you manage labor, bodies, time, and all of these sorts of constructs, but actually as a way of deepening attachments. I’d like to think of “trans” when I think about transnational politics and even transdisciplinary scholarship as a moving across borders drawing from how trans theorist Eva Hayward talks about trans being a series of attachments and modes of relating as opposed to across, because grammatically, trans is supposed to be across and then cis would be on the same side. Instead of crossing a border or staying on the same side of a border, of gender, of geography, and so on, it could instead be a series of attachments to that very otherwise set of possibilities that we’re trying to mobilize.\nTo go back to your concrete example with the Ethiopian birth certificates, I think it’s a super cool note to end on, right, because you actually are talking about possibility. No, of course you’re not saying, “Ethiopia is the trans friendliest place on Earth” or whatever. But by nature of these minor refusals that accumulate into a set of possibilities, then we have possibilities there, right? Like 1.2 percent is nothing to sniff at. So now if I wanted to play with my gender or what I understood or perceived to be gender, away from this kind of assignation, and I’m a trans Ethiopian or a person who is—and there are different words to talk about gender variance in different geographical contexts—then I can make some room, make something else possible for myself. And so I can use the very refusal that the masses are enacting to make room for myself. \nAnd then when I’m carving up that space, because how we identify, and how we are identified is always already relational, then I’m making room for an “us” to thrive in that refusal. Again, I think that is linked to the becoming ungovernable that Stanley talks about, the moving in the wake of interminable catastrophe that Alagraa talks about, the thinking away from sort of genocidal politics of enumeration that Samudzi talks about. These are circulating conversations that black study has made, that precisely can be situated in thinking about technology. Now we’ve moved beyond “just” tech, and also to technologies of refusal and how to make those possibilities endure. \n\nA note to the reader from SA Smythe: In response to decades of Black resistance in the US, many publishers have adopted a “house style” where “Black” is capitalized when referring to Black Americans/USians. This conversation was initially recorded and then edited, but SA Smythe spoke with us about the distinction between Black/black in terms of the larger African diaspora and the continent, and what capitalization gestures toward for/as Western grammar. When referring to Black USians explicitly, they usually capitalize the word in response to those important struggles and conventions of naming. Transnationally, the debates/struggles around that aren’t consistent, and thus Smythe considers it useful to be mindful about making those conventions hegemonic from the US, and what that means for collective, global black liberation. For this reason, global black struggles outside of the US, black study (independent from the interdiscipline of Black Studies), etc., are not capitalized in this interview. As La Marr Jurelle Bruce once tweeted: “As long as you’re writing and uttering the word ‘B/black’ with love and toward liberation, we’re good.” That’s the spirit through which this conversation was held.",
      "date_published": "2022-01-11T15:08:14.000Z",
      "date_modified": "2022-01-11T15:08:14.000Z",
      "_plugin": {
        "pageFilename": "041e6f6165d619e3f2af7c567af5ca6a153f9862893b90da04dc3307414d3b71.html"
      }
    },
    {
      "id": "https://logicmag.io/beacons/a-body-of-work-that-cannot-be-ignored",
      "url": "https://logicmag.io/beacons/a-body-of-work-that-cannot-be-ignored",
      "title": "A Body of Work That Cannot Be Ignored",
      "summary": "What does it mean to “Get Out!” in the twenty-first century? How do we build fugitive technologies?",
      "content_html": "<p><b>1/</b></p>\n<p>In June 1945, a committee chaired by the physicist James Franck raised the alarm about the Manhattan Project’s development of nuclear weapons. The document they produced, known as the Franck Report, urged President Truman not to use the atomic bomb against Japan. Instead, Truman should demonstrate the bomb’s destructive power by dropping it on a desert or a barren island—or he should try to keep the bomb’s existence secret for as long as possible. Otherwise, the scientists warned, a global nuclear arms race would ensue, with catastrophic consequences for the planet.</p>\n<p>The authors of the Franck Report had worked on the Manhattan Project. But rather than siphon the scientific knowledge they had accrued in developing nuclear weapons out of the lab and into the commons in order to build a mass movement, they waited until the final hour to pen a letter, addressed to a government that would never heed their call. The scientists understood the stakes of nuclear weapons better than anyone. But in making a moral appeal to the American empire, they demonstrated a profound misunderstanding of the social and political context the technology was developed in service of. Two months after they wrote the report, atomic bombs were dropped on Hiroshima and Nagasaki.</p>\n<p>I was reminded of those physicists in December 2020, in the wake of Google’s high-profile termination of AI ethics scholar Timnit Gebru. Her firing was the final step in management’s systematic silencing of her scholarship, which came to a head over a paper she coauthored called “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” The paper offers a damning critique of the energy demands and ecological costs of the sorts of large language models that are core to Google’s business, as well as how those models reproduce white supremacy—and codify dominant languages as default while expediting the erasure of marginalized languages. Thousands of Google workers, as well as supporters throughout academia, industry, and civil society, rapidly mobilized in defense of Gebru, writing an open letter to Google executives that demanded both her reinstatement and an apology for the egregious treatment she received. </p>\n<p>Like the Franck Report before it, however, this open letter represented a grave misunderstanding of the politics of AI and was in no way commensurate with the threat we face. The technologies being developed at companies like Google present major stakes for all of humanity, just as the invention of nuclear weapons did in the previous century. They are strengthening concentrations of power, deepening existing hierarchies, and accelerating the ecological crisis. More specifically, big tech corporations are extracting labor, ideas, and branding from Black people, and then disposing of them with impunity—whether it’s scholars like Gebru or Amazon workers in Bessemer, Alabama organizing against plantation conditions. </p>\n<p>Racial capitalism’s roadmap for innovation is predicated on profound extraction. AI is central to this process. The next flashpoint over AI is inevitable—but our failure to respond adequately is not. Will we continue to write letters appealing to the conscience of corporations or the state? Or will we build a mass movement? As Audre Lorde said, we cannot dismantle the master’s house with the master’s tools. We cannot stop Google from being evil by uncritically relying on the G Suite tools it developed. We cannot uncritically champion the most popular among us, as if social capital will resolve the colonial entanglements reproduced in much of what passes for research in the field of technology studies. An atlas ain’t no Green Book, and we cannot afford to pretend otherwise. What we can do is to build a better analysis of the context of racial capitalism in which extractive technologies are developed. We can share knowledge about the ways in which such technologies can be refused or have their harms mitigated. We can forge solidarities among workers, tenants, and technologists to help them organize for different futures. We can light alternate beacons. </p>\n<p><b>2/</b></p>\n<p>Dismantling racial capitalism and displacing the carceral systems on which it relies requires an understanding of how technology produces “new modes of state surveillance and control,” Dorothy Roberts argues. Part of the challenge is that these new geographies of policing, regulation, and management are largely invisible. We experience the immediacy of our Amazon package being delivered without seeing the exploitative labor conditions decreasing the distance between order and arrival. This is not a function of insufficient effort—it’s an indication of how successful big tech corporations have been in concealing the sources of their power. In his essay in this issue, Julian Posada provides a detailed account of Venezeulans performing the tedious, low-paid labor of data labeling on which AI depends—labor that is hidden beneath Silicon Valley’s minimalist user interfaces and promises of automation. The circuits of racialized capital link us ever more closely together even as the pandemic has deepened our sense of alienation. </p>\n<p>Understanding how tech has reorganized labor, and developing a strategy to break free, is not easy. It cannot be done with the narrow technical training that produces computer science PhDs—the recent appending of ethics courses notwithstanding. It requires an interdisciplinary analysis in partnership with impacted people who are on the forefront of digital experimentation. There is no way around doing this work.</p>\n<p>In theory, Black study is the intellectual method and tradition that is best positioned to lead such an analysis. As SA Smythe clarifies in these pages, Black study does not mean Black Studies™ —“a hegemonic and ethnonationalist interdisciplinary framework that was heavily funded by the government” during its founding in the 1960s. Instead, drawing on the work of Robin D. G. Kelley, Smythe defines Black study as “the deeply invested commitment to Black people, Black life, Black possibility, and freedom dreaming.” </p>\n<p>The Bulletin of the Atomic Scientists was founded by former Manhattan Project scientists in 1945 after the atomic bombs were dropped on Hiroshima and Nagasaki. Its iconic doomsday clock is currently set at one hundred seconds to midnight. This reflects the risk posed to the world from nuclear weapons, climate change, and, notably, “disruptive technologies.” Black study would have us trouble this notion of catastrophe as a singular event or a state of exception. As Smythe explains, exclamations of “How is this still happening and it’s 2021?” show that we’ve been bamboozled and hoodwinked into thinking time has marched linearly forward towards modernity. Smythe insists that the reason we find ourselves in what scholar Bedour Alagraa calls “the changing same” is that we are in fact still in 1492, circling the drain of the ongoing catastrophe initiated by white contact with the “new world.” But this is not cause for despair—it’s an opportunity to ask better questions, like the one posed by Katherine McKittrick in “Mathematics Black Life”: “What if we... begin to count it all out differently?”</p>\n<p>This desperately needed intervention is constrained by the fragmented character of knowledge production. Within computer science and information studies, race is treated primarily as a social <i>consequence</i> of technology rather than <i>constitutive</i> of technology. In the six years since Simone Browne published <i>Dark Matters</i>, a seminal work tracing the links from the proto-biometrics of the Middle Passage to the present-day use of facial-recognition technology, important scholarship has emerged—including from Gebru, Ruha Benjamin, and Safiya Noble—but not at the urgency and scale with which new technologies are violently renegotiating the social contract. And although Black folks have had no choice but to survive the tools and techniques of social control, technology with a capital T has not been a central object of Black study. Similarly, abolitionist organizers have rightly disavowed technical solutions to the prison-industrial complex as reformist reforms, but have not often recognized how central technology is to intensifying the carceral state.</p>\n<p><b>3/</b></p>\n<p>What does it mean to <i>Get Out</i>! in the twenty-first century? How do we build fugitive technologies?</p>\n<p>This special issue of <i>Logic</i> does not seek to provide a totalizing narrative or singular solution. Rather, our goal is to “call in” thinkers and artists from different disciplines—for example, Black studies scholars who are engaged with notions of catastrophe but whose insights have not been yet been taken up by people investigating how technology produces catastrophe, or integrated into the resistance strategies of communities being harmed by new forms of digital experimentation. (The approach of this issue is many times over indebted to Bedour Alagraa’s thinking on “the interminable catastrophe.”) Similarly, how can computer scientists and engineers more effectively communicate to the public not just about the harmful effects of technology but about how these systems actually work and what interventions on the level of software or hardware offer a more liberatory future? </p>\n<p>We take the stakes we’re facing seriously while leaving room for our futures to not be overdetermined by white supremacy. As André Brock, Jr. discusses in these pages, our approach to technology does not need to be one of abjectness. “I’m not saying, ‘Oh, I’m on the other side of the digital divide and I’m trying to cross that bridge,’” says Brock. “No, I peeped that bridge and it doesn’t take me anywhere that’s really necessary for me to go.” While we may not offer one path forward, we hope to <i>get in the way</i> of techno-solutionism and corporate-funded initiatives that absorb the most radical elements of the discourse without actually supporting people to go do the most radical thing. Our hope for this issue is that it will be what Seeta Peña Gangadharan, coorganizer of Our Data Bodies, calls “a body of work that cannot be ignored.”</p>\n<p>I am grateful to the <i>Logic</i> team for letting me hijack their operation, to give us some space where <i>we be imagining</i>, even as the work punctures the myth embedded in the magazine’s name. We offer no singular way of knowing, no hope for messianic deliverance. We be needing <i>logics</i>. This issue is an outlet in which we can explore these logics and meaningfully argue with each other. In a recent interview, Keeanga-Yamahtta Taylor lamented the fact that “debates that exist in the left have no space to be deliberated upon. People get on social media to either ignore or insult each other’s political ideas and opinions,” she continued, “but I’m saying if we want to be impactful in building a mass movement, to shape and direct politics in this country, then something radically different needs to happen.”</p>\n<p>In this issue you’ll find Marxists, Wynterians, Black speculative fiction, poetry written inside a cage, a graphic story about internet shutdowns in Kashmir, abolitionists, and the unaffiliated. In this issue you’ll find many beacons because, like Neta Bomani’s tween zine insists, we need to move beyond <i>The Way</i>. As guest editor, I chose to curate love letters over a manifesto—because I know plans and leaders get captured or beheaded, but we can nourish an otherwise set of relations to each other while we strategize on getting free. </p>\n<p></p>\n<h1>Postscript by Ben Tarnoff</h1>\n<p></p>\n<p>One December morning in 2020, I DM’d Khadijah on Twitter. We’d never spoken before, but I’d just read a recent essay of hers, “<a href=\"https://upfromthecracks.medium.com/on-the-moral-collapse-of-ai-ethics-791cbc7df872\">On the Moral Collapse of AI Ethics</a>,” and loved it, and wanted her to contribute to <i>Logic</i>. She said she’d be in touch with some further thoughts.</p>\n<p>A couple weeks later, she followed up by email. What she really wanted to do wasn’t write a piece, she said, but edit a whole issue:</p>\n<blockquote><p><i>I’ve been thinking about concrete next steps to move beyond calling out the failure of the status quo to providing an alternate beacon for people who are looking for space to build and think critically, take risks and specifically room to think about currently under resourced domains ie tech/data policy in the global south, grassroots response beyond the right to refuse surveillance, bringing in agroecology, the core of Black studies (ie not just citations for bias but the epistemic and historical challenges being raised at the forefront of the field) etc.</i></p></blockquote>\n<p>The aspiration for the issue would be to create “alternate beacons”—that is, to present new ways of thinking about and living with technology, drawn in particular from Black thinkers and practitioners, with the hope of moving beyond critique (as much as we love critique) and toward imagining new worlds. It felt perfect for us. I brought the idea back to the <i>Logic</i> group, who shared my enthusiasm. Soon after, I connected Khadijah to our managing editor Alex Blasdel, and the two of them embarked on the long and labor-intensive task of making this issue.</p>\n<p>Why did <i>Logic</i> decide to undertake this collaboration? I don’t presume to speak for the magazine as a whole—<i>Logic</i> is very much a collective venture, of which I am only one part—but I think it’s because Khadijah was giving us a way to evolve, to find new pathways for our project, now in its fifth year.</p>\n<p>A lot has changed since we launched <i>Logic</i> in early 2017. One of our main motivations was our contempt for popular writing about technology. In the manifesto that led our first issue, we announced that “most tech writing is shallow and pointless.” In the intervening years, however, this statement has become less defensible. As the “techlash” has bloomed, the discourse has become immeasurably more sophisticated. There is now very good reporting about the industry and, with some exceptions, tech criticism as a whole has become less idiotic, more tethered to fact.</p>\n<p>But not everything has changed. Despite the greater sense of clarity and concern, a lawyerly liberalism continues to dominate, and domesticate, the political conversation about tech. Some years back I attended a conference in which a fairly prominent tech policy person said that the best way to solve the various problems underlined by the techlash would be to put all of the “smartest people” from industry, government, and academia into one room and have them figure it out. All that was needed was the right constellation of experts, in other words.</p>\n<p>So <i>Logic</i> still has work to do. The techlash has altered the terrain, but wherever there is power there is a court, and every court has its courtiers. The new common sense is much like the old; techno-utopianism may have fallen out of fashion, but technocracy of one kind or another is harder to eradicate. The techlash has served as a mass credentialing event for a new class of experts, as “AI ethics,” “responsible innovation,” and similar pursuits attract significant funding and visibility. Many of these experts do interesting work, and everyone needs to eat, but the overall arrangement in which they participate can’t help but reiterate the logic of technocracy.</p>\n<p>What’s missing from this arrangement is the people whose lives are being reordered by technology—or, more precisely, by a particular set of practices as structured and mediated by technology. What’s missing is a view of technology <i>from below</i>, as it is encountered and experienced by living and breathing human beings. There are both epistemological and political stakes here. The feminist philosopher Nancy Hartsock once argued that systems of domination can only be fully understood from the standpoint of those they dominate, an insight she drew from Marx (only proletarians can obtain a complete view of class society) and applied to gender (only women can obtain a complete view of patriarchy). We can extend her argument further, and say that today’s technological regimes are most accurately perceived from the standpoint of those they oppress, exploit, and exclude. And this perception is to be acquired not simply for its own sake, but rather in the service of a broader political project of liberation, as it was for Hartsock and Marx. To see technology from below is also to develop the knowledge needed to govern it from below. Every cook can govern, C. L. R James reminds us, and the internet would undoubtedly be a better place if it were governed by more cooks (and fewer lawyers).</p>\n<p>This is the spirit that animates the issue that Khadijah has curated. In these pages we see technology through the eyes of sex workers and click workers, of the incarcerated and the disabled. And while there is much injustice, there is also hope, creativity, and joy. There is the great imaginative power of the Black freedom struggle and the Black radical tradition. We are not led to any single set of conclusions and we never arrive at a final orthodoxy. Some circles on the left have long believed that orthodoxy is what makes revolutions. But revolutions are notoriously irregular affairs; their combustion derives from the diversity of their inputs, which interact in unpredictable ways. “The rise of a group of people is not a simultaneous shift of the whole mass,” W. E. B. Du Bois observed, “it is a continuous differentiation of individuals with inner strife and differences of opinion, so that individuals, groups and classes begin to appear seeking higher levels, groping for better ways, uniting with other likeminded bodies and movements.” This issue attempts to seek some of those higher levels and grope for some of those better ways, to do the right kinds of searching and struggle. <i>Logic</i> will do its best to keep lighting beacons in the years ahead.</p>",
      "content_text": "1/\nIn June 1945, a committee chaired by the physicist James Franck raised the alarm about the Manhattan Project’s development of nuclear weapons. The document they produced, known as the Franck Report, urged President Truman not to use the atomic bomb against Japan. Instead, Truman should demonstrate the bomb’s destructive power by dropping it on a desert or a barren island—or he should try to keep the bomb’s existence secret for as long as possible. Otherwise, the scientists warned, a global nuclear arms race would ensue, with catastrophic consequences for the planet.\nThe authors of the Franck Report had worked on the Manhattan Project. But rather than siphon the scientific knowledge they had accrued in developing nuclear weapons out of the lab and into the commons in order to build a mass movement, they waited until the final hour to pen a letter, addressed to a government that would never heed their call. The scientists understood the stakes of nuclear weapons better than anyone. But in making a moral appeal to the American empire, they demonstrated a profound misunderstanding of the social and political context the technology was developed in service of. Two months after they wrote the report, atomic bombs were dropped on Hiroshima and Nagasaki.\nI was reminded of those physicists in December 2020, in the wake of Google’s high-profile termination of AI ethics scholar Timnit Gebru. Her firing was the final step in management’s systematic silencing of her scholarship, which came to a head over a paper she coauthored called “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” The paper offers a damning critique of the energy demands and ecological costs of the sorts of large language models that are core to Google’s business, as well as how those models reproduce white supremacy—and codify dominant languages as default while expediting the erasure of marginalized languages. Thousands of Google workers, as well as supporters throughout academia, industry, and civil society, rapidly mobilized in defense of Gebru, writing an open letter to Google executives that demanded both her reinstatement and an apology for the egregious treatment she received. \nLike the Franck Report before it, however, this open letter represented a grave misunderstanding of the politics of AI and was in no way commensurate with the threat we face. The technologies being developed at companies like Google present major stakes for all of humanity, just as the invention of nuclear weapons did in the previous century. They are strengthening concentrations of power, deepening existing hierarchies, and accelerating the ecological crisis. More specifically, big tech corporations are extracting labor, ideas, and branding from Black people, and then disposing of them with impunity—whether it’s scholars like Gebru or Amazon workers in Bessemer, Alabama organizing against plantation conditions. \nRacial capitalism’s roadmap for innovation is predicated on profound extraction. AI is central to this process. The next flashpoint over AI is inevitable—but our failure to respond adequately is not. Will we continue to write letters appealing to the conscience of corporations or the state? Or will we build a mass movement? As Audre Lorde said, we cannot dismantle the master’s house with the master’s tools. We cannot stop Google from being evil by uncritically relying on the G Suite tools it developed. We cannot uncritically champion the most popular among us, as if social capital will resolve the colonial entanglements reproduced in much of what passes for research in the field of technology studies. An atlas ain’t no Green Book, and we cannot afford to pretend otherwise. What we can do is to build a better analysis of the context of racial capitalism in which extractive technologies are developed. We can share knowledge about the ways in which such technologies can be refused or have their harms mitigated. We can forge solidarities among workers, tenants, and technologists to help them organize for different futures. We can light alternate beacons. \n2/\nDismantling racial capitalism and displacing the carceral systems on which it relies requires an understanding of how technology produces “new modes of state surveillance and control,” Dorothy Roberts argues. Part of the challenge is that these new geographies of policing, regulation, and management are largely invisible. We experience the immediacy of our Amazon package being delivered without seeing the exploitative labor conditions decreasing the distance between order and arrival. This is not a function of insufficient effort—it’s an indication of how successful big tech corporations have been in concealing the sources of their power. In his essay in this issue, Julian Posada provides a detailed account of Venezeulans performing the tedious, low-paid labor of data labeling on which AI depends—labor that is hidden beneath Silicon Valley’s minimalist user interfaces and promises of automation. The circuits of racialized capital link us ever more closely together even as the pandemic has deepened our sense of alienation. \nUnderstanding how tech has reorganized labor, and developing a strategy to break free, is not easy. It cannot be done with the narrow technical training that produces computer science PhDs—the recent appending of ethics courses notwithstanding. It requires an interdisciplinary analysis in partnership with impacted people who are on the forefront of digital experimentation. There is no way around doing this work.\nIn theory, Black study is the intellectual method and tradition that is best positioned to lead such an analysis. As SA Smythe clarifies in these pages, Black study does not mean Black Studies™ —“a hegemonic and ethnonationalist interdisciplinary framework that was heavily funded by the government” during its founding in the 1960s. Instead, drawing on the work of Robin D. G. Kelley, Smythe defines Black study as “the deeply invested commitment to Black people, Black life, Black possibility, and freedom dreaming.” \nThe Bulletin of the Atomic Scientists was founded by former Manhattan Project scientists in 1945 after the atomic bombs were dropped on Hiroshima and Nagasaki. Its iconic doomsday clock is currently set at one hundred seconds to midnight. This reflects the risk posed to the world from nuclear weapons, climate change, and, notably, “disruptive technologies.” Black study would have us trouble this notion of catastrophe as a singular event or a state of exception. As Smythe explains, exclamations of “How is this still happening and it’s 2021?” show that we’ve been bamboozled and hoodwinked into thinking time has marched linearly forward towards modernity. Smythe insists that the reason we find ourselves in what scholar Bedour Alagraa calls “the changing same” is that we are in fact still in 1492, circling the drain of the ongoing catastrophe initiated by white contact with the “new world.” But this is not cause for despair—it’s an opportunity to ask better questions, like the one posed by Katherine McKittrick in “Mathematics Black Life”: “What if we... begin to count it all out differently?”\nThis desperately needed intervention is constrained by the fragmented character of knowledge production. Within computer science and information studies, race is treated primarily as a social consequence of technology rather than constitutive of technology. In the six years since Simone Browne published Dark Matters, a seminal work tracing the links from the proto-biometrics of the Middle Passage to the present-day use of facial-recognition technology, important scholarship has emerged—including from Gebru, Ruha Benjamin, and Safiya Noble—but not at the urgency and scale with which new technologies are violently renegotiating the social contract. And although Black folks have had no choice but to survive the tools and techniques of social control, technology with a capital T has not been a central object of Black study. Similarly, abolitionist organizers have rightly disavowed technical solutions to the prison-industrial complex as reformist reforms, but have not often recognized how central technology is to intensifying the carceral state.\n3/\nWhat does it mean to Get Out! in the twenty-first century? How do we build fugitive technologies?\nThis special issue of Logic does not seek to provide a totalizing narrative or singular solution. Rather, our goal is to “call in” thinkers and artists from different disciplines—for example, Black studies scholars who are engaged with notions of catastrophe but whose insights have not been yet been taken up by people investigating how technology produces catastrophe, or integrated into the resistance strategies of communities being harmed by new forms of digital experimentation. (The approach of this issue is many times over indebted to Bedour Alagraa’s thinking on “the interminable catastrophe.”) Similarly, how can computer scientists and engineers more effectively communicate to the public not just about the harmful effects of technology but about how these systems actually work and what interventions on the level of software or hardware offer a more liberatory future? \nWe take the stakes we’re facing seriously while leaving room for our futures to not be overdetermined by white supremacy. As André Brock, Jr. discusses in these pages, our approach to technology does not need to be one of abjectness. “I’m not saying, ‘Oh, I’m on the other side of the digital divide and I’m trying to cross that bridge,’” says Brock. “No, I peeped that bridge and it doesn’t take me anywhere that’s really necessary for me to go.” While we may not offer one path forward, we hope to get in the way of techno-solutionism and corporate-funded initiatives that absorb the most radical elements of the discourse without actually supporting people to go do the most radical thing. Our hope for this issue is that it will be what Seeta Peña Gangadharan, coorganizer of Our Data Bodies, calls “a body of work that cannot be ignored.”\nI am grateful to the Logic team for letting me hijack their operation, to give us some space where we be imagining, even as the work punctures the myth embedded in the magazine’s name. We offer no singular way of knowing, no hope for messianic deliverance. We be needing logics. This issue is an outlet in which we can explore these logics and meaningfully argue with each other. In a recent interview, Keeanga-Yamahtta Taylor lamented the fact that “debates that exist in the left have no space to be deliberated upon. People get on social media to either ignore or insult each other’s political ideas and opinions,” she continued, “but I’m saying if we want to be impactful in building a mass movement, to shape and direct politics in this country, then something radically different needs to happen.”\nIn this issue you’ll find Marxists, Wynterians, Black speculative fiction, poetry written inside a cage, a graphic story about internet shutdowns in Kashmir, abolitionists, and the unaffiliated. In this issue you’ll find many beacons because, like Neta Bomani’s tween zine insists, we need to move beyond The Way. As guest editor, I chose to curate love letters over a manifesto—because I know plans and leaders get captured or beheaded, but we can nourish an otherwise set of relations to each other while we strategize on getting free. \n\nPostscript by Ben Tarnoff\n\nOne December morning in 2020, I DM’d Khadijah on Twitter. We’d never spoken before, but I’d just read a recent essay of hers, “On the Moral Collapse of AI Ethics,” and loved it, and wanted her to contribute to Logic. She said she’d be in touch with some further thoughts.\nA couple weeks later, she followed up by email. What she really wanted to do wasn’t write a piece, she said, but edit a whole issue:\nI’ve been thinking about concrete next steps to move beyond calling out the failure of the status quo to providing an alternate beacon for people who are looking for space to build and think critically, take risks and specifically room to think about currently under resourced domains ie tech/data policy in the global south, grassroots response beyond the right to refuse surveillance, bringing in agroecology, the core of Black studies (ie not just citations for bias but the epistemic and historical challenges being raised at the forefront of the field) etc.\nThe aspiration for the issue would be to create “alternate beacons”—that is, to present new ways of thinking about and living with technology, drawn in particular from Black thinkers and practitioners, with the hope of moving beyond critique (as much as we love critique) and toward imagining new worlds. It felt perfect for us. I brought the idea back to the Logic group, who shared my enthusiasm. Soon after, I connected Khadijah to our managing editor Alex Blasdel, and the two of them embarked on the long and labor-intensive task of making this issue.\nWhy did Logic decide to undertake this collaboration? I don’t presume to speak for the magazine as a whole—Logic is very much a collective venture, of which I am only one part—but I think it’s because Khadijah was giving us a way to evolve, to find new pathways for our project, now in its fifth year.\nA lot has changed since we launched Logic in early 2017. One of our main motivations was our contempt for popular writing about technology. In the manifesto that led our first issue, we announced that “most tech writing is shallow and pointless.” In the intervening years, however, this statement has become less defensible. As the “techlash” has bloomed, the discourse has become immeasurably more sophisticated. There is now very good reporting about the industry and, with some exceptions, tech criticism as a whole has become less idiotic, more tethered to fact.\nBut not everything has changed. Despite the greater sense of clarity and concern, a lawyerly liberalism continues to dominate, and domesticate, the political conversation about tech. Some years back I attended a conference in which a fairly prominent tech policy person said that the best way to solve the various problems underlined by the techlash would be to put all of the “smartest people” from industry, government, and academia into one room and have them figure it out. All that was needed was the right constellation of experts, in other words.\nSo Logic still has work to do. The techlash has altered the terrain, but wherever there is power there is a court, and every court has its courtiers. The new common sense is much like the old; techno-utopianism may have fallen out of fashion, but technocracy of one kind or another is harder to eradicate. The techlash has served as a mass credentialing event for a new class of experts, as “AI ethics,” “responsible innovation,” and similar pursuits attract significant funding and visibility. Many of these experts do interesting work, and everyone needs to eat, but the overall arrangement in which they participate can’t help but reiterate the logic of technocracy.\nWhat’s missing from this arrangement is the people whose lives are being reordered by technology—or, more precisely, by a particular set of practices as structured and mediated by technology. What’s missing is a view of technology from below, as it is encountered and experienced by living and breathing human beings. There are both epistemological and political stakes here. The feminist philosopher Nancy Hartsock once argued that systems of domination can only be fully understood from the standpoint of those they dominate, an insight she drew from Marx (only proletarians can obtain a complete view of class society) and applied to gender (only women can obtain a complete view of patriarchy). We can extend her argument further, and say that today’s technological regimes are most accurately perceived from the standpoint of those they oppress, exploit, and exclude. And this perception is to be acquired not simply for its own sake, but rather in the service of a broader political project of liberation, as it was for Hartsock and Marx. To see technology from below is also to develop the knowledge needed to govern it from below. Every cook can govern, C. L. R James reminds us, and the internet would undoubtedly be a better place if it were governed by more cooks (and fewer lawyers).\nThis is the spirit that animates the issue that Khadijah has curated. In these pages we see technology through the eyes of sex workers and click workers, of the incarcerated and the disabled. And while there is much injustice, there is also hope, creativity, and joy. There is the great imaginative power of the Black freedom struggle and the Black radical tradition. We are not led to any single set of conclusions and we never arrive at a final orthodoxy. Some circles on the left have long believed that orthodoxy is what makes revolutions. But revolutions are notoriously irregular affairs; their combustion derives from the diversity of their inputs, which interact in unpredictable ways. “The rise of a group of people is not a simultaneous shift of the whole mass,” W. E. B. Du Bois observed, “it is a continuous differentiation of individuals with inner strife and differences of opinion, so that individuals, groups and classes begin to appear seeking higher levels, groping for better ways, uniting with other likeminded bodies and movements.” This issue attempts to seek some of those higher levels and grope for some of those better ways, to do the right kinds of searching and struggle. Logic will do its best to keep lighting beacons in the years ahead.",
      "date_published": "2021-12-13T14:33:52.000Z",
      "date_modified": "2021-12-13T14:33:52.000Z",
      "_plugin": {
        "pageFilename": "978d10170e27d2b2443ab72eedc95b7730340545cd3db1d12ea31f046e3e5910.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/the-immune-sequence",
      "url": "https://logicmag.io/kids/the-immune-sequence",
      "title": "The Immune Sequence",
      "summary": "On the dangers of chasing childhood purity.",
      "content_html": "<p>A faceless, soft doll in red or blue; a wooden rattle; a mirror; kinetic sand; a rainbow silk scarf. For many families, this particular genre of children’s toy—often sold on Etsy, via targeted ads, or through subscription kits—may arrive benignly and incidentally into a child’s repertoire of plastic dolls, metal trucks, and rubber balls. But for other parents and their families, they are part of a larger system: an elaborate pedagogy meant to steer every aspect of a child’s life—including diet, environment, and even play. In these philosophies—popularized by “alternative” schools such as Montessori, Reggio Emilia, and Waldorf—such whimsical recreation is also a tool of parental control prescribed to ward off an ultimate threat: technology. </p>\n<p>Today, “alternative” schools, which focus on “hands-on” learning and spiritual development, are largely considered niche options reserved for the very wealthy—although their reach quietly extends far beyond Silicon Valley and Park Slope. In pop culture, they may most commonly be recognized as the tech-free schools where eBay’s CTO and other Valley executives send their kids, supposedly driven by esoteric knowledge about the threat of the products their companies make. (Knowledge which, as scholar Morgan Ames has pointed out, doesn’t actually exist.) It’s more likely that these parents are anxious over a question faced by most parents today: What exactly does technology do to our children, and how do we protect them from it? </p>\n<p>Parents’ individual answers to that question fall on a spectrum. Some, in the words of child icon Elsa, simply “let it go,” allowing tech to be a much-needed parenting aid. Others champion ameliorating measures, from limiting screen time, to delaying cell phone ownership, to using parental controls on the TV. But for a subset of parents, like many of those who employ “alternative” schooling, the answer is tech refusal—banishing it altogether. And where this kind of adamancy is present, other extreme politics often lurk just out of view. Such is the case with Waldorf and its underlying philosophy, a longer history of which reveals ideological ties to fascistic thought and racial hierarchies.</p>\n<p>Although it represents one extreme, the roots of this niche pedagogy can help us understand the whole spectrum of anxiety when it comes to technology and parenting. Particularly, its history makes clear how the quietly interlocking panics surrounding the technologies of screens and vaccines connect to dangerous notions of purity; ideas that—just as wooden toys tend to appear in ordinary homes—have often made their way into the mainstream, mostly unnoticed. </p>\n<h1><b>Stagnant Souls</b></h1>\n<p>In 1919—against the backdrop of the Spanish Flu, countless political uprisings, and the aftermath of World War I—Rudolf Steiner founded the first Waldorf School, located in Stuttgart, Germany. Having grown up as the son of a railway worker, Steiner’s childhood had been shaped by the violent rise of modernity, and he was determined to save future children from the same fate. Intended as a school for the children of the workers at the Waldorf-Astoria cigarette factory, two-thirds of the students were children of factory workers; the last third were children of Steiner followers.</p>\n<p>By that time, Steiner had gained prominence as the charismatic leader of an occultist movement he called “Anthroposophy,” underpinned by an original, esoteric philosophy replete with a comprehensive theory of reincarnation, spirit worlds, and higher realms. Waldorf was Steiner’s translation of Anthroposophy into pedagogy—down to the curricula and classroom design. It was, in essence, a pedagogical laboratory for an alternative spiritual life, one imagined as free from modernity while tied intimately to its labors and afflictions. </p>\n<p>The Steiner model, or “Waldorf schooling” as it became more commonly known, in part preserved traditional education in the present to safeguard it for the future; students spent time outdoors to learn from nature and worked on handicrafts. But it also used approaches that were archaic even for the time: children were categorized into supposedly preordained temperaments based on the typology of humors (phlegmatic, melancholic, sanguine, choleric) that had fallen out of the medical canon centuries prior. </p>\n<p>A system of guided movement called “Eurythmy” also played a large role in this counter-training, not just as physical education, but as medico-spiritual intervention to care palliatively for the kids. In that first year of the school, students likely would have practiced a specific pattern from Steiner’s growing repertoire, which he taught widely to address the pandemic that raged outside: “The Immune Sequence.” By coordinating sound, dance, and intention, its practitioner was thought to become their best, truest self, and therefore physically immune.</p>\n<p>At the time, medical technologies and interventions, especially vaccines, were rapidly advancing. But Steiner believed that they made one “lose an urge for a spiritual life.” He argued that illness was not just the result of pathogenetic spread or due to microorganisms. There was an extra-material reason for illness to present in its host: karma. According to Steiner, not all souls were created equal. As with the temperaments of children, the wider outcomes of this life are already written by the actions in previous incarnations, which corresponded to the supposed “evolution”—or “devolution”—of race. </p>\n<p>Put bluntly, Steiner saw the white race as the race of the future—the highest form of being, the endpoint of reincarnation, and therefore the most naturally immune. Meanwhile, melanin showed the susceptibility, karmic impurity, and “stagnation” of a soul. These stagnated souls were, for Steiner, one way illness spread—to be faulted not just for their own static sickness, but that of society. The problem posed an endless feedback loop: society ruins the soul and ruined souls, in turn, degrade society. Care of the individual soul—via the body and the mind—was to be the cure, the solve, the salvation. </p>\n<p>Additional schools followed in Germany, The Netherlands, and England. Then, in 1928, the first Rudolph Steiner school opened in New York City as a private school, which still operates today. Of course, Steiner’s set of beliefs made Anthroposophy ripe for uptake in the emerging Nazi Party. Although the Nazis temporarily closed nearly all Waldorf schools in their control, many of Steiner’s followers—including his widow—had close ties to the Party, where the occultist-karmic philosophy was taken up, both strategically and in deeper belief: both systems of thought worked to bring the world into “harmony” and achieve “regeneration.” </p>\n<p>Today, the connections (and disconnections) between Nazism, fascism, and this spiritual science are somewhat of an academic debate. According to the historical scholarship of Peter Staudenmaier, much of Steiner’s works and literatures were “cleaned up” to delete mentions of race when translated into English. That’s mostly how the ideas are implemented today: While every Waldorf school differs slightly, Steiner’s initial approach remains largely intact—from typologies, to daily Eurythmy, to anti-vax sentiment—with mentions of race simply excluded. But Steiner’s theories of illness, race, and technology all come from the same well, no matter how obscured in or by the present. His notion of the ideal child endures: The perfect kid is one who is pure. </p>\n<h1><b>Fantasies of Purity</b></h1>\n<p>And purity, it turns out, can be marketed and purchased.</p>\n<p>There are now roughly 125 Waldorf schools nationwide and more than 3,000 internationally, according to one Waldorf executive. Where Waldorf exists as an alternative, parents who see themselves as progressive—even Left—have sought it out, some in spite of larger philosophical differences or outright disbelief. “Private schools almost by definition have to craft stories that appeal to privileged strivers anxious about their children’s futures,” Morgan Ames wrote of Waldorf schools in 2019 for the <i>Los Angeles Review of Books</i>. “Some of these stories recount how their graduates’ creative brilliance was spawned in their school’s tech-free environment. Related ones ply anti-contamination themes, and fetishize the purity of childhood.” These stories frame technology as a constant threat, presenting Waldorf schools as bubbles of safety, oases within the desert of the modern. </p>\n<p>Waldorf is not alone in the pursuit of a tech-free environment. There have been many movements and philosophies that attempt to achieve purity by cutting off access to technology, specifically media, and they don’t all bend towards fascism or even apoliticality. Tech refusal looks quite different in the context of utopian projects like the back-to-the-land movement of the ’60s and other forms of communal care focused on raising children in nature, including the MOVE Family and the international “unschooling movement” of the ’70s. In the hands of the Left, the rejection of technology can be a radical act of carving out a space of resistance within capitalism and systems of repression to imagine a deeper liberation. But, following Danya Glabau in <i>Real Life</i>, “As a metaphor, purity easily translates from necessary practices to exclusionary principles.” Where the aspiration of purity becomes dangerous is when principles entail protecting one’s individual child at the <i>expense</i> of a child next door.</p>\n<p>Steiner’s adherents, whether they are “Waldorf families” or in the Anthroposophical movement, or both, subscribe to a sense of predestined exceptionalism that Laura Portwood-Stacer argues is frequently behind the rejection of media and technology—including vaccines. Such principles can lead believers and their fellow travelers to reject “herd mentality” and compromise herd immunity in the process. While Waldorf philosophy aims to protect new life from various social ills, it has become a literal incubator of viruses that, like its greater ethos, organically seep beyond its walls—whether in the case of a Waldorf school at the epicenter of a measles outbreak in New York or now, during the Covid-19 pandemic. Estimates vary, but some suggest 60 percent of Waldorf children are unvaccinated against infectious illness for which there are routine childhood vaccines. Where states grant exceptions for religious or philosophical reasons, rates of refusal are even higher. </p>\n<p>The endurance of this resistance is disquieting precisely because of the ways that this notion of purity feeds into unbridled exceptionalism—especially as it takes new, viral forms in our present. Today, 15 to 20 percent of Americans believe in some form of the QAnon conspiracy—another system of belief that, like Anthroposophy, has ties to fascism and the occult—while vaccine rejectors claim that taking the shot is antagonistic to bodily autonomy, and even argue in some cases that it causes sterilization. In turn, some vaccine rejectors are referring to their eggs or sperm as “vaccine free”—triumphantly stating that they are the <i>only</i> key to any possible reproductive future precisely because their bodies stayed pure of medical technology. These ideologies reject the basic, collective reality of modernity and late stage capitalism, as if by doing so they might manifest a different future, one that furthers the comforting—and ultimately racist—fantasy of purity. </p>\n<p>It makes sense that Steiner’s philosophies are frequently read as <i>anti</i>-modern. But perhaps this is the other side of modernity. To buy into these teachings is to search for alternative spaces within techno-culture, turning the school into a pastoral enclave that can be carried home with children in the form of rules for families and domestic space. In cherry-picking Steiner’s philosophy to exclude these other insidious forms of purity ideology, Waldorf schools have, in the words of scholar Wendy Chun, “updated to remain the same.” </p>\n<p>During our ongoing pandemic, at a Waldorf School in Upstate New York, middle schoolers and high schoolers continued to meet regularly outdoors to practice Eurythmy. According to a blog post by the school, they decided to focus on one pattern of movement to address this latest health crisis: “The Immune Sequence.”</p>",
      "content_text": "A faceless, soft doll in red or blue; a wooden rattle; a mirror; kinetic sand; a rainbow silk scarf. For many families, this particular genre of children’s toy—often sold on Etsy, via targeted ads, or through subscription kits—may arrive benignly and incidentally into a child’s repertoire of plastic dolls, metal trucks, and rubber balls. But for other parents and their families, they are part of a larger system: an elaborate pedagogy meant to steer every aspect of a child’s life—including diet, environment, and even play. In these philosophies—popularized by “alternative” schools such as Montessori, Reggio Emilia, and Waldorf—such whimsical recreation is also a tool of parental control prescribed to ward off an ultimate threat: technology. \nToday, “alternative” schools, which focus on “hands-on” learning and spiritual development, are largely considered niche options reserved for the very wealthy—although their reach quietly extends far beyond Silicon Valley and Park Slope. In pop culture, they may most commonly be recognized as the tech-free schools where eBay’s CTO and other Valley executives send their kids, supposedly driven by esoteric knowledge about the threat of the products their companies make. (Knowledge which, as scholar Morgan Ames has pointed out, doesn’t actually exist.) It’s more likely that these parents are anxious over a question faced by most parents today: What exactly does technology do to our children, and how do we protect them from it? \nParents’ individual answers to that question fall on a spectrum. Some, in the words of child icon Elsa, simply “let it go,” allowing tech to be a much-needed parenting aid. Others champion ameliorating measures, from limiting screen time, to delaying cell phone ownership, to using parental controls on the TV. But for a subset of parents, like many of those who employ “alternative” schooling, the answer is tech refusal—banishing it altogether. And where this kind of adamancy is present, other extreme politics often lurk just out of view. Such is the case with Waldorf and its underlying philosophy, a longer history of which reveals ideological ties to fascistic thought and racial hierarchies.\nAlthough it represents one extreme, the roots of this niche pedagogy can help us understand the whole spectrum of anxiety when it comes to technology and parenting. Particularly, its history makes clear how the quietly interlocking panics surrounding the technologies of screens and vaccines connect to dangerous notions of purity; ideas that—just as wooden toys tend to appear in ordinary homes—have often made their way into the mainstream, mostly unnoticed. \nStagnant Souls\nIn 1919—against the backdrop of the Spanish Flu, countless political uprisings, and the aftermath of World War I—Rudolf Steiner founded the first Waldorf School, located in Stuttgart, Germany. Having grown up as the son of a railway worker, Steiner’s childhood had been shaped by the violent rise of modernity, and he was determined to save future children from the same fate. Intended as a school for the children of the workers at the Waldorf-Astoria cigarette factory, two-thirds of the students were children of factory workers; the last third were children of Steiner followers.\nBy that time, Steiner had gained prominence as the charismatic leader of an occultist movement he called “Anthroposophy,” underpinned by an original, esoteric philosophy replete with a comprehensive theory of reincarnation, spirit worlds, and higher realms. Waldorf was Steiner’s translation of Anthroposophy into pedagogy—down to the curricula and classroom design. It was, in essence, a pedagogical laboratory for an alternative spiritual life, one imagined as free from modernity while tied intimately to its labors and afflictions. \nThe Steiner model, or “Waldorf schooling” as it became more commonly known, in part preserved traditional education in the present to safeguard it for the future; students spent time outdoors to learn from nature and worked on handicrafts. But it also used approaches that were archaic even for the time: children were categorized into supposedly preordained temperaments based on the typology of humors (phlegmatic, melancholic, sanguine, choleric) that had fallen out of the medical canon centuries prior. \nA system of guided movement called “Eurythmy” also played a large role in this counter-training, not just as physical education, but as medico-spiritual intervention to care palliatively for the kids. In that first year of the school, students likely would have practiced a specific pattern from Steiner’s growing repertoire, which he taught widely to address the pandemic that raged outside: “The Immune Sequence.” By coordinating sound, dance, and intention, its practitioner was thought to become their best, truest self, and therefore physically immune.\nAt the time, medical technologies and interventions, especially vaccines, were rapidly advancing. But Steiner believed that they made one “lose an urge for a spiritual life.” He argued that illness was not just the result of pathogenetic spread or due to microorganisms. There was an extra-material reason for illness to present in its host: karma. According to Steiner, not all souls were created equal. As with the temperaments of children, the wider outcomes of this life are already written by the actions in previous incarnations, which corresponded to the supposed “evolution”—or “devolution”—of race. \nPut bluntly, Steiner saw the white race as the race of the future—the highest form of being, the endpoint of reincarnation, and therefore the most naturally immune. Meanwhile, melanin showed the susceptibility, karmic impurity, and “stagnation” of a soul. These stagnated souls were, for Steiner, one way illness spread—to be faulted not just for their own static sickness, but that of society. The problem posed an endless feedback loop: society ruins the soul and ruined souls, in turn, degrade society. Care of the individual soul—via the body and the mind—was to be the cure, the solve, the salvation. \nAdditional schools followed in Germany, The Netherlands, and England. Then, in 1928, the first Rudolph Steiner school opened in New York City as a private school, which still operates today. Of course, Steiner’s set of beliefs made Anthroposophy ripe for uptake in the emerging Nazi Party. Although the Nazis temporarily closed nearly all Waldorf schools in their control, many of Steiner’s followers—including his widow—had close ties to the Party, where the occultist-karmic philosophy was taken up, both strategically and in deeper belief: both systems of thought worked to bring the world into “harmony” and achieve “regeneration.” \nToday, the connections (and disconnections) between Nazism, fascism, and this spiritual science are somewhat of an academic debate. According to the historical scholarship of Peter Staudenmaier, much of Steiner’s works and literatures were “cleaned up” to delete mentions of race when translated into English. That’s mostly how the ideas are implemented today: While every Waldorf school differs slightly, Steiner’s initial approach remains largely intact—from typologies, to daily Eurythmy, to anti-vax sentiment—with mentions of race simply excluded. But Steiner’s theories of illness, race, and technology all come from the same well, no matter how obscured in or by the present. His notion of the ideal child endures: The perfect kid is one who is pure. \nFantasies of Purity\nAnd purity, it turns out, can be marketed and purchased.\nThere are now roughly 125 Waldorf schools nationwide and more than 3,000 internationally, according to one Waldorf executive. Where Waldorf exists as an alternative, parents who see themselves as progressive—even Left—have sought it out, some in spite of larger philosophical differences or outright disbelief. “Private schools almost by definition have to craft stories that appeal to privileged strivers anxious about their children’s futures,” Morgan Ames wrote of Waldorf schools in 2019 for the Los Angeles Review of Books. “Some of these stories recount how their graduates’ creative brilliance was spawned in their school’s tech-free environment. Related ones ply anti-contamination themes, and fetishize the purity of childhood.” These stories frame technology as a constant threat, presenting Waldorf schools as bubbles of safety, oases within the desert of the modern. \nWaldorf is not alone in the pursuit of a tech-free environment. There have been many movements and philosophies that attempt to achieve purity by cutting off access to technology, specifically media, and they don’t all bend towards fascism or even apoliticality. Tech refusal looks quite different in the context of utopian projects like the back-to-the-land movement of the ’60s and other forms of communal care focused on raising children in nature, including the MOVE Family and the international “unschooling movement” of the ’70s. In the hands of the Left, the rejection of technology can be a radical act of carving out a space of resistance within capitalism and systems of repression to imagine a deeper liberation. But, following Danya Glabau in Real Life, “As a metaphor, purity easily translates from necessary practices to exclusionary principles.” Where the aspiration of purity becomes dangerous is when principles entail protecting one’s individual child at the expense of a child next door.\nSteiner’s adherents, whether they are “Waldorf families” or in the Anthroposophical movement, or both, subscribe to a sense of predestined exceptionalism that Laura Portwood-Stacer argues is frequently behind the rejection of media and technology—including vaccines. Such principles can lead believers and their fellow travelers to reject “herd mentality” and compromise herd immunity in the process. While Waldorf philosophy aims to protect new life from various social ills, it has become a literal incubator of viruses that, like its greater ethos, organically seep beyond its walls—whether in the case of a Waldorf school at the epicenter of a measles outbreak in New York or now, during the Covid-19 pandemic. Estimates vary, but some suggest 60 percent of Waldorf children are unvaccinated against infectious illness for which there are routine childhood vaccines. Where states grant exceptions for religious or philosophical reasons, rates of refusal are even higher. \nThe endurance of this resistance is disquieting precisely because of the ways that this notion of purity feeds into unbridled exceptionalism—especially as it takes new, viral forms in our present. Today, 15 to 20 percent of Americans believe in some form of the QAnon conspiracy—another system of belief that, like Anthroposophy, has ties to fascism and the occult—while vaccine rejectors claim that taking the shot is antagonistic to bodily autonomy, and even argue in some cases that it causes sterilization. In turn, some vaccine rejectors are referring to their eggs or sperm as “vaccine free”—triumphantly stating that they are the only key to any possible reproductive future precisely because their bodies stayed pure of medical technology. These ideologies reject the basic, collective reality of modernity and late stage capitalism, as if by doing so they might manifest a different future, one that furthers the comforting—and ultimately racist—fantasy of purity. \nIt makes sense that Steiner’s philosophies are frequently read as anti-modern. But perhaps this is the other side of modernity. To buy into these teachings is to search for alternative spaces within techno-culture, turning the school into a pastoral enclave that can be carried home with children in the form of rules for families and domestic space. In cherry-picking Steiner’s philosophy to exclude these other insidious forms of purity ideology, Waldorf schools have, in the words of scholar Wendy Chun, “updated to remain the same.” \nDuring our ongoing pandemic, at a Waldorf School in Upstate New York, middle schoolers and high schoolers continued to meet regularly outdoors to practice Eurythmy. According to a blog post by the school, they decided to focus on one pattern of movement to address this latest health crisis: “The Immune Sequence.”",
      "date_published": "2021-12-01T21:59:11.000Z",
      "date_modified": "2021-12-01T21:59:11.000Z",
      "_plugin": {
        "pageFilename": "9282e02da2d48fff73d2a25bea4262a54f9c0a3e1d77080085c92c89b2ca992e.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/zoomers-versus-the-national-security-state",
      "url": "https://logicmag.io/kids/zoomers-versus-the-national-security-state",
      "title": "Zoomers Versus the National Security State",
      "summary": "Finding the Guantánamo that lives online.",
      "content_html": "<p>In October 2019, an op-ed in a student newspaper at the University of North Carolina at Charlotte made an allegation that rippled across campus: it claimed that the university’s administration had quietly appointed a war criminal as the new head of campus safety and security. The man, retired army colonel John Bogdan, had spent two years running the notorious detention facilities at Guantánamo Bay.</p>\n<p>The student who wrote the op-ed didn’t have to look far to find traces of Bogdan’s record. The colonel’s LinkedIn profile noted that, between 2012 and 2014, Bogdan had been “responsible for the safe and legal custody of 166 opposing force detainees.” Those detainees were young and middle-aged Muslim men who had been extrajudicially imprisoned during the so-called War on Terror. Further internet searches revealed that while Bogdan was warden of Guantánamo Bay, he had implemented a regime of intrusive genital searches, had detainees on hunger strike intravenously force fed, and had allowed guards to use rubber bullets on hunger-striking detainees. One lawyer for detainees has written that Bogdan’s Guantánamo was characterized by “displays of power for power’s sake.” Although Bogdan’s actions likely do not constitute war crimes under international law, the UNC Charlotte Chapter of the American Association of University Professors later argued that those actions “clearly violate human decency and the spirit of the Third Geneva Convention and other protocols for the treatment of prisoners.”</p>\n<p>Almost immediately, the op-ed set off a campaign to have Bogdan fired. A group of several dozen students, consisting primarily of campus Democrats and Young Democratic Socialists of America members, began searching for more evidence of what Bogdan had done at Guantánamo. They formed a group chat on GroupMe to strategize and share articles about Bogdan’s past, and a Twitter feed to publicize their discoveries and rally support. They called themselves the Coalition to Remove John Bogdan. </p>\n<p>Members of the coalition soon found themselves clashing with the university’s administration over Bogdan’s role on campus, and struggling to convince their Zoomer-generation peers—most of whom were born after 9/11 and were children during the early years of the Iraq and Afghanistan Wars—that the man who ran the Guantánamo detention center shouldn’t be the head of campus security. At the same time, the coalition members were trying to educate themselves about what had transpired in the detention facilities. In the decade after 9/11, Guantánamo was perhaps the most potent symbol of the abuses and excesses of the US national security state, but its place in the public imagination had been receding since Barack Obama’s second term in office. “I didn’t really know anything about it,” one coalition member recently told me over Zoom.</p>\n<p>The coalition members’ understanding of the base was almost entirely mediated by digital records, “Guantánamo” Google searches, Wikipedia skims, and tidbits teachers had told them along the way. But the version of Guantánamo that public schools teach and that tends to live online is very narrowly defined: a hundred-year-old naval base on forty-five square miles of US-controlled land and sea at the southeastern tip of Cuba. Though the identities and experiences of the people detained at Guantánamo have now been reported, catalogued, and even cinematized, a political and technological veil has been cast over the past and future of most former guards. The result is a Guantánamo that is always far away: the people <i>there</i> are never coming <i>here</i>, to America. </p>\n<p>That myth has made formulating the right questions about truth, justice, and the US detention center at Guantánamo Bay incredibly hard to do. Bogdan’s presence at UNC Charlotte raised exactly those questions. He was the rare exception of someone who had emerged from behind the veil.</p>\n<h1><b>A Pinpoint on Google Maps</b></h1>\n<p>Although Bogdan had listed his Guantánamo experience on his LinkedIn profile, knowledge about most of the guards that return from Guantánamo is extraordinarily hard to come by. This is largely the result of decisions made by the Pentagon, which worked for years to ensure that most guards’ identities, decisions, and actions would not be documented in public archives.</p>\n<p>The Guantánamo that emerges online tends to be a pinpoint on Google Maps, a small strip of land through which all kinds of people—private contractors, intelligence agents, soldiers, sailors, policymakers, lawyers, journalists—pass through, disappearing in discourse once they leave the base. Google Images almost inevitably turns one’s attention to the physical detention camp, too. Searches produce a checkerboard of orange jumpsuits, snapshots of current detainees, splatters of camouflage. Over the past decade, the first page of results has evolved to include photographs of protesters in the mainland US, but even those images point back to the camp: many protesters have decided that the best way to remind civilians of Gitmo’s continued existence is to dress up like detainees. In the digital archives of major US newspaper outlets, there is a parallel pattern. Almost all the photographs accompanying stories about the detention facilities show a similar montage: hurricane fencing and barbed wire; American flags and the backs of military personnel; the small, beige-colored trailers containing men deemed too dangerous for US soil. </p>\n<p>Political discourse about Guantánamo has also centered on the prison and its detainees. If the Zoomers at UNC Charlotte had looked for Guantánamo on C-SPAN.org, they would have scrolled through decades of videos of congressional representatives, national security lawyers, lieutenants, and journalists regurgitating the same five or six questions. <i>When will Guantánamo close? Where will the detainees go? What might happen to the detention facilities if they are ever emptied of people? What is it like to see Guantánamo with your own eyes? What horrors might befall America if detainees were to be housed and tried in US federal criminal courts instead of military commissions?</i></p>\n<p>Wikipedia articles about Guantánamo echo these frames, and have become repositories of contested knowledge about the detained. Footnotes include Supreme Court cases about habeas corpus petitions, links to lengthy Pentagon reports on the detention facilities, memos written by ACLU lawyers arguing for the immediate closure of the prison, and a rich archive of investigative news articles that try to detail human rights abuses at the prison. In much of this writing, the passive voice lurks in the prose, quietly obfuscating precisely who is ordering that detainees be force-fed, who is implementing groin searches, who is <i>doing</i> the detaining.</p>\n<p>Archivists, activists, and journalists have pushed against this erasure, and initiatives such as the Guantánamo Public Memory Project have endeavored to trace the lineage of the place. Reporters from some countries whose citizens have been imprisoned at Guantánamo have tried to document who did what, when, and why, and individuals released from the detention facilities have written about their experiences. Some of the most rigorous coverage of the prison is unsurprisingly written in Arabic. But language barriers have made this knowledge relatively inaccessible to English-speaking monolinguals living in the United States.</p>\n<p>Some guards have chosen to identify themselves on Twitter and other social media platforms. One even started a gym in Philly. But most keep quiet. There is no public list, no Excel spreadsheet of former guards. Instead, there is a persistent informational void about who the individual guards were, who they harmed, what ideologies motivated them, and where they went when they left the camp. Contrary to what Google Maps might show you, Guantánamo runs on the dreams and sweat and blood and logics of people like John Bogdan—former guards and wardens who are now scattered across the United States.</p>\n<h1><b>Fact Sets</b></h1>\n<p>Once wardens and guards leave Guantánamo, they tend to go quietly into the night of civilian life. The uproar over Bogdan’s appointment at UNC Charlotte was an anomaly. Members of the Coalition to Remove John Bogdan met in the GroupMe chat and in the library late at night to imagine a campus without him. They amplified their cause by tweeting and chalking the streets. In their written statements, coalition members drew heavily on reports written by Amnesty International and other organizations that had made a concerted effort to track and trace the wrongs that Bogdan’s Guantánamo had wrought. There was plenty of documentation of what was done to detainees. Reports from Human Rights Watch noted that a federal district judge had ordered Bogdan to explain a standing order that called for the use of restraint chairs during the force-feeding of detainees. But there was little information about who apart from Bogdan had been involved in doing it. </p>\n<p>It is fair to say that the administrators of UNC Charlotte did not imagine their campus would become the site of a battle over the legacy, meaning, and future of detention facilities that are over a thousand miles away. After the coalition began drawing attention to Bogdan’s alleged crimes, the university’s chancellor issued what he called a “fact set” to defend Bogdan’s reputation and employment history. But the document also went many steps further, legitimizing Guantánamo as just one of the US military’s hundreds of bases. </p>\n<p>Bogdan fought back as well. In an interview with a local reporter, he pushed the thesis that “the mission here is not far off from the military.” He declared, “The mission of the Army is to fight and win the nation’s wars. And you do that by developing a team, and teaching and growing and building the future of the nation. That’s exactly what universities do, right?” Around the same time, university administrators instructed the social media team associated with the admissions department to block the coalition on Twitter, so that prospective students were less likely to come across their arguments against the colonel.</p>\n<p>Ultimately, the coalition couldn’t translate their understanding of Guantánamo into a campaign that resonated with most of their fellow students. In part, the Zoomers had faced the challenge of teaching themselves and their peers what the military prison was and why it mattered. More importantly, perhaps, in setting out to learn about Guantánamo, they were never going to encounter examples of other struggles like theirs. In fact, there has only been one analogous case relating directly to Gitmo: since 2009, Berkeley law students have repeatedly called for the dismissal of professor John Yoo, who gained the nickname “architect of torture” for his role in justifying harsh CIA interrogation techniques deployed at Guantánamo. The students’ Google searching had led them back in time, to a period during their childhoods when Bogdan was running Guantánamo, but it brought them no closer to a blueprint for how to hold people like Bogdan accountable in the present.</p>\n<h1><b>Tindering Gitmo</b></h1>\n<p>If Guantánamo is more than a physical detention camp, if it is also a network of people and ideologies that have successfully implemented the continuous extrajudicial detention of individuals, then how can researchers, reporters, and future generations trace its contours online, and formulate questions about what justice with regard to Guantánamo might look like?</p>\n<p>In 2015, as a master’s student in comparative literature, I emailed the Joint Task Force Guantánamo, requesting to see the prison’s library. I was informed that only reporters could go, so I began a foray into freelance journalism. To go would be to see, and to see would be to understand, I told myself. Among other things, I set out to learn how the arrival of T-Mobile cell service had changed life on the naval base. I hoped I could convince US civilians that Guantánamo was not so far away—what the Bush administration had described as “the legal equivalent of outer space” was, in fact, connected by multiple fiber optic cables to the state of Florida. </p>\n<p>As I interviewed guards stationed at the base, I discovered many of them were millennials like me. They were mostly twenty-somethings, some actually younger, many of whom scuba-dived on the weekends, acting as if warehousing Muslim men was part of their patriotic duty. At the same time, I could not shake the feeling that everything I saw in the detention facilities, where I was surveilled and accompanied by a handler most of the time, was a curated performance. To understand Gitmo, I realized, I would need to find a different way backstage. </p>\n<p>For the past five years, I have relied on different open-source intelligence methods to explore the porousness of Gitmo and to follow the people who move through it. I spent one year watching the Joint Task Force scrub its own official Twitter feed of hundreds of tweets. (They subsequently deactivated the account, and I took over the handle.) I sat quietly for years with the knowledge that geolocation-based smartphone apps were a window into a military culture that most civilians will never see, and nodded my head when people told me that fitness trackers like Strava could reveal someone’s location on a military base. I knew that Strava was just the tip of the iceberg. I didn’t need to go to Gitmo to speak with personnel there; I could just turn on my phone.</p>\n<p>I considered different platforms—Facebook, YouTube, Reddit—where current and former guards might hover. All seemed too public—except Tinder. And so, in the summer of 2017, I plugged in a little personal information about myself on the app, geolocated to Guantánamo, and began to chat with men who were stationed there. I ended up swiping right on private contractors, members of the Military Police, sailors who were just passing through the port. Meanwhile, I sat in my small apartment in Massachusetts trying to understand what precisely I was trying to understand about the detention facilities. </p>\n<p>What I began to see through Tinder is that Americans would pass through the base and eventually return stateside. My new digital strategies were leading me to reckon with the fact that guards themselves were constantly returning after their rotations to communities throughout the United States, many slipping back into civilian life. Guards came, guards went, rinse, repeat. Through swiping, I could ask these people what they saw on the ground, and I could do what I had largely been unable to do at Guantánamo—learn their names, gain records of their faces, outline their moral codes, inquire what the detention facilities represented to them. </p>\n<p>The responses I gathered included disavowals and defenses of the national security state—a diversity of perspectives absent in much of the public record. At the same time, I was trying to document the identities of former guards, though at a certain point I recognized that this alone wouldn’t cause me to reckon with the vastness of the US national security state represented by Guantánamo Bay. As the scholar A. Naomi Paik argues in her book <i>Rightlessness: Testimony and Redress in U.S. Prison Camps since World War II</i>, Gitmo is part of a longstanding and ongoing US project to create physical and legal black sites. A few truths told on Tinder couldn’t make for a global reconciliation. </p>\n<h1><b>Home Truths</b></h1>\n<p>It took the UNC Charlotte students’ campaign, which I first heard about in late 2019, for me to reckon with my own lack of imagination. I had been so intent on using social media to map the identities, ideologies, and movements of former guards that I hadn’t considered what might transpire if their identities were to be widely known. The Zoomers had first learned about Bogdan’s history through LinkedIn—and then they led a concerted effort to fire him.</p>\n<p>But when I speak to members of the Coalition to Remove John Bogdan and other former UNC Charlotte students, I always find myself circling back to the same question. After unearthing this knowledge about Bogdan, if they didn’t think he belonged on their campus, where did he belong? </p>\n<p>One UNC Charlotte alumna, who now works in the national security sector, responded, “I think what shocked me was the ease with which someone that had such a high-profile position like that was able to come back and seamlessly reenter society, and that was it. I guess I just assumed they’d go to like RAND or Deloitte or somewhere like that.” Another Coalition member, now an alumnus, said the question of where Bogdan should be removed to had been stumping him from the start. “My initial reaction was to say that John Bogdan is not fit for any sort of civilian job,” he told me. “But then, I don’t necessarily want people like John Bogdan in our police or military either.” </p>\n<p>It struck me that what the students lacked was a model for justice that goes beyond any single warden or guard. This was partly a consequence of the algorithmically curated information they encountered online, but it is also the result of a widespread refusal by American society as a whole to confront this issue. As the students leave their campus and scatter across the United States, like former guards returning from their rotations, they’ll have to decide if they, too, want to leave Gitmo behind.</p>",
      "content_text": "In October 2019, an op-ed in a student newspaper at the University of North Carolina at Charlotte made an allegation that rippled across campus: it claimed that the university’s administration had quietly appointed a war criminal as the new head of campus safety and security. The man, retired army colonel John Bogdan, had spent two years running the notorious detention facilities at Guantánamo Bay.\nThe student who wrote the op-ed didn’t have to look far to find traces of Bogdan’s record. The colonel’s LinkedIn profile noted that, between 2012 and 2014, Bogdan had been “responsible for the safe and legal custody of 166 opposing force detainees.” Those detainees were young and middle-aged Muslim men who had been extrajudicially imprisoned during the so-called War on Terror. Further internet searches revealed that while Bogdan was warden of Guantánamo Bay, he had implemented a regime of intrusive genital searches, had detainees on hunger strike intravenously force fed, and had allowed guards to use rubber bullets on hunger-striking detainees. One lawyer for detainees has written that Bogdan’s Guantánamo was characterized by “displays of power for power’s sake.” Although Bogdan’s actions likely do not constitute war crimes under international law, the UNC Charlotte Chapter of the American Association of University Professors later argued that those actions “clearly violate human decency and the spirit of the Third Geneva Convention and other protocols for the treatment of prisoners.”\nAlmost immediately, the op-ed set off a campaign to have Bogdan fired. A group of several dozen students, consisting primarily of campus Democrats and Young Democratic Socialists of America members, began searching for more evidence of what Bogdan had done at Guantánamo. They formed a group chat on GroupMe to strategize and share articles about Bogdan’s past, and a Twitter feed to publicize their discoveries and rally support. They called themselves the Coalition to Remove John Bogdan. \nMembers of the coalition soon found themselves clashing with the university’s administration over Bogdan’s role on campus, and struggling to convince their Zoomer-generation peers—most of whom were born after 9/11 and were children during the early years of the Iraq and Afghanistan Wars—that the man who ran the Guantánamo detention center shouldn’t be the head of campus security. At the same time, the coalition members were trying to educate themselves about what had transpired in the detention facilities. In the decade after 9/11, Guantánamo was perhaps the most potent symbol of the abuses and excesses of the US national security state, but its place in the public imagination had been receding since Barack Obama’s second term in office. “I didn’t really know anything about it,” one coalition member recently told me over Zoom.\nThe coalition members’ understanding of the base was almost entirely mediated by digital records, “Guantánamo” Google searches, Wikipedia skims, and tidbits teachers had told them along the way. But the version of Guantánamo that public schools teach and that tends to live online is very narrowly defined: a hundred-year-old naval base on forty-five square miles of US-controlled land and sea at the southeastern tip of Cuba. Though the identities and experiences of the people detained at Guantánamo have now been reported, catalogued, and even cinematized, a political and technological veil has been cast over the past and future of most former guards. The result is a Guantánamo that is always far away: the people there are never coming here, to America. \nThat myth has made formulating the right questions about truth, justice, and the US detention center at Guantánamo Bay incredibly hard to do. Bogdan’s presence at UNC Charlotte raised exactly those questions. He was the rare exception of someone who had emerged from behind the veil.\nA Pinpoint on Google Maps\nAlthough Bogdan had listed his Guantánamo experience on his LinkedIn profile, knowledge about most of the guards that return from Guantánamo is extraordinarily hard to come by. This is largely the result of decisions made by the Pentagon, which worked for years to ensure that most guards’ identities, decisions, and actions would not be documented in public archives.\nThe Guantánamo that emerges online tends to be a pinpoint on Google Maps, a small strip of land through which all kinds of people—private contractors, intelligence agents, soldiers, sailors, policymakers, lawyers, journalists—pass through, disappearing in discourse once they leave the base. Google Images almost inevitably turns one’s attention to the physical detention camp, too. Searches produce a checkerboard of orange jumpsuits, snapshots of current detainees, splatters of camouflage. Over the past decade, the first page of results has evolved to include photographs of protesters in the mainland US, but even those images point back to the camp: many protesters have decided that the best way to remind civilians of Gitmo’s continued existence is to dress up like detainees. In the digital archives of major US newspaper outlets, there is a parallel pattern. Almost all the photographs accompanying stories about the detention facilities show a similar montage: hurricane fencing and barbed wire; American flags and the backs of military personnel; the small, beige-colored trailers containing men deemed too dangerous for US soil. \nPolitical discourse about Guantánamo has also centered on the prison and its detainees. If the Zoomers at UNC Charlotte had looked for Guantánamo on C-SPAN.org, they would have scrolled through decades of videos of congressional representatives, national security lawyers, lieutenants, and journalists regurgitating the same five or six questions. When will Guantánamo close? Where will the detainees go? What might happen to the detention facilities if they are ever emptied of people? What is it like to see Guantánamo with your own eyes? What horrors might befall America if detainees were to be housed and tried in US federal criminal courts instead of military commissions?\nWikipedia articles about Guantánamo echo these frames, and have become repositories of contested knowledge about the detained. Footnotes include Supreme Court cases about habeas corpus petitions, links to lengthy Pentagon reports on the detention facilities, memos written by ACLU lawyers arguing for the immediate closure of the prison, and a rich archive of investigative news articles that try to detail human rights abuses at the prison. In much of this writing, the passive voice lurks in the prose, quietly obfuscating precisely who is ordering that detainees be force-fed, who is implementing groin searches, who is doing the detaining.\nArchivists, activists, and journalists have pushed against this erasure, and initiatives such as the Guantánamo Public Memory Project have endeavored to trace the lineage of the place. Reporters from some countries whose citizens have been imprisoned at Guantánamo have tried to document who did what, when, and why, and individuals released from the detention facilities have written about their experiences. Some of the most rigorous coverage of the prison is unsurprisingly written in Arabic. But language barriers have made this knowledge relatively inaccessible to English-speaking monolinguals living in the United States.\nSome guards have chosen to identify themselves on Twitter and other social media platforms. One even started a gym in Philly. But most keep quiet. There is no public list, no Excel spreadsheet of former guards. Instead, there is a persistent informational void about who the individual guards were, who they harmed, what ideologies motivated them, and where they went when they left the camp. Contrary to what Google Maps might show you, Guantánamo runs on the dreams and sweat and blood and logics of people like John Bogdan—former guards and wardens who are now scattered across the United States.\nFact Sets\nOnce wardens and guards leave Guantánamo, they tend to go quietly into the night of civilian life. The uproar over Bogdan’s appointment at UNC Charlotte was an anomaly. Members of the Coalition to Remove John Bogdan met in the GroupMe chat and in the library late at night to imagine a campus without him. They amplified their cause by tweeting and chalking the streets. In their written statements, coalition members drew heavily on reports written by Amnesty International and other organizations that had made a concerted effort to track and trace the wrongs that Bogdan’s Guantánamo had wrought. There was plenty of documentation of what was done to detainees. Reports from Human Rights Watch noted that a federal district judge had ordered Bogdan to explain a standing order that called for the use of restraint chairs during the force-feeding of detainees. But there was little information about who apart from Bogdan had been involved in doing it. \nIt is fair to say that the administrators of UNC Charlotte did not imagine their campus would become the site of a battle over the legacy, meaning, and future of detention facilities that are over a thousand miles away. After the coalition began drawing attention to Bogdan’s alleged crimes, the university’s chancellor issued what he called a “fact set” to defend Bogdan’s reputation and employment history. But the document also went many steps further, legitimizing Guantánamo as just one of the US military’s hundreds of bases. \nBogdan fought back as well. In an interview with a local reporter, he pushed the thesis that “the mission here is not far off from the military.” He declared, “The mission of the Army is to fight and win the nation’s wars. And you do that by developing a team, and teaching and growing and building the future of the nation. That’s exactly what universities do, right?” Around the same time, university administrators instructed the social media team associated with the admissions department to block the coalition on Twitter, so that prospective students were less likely to come across their arguments against the colonel.\nUltimately, the coalition couldn’t translate their understanding of Guantánamo into a campaign that resonated with most of their fellow students. In part, the Zoomers had faced the challenge of teaching themselves and their peers what the military prison was and why it mattered. More importantly, perhaps, in setting out to learn about Guantánamo, they were never going to encounter examples of other struggles like theirs. In fact, there has only been one analogous case relating directly to Gitmo: since 2009, Berkeley law students have repeatedly called for the dismissal of professor John Yoo, who gained the nickname “architect of torture” for his role in justifying harsh CIA interrogation techniques deployed at Guantánamo. The students’ Google searching had led them back in time, to a period during their childhoods when Bogdan was running Guantánamo, but it brought them no closer to a blueprint for how to hold people like Bogdan accountable in the present.\nTindering Gitmo\nIf Guantánamo is more than a physical detention camp, if it is also a network of people and ideologies that have successfully implemented the continuous extrajudicial detention of individuals, then how can researchers, reporters, and future generations trace its contours online, and formulate questions about what justice with regard to Guantánamo might look like?\nIn 2015, as a master’s student in comparative literature, I emailed the Joint Task Force Guantánamo, requesting to see the prison’s library. I was informed that only reporters could go, so I began a foray into freelance journalism. To go would be to see, and to see would be to understand, I told myself. Among other things, I set out to learn how the arrival of T-Mobile cell service had changed life on the naval base. I hoped I could convince US civilians that Guantánamo was not so far away—what the Bush administration had described as “the legal equivalent of outer space” was, in fact, connected by multiple fiber optic cables to the state of Florida. \nAs I interviewed guards stationed at the base, I discovered many of them were millennials like me. They were mostly twenty-somethings, some actually younger, many of whom scuba-dived on the weekends, acting as if warehousing Muslim men was part of their patriotic duty. At the same time, I could not shake the feeling that everything I saw in the detention facilities, where I was surveilled and accompanied by a handler most of the time, was a curated performance. To understand Gitmo, I realized, I would need to find a different way backstage. \nFor the past five years, I have relied on different open-source intelligence methods to explore the porousness of Gitmo and to follow the people who move through it. I spent one year watching the Joint Task Force scrub its own official Twitter feed of hundreds of tweets. (They subsequently deactivated the account, and I took over the handle.) I sat quietly for years with the knowledge that geolocation-based smartphone apps were a window into a military culture that most civilians will never see, and nodded my head when people told me that fitness trackers like Strava could reveal someone’s location on a military base. I knew that Strava was just the tip of the iceberg. I didn’t need to go to Gitmo to speak with personnel there; I could just turn on my phone.\nI considered different platforms—Facebook, YouTube, Reddit—where current and former guards might hover. All seemed too public—except Tinder. And so, in the summer of 2017, I plugged in a little personal information about myself on the app, geolocated to Guantánamo, and began to chat with men who were stationed there. I ended up swiping right on private contractors, members of the Military Police, sailors who were just passing through the port. Meanwhile, I sat in my small apartment in Massachusetts trying to understand what precisely I was trying to understand about the detention facilities. \nWhat I began to see through Tinder is that Americans would pass through the base and eventually return stateside. My new digital strategies were leading me to reckon with the fact that guards themselves were constantly returning after their rotations to communities throughout the United States, many slipping back into civilian life. Guards came, guards went, rinse, repeat. Through swiping, I could ask these people what they saw on the ground, and I could do what I had largely been unable to do at Guantánamo—learn their names, gain records of their faces, outline their moral codes, inquire what the detention facilities represented to them. \nThe responses I gathered included disavowals and defenses of the national security state—a diversity of perspectives absent in much of the public record. At the same time, I was trying to document the identities of former guards, though at a certain point I recognized that this alone wouldn’t cause me to reckon with the vastness of the US national security state represented by Guantánamo Bay. As the scholar A. Naomi Paik argues in her book Rightlessness: Testimony and Redress in U.S. Prison Camps since World War II, Gitmo is part of a longstanding and ongoing US project to create physical and legal black sites. A few truths told on Tinder couldn’t make for a global reconciliation. \nHome Truths\nIt took the UNC Charlotte students’ campaign, which I first heard about in late 2019, for me to reckon with my own lack of imagination. I had been so intent on using social media to map the identities, ideologies, and movements of former guards that I hadn’t considered what might transpire if their identities were to be widely known. The Zoomers had first learned about Bogdan’s history through LinkedIn—and then they led a concerted effort to fire him.\nBut when I speak to members of the Coalition to Remove John Bogdan and other former UNC Charlotte students, I always find myself circling back to the same question. After unearthing this knowledge about Bogdan, if they didn’t think he belonged on their campus, where did he belong? \nOne UNC Charlotte alumna, who now works in the national security sector, responded, “I think what shocked me was the ease with which someone that had such a high-profile position like that was able to come back and seamlessly reenter society, and that was it. I guess I just assumed they’d go to like RAND or Deloitte or somewhere like that.” Another Coalition member, now an alumnus, said the question of where Bogdan should be removed to had been stumping him from the start. “My initial reaction was to say that John Bogdan is not fit for any sort of civilian job,” he told me. “But then, I don’t necessarily want people like John Bogdan in our police or military either.” \nIt struck me that what the students lacked was a model for justice that goes beyond any single warden or guard. This was partly a consequence of the algorithmically curated information they encountered online, but it is also the result of a widespread refusal by American society as a whole to confront this issue. As the students leave their campus and scatter across the United States, like former guards returning from their rotations, they’ll have to decide if they, too, want to leave Gitmo behind.",
      "date_published": "2021-12-01T21:58:51.000Z",
      "date_modified": "2021-12-01T21:58:51.000Z",
      "_plugin": {
        "pageFilename": "30dd6bdf1ab23782ba8c5efc6121098dcf4b86529bec57abd2133f00acd07d1b.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/big-data-stream",
      "url": "https://logicmag.io/kids/big-data-stream",
      "title": "Big Data Stream",
      "summary": "Who controls the algorithms that control the Colorado River?",
      "content_html": "<p>The Colorado River snakes southwest from fifteen thousand feet high in the Rocky Mountains, down through plains and desert to present-day Mexico and the Gulf of California, draining a vast watershed of 250,000 square miles. Indigenous peoples—the Navajo and the Hopi, the Zuni and the Ute, and dozens of other nations—have been living alongside the river and its tributaries for centuries. Beginning in the 1820s, Anglo settlers began seizing water and land in the Colorado River Basin, and by the 1870s, the Colorado River Basin region had become part of the expanding United States empire. The region was reimagined by the US state as what the American geologist John Wesley Powell called “arid earth”: “drought-stricken” lands that supposedly needed to be salvaged through settler control and technology. </p>\n<p>In the decades that followed, the newly created US Geological Survey initiated a massive program of data collection to map, chart, graph, and apportion the basin’s water, land, and people. This stream of information—from acre-feet per year of river flow to racist atlases of Indigenous peoples—fed into decisions by US agencies like the Bureau of Reclamation about who should be allowed to live in the basin and use its land and water. This was, in effect, a data analytics program that entrenched white supremacist ideology into the legal and scientific functioning of the US state.</p>\n<p>Guiding decisions about how to distribute the region’s land and water was the belief that scarce resources should be optimized to foster development and maximize profits for white settlers. This regime of resource optimization persisted into the mid-twentieth century, when it was combined with a newly dominant mode of economic analysis called Input-Output (I/O) economics and programmed into computer algorithms known as linear programming algorithms, which guided the work of deciding how to allocate the basin’s water and land.</p>\n<p>Today, those optimization algorithms, and the settler-colonial logics they derive from, control the distribution of resources on which forty million people throughout the American southwest depend. According to officials in Colorado, New Mexico, Arizona, and Utah, and other states, that water system is now collapsing in the face of what the media, in a contemporary echo of Powell’s drought-stricken arid lands thesis, has described as “megadrought” and “water starvation” exacerbated by the climate crisis. That has led to calls for further technological intervention of the same kind that has long enabled settler control. But it is clear the optimization framework—which over the past century has contributed to water shortages, toxic waste from profit-driven energy development, flooding of Native American agricultural land, and enduring campaigns of water appropriation—will not solve the water crisis.</p>\n<p>There is now an urgent need to abandon that framework and imagine better water futures. Luckily, the resources for this work already exist. In the period when settler-colonial water policy was being entrenched in digital algorithms, a group of young people from the National Indian Youth Council (NIYC) were developing critiques of the optimization regime, and articulating a different vision for the Colorado River Basin. That vision can help us support sustainability and justice-centered water policy for generations to come. </p>\n<h1><b>Computing Landscapes</b></h1>\n<p>The story of how the optimization regime took over the Colorado River Basin is a complicated one. But at its core are innovations in policy, law, and technology that enthroned profit as the guiding principle of resource distribution in the region.</p>\n<p>In the nineteenth century, two doctrines guided the US empire’s allocation of Colorado River water. The first, known as the doctrine of prior appropriation, was basically a “first come, first served” rule that privileged the first interests to lay claim to the use of a given amount of water. The second, known as the doctrine of equitable apportionment, split water between US territories. In theory, these water doctrines might have favored Native American water rights, as they did after the 1908 <i>Winters v. United States</i> Supreme Court decision, which upheld the water rights of the Fort Belknap Indian Reservation over encroaching settlers. But since then, white settlers have managed to subordinate water rights under the principle of “beneficial use,” which holds that in the case of disputes, water should be allocated to the parties that intend to use it for vaguely defined beneficial purposes. In practice, this has usually meant profits for technological developers and extractive energy industries.</p>\n<p>That evolution in the principles of water distribution policies was later operationalized in new computing technologies. Beginning earlier but expanding significantly in the 1960s, analysts in laboratories at major land-grant universities like the University of Arizona took the data collected by the US Geological Survey and other agencies and encoded it onto punch cards. Mathematicians, economists, and other technologists then used those cards as the fodder for computer programs that would optimize water distribution for profit maximization.</p>\n<p>The design of these computer programs was derived from the economic technique known as Input-Output modeling. Created in the 1920s by the economist Wassily Leontief in order to optimize the transportation of grain in Soviet Russia, I/O modeling was later used to analyze entire national economies and even to guide US bombing campaigns in the Second World War, thereby advancing US imperialism and rationalizing mass destruction on the world stage.</p>\n<p>I/O models are based on a table that looks like an Excel spreadsheet, in which columns for materials (such as oil, steel, or coal) intersect with rows for industries (such as agriculture or manufacturing). The basic idea is that an economic system can be measured as the overall ratio of resources used (input) to goods produced (output). In the Cold War period, scientists at Harvard, the Pentagon, and elsewhere developed mathematical techniques known as linear programming algorithms to determine the optimal input and output numbers for a desired objective, such as optimizing resources for military development at the lowest possible cost. </p>\n<p>After being successfully implemented in imperial bombing campaigns and New England manufacturing, I/O economics and linear programming algorithms began expanding westward in the 1950s into water management on the Colorado River, becoming the dominant mode of modeling water within a decade. Researchers and students at the land-grant universities were charged with optimizing water distribution across the region. As the basis of their analysis, they carved the diverse land into relatively homogenous virtual quadrants known as “problem settings.”</p>\n<p>For example, in proposals for the Central Utah Project, initially formalized in the 1960s, the state of Utah was represented as a square divided into a grid of eight to ten smaller squares that obliterated all distinctions about whose land, histories, and water rights the grid overlaid. Researchers then used computer programs to figure out how to distribute X acre-feet of water for Y farm plots across each problem setting, so as to maximize profits and minimize costs for the region’s large agribusinesses and other industries.</p>\n<h1><b>Youth Against the Empire</b></h1>\n<p>The optimization regime is so entrenched in water policy and technology that, even in the midst of catastrophic climate change, it is difficult to imagine other futures for the Colorado River Basin and proximate regions. But in the late 1970s, a group of Native American students did just that, fighting back against a water diversion program in New Mexico, and providing a model for activism and water management that could guide us today.</p>\n<p>The NIYC was founded in 1961 as a nationwide coalition focused on environmental justice work and an intergenerational fight against US colonialism and economic extraction. In the subsequent decades, the NIYC argued countless environmental court cases, wrote numerous policy reports, and utilized every political and scientific tool to fight against the settler policy and technologies of the US empire. </p>\n<p>One of the tools they used was the Environmental Impact Statement (EIS). These statements were created in 1969 by the National Environmental Protection Act to help guide government decisions on new development projects. In the Colorado River Basin region, developers manipulated the EIS format to justify the impacts of their projects in light of those projects’ beneficial use—in other words, to show that the profits outweighed the environmental costs. </p>\n<p>In 1976, student youth members of the NIYC of Albuquerque, New Mexico, wrote their own anti-colonial EIS for the Bureau of Indian Affairs. They recognized that the EIS was a powerful policy medium that could be repurposed for environmental justice work. They were attempting to intervene against a recent data-driven decision about the allocation of water from the San Juan River—a major tributary of the Colorado River—as part of the Navajo Indian Irrigation Project. The project was supposed to take water from the Navajo Dam and Reservoir, created in early ’60s, and use it to irrigate land in San Juan County in northwestern New Mexico. </p>\n<p>The students supported the irrigation project in principle—as a founding member of the NIYC, John Redhouse, said in another context, “we’re not anti-development, we’re just anti-exploitation”—but they were concerned that Native oversight was lacking, and that the project would thereby undermine Navajo self-governance. They focused their EIS on the New Mexico state government’s opaque decision to divert 330,000 acre-feet of water from the Navajo Dam, which they pointed out was just one among countless decisions made without robust structures of Native oversight.</p>\n<p>In their statement, the students recounted how Native American water rights had been diminished since at least the early twentieth century by the doctrine of beneficial use. They pointed to the ways that dominant data-driven decision-making processes had been used to disavow Native American claims to water, and questioned the specific hydrological data employed to make the decision in this case. They decried the influence of corporate agriculture in the decision, as well as recent changes in the Navajo Council that weakened possibilities for total self-sufficiency from US resource governance. They also provided a clear vision for Navajo self-sufficiency, which included breaking away from the domination of US agribusiness to create a system of food production and distribution organized into small family farming and local Navajo food-producing cooperatives. </p>\n<p>Perhaps most importantly, they demanded transparency and power in the decision-making process, so that they could assert their voice within the Native council, and break from US water management and the technological regime of optimization. This has become a central tenet of contemporary Indigenous Environmental Justice and Indigenous Data Sovereignty resistance movements: the right to collection, ownership, and application of all data about Indigenous peoples, their lifeways, and territories. </p>\n<h1><b>Crisis Epistemology</b></h1>\n<p>Water justice requires acknowledging historical pasts as much as imagining new futures, but optimization frameworks flatten past, present, and future into calculations of profit-driven time.</p>\n<p>Optimization algorithms are misleading in stories about water in other ways, too. In upholding extractive economic systems, they formulate water crisis as a future problem and ignore the fact that this crisis has been caused by centuries of settler and capitalist control. Scholar Kyle Whyte has named this false description of climate change as new and urgent as “crisis epistemology.” This anxiety is evident in “megadrought” media descriptions of the Colorado River that warn of impending collapse. In response, technological developers and policy makers are granted unchecked decision-making power that reaffirms optimization-led economic systems. </p>\n<p>Environmental Impact Statements continue to dominate in water development policies. Standard EIS reports utilize optimization algorithms, Monte Carlo methods, and other predictive statistical frameworks. This means that dominant water policy assessment tools are designed with the same optimization logics that they are supposed to check. Against this, the NIYC’s anti-colonial EIS is a model of environmental assessment that breaks optimization’s stranglehold on water policy, and privileges intergenerational sustainability and water rights. Their approach centers the needs of the people over the profit of technological developers. </p>\n<p>The NIYC’s environmental justice work over the past seventy years—including their 1976 intervention into the Navajo irrigation project water diversion decision—and their unparalleled expertise in water policy, water-related technological development, and agriculture, underscore the critical importance of local organizing and wider coalition building, as well as centering youth perspectives, in formulating water futures written by the people. There is already enough information in these past interventions to write justice-centered policy and support livable water futures for the Colorado River.</p>",
      "content_text": "The Colorado River snakes southwest from fifteen thousand feet high in the Rocky Mountains, down through plains and desert to present-day Mexico and the Gulf of California, draining a vast watershed of 250,000 square miles. Indigenous peoples—the Navajo and the Hopi, the Zuni and the Ute, and dozens of other nations—have been living alongside the river and its tributaries for centuries. Beginning in the 1820s, Anglo settlers began seizing water and land in the Colorado River Basin, and by the 1870s, the Colorado River Basin region had become part of the expanding United States empire. The region was reimagined by the US state as what the American geologist John Wesley Powell called “arid earth”: “drought-stricken” lands that supposedly needed to be salvaged through settler control and technology. \nIn the decades that followed, the newly created US Geological Survey initiated a massive program of data collection to map, chart, graph, and apportion the basin’s water, land, and people. This stream of information—from acre-feet per year of river flow to racist atlases of Indigenous peoples—fed into decisions by US agencies like the Bureau of Reclamation about who should be allowed to live in the basin and use its land and water. This was, in effect, a data analytics program that entrenched white supremacist ideology into the legal and scientific functioning of the US state.\nGuiding decisions about how to distribute the region’s land and water was the belief that scarce resources should be optimized to foster development and maximize profits for white settlers. This regime of resource optimization persisted into the mid-twentieth century, when it was combined with a newly dominant mode of economic analysis called Input-Output (I/O) economics and programmed into computer algorithms known as linear programming algorithms, which guided the work of deciding how to allocate the basin’s water and land.\nToday, those optimization algorithms, and the settler-colonial logics they derive from, control the distribution of resources on which forty million people throughout the American southwest depend. According to officials in Colorado, New Mexico, Arizona, and Utah, and other states, that water system is now collapsing in the face of what the media, in a contemporary echo of Powell’s drought-stricken arid lands thesis, has described as “megadrought” and “water starvation” exacerbated by the climate crisis. That has led to calls for further technological intervention of the same kind that has long enabled settler control. But it is clear the optimization framework—which over the past century has contributed to water shortages, toxic waste from profit-driven energy development, flooding of Native American agricultural land, and enduring campaigns of water appropriation—will not solve the water crisis.\nThere is now an urgent need to abandon that framework and imagine better water futures. Luckily, the resources for this work already exist. In the period when settler-colonial water policy was being entrenched in digital algorithms, a group of young people from the National Indian Youth Council (NIYC) were developing critiques of the optimization regime, and articulating a different vision for the Colorado River Basin. That vision can help us support sustainability and justice-centered water policy for generations to come. \nComputing Landscapes\nThe story of how the optimization regime took over the Colorado River Basin is a complicated one. But at its core are innovations in policy, law, and technology that enthroned profit as the guiding principle of resource distribution in the region.\nIn the nineteenth century, two doctrines guided the US empire’s allocation of Colorado River water. The first, known as the doctrine of prior appropriation, was basically a “first come, first served” rule that privileged the first interests to lay claim to the use of a given amount of water. The second, known as the doctrine of equitable apportionment, split water between US territories. In theory, these water doctrines might have favored Native American water rights, as they did after the 1908 Winters v. United States Supreme Court decision, which upheld the water rights of the Fort Belknap Indian Reservation over encroaching settlers. But since then, white settlers have managed to subordinate water rights under the principle of “beneficial use,” which holds that in the case of disputes, water should be allocated to the parties that intend to use it for vaguely defined beneficial purposes. In practice, this has usually meant profits for technological developers and extractive energy industries.\nThat evolution in the principles of water distribution policies was later operationalized in new computing technologies. Beginning earlier but expanding significantly in the 1960s, analysts in laboratories at major land-grant universities like the University of Arizona took the data collected by the US Geological Survey and other agencies and encoded it onto punch cards. Mathematicians, economists, and other technologists then used those cards as the fodder for computer programs that would optimize water distribution for profit maximization.\nThe design of these computer programs was derived from the economic technique known as Input-Output modeling. Created in the 1920s by the economist Wassily Leontief in order to optimize the transportation of grain in Soviet Russia, I/O modeling was later used to analyze entire national economies and even to guide US bombing campaigns in the Second World War, thereby advancing US imperialism and rationalizing mass destruction on the world stage.\nI/O models are based on a table that looks like an Excel spreadsheet, in which columns for materials (such as oil, steel, or coal) intersect with rows for industries (such as agriculture or manufacturing). The basic idea is that an economic system can be measured as the overall ratio of resources used (input) to goods produced (output). In the Cold War period, scientists at Harvard, the Pentagon, and elsewhere developed mathematical techniques known as linear programming algorithms to determine the optimal input and output numbers for a desired objective, such as optimizing resources for military development at the lowest possible cost. \nAfter being successfully implemented in imperial bombing campaigns and New England manufacturing, I/O economics and linear programming algorithms began expanding westward in the 1950s into water management on the Colorado River, becoming the dominant mode of modeling water within a decade. Researchers and students at the land-grant universities were charged with optimizing water distribution across the region. As the basis of their analysis, they carved the diverse land into relatively homogenous virtual quadrants known as “problem settings.”\nFor example, in proposals for the Central Utah Project, initially formalized in the 1960s, the state of Utah was represented as a square divided into a grid of eight to ten smaller squares that obliterated all distinctions about whose land, histories, and water rights the grid overlaid. Researchers then used computer programs to figure out how to distribute X acre-feet of water for Y farm plots across each problem setting, so as to maximize profits and minimize costs for the region’s large agribusinesses and other industries.\nYouth Against the Empire\nThe optimization regime is so entrenched in water policy and technology that, even in the midst of catastrophic climate change, it is difficult to imagine other futures for the Colorado River Basin and proximate regions. But in the late 1970s, a group of Native American students did just that, fighting back against a water diversion program in New Mexico, and providing a model for activism and water management that could guide us today.\nThe NIYC was founded in 1961 as a nationwide coalition focused on environmental justice work and an intergenerational fight against US colonialism and economic extraction. In the subsequent decades, the NIYC argued countless environmental court cases, wrote numerous policy reports, and utilized every political and scientific tool to fight against the settler policy and technologies of the US empire. \nOne of the tools they used was the Environmental Impact Statement (EIS). These statements were created in 1969 by the National Environmental Protection Act to help guide government decisions on new development projects. In the Colorado River Basin region, developers manipulated the EIS format to justify the impacts of their projects in light of those projects’ beneficial use—in other words, to show that the profits outweighed the environmental costs. \nIn 1976, student youth members of the NIYC of Albuquerque, New Mexico, wrote their own anti-colonial EIS for the Bureau of Indian Affairs. They recognized that the EIS was a powerful policy medium that could be repurposed for environmental justice work. They were attempting to intervene against a recent data-driven decision about the allocation of water from the San Juan River—a major tributary of the Colorado River—as part of the Navajo Indian Irrigation Project. The project was supposed to take water from the Navajo Dam and Reservoir, created in early ’60s, and use it to irrigate land in San Juan County in northwestern New Mexico. \nThe students supported the irrigation project in principle—as a founding member of the NIYC, John Redhouse, said in another context, “we’re not anti-development, we’re just anti-exploitation”—but they were concerned that Native oversight was lacking, and that the project would thereby undermine Navajo self-governance. They focused their EIS on the New Mexico state government’s opaque decision to divert 330,000 acre-feet of water from the Navajo Dam, which they pointed out was just one among countless decisions made without robust structures of Native oversight.\nIn their statement, the students recounted how Native American water rights had been diminished since at least the early twentieth century by the doctrine of beneficial use. They pointed to the ways that dominant data-driven decision-making processes had been used to disavow Native American claims to water, and questioned the specific hydrological data employed to make the decision in this case. They decried the influence of corporate agriculture in the decision, as well as recent changes in the Navajo Council that weakened possibilities for total self-sufficiency from US resource governance. They also provided a clear vision for Navajo self-sufficiency, which included breaking away from the domination of US agribusiness to create a system of food production and distribution organized into small family farming and local Navajo food-producing cooperatives. \nPerhaps most importantly, they demanded transparency and power in the decision-making process, so that they could assert their voice within the Native council, and break from US water management and the technological regime of optimization. This has become a central tenet of contemporary Indigenous Environmental Justice and Indigenous Data Sovereignty resistance movements: the right to collection, ownership, and application of all data about Indigenous peoples, their lifeways, and territories. \nCrisis Epistemology\nWater justice requires acknowledging historical pasts as much as imagining new futures, but optimization frameworks flatten past, present, and future into calculations of profit-driven time.\nOptimization algorithms are misleading in stories about water in other ways, too. In upholding extractive economic systems, they formulate water crisis as a future problem and ignore the fact that this crisis has been caused by centuries of settler and capitalist control. Scholar Kyle Whyte has named this false description of climate change as new and urgent as “crisis epistemology.” This anxiety is evident in “megadrought” media descriptions of the Colorado River that warn of impending collapse. In response, technological developers and policy makers are granted unchecked decision-making power that reaffirms optimization-led economic systems. \nEnvironmental Impact Statements continue to dominate in water development policies. Standard EIS reports utilize optimization algorithms, Monte Carlo methods, and other predictive statistical frameworks. This means that dominant water policy assessment tools are designed with the same optimization logics that they are supposed to check. Against this, the NIYC’s anti-colonial EIS is a model of environmental assessment that breaks optimization’s stranglehold on water policy, and privileges intergenerational sustainability and water rights. Their approach centers the needs of the people over the profit of technological developers. \nThe NIYC’s environmental justice work over the past seventy years—including their 1976 intervention into the Navajo irrigation project water diversion decision—and their unparalleled expertise in water policy, water-related technological development, and agriculture, underscore the critical importance of local organizing and wider coalition building, as well as centering youth perspectives, in formulating water futures written by the people. There is already enough information in these past interventions to write justice-centered policy and support livable water futures for the Colorado River.",
      "date_published": "2021-11-22T17:02:44.000Z",
      "date_modified": "2021-11-22T17:02:44.000Z",
      "_plugin": {
        "pageFilename": "19b3a05a14a38db36c0cc8b121adcf18eb50df2ae4752ff4fda3eae1bed8ded8.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/gay-in-a-tiktok-way",
      "url": "https://logicmag.io/kids/gay-in-a-tiktok-way",
      "title": "Gay in a TikTok Way",
      "summary": "When identity gets optimized.",
      "content_html": "<blockquote><p><i>@gucaslelfond</i></p><p><i>“I’m so confused because there is this girl who is really pretty and nice and such a genuine person and I want to be friends with her but I’m really nervous?” narrates a freckled, teenaged-looking girl. “Weird. It’s almost like I like her but I’m not gay, so I don’t get it.” She shows the pages of an old notebook as a caption completes the joke: “Reading my ‘straight’ diary from middle school LMAO.”</i></p><p><i>I’d spent a few weeks on TikTok by this point, consistently amazed by how quickly the app seemed to sense my taste. We know little about how TikTok’s algorithm works. A cagey corporate blog post titled “How TikTok recommends videos #ForYou” mostly just explains that it watches the way you engage and gradually tailors the stream of videos to your interests. My feed had already begun to fill with “queer” content—music from queer artists, videos of queer couples, and the like—but nothing explicitly about identity. This video took me by surprise. </i></p><p><i>By this point, I had a vague notion that I was attracted to men, but had only shared this with a few close friends. I still felt confused and ashamed. I’d just begun to think about how my potential queerness may have played into previous friendships—when the video showed up in my feed, I surged with a sense of uncanny recognition. Suddenly, TikTok seemed like a portal, a place where I could more firmly figure out who I was. </i></p><p><i>At the same time, I felt deeply uneasy. As videos about queerness became more common on my feed, I started to feel uncomfortably exposed: </i>How could TikTok know I was bisexual before I fully knew it myself? </p></blockquote>\n<p>For decades, queer people in the United States have been subjected to surveillance. In 1950, Congress issued a report titled “Employment of Homosexuals and Other Sex Perverts in Government” after covertly investigating federal employees’ sexual orientation. The report declared homosexuality a mental illness and homosexuals a national security risk; employees suspected to be gay were immediately terminated. The practice was common among private employers, too. Although some states eventually had statutes prohibiting employment discrimination on the basis of sexual orientation, it wasn’t federally outlawed until June 2020. </p>\n<p>Of course, the monitoring also extended to social spaces. Throughout the ’60s, police raids were a frequent ritual of the queer New York nightlife scene. Police officers regularly lined up gender-nonconforming folks and sent those who failed to wear the mandated three pieces of “gender appropriate clothing” to jail. And trans people are still subjected to such scrutiny on a daily basis—in the bathroom, on the playing field, at TSA. </p>\n<p>In this environment, queer people have long worked to craft subtle ways of controlling their own visibility, signaling queerness to each other while remaining undercover to the mainstream. You can see it in customs like the “hanky code” of the ’70s, by which gay men used a system of colored bandanas to covertly flag their sexual preferences. By the ’80s, some of those symbols—the rainbow flag, the pink triangle, the lowercase lambda—became well-known markers of the rising gay liberation movement. Meanwhile, queer people were still seeking intimacy in out-of-view venues—bars, parks, piers. They found community after dark in liminal urban spaces, communicating through lingering eye contact, subtle head nods, the slight twitch of a knowing smile. </p>\n<p>Once the digital age arrived, internet anonymity supplanted the cover of night. Sites like Tumblr and Reddit acted as queer watering holes, as teens across the world poured themselves into blog posts and suggestive GIFs that allowed them to safely bare their souls and build community across distance. In these instances, the platforms were just that—platforms, on which queer people could, using re-blogs and upvotes, determine what mattered to them.</p>\n<p>Now, that brings us to TikTok, perhaps our generation’s closest analogue to those earlier platforms and venues. We imagine, however, that something is missing. We’re still finding community and expressing ourselves through shared signals, and (through monitored engagement) by choosing what becomes popular. But ultimately, on TikTok, it’s the algorithm that decides what gets seen and what doesn’t—when we’re visible, and to whom. The practice of coding once intended to maintain discretion has been flipped on its head, incorporated into a system of self-submitted surveillance by an enigmatic AI. To quote writer Eugene Wei, “When you gaze into TikTok, TikTok gazes into you.”</p>\n<blockquote><p><i>@anabellejohnston</i></p><p><i>I realized I was queer when I kissed a girl at tennis camp at the age of thirteen. (Or rather, when she kissed me and I liked it.) Although I felt different than I did seven seconds before, no one around me could tell that I had changed. In true Gen-Z fashion, I turned to the internet to learn what queer people looked like and how they went about finding each other. After concluding a pixie-cut would be the surest way to subtly scream “I’m gay,” I spent most of the following years searching for other queer people. I floated through GSA, cuffed my jeans, and eventually “came out” to avoid the constant guessing game of interpreting furtive glances. </i></p><p><i>When I downloaded TikTok during my freshman year of college, the algorithm quickly clocked me. The steady stream of videos about thrifted clothing, cottagecore, and Phoebe Bridgers—along with explicit hashtags such as #wlw (women loving women) and #bisexual—loudly let me know: you’re on “gay TikTok.” But could I call this a “queer community?” The idea of queerness that I stumbled upon was completely disembodied; divorced, even, from sexual identity. It had been optimized—boiled down to a specific sartorial aesthetic, hashtag, and list of micro identity labels—all in the name of being maximally legible to a machine learning algorithm. </i></p><p><i>In some ways, I felt seen. But not entirely. While “gay TikTok” served me hashtags like #FemmeBoyFriday—which compiles videos of presumably straight boys dressing up in skirts and dresses for views and cultural caché—what was missing was the forlorn glances, sweaty palms, awkward pauses, terrible first kisses; the stumbling inherent to self-discovery. Meanwhile, a popular meme illustrates the other perspective: “When she start rubbin’ on your thighs but you only gay on TikTok.” </i></p></blockquote>\n<p>We will never intimately know a pre-internet queerness. By the time we reached adolescence, Tumblr was already in decline. While we recognize and appreciate the sacrifices made by previous generations that have given us the freedom to be visibly queer, it’s difficult not to romanticize prior forms of queer community, be they in physical or cyberspace. The way those spaces preserved the agency of queer people feels particularly significant. </p>\n<p>Ultimately, TikTok’s algorithm has one goal: to hold our attention long enough to serve us more ads. The organic formation of “gay TikTok”—and all the content niches—likely serve those same business goals. There’s agency in finding community and meaning in each other’s content, as queer people have been doing with commercial media for decades. Still, there’s an unsettling imbalance of power: while TikTok learns things about us that we may not even share with close friends, its own inner workings are inscrutable. The app can see us, but we can’t see it back. </p>\n<p>This opacity has already proved concerning. In 2019, an investigation by German publication <i>Netzpolitik</i> found that, in certain countries, TikTok had established a list of “special users” (queer, disabled, and fat people) whose videos were regarded as a “bullying risk” by default and capped in their reach, regardless of content. TikTok claims the list has since been retired. Still, the app’s algorithm and affordances automate and shape the ongoing co-production of what it means—and how it looks—to be queer in ways we can’t fully control or discern. </p>\n<p>For many young people, TikTok serves as more than an app; often, it’s a site of self-discovery. And the pressure to fit into a prescribed image of queerness can easily lead you astray. But our forebears remind us that queerness is about self-definition and the freedom to continually redefine. In <i>Cruising Utopia: The Then and There of Queer Futurity</i>, José Esteban Muñoz warns against the way that pop culture representations of queerness ossify it, writing, “What we will really know of queerness, does not yet exist.” In other words, while the algorithm may be able to determine what we like, we can’t let it define who we are or predict who we will become.</p>",
      "content_text": "@gucaslelfond“I’m so confused because there is this girl who is really pretty and nice and such a genuine person and I want to be friends with her but I’m really nervous?” narrates a freckled, teenaged-looking girl. “Weird. It’s almost like I like her but I’m not gay, so I don’t get it.” She shows the pages of an old notebook as a caption completes the joke: “Reading my ‘straight’ diary from middle school LMAO.”I’d spent a few weeks on TikTok by this point, consistently amazed by how quickly the app seemed to sense my taste. We know little about how TikTok’s algorithm works. A cagey corporate blog post titled “How TikTok recommends videos #ForYou” mostly just explains that it watches the way you engage and gradually tailors the stream of videos to your interests. My feed had already begun to fill with “queer” content—music from queer artists, videos of queer couples, and the like—but nothing explicitly about identity. This video took me by surprise. By this point, I had a vague notion that I was attracted to men, but had only shared this with a few close friends. I still felt confused and ashamed. I’d just begun to think about how my potential queerness may have played into previous friendships—when the video showed up in my feed, I surged with a sense of uncanny recognition. Suddenly, TikTok seemed like a portal, a place where I could more firmly figure out who I was. At the same time, I felt deeply uneasy. As videos about queerness became more common on my feed, I started to feel uncomfortably exposed: How could TikTok know I was bisexual before I fully knew it myself? \nFor decades, queer people in the United States have been subjected to surveillance. In 1950, Congress issued a report titled “Employment of Homosexuals and Other Sex Perverts in Government” after covertly investigating federal employees’ sexual orientation. The report declared homosexuality a mental illness and homosexuals a national security risk; employees suspected to be gay were immediately terminated. The practice was common among private employers, too. Although some states eventually had statutes prohibiting employment discrimination on the basis of sexual orientation, it wasn’t federally outlawed until June 2020. \nOf course, the monitoring also extended to social spaces. Throughout the ’60s, police raids were a frequent ritual of the queer New York nightlife scene. Police officers regularly lined up gender-nonconforming folks and sent those who failed to wear the mandated three pieces of “gender appropriate clothing” to jail. And trans people are still subjected to such scrutiny on a daily basis—in the bathroom, on the playing field, at TSA. \nIn this environment, queer people have long worked to craft subtle ways of controlling their own visibility, signaling queerness to each other while remaining undercover to the mainstream. You can see it in customs like the “hanky code” of the ’70s, by which gay men used a system of colored bandanas to covertly flag their sexual preferences. By the ’80s, some of those symbols—the rainbow flag, the pink triangle, the lowercase lambda—became well-known markers of the rising gay liberation movement. Meanwhile, queer people were still seeking intimacy in out-of-view venues—bars, parks, piers. They found community after dark in liminal urban spaces, communicating through lingering eye contact, subtle head nods, the slight twitch of a knowing smile. \nOnce the digital age arrived, internet anonymity supplanted the cover of night. Sites like Tumblr and Reddit acted as queer watering holes, as teens across the world poured themselves into blog posts and suggestive GIFs that allowed them to safely bare their souls and build community across distance. In these instances, the platforms were just that—platforms, on which queer people could, using re-blogs and upvotes, determine what mattered to them.\nNow, that brings us to TikTok, perhaps our generation’s closest analogue to those earlier platforms and venues. We imagine, however, that something is missing. We’re still finding community and expressing ourselves through shared signals, and (through monitored engagement) by choosing what becomes popular. But ultimately, on TikTok, it’s the algorithm that decides what gets seen and what doesn’t—when we’re visible, and to whom. The practice of coding once intended to maintain discretion has been flipped on its head, incorporated into a system of self-submitted surveillance by an enigmatic AI. To quote writer Eugene Wei, “When you gaze into TikTok, TikTok gazes into you.”\n@anabellejohnstonI realized I was queer when I kissed a girl at tennis camp at the age of thirteen. (Or rather, when she kissed me and I liked it.) Although I felt different than I did seven seconds before, no one around me could tell that I had changed. In true Gen-Z fashion, I turned to the internet to learn what queer people looked like and how they went about finding each other. After concluding a pixie-cut would be the surest way to subtly scream “I’m gay,” I spent most of the following years searching for other queer people. I floated through GSA, cuffed my jeans, and eventually “came out” to avoid the constant guessing game of interpreting furtive glances. When I downloaded TikTok during my freshman year of college, the algorithm quickly clocked me. The steady stream of videos about thrifted clothing, cottagecore, and Phoebe Bridgers—along with explicit hashtags such as #wlw (women loving women) and #bisexual—loudly let me know: you’re on “gay TikTok.” But could I call this a “queer community?” The idea of queerness that I stumbled upon was completely disembodied; divorced, even, from sexual identity. It had been optimized—boiled down to a specific sartorial aesthetic, hashtag, and list of micro identity labels—all in the name of being maximally legible to a machine learning algorithm. In some ways, I felt seen. But not entirely. While “gay TikTok” served me hashtags like #FemmeBoyFriday—which compiles videos of presumably straight boys dressing up in skirts and dresses for views and cultural caché—what was missing was the forlorn glances, sweaty palms, awkward pauses, terrible first kisses; the stumbling inherent to self-discovery. Meanwhile, a popular meme illustrates the other perspective: “When she start rubbin’ on your thighs but you only gay on TikTok.” \nWe will never intimately know a pre-internet queerness. By the time we reached adolescence, Tumblr was already in decline. While we recognize and appreciate the sacrifices made by previous generations that have given us the freedom to be visibly queer, it’s difficult not to romanticize prior forms of queer community, be they in physical or cyberspace. The way those spaces preserved the agency of queer people feels particularly significant. \nUltimately, TikTok’s algorithm has one goal: to hold our attention long enough to serve us more ads. The organic formation of “gay TikTok”—and all the content niches—likely serve those same business goals. There’s agency in finding community and meaning in each other’s content, as queer people have been doing with commercial media for decades. Still, there’s an unsettling imbalance of power: while TikTok learns things about us that we may not even share with close friends, its own inner workings are inscrutable. The app can see us, but we can’t see it back. \nThis opacity has already proved concerning. In 2019, an investigation by German publication Netzpolitik found that, in certain countries, TikTok had established a list of “special users” (queer, disabled, and fat people) whose videos were regarded as a “bullying risk” by default and capped in their reach, regardless of content. TikTok claims the list has since been retired. Still, the app’s algorithm and affordances automate and shape the ongoing co-production of what it means—and how it looks—to be queer in ways we can’t fully control or discern. \nFor many young people, TikTok serves as more than an app; often, it’s a site of self-discovery. And the pressure to fit into a prescribed image of queerness can easily lead you astray. But our forebears remind us that queerness is about self-definition and the freedom to continually redefine. In Cruising Utopia: The Then and There of Queer Futurity, José Esteban Muñoz warns against the way that pop culture representations of queerness ossify it, writing, “What we will really know of queerness, does not yet exist.” In other words, while the algorithm may be able to determine what we like, we can’t let it define who we are or predict who we will become.",
      "date_published": "2021-11-10T22:02:43.000Z",
      "date_modified": "2021-11-10T22:02:43.000Z",
      "_plugin": {
        "pageFilename": "3a06907c26a6838958bbbab7a6c1854217b3cb9f97774640fa889f982b8dddc8.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/youth-of-today-jasmine-sun-jasmine-wang-alan-luo-on-coming-of-age-in-silicon",
      "url": "https://logicmag.io/kids/youth-of-today-jasmine-sun-jasmine-wang-alan-luo-on-coming-of-age-in-silicon",
      "title": "Youth of Today: Jasmine Sun, Jasmine Wang, Alan Luo on Coming of Age in Silicon Valley",
      "summary": "A conversation about learning to speak the languages of Big Tech.",
      "content_html": "<p><i>Coming of age is never easy, but coming of age in Silicon Valley is especially weird. Between applying for Thiel Fellowships, courting VCs, and getting recruited by Palantir at the career fair, today’s young tech workers are entering a world deeply marked by the previous generation’s mistakes. But they’re also joining the industry at a time of genuine disruption, with business as usual facing challenges from below. Unprecedented numbers of tech workers are organizing their workplaces and new algorithmic justice movements are achieving real victories. What does that mean for young people going into tech?</i></p>\n<p><i>Reboot is a publication and community for young technologists, primarily students and new graduates. Its aspiration is to reclaim techno-optimism from the techno-utopians—a counterpoint to the endless parade of “tech for good” initiatives, where solving systemic crises is only ever an app away. We sat down with some members of </i>Reboot<i>—Jasmine Sun, Jasmine Wang, and Alan Luo—to help understand how the next generation of tech workers sees their work and their future. We talked about lying to VCs, learning to “pass” in Silicon Valley, and how to find a sense of agency in a world of crisis.</i></p>\n<p><b>Let’s start by having each of you introduce yourself. </b></p>\n<p><b>Jasmine Sun (JS):</b> I’m currently a tech worker at a startup. I grew up around the tech industry on the Eastside of Seattle, but I was always more interested in the humanities and social sciences. Then I went to Stanford and got immersed in Silicon Valley. I was shocked by the amount of money and power and prestige flowing through the Valley and ending up in the hands of very young people—even some of my freshman-year classmates. Often, the young people didn’t know what to do with all that responsibility. But it also felt like an opportunity to me. I had an interest in social justice, and while I was initially interested in going into academia or law, I started to think it would be higher leverage to apply that interest in social justice to the tech world.</p>\n<p><b>Jasmine Wang (JW):</b> I was born and raised in Alberta, Canada. The main industries there are oil and gas and agriculture—no tech. There were no computer science classes offered in my K-12, except for a typing class in elementary school, and a class in junior high where I learned how to use Google Drive, if those count. In university, I started out studying comparative literature and doing nonprofit work. I went to my first hackathon in my first semester and built a website for the nonprofit I had founded. I was really moved by the scale at which people were dreaming in technology, as well as seminal texts I was reading in the digital humanities class I was taking, and it was an easy decision to transfer into computer science the next semester. I had the sense that I needed to move to Silicon Valley to have a real pulse on things, and worked hard to get internships there, and ended up living in the area for about two years all together. It very much felt like I came of age in the Valley—a lot of my worldview and value systems were deeply formed by that experience. </p>\n<p><b>Alan Luo (AL): </b>I started programming at a young age. I was always interested in making video games because I played them growing up. My first exposure to the industry was when I published something that I made on Reddit, and it went a bit viral on Hacker News. It was this program that you could use to generate art. Then someone reached out to me to ask whether I wanted to freelance for them. So that was my first job in high school. What immediately struck me was how much money I was receiving for the work I was doing—there was nothing else like it. So then I went to Columbia, and did one year there before the pandemic hit. </p>\n<p><b>Jasmine (Wang), you said you founded a company. What was that experience like for you? There’s a lot of cultural emphasis in Silicon Valley on the young founder. How did you navigate that?</b></p>\n<p><b>JW: </b>Founding is an interesting thing. When you are a founder, the mission of the company has to be your personal mission. You are not able to recruit talented people or get venture investors on your side if you can’t convince them that you’re going to put the best ten years of your life into a company. You have to bleed, sweat, and die for this thing to exist. You need to persuade everyone that your startup is deeply aligned with your value system and worldview, or people won’t take a bet on you. </p>\n<p>I think it’s deeply unhealthy. I think it has caused a lot of mental health problems that founders are not able to talk about, because it would hurt their prospects at raising another round and hiring people, not to mention keeping bread on the table. That’s the thing: as an employee, you can just show up and do the job, to pay the bills. As a founder, you still have to pay the bills, but you can’t divorce yourself from your work on an ideological level. Even if you’re super burnt out, you can’t check out—you have to keep performing that founder role. This wasn’t the case for me, but I imagine that for younger founders labeled as some sort of wunderkind that this dynamic would be even more damaging—especially if the company fails, as most do.</p>\n<p><b>AL: </b>The way people view you affects how you raise money. That is definitely true.</p>\n<p><b>JW:</b> I remember a conversation I had with a mentor of mine where I told her, “I only want to say things that are true.” To me, words and language are almost the only things that we have; they’re so precious. They’re how we dream and make commitments to each other. And my mentor laughed at me, in all kindness. She said, “Never start a company. You will constantly have to say things that are not true to you, if that is what is required for the company to exist.” There’s also actual danger with saying things that are not true to you—the cognitive dissonance is so painful that you shift your self-concept for saying those words to make sense. It’s the same reason why manipulation tricks, like getting someone to do a favor for you to make them like you, work.</p>\n<p><b>JS: </b>I am uncomfortable with lying in general, even when it isn’t harmful, or if it’s just an exaggeration. I had a couple of advisory conversations recently where I was asked whether I would ever do <i>Reboot</i> full-time as a nonprofit. I told them, “Oh, I feel like I couldn’t get the money to do it.” And they were like, “No, you can get the money, that’s easy. But in order to get the money, you have to say you’re gonna scale <i>Reboot</i> to 20,000 people and 200 schools.” On the subway home, I was just like, do I want those things? Would I enjoy the version of <i>Reboot</i> where I was trying to scale it 100 times? </p>\n<p><b>JW:</b> I want to make a distinction. When I use the word “lying,” I mean saying things that are not true to one’s self. And this doesn’t have to be an outright lie. It can be something that is factually true, but misaligned with who you are. </p>\n<p>I remember calling some friends as I was getting ready to raise a round. Their advice was: “Act like Mark Zuckerberg.” Apparently Mark had a reputation of being disrespectful to VCs and telling them he didn’t need their money. That shocked me. And I think it’s because being disrespectful goes against my core values. I’ve never intentionally disrespected someone. And also, I couldn’t imagine telling VCs I didn’t need their money. What a concept. Of course I need their money! What sort of world are you coming from? Like, how can you not need money? And then I was looking at Zuckerberg and realized, oh yeah, his dad gave him a $100,000 loan to help start Facebook. He didn’t need other people’s money—at least not in a food-on-the-table type way.</p>\n<h1>Second Languages</h1>\n<p><b>You all had to learn to present yourself a certain way in order to be maximally appealing to the gatekeepers of the industry, whether it was VCs who might fund your startup or companies that might hire you. But how did you learn to perform these roles? Was it just a process of trial-and-error, or was there a more systematic way that you taught yourself the cultural protocols of the Valley? </b></p>\n<p><b>JS: </b>When I first got to college I had imposter syndrome, because I met so many people who were child prodigies. They were on magazine covers. I hadn’t done anything. I felt depressed. I also noticed that everyone in Silicon Valley was speaking a language that I didn’t understand. Like literally, I didn’t know what the words meant. So for a year I read a bunch of books that seemed to be the Silicon Valley canon: <i>Zero to One</i> by Peter Thiel, <i>The Hard Thing About Hard Things</i> by Ben Horowitz, <i>Hackers: Heroes of the Computer Revolution</i> by Steven Levy, <i>Radical Candor </i>by Kim Scott. I read whatever I thought other people were reading. Because I didn’t have a network yet—I didn’t have a way to learn directly from other people. But I wanted to know how the Valley thought.</p>\n<p><b>JW:</b> I didn’t know anybody in the Bay Area when I came here. I didn’t even know what books I was supposed to read. So I joined as many different communities as I could. I thought they could give me what I was missing. It can be hard to find that information, because there are so many limits in terms of what is chronicled. Most of the stories about Silicon Valley are written by very particular people who live very particular sorts of lives. There are so many stories that are not chronicled, like those of women and people of color. So you have to go find those stories in different contexts—more high-trust contexts, not public forums but Signal and phone calls.</p>\n<p>Ultimately, I felt like I had to learn the right language to pass in the Valley. A lot of what you need to know is what you’re <i>not</i> supposed to talk about. In tech, you don’t really talk about money or power. Everyone’s default is, “I have no idea how much anyone earns.” Everyone dresses approximately the same and lives in approximately the same way. But some people wield much more power—orders of magnitude more. </p>\n<p><b>AL: </b>A lot of queer culture is oriented around being very “out.” But something’s at stake, so you might want to twist your words to get what’s best for the company. I don’t know if I care about participating in mainstream queer culture anymore, because it’s just not made for Asians. I want to be representing me, I don’t want to be queer for the sake of being queer. So if there is a version of like, Sino-queerness, which draws from traditions of Taoism and the existence of two spirits within the body or whatever, that’s the version I want to be creating. </p>\n<h1>The Bamboo Ceiling</h1>\n<p><b>JW: </b>Technologists are told that they only need technical competence, which is incidentally convenient for the bureaucratic governing class. This is perpetuated by the model minority myth, which says you only need to be good at STEM to have a good life, and that to be a good citizen you should keep your mouth closed. But the reality is that those skills only go so far. People talk more about the “bamboo ceiling,” but it’s always been there: Chinese-Americans might have technical competence, but they often don’t have the social capital needed to rise into C-level positions. Those are positions that require a lot of networking, a lot of buy-in, and often build off of generational privilege. Seeing which founders get funded and what they look like—that’s all about social capital, not engineering prowess. But then you look at those founders’ engineering teams and it’s a very different demographic makeup.</p>\n<p><b>JS: </b>My mom told me many times, “If you’re good at math, you’ll be good at everything.” I’m not good at math. And I had a lot of issues around my failure to be good at math growing up. It made me feel like I was failing in general, because my parents, and all their friends, and all their friends’ kids, were good at math. </p>\n<p>But yeah, the reason Asian kids get ushered into STEM careers, like being a doctor or being an engineer, is because you usually don’t need social or cultural capital to succeed in those roles. There’s a certain set of things you need to learn to join those professions, and they’re open knowledge. You go on LeetCode [an online programming education platform] or you study for the MCAT. There’s not too many hidden codes about how to get those sorts of jobs.</p>\n<p>Whereas being a VC is 100 percent hidden codes. There’s no playbook on how to get into VC. And if you don’t speak English well, or even if you just don’t know the social landscape, you can’t break in. I remember when I learned about cold emailing my freshman year of college. It blew my mind. I had no idea you could just email somebody and they would respond, because I couldn’t understand why they would talk to me. Now I love cold emailing—it’s the best thing invented. But you need that confidence. </p>\n<p>The reason that I’m so interested in sociology is because I have been so baffled by the non-explicit networks and the other social components that go into creating technology products. Silicon Valley claims that it’s all about technology, that the product sells itself. But Silicon Valley is where I learned how much networking mattered, and how much it mattered to speak a language—which is very incongruent with what the Valley tells itself. </p>\n<p><b>JW: </b>My mother spent her entire life programming and she remained just an IC [individual contributor], and was never promoted. Once, she was fired out of the blue. It was simple to swap in another engineer for her. It seems much harder to swap out a general partner at a venture firm. That person’s power is rooted in relationships that are harder to build—less fungible. You can build technical skills by yourself, but social capital is predicated on so many other things. Who do you know? Where did you grow up? Do people like the sort of person that you are? Do you ‘pass’ to them as someone who’s in their social class? Are you able to afford the hobbies that give you access to the right people? In the Valley, people go to Equinox, Barry’s, and Burning Man—there’s all these stories about founders and VCs meeting at Burning Man. It costs thousands of dollars to sustain that lifestyle. So all these invisible things that accrue social capital take a lot of real capital and time to build. If you’re building technical skills, you can literally sit on your computer and do it alone in your room, and then go somewhere and get employed. But that also makes it less robust, in some sense.</p>\n<h1>Coming of Age</h1>\n<p><b>JW: </b>Broadly, what we’re talking about here is coming of age. Some of the questions we’re struggling with are the same ones that young people have been struggling with forever. “What are my values?” “How do I prioritize between those values in order to ensure my personal stability and the stability of the work that I feel like I need to do?” “What conflicts do I attend to?” “How do I take care of and steward the lineages that are important to me?” </p>\n<p>But we’re also asking those questions in a particular historical moment. So what’s changed for our generation? And how does technology fit in? What is unique about our time?</p>\n<p><b>AL: </b>I’ve been talking to my parents a lot. And they said, “Yeah, we knew this was going to happen, because this is what happened to our generation, when we were growing up in the Cultural Revolution. Every single one of us went through the exact same thing that you’re going through now. We started off being idealistic, and eventually realized somebody somewhere else was profiting from us.” </p>\n<p>Because I spent so much time on social media, I just didn’t talk to my parents when I was younger. I wish I had, because then I would’ve heard those stories earlier, and maybe could’ve avoided certain situations. Social media put my head elsewhere. It uprooted me from my family and my history and placed me into a strange soup of fellow Gen Z’ers. My values have been shaped by that soup, not my parents or my lineage.</p>\n<p><b>JS: </b>I’ve been moving in the opposite direction when it comes to idealism. I was not idealistic for the vast majority of my life. I am a skeptic, and critic, by default. I think it has to do with coming of age while reading and being influenced by a left-wing academic world that has a lot of pessimism and negativity. In that world, the assumption is that anything you build is going to get co-opted. Everything fails, so there’s no future possible unless we burn it all down. And we probably can’t burn it all down. </p>\n<p>I feel grateful to that world, because it gave me the capacity to understand power and systems. At the same time, it deprived me of a sense of personal agency because it doesn’t believe that things are worth trying. I see the same hopelessness in many of my friends and peers. They feel disillusioned by Big Tech—or really, by capitalism. They’re not very happy on a day-to-day basis. They’re depressed about climate change but feel they can’t do anything about it. Or they hate their job and think the company they work for is terrible for the world. But they also need to pay rent and have no idea what else to do. I also have friends who go into academia. And when I ask them why they’re doing it, they say, “Harm mitigation.” I’ve heard this from multiple friends. They’re like, “Every job is so flawed—it’s either the private sector or the nonprofit industrial complex. So I’m just going to go into academia, because I know that the university is not perfect, either. But it feels like it does the least harm.” </p>\n<p>It’s a very pessimistic point of view. I want to reclaim a sense of agency. I think we need more idealism.</p>",
      "content_text": "Coming of age is never easy, but coming of age in Silicon Valley is especially weird. Between applying for Thiel Fellowships, courting VCs, and getting recruited by Palantir at the career fair, today’s young tech workers are entering a world deeply marked by the previous generation’s mistakes. But they’re also joining the industry at a time of genuine disruption, with business as usual facing challenges from below. Unprecedented numbers of tech workers are organizing their workplaces and new algorithmic justice movements are achieving real victories. What does that mean for young people going into tech?\nReboot is a publication and community for young technologists, primarily students and new graduates. Its aspiration is to reclaim techno-optimism from the techno-utopians—a counterpoint to the endless parade of “tech for good” initiatives, where solving systemic crises is only ever an app away. We sat down with some members of Reboot—Jasmine Sun, Jasmine Wang, and Alan Luo—to help understand how the next generation of tech workers sees their work and their future. We talked about lying to VCs, learning to “pass” in Silicon Valley, and how to find a sense of agency in a world of crisis.\nLet’s start by having each of you introduce yourself. \nJasmine Sun (JS): I’m currently a tech worker at a startup. I grew up around the tech industry on the Eastside of Seattle, but I was always more interested in the humanities and social sciences. Then I went to Stanford and got immersed in Silicon Valley. I was shocked by the amount of money and power and prestige flowing through the Valley and ending up in the hands of very young people—even some of my freshman-year classmates. Often, the young people didn’t know what to do with all that responsibility. But it also felt like an opportunity to me. I had an interest in social justice, and while I was initially interested in going into academia or law, I started to think it would be higher leverage to apply that interest in social justice to the tech world.\nJasmine Wang (JW): I was born and raised in Alberta, Canada. The main industries there are oil and gas and agriculture—no tech. There were no computer science classes offered in my K-12, except for a typing class in elementary school, and a class in junior high where I learned how to use Google Drive, if those count. In university, I started out studying comparative literature and doing nonprofit work. I went to my first hackathon in my first semester and built a website for the nonprofit I had founded. I was really moved by the scale at which people were dreaming in technology, as well as seminal texts I was reading in the digital humanities class I was taking, and it was an easy decision to transfer into computer science the next semester. I had the sense that I needed to move to Silicon Valley to have a real pulse on things, and worked hard to get internships there, and ended up living in the area for about two years all together. It very much felt like I came of age in the Valley—a lot of my worldview and value systems were deeply formed by that experience. \nAlan Luo (AL): I started programming at a young age. I was always interested in making video games because I played them growing up. My first exposure to the industry was when I published something that I made on Reddit, and it went a bit viral on Hacker News. It was this program that you could use to generate art. Then someone reached out to me to ask whether I wanted to freelance for them. So that was my first job in high school. What immediately struck me was how much money I was receiving for the work I was doing—there was nothing else like it. So then I went to Columbia, and did one year there before the pandemic hit. \nJasmine (Wang), you said you founded a company. What was that experience like for you? There’s a lot of cultural emphasis in Silicon Valley on the young founder. How did you navigate that?\nJW: Founding is an interesting thing. When you are a founder, the mission of the company has to be your personal mission. You are not able to recruit talented people or get venture investors on your side if you can’t convince them that you’re going to put the best ten years of your life into a company. You have to bleed, sweat, and die for this thing to exist. You need to persuade everyone that your startup is deeply aligned with your value system and worldview, or people won’t take a bet on you. \nI think it’s deeply unhealthy. I think it has caused a lot of mental health problems that founders are not able to talk about, because it would hurt their prospects at raising another round and hiring people, not to mention keeping bread on the table. That’s the thing: as an employee, you can just show up and do the job, to pay the bills. As a founder, you still have to pay the bills, but you can’t divorce yourself from your work on an ideological level. Even if you’re super burnt out, you can’t check out—you have to keep performing that founder role. This wasn’t the case for me, but I imagine that for younger founders labeled as some sort of wunderkind that this dynamic would be even more damaging—especially if the company fails, as most do.\nAL: The way people view you affects how you raise money. That is definitely true.\nJW: I remember a conversation I had with a mentor of mine where I told her, “I only want to say things that are true.” To me, words and language are almost the only things that we have; they’re so precious. They’re how we dream and make commitments to each other. And my mentor laughed at me, in all kindness. She said, “Never start a company. You will constantly have to say things that are not true to you, if that is what is required for the company to exist.” There’s also actual danger with saying things that are not true to you—the cognitive dissonance is so painful that you shift your self-concept for saying those words to make sense. It’s the same reason why manipulation tricks, like getting someone to do a favor for you to make them like you, work.\nJS: I am uncomfortable with lying in general, even when it isn’t harmful, or if it’s just an exaggeration. I had a couple of advisory conversations recently where I was asked whether I would ever do Reboot full-time as a nonprofit. I told them, “Oh, I feel like I couldn’t get the money to do it.” And they were like, “No, you can get the money, that’s easy. But in order to get the money, you have to say you’re gonna scale Reboot to 20,000 people and 200 schools.” On the subway home, I was just like, do I want those things? Would I enjoy the version of Reboot where I was trying to scale it 100 times? \nJW: I want to make a distinction. When I use the word “lying,” I mean saying things that are not true to one’s self. And this doesn’t have to be an outright lie. It can be something that is factually true, but misaligned with who you are. \nI remember calling some friends as I was getting ready to raise a round. Their advice was: “Act like Mark Zuckerberg.” Apparently Mark had a reputation of being disrespectful to VCs and telling them he didn’t need their money. That shocked me. And I think it’s because being disrespectful goes against my core values. I’ve never intentionally disrespected someone. And also, I couldn’t imagine telling VCs I didn’t need their money. What a concept. Of course I need their money! What sort of world are you coming from? Like, how can you not need money? And then I was looking at Zuckerberg and realized, oh yeah, his dad gave him a $100,000 loan to help start Facebook. He didn’t need other people’s money—at least not in a food-on-the-table type way.\nSecond Languages\nYou all had to learn to present yourself a certain way in order to be maximally appealing to the gatekeepers of the industry, whether it was VCs who might fund your startup or companies that might hire you. But how did you learn to perform these roles? Was it just a process of trial-and-error, or was there a more systematic way that you taught yourself the cultural protocols of the Valley? \nJS: When I first got to college I had imposter syndrome, because I met so many people who were child prodigies. They were on magazine covers. I hadn’t done anything. I felt depressed. I also noticed that everyone in Silicon Valley was speaking a language that I didn’t understand. Like literally, I didn’t know what the words meant. So for a year I read a bunch of books that seemed to be the Silicon Valley canon: Zero to One by Peter Thiel, The Hard Thing About Hard Things by Ben Horowitz, Hackers: Heroes of the Computer Revolution by Steven Levy, Radical Candor by Kim Scott. I read whatever I thought other people were reading. Because I didn’t have a network yet—I didn’t have a way to learn directly from other people. But I wanted to know how the Valley thought.\nJW: I didn’t know anybody in the Bay Area when I came here. I didn’t even know what books I was supposed to read. So I joined as many different communities as I could. I thought they could give me what I was missing. It can be hard to find that information, because there are so many limits in terms of what is chronicled. Most of the stories about Silicon Valley are written by very particular people who live very particular sorts of lives. There are so many stories that are not chronicled, like those of women and people of color. So you have to go find those stories in different contexts—more high-trust contexts, not public forums but Signal and phone calls.\nUltimately, I felt like I had to learn the right language to pass in the Valley. A lot of what you need to know is what you’re not supposed to talk about. In tech, you don’t really talk about money or power. Everyone’s default is, “I have no idea how much anyone earns.” Everyone dresses approximately the same and lives in approximately the same way. But some people wield much more power—orders of magnitude more. \nAL: A lot of queer culture is oriented around being very “out.” But something’s at stake, so you might want to twist your words to get what’s best for the company. I don’t know if I care about participating in mainstream queer culture anymore, because it’s just not made for Asians. I want to be representing me, I don’t want to be queer for the sake of being queer. So if there is a version of like, Sino-queerness, which draws from traditions of Taoism and the existence of two spirits within the body or whatever, that’s the version I want to be creating. \nThe Bamboo Ceiling\nJW: Technologists are told that they only need technical competence, which is incidentally convenient for the bureaucratic governing class. This is perpetuated by the model minority myth, which says you only need to be good at STEM to have a good life, and that to be a good citizen you should keep your mouth closed. But the reality is that those skills only go so far. People talk more about the “bamboo ceiling,” but it’s always been there: Chinese-Americans might have technical competence, but they often don’t have the social capital needed to rise into C-level positions. Those are positions that require a lot of networking, a lot of buy-in, and often build off of generational privilege. Seeing which founders get funded and what they look like—that’s all about social capital, not engineering prowess. But then you look at those founders’ engineering teams and it’s a very different demographic makeup.\nJS: My mom told me many times, “If you’re good at math, you’ll be good at everything.” I’m not good at math. And I had a lot of issues around my failure to be good at math growing up. It made me feel like I was failing in general, because my parents, and all their friends, and all their friends’ kids, were good at math. \nBut yeah, the reason Asian kids get ushered into STEM careers, like being a doctor or being an engineer, is because you usually don’t need social or cultural capital to succeed in those roles. There’s a certain set of things you need to learn to join those professions, and they’re open knowledge. You go on LeetCode [an online programming education platform] or you study for the MCAT. There’s not too many hidden codes about how to get those sorts of jobs.\nWhereas being a VC is 100 percent hidden codes. There’s no playbook on how to get into VC. And if you don’t speak English well, or even if you just don’t know the social landscape, you can’t break in. I remember when I learned about cold emailing my freshman year of college. It blew my mind. I had no idea you could just email somebody and they would respond, because I couldn’t understand why they would talk to me. Now I love cold emailing—it’s the best thing invented. But you need that confidence. \nThe reason that I’m so interested in sociology is because I have been so baffled by the non-explicit networks and the other social components that go into creating technology products. Silicon Valley claims that it’s all about technology, that the product sells itself. But Silicon Valley is where I learned how much networking mattered, and how much it mattered to speak a language—which is very incongruent with what the Valley tells itself. \nJW: My mother spent her entire life programming and she remained just an IC [individual contributor], and was never promoted. Once, she was fired out of the blue. It was simple to swap in another engineer for her. It seems much harder to swap out a general partner at a venture firm. That person’s power is rooted in relationships that are harder to build—less fungible. You can build technical skills by yourself, but social capital is predicated on so many other things. Who do you know? Where did you grow up? Do people like the sort of person that you are? Do you ‘pass’ to them as someone who’s in their social class? Are you able to afford the hobbies that give you access to the right people? In the Valley, people go to Equinox, Barry’s, and Burning Man—there’s all these stories about founders and VCs meeting at Burning Man. It costs thousands of dollars to sustain that lifestyle. So all these invisible things that accrue social capital take a lot of real capital and time to build. If you’re building technical skills, you can literally sit on your computer and do it alone in your room, and then go somewhere and get employed. But that also makes it less robust, in some sense.\nComing of Age\nJW: Broadly, what we’re talking about here is coming of age. Some of the questions we’re struggling with are the same ones that young people have been struggling with forever. “What are my values?” “How do I prioritize between those values in order to ensure my personal stability and the stability of the work that I feel like I need to do?” “What conflicts do I attend to?” “How do I take care of and steward the lineages that are important to me?” \nBut we’re also asking those questions in a particular historical moment. So what’s changed for our generation? And how does technology fit in? What is unique about our time?\nAL: I’ve been talking to my parents a lot. And they said, “Yeah, we knew this was going to happen, because this is what happened to our generation, when we were growing up in the Cultural Revolution. Every single one of us went through the exact same thing that you’re going through now. We started off being idealistic, and eventually realized somebody somewhere else was profiting from us.” \nBecause I spent so much time on social media, I just didn’t talk to my parents when I was younger. I wish I had, because then I would’ve heard those stories earlier, and maybe could’ve avoided certain situations. Social media put my head elsewhere. It uprooted me from my family and my history and placed me into a strange soup of fellow Gen Z’ers. My values have been shaped by that soup, not my parents or my lineage.\nJS: I’ve been moving in the opposite direction when it comes to idealism. I was not idealistic for the vast majority of my life. I am a skeptic, and critic, by default. I think it has to do with coming of age while reading and being influenced by a left-wing academic world that has a lot of pessimism and negativity. In that world, the assumption is that anything you build is going to get co-opted. Everything fails, so there’s no future possible unless we burn it all down. And we probably can’t burn it all down. \nI feel grateful to that world, because it gave me the capacity to understand power and systems. At the same time, it deprived me of a sense of personal agency because it doesn’t believe that things are worth trying. I see the same hopelessness in many of my friends and peers. They feel disillusioned by Big Tech—or really, by capitalism. They’re not very happy on a day-to-day basis. They’re depressed about climate change but feel they can’t do anything about it. Or they hate their job and think the company they work for is terrible for the world. But they also need to pay rent and have no idea what else to do. I also have friends who go into academia. And when I ask them why they’re doing it, they say, “Harm mitigation.” I’ve heard this from multiple friends. They’re like, “Every job is so flawed—it’s either the private sector or the nonprofit industrial complex. So I’m just going to go into academia, because I know that the university is not perfect, either. But it feels like it does the least harm.” \nIt’s a very pessimistic point of view. I want to reclaim a sense of agency. I think we need more idealism.",
      "date_published": "2021-11-03T16:15:57.000Z",
      "date_modified": "2021-11-03T16:15:57.000Z",
      "_plugin": {
        "pageFilename": "a4a5e8138b0f1438a986e0c8ad22a44b508ce5e0bf6ccdbbeea87fabaff21b6c.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/being-sad-on-the-internet-ysabel-gerrard-on-what-young-people-do-online",
      "url": "https://logicmag.io/kids/being-sad-on-the-internet-ysabel-gerrard-on-what-young-people-do-online",
      "title": "Being Sad on the Internet: Ysabel Gerrard on What Young People Do Online",
      "summary": "How do you do, fellow kids?",
      "content_html": "<p><i>What are kids doing on the internet, and what is the internet doing to them? These questions have preoccupied parents, teachers, and the media for decades. But all too often the conversation is clouded with condescension and panic. Obviously, there are issues here worth exploring, and we wanted to find a way to do so without indulging in the usual caricatures and fear mongering. So </i>Logic<i> editor Ben Tarnoff spoke with Ysabel Gerrard, a lecturer in Digital Media and Society at the University of Sheffield in the United Kingdom and an expert on young people’s mental health and social media. She explained what exactly the kids are up to, and how their elders get it wrong.</i></p>\n<p>---</p>\n<p>\n<b>There’s a lot of concern out there about the effect of social media on the mental health of young people. But this concern isn’t new. It belongs to a broader historical trend. When the internet was first becoming popularized in the 1990s, the media ran a number of stories fretting about kids going online: they could access pornography, be entrapped by predators, and so on. A prominent 1998 study from Carnegie Mellon University that got a lot of attention at the time claimed that spending time online made people lonely, depressed, and antisocial. Decades later, we’re seeing similar themes in the popular narratives around young people and the internet. How would you describe the current iteration of this discourse? What are the continuities and discontinuities with the 1990s?</b></p>\n<p>The major difference is the kind of media we’re dealing with—social media. Social media enables the sharing of a greater volume and range of content (e.g., live-streamed videos, high-quality images, and so on). That said, the discourse around “kids online” today is similar to what it was in the 1990s, because we see the same lack of dedication to understanding what young people are actually doing on the internet. I speak to teachers, parents, policymakers, and I name apps they’ve never heard of. I talk about things they’ve never heard of. And I think to myself, “How can you sit there and be afraid of what kids are doing online when you haven’t fully tried to understand it?” So the internet has changed, and the kinds of things that kids are doing on the internet has changed. But the reluctance to understand what kids are actually doing—and to take seriously their pleasures, as well as the harms that might arise—has not changed. </p>\n<p><b>One continuity with the 1990s is the presence of a moral panic that prevents people from seeing clearly. If you’re in panic mode, you’re not capable of perceiving what kids are actually doing with the technology. But, as you point out, the technology itself has changed: social media has transformed the internet, as well as how kids interact with the internet.</b></p>\n<p>Exactly. I give lots of talks at schools and I’m usually invited to talk about the “dangers” of social media. But I always say, “No, that’s not my job. I can come, but I’m not going to do that.” And what I’ve found in every single school is a disconnect between how seriously the kids take the things they do online versus how seriously the adults take it. </p>\n<p>For example, most schools in the UK have a “meme account”—a social media account that posts funny memes about the school, its kids, and its teachers. It’s anonymous: schools rarely find out who set it up. Teachers usually take it very seriously: they contact the parents; sometimes they contact the police. But when you speak to the kids, they say it’s just banter, it’s just humor, it’s just fun.</p>\n<p><b>The kind of concern from elders you’re describing is often expressed in a mental health idiom—that kids shouldn’t be engaging in certain online behaviors because it’s bad for their mental health. And clearly, there are certain online behaviors that are bad for one’s mental health. For example, you’ve written extensively about social media communities that promote anorexia and other eating disorders. But sometimes the mental health frame can be stretched too far, to the point that all sorts of online behaviors are unfairly pathologized. And this can lead to counterproductive interventions by parents and other authority figures, who discipline kids for doing things that might be harmless or even beneficial. I mean, there are lot of kids out there—particularly queer kids—whose life was quite literally saved by the internet. How do you strike the right balance? How do you find a way to identify genuinely destructive behaviors online without overpathologizing?</b></p>\n<p>This question reminds me of the favorite piece of research I’ve ever done. It was for an article I wrote with Dr. Anthony McCosker, where we analyzed all the Instagram posts that were tagged as “#depressed” within a certain timeframe. One of the most fascinating things we found was that when people were having discussions related to mental health, they were using pseudonyms 76 percent of the time.</p>\n<p>In recent decades, we’ve seen a greater destigmatization of mental health. People use terms like depression much more frequently than they used to. But I wonder how far destigmatization has really gone, if 76 percent of people don’t feel comfortable talking about the lived realities of depression while using their real name. As you said, the internet can clearly be a life-saving space. And much of its power comes from the ability for people to use a pseudonym on a major platform like Instagram to talk about depression. That’s why it can be counterproductive when platforms try to enforce enhanced identification measures like real name policies.</p>\n<p><b>Real name policies are motivated, at least in part, by the idea that the ability to be anonymous or pseudonymous on the internet is a major contributor to online toxicity. But what your research reveals is that the same anonymity or pseudonymity can be a life-saver, since it enables kids to discuss mental health issues they wouldn’t feel comfortable discussing otherwise. And there may not be an obvious real-world space where they could have those discussions.</b></p>\n<p>Precisely, it’s a double-edged sword. One of the things I’m talking to kids about in my current research is how they feel about “secret-telling” apps like Secret, which let users communicate anonymously. (I should note early on that, technically, they’re communicating <i>pseudonymously</i>, since anonymity is incredibly difficult to fully achieve in practice, but I’d like to use the word “anonymous” here—because they do.) These apps have been the subject of intense scrutiny by the press and some parents, particularly due to their connection to cyberbullying. What kids often say is, “I don’t really like secret-telling apps. I think they can be toxic. They scare me. I only use them because my friends do.” And then I say, “Imagine a world where there’s no such thing as a secret-telling app. Imagine a world where there’s no such thing as anonymity. Are you happier? Are you safer?” And they go, “No, you can’t get rid of it!” </p>\n<p>What they’re telling me is, “How are my friends going to ask questions about their sexuality?” “How are my friends going to announce to the world that somebody is being racist to them and they don’t know what to do?” “How are my friends going to ask what to do when someone takes an inappropriate picture of them?” “Who else can I talk to about aspects of adolescence, like sex?”</p>\n<p>Kids need these spaces. They need to be anonymous. And that’s why—at least for the kids I spoke to in my research—they rarely use social media with their real name, instead relying on what they often call “nicknames.” So they’re simultaneously reliant on anonymity as a safety mechanism but, at the same time, they’re fearful of it. And I wonder whether they are fearful of it because they are told to be fearful of it. </p>\n<p><b>It’s clearly a good thing that young people are able to find some solace in these online spaces. But I also wish we could be supporting them better. I mean, I want them to be able to go online and have these conversations. But I also really want them to have access to professional therapy and other mental healthcare. Talking to strangers through an Instagram hashtag is fine, but it shouldn’t be the main way for kids to get help.</b></p>\n<p>Absolutely. And this is the problem with the whole “social media is bad for kids” discourse. Is it social media or is it, perhaps, rising poverty levels, global warming, or increasing polarization? Is it maybe these things as well? I hear this sort of thing from kids all the time. “Why are you so worried that we created a meme account? Why aren’t you worried that I can barely get out of bed in the morning?”</p>\n<p><b>It’s a form of victim-blaming that feels very familiar. I’m reminded of the “avocado toast” discourse: the notion that many millennials can’t afford to buy homes because they spend too much money on expensive artisanal avocado toast. Similarly, it’s easier to blame teenagers’ anxiety and depression on their use of smartphones instead of looking at the deeper issues that are causing their anxiety and depression—as well as recognizing that, in some cases, a smartphone might be the best outlet they have for dealing with the problems. Not a great one, and not nearly as good as fully funded mental health services. But it’s what they have.</b></p>\n<p>You know, “Phone Saves Teen’s Life” doesn’t make for as good a headline as “Pro-anorexia Memes Drove Girl to Death.” What is <i>The Daily Mail </i>going to publish? It’s going to be the second one. </p>\n<p>But it’s a difficult balance. People often think I’m too defensive of social media. And maybe I don’t say it enough, but yes, there are some awful things on social media. Content moderators have one of the worst jobs in the world because they have to look at diabolically bad stuff for hours and hours every day. And yes, kids have seen some of that stuff. </p>\n<p>I recognize that. But the reality is that social media is highly contextual. You need to look at how social media is being experienced by a particular person in a particular moment. It seems to me that the press in particular prefers a solid, clean-cut answer: that social media is totally fine or completely evil. But it’s neither. We need to get better at thinking of social media as something that is deeply complex. </p>\n<h1>Balancing Acts</h1>\n<p><b>You mentioned content moderators. Let’s talk a bit about how content moderation, as implemented by large tech firms, shapes the conversations that young people have about mental health in online spaces. </b></p>\n<p><b>In your 2018 article, “Community Guidelines and the Language of Eating Disorders on Social Media,” you reproduce some images of women’s bodies from Instagram and explore whether the images promote eating disorders. “Yes, the people’s bones are outlined and emphasised in the framing of the images,” you write, “but when do they become </b><b><i>too</i></b><b> bony, to the point where these images are read as the promotion of anorexia or similar?” A human content moderator, or an automated content moderation system, might have trouble looking at these images and determining definitively whether they were “pro-anorexic.” How should we think about these challenges? </b></p>\n<p>I’m on Facebook and Instagram’s Suicide and Self-Injury Advisory Board. It’s an unpaid role, and I really enjoy it. I contribute to meetings about once or twice a month, and what they generally do is give us example imagery—for example, an image of a person with a slender body and visible rib cage—and ask us how it should be moderated. But a talking point we reach in more or less every meeting is that we need far greater context: the caption, the comments, the other posts in a user’s feed, and so on.</p>\n<p>That’s something I struggle with. Nobody—no company, no moderator—should be looking at an image of a person and deciding if they are too thin or if their size promotes eating disorders. We’ve had decades and decades of feminist history, and this is the point we’ve reached! We shouldn’t be doing that to anyone of any gender. It shouldn’t be happening. </p>\n<p>What you need is context. You need the caption. You need the comments underneath. You need the qualitative data. You need a deep understanding of the situation in which that image is being used, especially when it comes to posts about mental health. And that’s why we’re always going to need humans to do the work of content moderation. We have to find ways of making their work easier, but we need them. </p>\n<p><b>To your point about context, those images of women’s bodies from Instagram might be circulating within a hashtag devoted to supporting people who are trying to overcome their eating disorders. In that context, the content might be playing a beneficial role. </b></p>\n<p>Exactly.</p>\n<p><b>But how can big tech companies afford to do that sort of nuanced, context-specific moderation at scale? It’s obviously much more time- and labor-intensive. And if you’re Facebook, you can’t maintain the profit margins that your investors demand while paying for high-quality content moderation across a social network of more than two billion people.</b></p>\n<p>Something I’ve learned from Jillian C. York and Tarleton Gillespie’s work in particular is that it’s very hard, probably impossible, to moderate content at scale. To take the example of the Instagram images, let’s say the content moderator decides that a piece of content is in fact promoting eating disorders. Okay, it breaks the rules, so what do you do? If you remove that user’s account, you’re also cutting off their support system. People often call on social media companies to do more about X, Y, and Z. But what that means in practice, given the scale at which these companies operate, is account deletions, blanket bans on hashtags, that sort of thing. </p>\n<p><b>So scale also incentivizes platforms to look for low-effort, cookie-cutter solutions when moderating content. If you’ve got lots of users and a relatively small number of overworked, underpaid content moderators, it’s easier to delete a bunch of posts or deactivate a bunch of accounts. But if someone’s having a mental health crisis online, that’s not going to do anything to address the crisis. In fact, it probably makes things worse.</b></p>\n<p>Right. Again, context matters. </p>\n<p>Another good example is the online fallout after the European football championship. Here in the UK, our team played Italy in the final. It was pretty monumental, because we haven’t been in the final for fifty-five years. The game was close. It went to a penalty shootout at the end, and the three players who missed the penalty shots were Black. The UK lost. You can only imagine the extent of racism directed at these players afterward. It was horrific. </p>\n<p>On social media, racist posts often used monkey emojis to refer to the Black players. So people began calling for social media companies to take action. Some folks asked, if you can slap a warning label on every post about Covid, why can’t you slap a warning label on every post that uses the monkey emoji to be racist?</p>\n<p>The problem is that context is everything. The same emoji or word can be racist in one context but then in another context might be a vernacular within a community. That’s why we’re always going to need humans to do content moderation. </p>\n<p>There was an interesting post on Twitter recently from a former content moderator. They were talking about how there were so few pathways for promotion and progression. Moreover, moderators at large social media companies often get no say on policy, despite the fact that they’re the ones doing the work. So yes, we need to improve their working conditions, and we need to find automated ways of taking the most traumatic content away from them. But we should also be transforming their very job description. They should become specialists in particular subject areas, so that they can better recognize context and better interpret nuanced content.</p>\n<p><b>What else do you think should be done?</b></p>\n<p>We need transparency. But we also need to be specific about the kind of transparency we’re asking for, instead of just saying to these companies, “Be transparent.” This is something I’ve learned from Nic Suzor’s work, in particular.</p>\n<p>I’ve been wrong about this issue in the past. A few years ago, I said platforms needed to publish lists of banned hashtags, because there’s a lot of discrimination present in the hashtags they ban. But often when you ban a hashtag, people just move the conversation to a different hashtag. So publishing a list of banned hashtags can make it easier for people to come up with workarounds. That’s one of the many reasons why we need to be careful with what we’re asking for when it comes to transparency. </p>\n<p>One form of transparency we really need is around content moderation guidebooks. In my view, we need to see most, if not all of the rules that content moderators are using to make decisions. It troubles me that these are hidden from the public, and therefore hidden from scrutiny. And maybe I’m being too idealistic here, but I believe it would make a big difference if researchers had access to those rules and could make evidence-based recommendations for their improvement. </p>\n<p><b>You’ve written on how feminist thought can inform our approach to content moderation, and to young people’s mental health on the internet more broadly. What in particular do you draw from the feminist tradition, and how does it bear on the question of where we should go from here? </b></p>\n<p>One of my biggest influences both in academia and in life is Dr. Carolina Are. She’s an academic, activist, and pole dance instructor, and often posts images and videos of her pole dance tutorials on social media. Carolina is constantly having her account suspended, then reinstated, then suspended, then reinstated. She gets told that she’s broken the guidelines and then, a day later, gets told it was a mistake. </p>\n<p>The reality is that social media companies often don’t know where they stand on issues like female nudity. That’s why they’re so inconsistent. What they want to do is to come up with one global rule. They want to have a single guideline about female nudity that they can globalize across the entire platform. But female nudity is an issue that is viewed so differently according to the country that you’re in, the region of the country that you’re in, the religion that you belong to. Many different elements factor into it. So, to have one international rule on an issue like that is impossible. On certain things, generalizability isn’t possible. </p>\n<p><b>If there’s one thought on the subject of mental health and young people on the internet that you’d like our readers to carry out into the world, what would it be?</b></p>\n<p>Again, I would push back against the “real-name web.” Lots of people have made the argument before me but it still stands. The kids I’ve spoken to feel so much safer on social media if they use a pseudonym. Pseudonymity has so many benefits for them and, while it will always carry risks, there’s a wealth of evidence telling us that the benefits outweigh the harms. We need to listen to the kids. We need to believe what they’re saying, and create a digital world that doesn’t alienate their ideas.</p>",
      "content_text": "What are kids doing on the internet, and what is the internet doing to them? These questions have preoccupied parents, teachers, and the media for decades. But all too often the conversation is clouded with condescension and panic. Obviously, there are issues here worth exploring, and we wanted to find a way to do so without indulging in the usual caricatures and fear mongering. So Logic editor Ben Tarnoff spoke with Ysabel Gerrard, a lecturer in Digital Media and Society at the University of Sheffield in the United Kingdom and an expert on young people’s mental health and social media. She explained what exactly the kids are up to, and how their elders get it wrong.\n---\n\nThere’s a lot of concern out there about the effect of social media on the mental health of young people. But this concern isn’t new. It belongs to a broader historical trend. When the internet was first becoming popularized in the 1990s, the media ran a number of stories fretting about kids going online: they could access pornography, be entrapped by predators, and so on. A prominent 1998 study from Carnegie Mellon University that got a lot of attention at the time claimed that spending time online made people lonely, depressed, and antisocial. Decades later, we’re seeing similar themes in the popular narratives around young people and the internet. How would you describe the current iteration of this discourse? What are the continuities and discontinuities with the 1990s?\nThe major difference is the kind of media we’re dealing with—social media. Social media enables the sharing of a greater volume and range of content (e.g., live-streamed videos, high-quality images, and so on). That said, the discourse around “kids online” today is similar to what it was in the 1990s, because we see the same lack of dedication to understanding what young people are actually doing on the internet. I speak to teachers, parents, policymakers, and I name apps they’ve never heard of. I talk about things they’ve never heard of. And I think to myself, “How can you sit there and be afraid of what kids are doing online when you haven’t fully tried to understand it?” So the internet has changed, and the kinds of things that kids are doing on the internet has changed. But the reluctance to understand what kids are actually doing—and to take seriously their pleasures, as well as the harms that might arise—has not changed. \nOne continuity with the 1990s is the presence of a moral panic that prevents people from seeing clearly. If you’re in panic mode, you’re not capable of perceiving what kids are actually doing with the technology. But, as you point out, the technology itself has changed: social media has transformed the internet, as well as how kids interact with the internet.\nExactly. I give lots of talks at schools and I’m usually invited to talk about the “dangers” of social media. But I always say, “No, that’s not my job. I can come, but I’m not going to do that.” And what I’ve found in every single school is a disconnect between how seriously the kids take the things they do online versus how seriously the adults take it. \nFor example, most schools in the UK have a “meme account”—a social media account that posts funny memes about the school, its kids, and its teachers. It’s anonymous: schools rarely find out who set it up. Teachers usually take it very seriously: they contact the parents; sometimes they contact the police. But when you speak to the kids, they say it’s just banter, it’s just humor, it’s just fun.\nThe kind of concern from elders you’re describing is often expressed in a mental health idiom—that kids shouldn’t be engaging in certain online behaviors because it’s bad for their mental health. And clearly, there are certain online behaviors that are bad for one’s mental health. For example, you’ve written extensively about social media communities that promote anorexia and other eating disorders. But sometimes the mental health frame can be stretched too far, to the point that all sorts of online behaviors are unfairly pathologized. And this can lead to counterproductive interventions by parents and other authority figures, who discipline kids for doing things that might be harmless or even beneficial. I mean, there are lot of kids out there—particularly queer kids—whose life was quite literally saved by the internet. How do you strike the right balance? How do you find a way to identify genuinely destructive behaviors online without overpathologizing?\nThis question reminds me of the favorite piece of research I’ve ever done. It was for an article I wrote with Dr. Anthony McCosker, where we analyzed all the Instagram posts that were tagged as “#depressed” within a certain timeframe. One of the most fascinating things we found was that when people were having discussions related to mental health, they were using pseudonyms 76 percent of the time.\nIn recent decades, we’ve seen a greater destigmatization of mental health. People use terms like depression much more frequently than they used to. But I wonder how far destigmatization has really gone, if 76 percent of people don’t feel comfortable talking about the lived realities of depression while using their real name. As you said, the internet can clearly be a life-saving space. And much of its power comes from the ability for people to use a pseudonym on a major platform like Instagram to talk about depression. That’s why it can be counterproductive when platforms try to enforce enhanced identification measures like real name policies.\nReal name policies are motivated, at least in part, by the idea that the ability to be anonymous or pseudonymous on the internet is a major contributor to online toxicity. But what your research reveals is that the same anonymity or pseudonymity can be a life-saver, since it enables kids to discuss mental health issues they wouldn’t feel comfortable discussing otherwise. And there may not be an obvious real-world space where they could have those discussions.\nPrecisely, it’s a double-edged sword. One of the things I’m talking to kids about in my current research is how they feel about “secret-telling” apps like Secret, which let users communicate anonymously. (I should note early on that, technically, they’re communicating pseudonymously, since anonymity is incredibly difficult to fully achieve in practice, but I’d like to use the word “anonymous” here—because they do.) These apps have been the subject of intense scrutiny by the press and some parents, particularly due to their connection to cyberbullying. What kids often say is, “I don’t really like secret-telling apps. I think they can be toxic. They scare me. I only use them because my friends do.” And then I say, “Imagine a world where there’s no such thing as a secret-telling app. Imagine a world where there’s no such thing as anonymity. Are you happier? Are you safer?” And they go, “No, you can’t get rid of it!” \nWhat they’re telling me is, “How are my friends going to ask questions about their sexuality?” “How are my friends going to announce to the world that somebody is being racist to them and they don’t know what to do?” “How are my friends going to ask what to do when someone takes an inappropriate picture of them?” “Who else can I talk to about aspects of adolescence, like sex?”\nKids need these spaces. They need to be anonymous. And that’s why—at least for the kids I spoke to in my research—they rarely use social media with their real name, instead relying on what they often call “nicknames.” So they’re simultaneously reliant on anonymity as a safety mechanism but, at the same time, they’re fearful of it. And I wonder whether they are fearful of it because they are told to be fearful of it. \nIt’s clearly a good thing that young people are able to find some solace in these online spaces. But I also wish we could be supporting them better. I mean, I want them to be able to go online and have these conversations. But I also really want them to have access to professional therapy and other mental healthcare. Talking to strangers through an Instagram hashtag is fine, but it shouldn’t be the main way for kids to get help.\nAbsolutely. And this is the problem with the whole “social media is bad for kids” discourse. Is it social media or is it, perhaps, rising poverty levels, global warming, or increasing polarization? Is it maybe these things as well? I hear this sort of thing from kids all the time. “Why are you so worried that we created a meme account? Why aren’t you worried that I can barely get out of bed in the morning?”\nIt’s a form of victim-blaming that feels very familiar. I’m reminded of the “avocado toast” discourse: the notion that many millennials can’t afford to buy homes because they spend too much money on expensive artisanal avocado toast. Similarly, it’s easier to blame teenagers’ anxiety and depression on their use of smartphones instead of looking at the deeper issues that are causing their anxiety and depression—as well as recognizing that, in some cases, a smartphone might be the best outlet they have for dealing with the problems. Not a great one, and not nearly as good as fully funded mental health services. But it’s what they have.\nYou know, “Phone Saves Teen’s Life” doesn’t make for as good a headline as “Pro-anorexia Memes Drove Girl to Death.” What is The Daily Mail going to publish? It’s going to be the second one. \nBut it’s a difficult balance. People often think I’m too defensive of social media. And maybe I don’t say it enough, but yes, there are some awful things on social media. Content moderators have one of the worst jobs in the world because they have to look at diabolically bad stuff for hours and hours every day. And yes, kids have seen some of that stuff. \nI recognize that. But the reality is that social media is highly contextual. You need to look at how social media is being experienced by a particular person in a particular moment. It seems to me that the press in particular prefers a solid, clean-cut answer: that social media is totally fine or completely evil. But it’s neither. We need to get better at thinking of social media as something that is deeply complex. \nBalancing Acts\nYou mentioned content moderators. Let’s talk a bit about how content moderation, as implemented by large tech firms, shapes the conversations that young people have about mental health in online spaces. \nIn your 2018 article, “Community Guidelines and the Language of Eating Disorders on Social Media,” you reproduce some images of women’s bodies from Instagram and explore whether the images promote eating disorders. “Yes, the people’s bones are outlined and emphasised in the framing of the images,” you write, “but when do they become too bony, to the point where these images are read as the promotion of anorexia or similar?” A human content moderator, or an automated content moderation system, might have trouble looking at these images and determining definitively whether they were “pro-anorexic.” How should we think about these challenges? \nI’m on Facebook and Instagram’s Suicide and Self-Injury Advisory Board. It’s an unpaid role, and I really enjoy it. I contribute to meetings about once or twice a month, and what they generally do is give us example imagery—for example, an image of a person with a slender body and visible rib cage—and ask us how it should be moderated. But a talking point we reach in more or less every meeting is that we need far greater context: the caption, the comments, the other posts in a user’s feed, and so on.\nThat’s something I struggle with. Nobody—no company, no moderator—should be looking at an image of a person and deciding if they are too thin or if their size promotes eating disorders. We’ve had decades and decades of feminist history, and this is the point we’ve reached! We shouldn’t be doing that to anyone of any gender. It shouldn’t be happening. \nWhat you need is context. You need the caption. You need the comments underneath. You need the qualitative data. You need a deep understanding of the situation in which that image is being used, especially when it comes to posts about mental health. And that’s why we’re always going to need humans to do the work of content moderation. We have to find ways of making their work easier, but we need them. \nTo your point about context, those images of women’s bodies from Instagram might be circulating within a hashtag devoted to supporting people who are trying to overcome their eating disorders. In that context, the content might be playing a beneficial role. \nExactly.\nBut how can big tech companies afford to do that sort of nuanced, context-specific moderation at scale? It’s obviously much more time- and labor-intensive. And if you’re Facebook, you can’t maintain the profit margins that your investors demand while paying for high-quality content moderation across a social network of more than two billion people.\nSomething I’ve learned from Jillian C. York and Tarleton Gillespie’s work in particular is that it’s very hard, probably impossible, to moderate content at scale. To take the example of the Instagram images, let’s say the content moderator decides that a piece of content is in fact promoting eating disorders. Okay, it breaks the rules, so what do you do? If you remove that user’s account, you’re also cutting off their support system. People often call on social media companies to do more about X, Y, and Z. But what that means in practice, given the scale at which these companies operate, is account deletions, blanket bans on hashtags, that sort of thing. \nSo scale also incentivizes platforms to look for low-effort, cookie-cutter solutions when moderating content. If you’ve got lots of users and a relatively small number of overworked, underpaid content moderators, it’s easier to delete a bunch of posts or deactivate a bunch of accounts. But if someone’s having a mental health crisis online, that’s not going to do anything to address the crisis. In fact, it probably makes things worse.\nRight. Again, context matters. \nAnother good example is the online fallout after the European football championship. Here in the UK, our team played Italy in the final. It was pretty monumental, because we haven’t been in the final for fifty-five years. The game was close. It went to a penalty shootout at the end, and the three players who missed the penalty shots were Black. The UK lost. You can only imagine the extent of racism directed at these players afterward. It was horrific. \nOn social media, racist posts often used monkey emojis to refer to the Black players. So people began calling for social media companies to take action. Some folks asked, if you can slap a warning label on every post about Covid, why can’t you slap a warning label on every post that uses the monkey emoji to be racist?\nThe problem is that context is everything. The same emoji or word can be racist in one context but then in another context might be a vernacular within a community. That’s why we’re always going to need humans to do content moderation. \nThere was an interesting post on Twitter recently from a former content moderator. They were talking about how there were so few pathways for promotion and progression. Moreover, moderators at large social media companies often get no say on policy, despite the fact that they’re the ones doing the work. So yes, we need to improve their working conditions, and we need to find automated ways of taking the most traumatic content away from them. But we should also be transforming their very job description. They should become specialists in particular subject areas, so that they can better recognize context and better interpret nuanced content.\nWhat else do you think should be done?\nWe need transparency. But we also need to be specific about the kind of transparency we’re asking for, instead of just saying to these companies, “Be transparent.” This is something I’ve learned from Nic Suzor’s work, in particular.\nI’ve been wrong about this issue in the past. A few years ago, I said platforms needed to publish lists of banned hashtags, because there’s a lot of discrimination present in the hashtags they ban. But often when you ban a hashtag, people just move the conversation to a different hashtag. So publishing a list of banned hashtags can make it easier for people to come up with workarounds. That’s one of the many reasons why we need to be careful with what we’re asking for when it comes to transparency. \nOne form of transparency we really need is around content moderation guidebooks. In my view, we need to see most, if not all of the rules that content moderators are using to make decisions. It troubles me that these are hidden from the public, and therefore hidden from scrutiny. And maybe I’m being too idealistic here, but I believe it would make a big difference if researchers had access to those rules and could make evidence-based recommendations for their improvement. \nYou’ve written on how feminist thought can inform our approach to content moderation, and to young people’s mental health on the internet more broadly. What in particular do you draw from the feminist tradition, and how does it bear on the question of where we should go from here? \nOne of my biggest influences both in academia and in life is Dr. Carolina Are. She’s an academic, activist, and pole dance instructor, and often posts images and videos of her pole dance tutorials on social media. Carolina is constantly having her account suspended, then reinstated, then suspended, then reinstated. She gets told that she’s broken the guidelines and then, a day later, gets told it was a mistake. \nThe reality is that social media companies often don’t know where they stand on issues like female nudity. That’s why they’re so inconsistent. What they want to do is to come up with one global rule. They want to have a single guideline about female nudity that they can globalize across the entire platform. But female nudity is an issue that is viewed so differently according to the country that you’re in, the region of the country that you’re in, the religion that you belong to. Many different elements factor into it. So, to have one international rule on an issue like that is impossible. On certain things, generalizability isn’t possible. \nIf there’s one thought on the subject of mental health and young people on the internet that you’d like our readers to carry out into the world, what would it be?\nAgain, I would push back against the “real-name web.” Lots of people have made the argument before me but it still stands. The kids I’ve spoken to feel so much safer on social media if they use a pseudonym. Pseudonymity has so many benefits for them and, while it will always carry risks, there’s a wealth of evidence telling us that the benefits outweigh the harms. We need to listen to the kids. We need to believe what they’re saying, and create a digital world that doesn’t alienate their ideas.",
      "date_published": "2021-10-26T14:11:44.000Z",
      "date_modified": "2021-10-26T14:11:44.000Z",
      "_plugin": {
        "pageFilename": "ed0cfa4aed0135a1757a6d0e3dafe59bd82dde554f90b4faf11b7027ae7df7ce.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/we-dont-need-no-innovation",
      "url": "https://logicmag.io/kids/we-dont-need-no-innovation",
      "title": "We Don’t Need No Innovation",
      "summary": "A fight over the meaning of “disruptive technologies” in schools.",
      "content_html": "<p>In the spring of 1969, a group of parents, residents, and activists staged a series of protests in West Philadelphia. They were attempting to disrupt plans for a cutting-edge new high school that was to be built in their neighborhood. The demonstrations centered on the far-reaching educational innovations that the school, University City High, promised to deliver, and the implications those changes held for students and the surrounding community.</p>\n<p>The new school was part of a larger initiative, the Educational System for the Seventies, or ES70. Developed by what was then the US Office of Education, a bureau within the Department of the Interior, with support from the departments of labor and defense, ES70 aimed to establish a national network of twenty “innovation schools” that could be exemplars of technology-enhanced, personalized education at the dawn of the 1970s. Schools in the ES70 network would forego conventional classrooms, replacing formal instruction with a “programmed” curriculum designed by disciplinary experts. Students could work through this curriculum at their own pace with the aid of audio-visual technologies and teaching machines, and they would be assessed on “competencies” in self-directed learning rather than with traditional grades.</p>\n<p>To recruit participating districts, like Philadelphia, program leaders presented ES70 as a way for school systems both to raise their profile as national leaders in modernized education, and to foster connections with industry—particularly companies associated with math, science, and technology. But for residents in West Philadelphia, the plans for University City High were a diversion—a way for white district leaders to dress up their persistent disregard for the demands of local Black education activists with an ostensibly benevolent investment in the community and its children. </p>\n<p>Residents objected that the novel educational tools advanced by the ES70 school were unmoored from the educational reforms for which people in West Philadelphia had long been fighting—community control, increased funding, African American history courses. The ES70 program would direct focus and resources away from these demands. The protests and their aftermath were the culmination of a broader struggle in the city over the nature of “innovative” reform in a school system riven with competing visions for public education.</p>\n<p>Today, “innovation” continues to circulate in popular discourse as a self-evident rationale for disrupting schools and school systems. Experimental programs like the XQ Super Schools Project, founded by Laurene Powell Jobs, and AltSchool, launched by ex-Google executive Max Ventilla, position themselves as dramatic shifts in the history of schooling. They promise to supplant the supposedly antiquated rituals of conventional classrooms, which are often portrayed as factory-like preparations for an industrial economy of the past, with technology-driven personalized learning. </p>\n<p>The story of University City High makes it clear that such programs are not a break from the past. They are outgrowths of a longer history of postwar reform efforts that have leveraged educational “innovation” to launder private interests as public goods, and to bolster national political-economic competition. To counter such initiatives, it’s crucial to center the alternate visions of reform that emerge from the people impacted by such efforts, like those who protested the ES70 initiative in West Philadelphia. Doing so points to an affirmative project for educational innovation—one that takes, as its starting point, a commitment to the material concerns and collective desires of the communities that public schools are meant to serve.</p>\n<h1><b>Set Up to Fail</b></h1>\n<p>Long before University City High was announced, or the ES70 program was inaugurated, parents and activists in West Philadelphia were advocating for transformation in their local schools. Residents in the working-poor African American neighborhood were attuned to the incongruities between their own classrooms and those in whiter, wealthier parts of the city. Facilities were crumbling and overcrowded; academic opportunities were sparse; and the curriculum did not reflect the racial and linguistic diversity of students and their families. </p>\n<p>Organizing and agitation against these imbalances was common. In 1949, irate mothers stormed the office of the district business manager, demanding increased funding and smaller class sizes. Throughout the next two decades, Black-led organizations like Citizens for Progress staged protests and sit-ins for community control over local education and for nearby universities to invest in surrounding neighborhood schools. In the 1960s, the city’s NAACP chapter threatened legal action against the district, citing segregation in West Philadelphia’s predominantly Black schools as a violation of <i>Brown v. Board of Education</i>. The force of these cumulative pressures led school board president and former city mayor Richardson Dilworth in 1967 to hire a new superintendent, Mark Shedd, to address the community’s concerns. In his first month on the job, more than 3,500 students organized a mass walkout, marching to the district office and calling for African American history courses and culturally representative school hiring and dress code policies.</p>\n<p>It was into this environment that the ES70 program was introduced. In an embattled school district with a new superintendent, the initiative had the appeal of addressing multiple problems simultaneously. A generous grant attached to the program would fund a new school building in West Philadelphia, which could ease overcrowding in other schools. The “personalized” lesson structure meant that fewer teachers were needed to run the school, freeing up money for the technological investments—teaching machines, audio-visual equipment, film strips—necessary for the ES70 model to operate. These resources, along with a math and science curriculum created by disciplinary experts from the ES70 project and the University of Pennsylvania, would also extend academic opportunities to the community. On its surface, ES70 appeared to be a win for everyone.</p>\n<p>Local businesses also saw an opportunity in the ES70 program. The West Philadelphia Corporation (WPC), a coalition of industry and university leaders, had long been committed to redeveloping the neighborhood into a hub for scientific innovation modeled on the Stanford Research Park. The new ES70 school appeared to be the missing link in this plan. If the building site could overlay the residential blocks that separated the two major universities in the area—the University of Pennsylvania and Drexel Institute of Technology—then the school would effectively bridge the campuses. This would demarcate “University City” as an up-and-coming neighborhood distinct from the rest of West Philadelphia. Even more, ES70’s emphasis on science, math, and personalized learning would lure professors and industry leaders to the area so their children could attend the school. Fortuitously for the WPC, its Executive Director Leo Molinaro was named to the ES70 planning committee. Not only did the school’s site selection follow the WPC’s blueprint, but its name—University City High—reflected the organization’s larger efforts to rebrand the neighborhood.</p>\n<p>Over time, these competing visions of education reform—of residents, administrators, and business leaders—clashed, flaring up most visibly at a series of public forums between 1968 and 1970. Titled “Educational Innovations in University City,” these gatherings featured Shedd and Molinaro sharing details about the ES70 program and responding to public concerns. Parents and activists packed into these forums to protest the “innovations” the district and WPC were prioritizing, and the effects these would have on the neighborhood. Longtime residents, who had seen their neighbors displaced during previous WPC “redevelopment” efforts, called out the racist and classist implications of the University City High project. Others expressed outrage at the material concerns overlooked in the ES70 reforms. As one teacher said, “Hunger isn’t new. Torn pants aren’t new. They aren’t innovative. Therefore, there are no funds for that kind of problem.” Even those who saw some potential in the ES70 model voiced concerns that their children, thrust into a new, self-directed learning environment with limited preparation and teacher support, were being set up to fail. </p>\n<p>This was borne out when the school opened in 1971. While some students managed to adapt to the ES70 model, the personalized curriculum failed to engage students as it promised. In the absence of formal instruction or classrooms, students opted to use their unstructured time in other ways. They abandoned their assignments and, instead, gathered in common areas where there was little supervision. After several fights broke out, local newspapers reported that University City High was in chaos. Within two months, administrators abandoned the ES70 model altogether, returning to a more traditional classroom and curricular structure.</p>\n<h1><b>Innovation and Its Aftermaths</b></h1>\n<p>On the surface, the ES70 program in Philadelphia was a failure. One could view it as a breakdown in implementation—that its core innovations, while sound, were undercut by reformers’ inability to build consensus with parents and residents. Others might blame the structure of schooling itself: that the rigid conditions of classrooms are resistant to change and, by extension, produce students who are equally inflexible in the face of transformative learning opportunities.</p>\n<p>But in another sense, it wasn’t a failure at all. The ostensible goal of ES70 and similar postwar reform efforts may have been to modernize schools, but the larger aim was always to enroll K-12 education into a nascent project of national innovation. The federal spending behind such programs was committed to “personalized” learning only to the extent that it turned public schools into proving grounds where the next generation of workers in innovative sectors could be trained. In this, ES70 was a success.</p>\n<p>Even before University City High opened, ES70’s director had already submitted a final report for the overarching project to the US Office of Education, celebrating ES70’s achievements in closing the loop between public education and scientific research and development. While individual initiatives may have faltered, as University City High did, the program was nevertheless effective at systematizing “innovation” as a model for, and aspiration of, educational policymaking. The report recommended continued investment in basic and applied research on educational innovation—an agenda that persists to the present.</p>\n<p>In Philadelphia, Superintendent Shedd followed up the district’s involvement with ES70 by inaugurating an Office of Innovative Programs, which pursued more than seventy experimental initiatives in its first five years. Most of these, like ES70, were short-lived, but they contributed to a significant discursive shift. “Innovation” became the dominant strategy for school reform; and being “innovative” became more important than any particular outcome of such experiments. This, too, has proven resilient: Philadelphia continues to operate an Innovation Network of nine public schools, many dedicated to technology-enhanced personalized learning.</p>\n<p>In 2021, the building for the newest of these schools was completed on the grounds where University City High once stood—a palimpsest, etched into a West Philadelphia remade by the aftermath of educational innovation. The neighborhood is no longer residential. It is now home to the University City Science Center, the largest urban research park in the US. University City High’s development in 1970 allowed the WPC to secure adjacent land for the project. While the WPC is now defunct, the reverberations of its urban renewal agenda live on in the gentrified academic-industrial economy of modern University City.</p>\n<p>In all, more than 2,600 residents, most working-poor and African American, were displaced by the construction of University City High and the adjoining research park. Their stories are inextricably linked to the city’s lineage of educational “innovation.” But so too are the transformations that might have been—the counter visions of innovation that exist alongside, and in opposition to, those that enlist public goods, like schools, in the service of private and national political-economic interests. </p>\n<p>How might West Philadelphia and its schools be different, today, if innovations fifty years ago had centered the material concerns of its residents: community control, equitable resourcing, small class sizes, racially and linguistically diverse teachers, and culturally sustaining instruction? What even more radical possibilities were preempted by the mode of “innovation” that gripped the district instead?</p>\n<p>The legacies of struggle in West Philadelphia point to an alternate frame for educational innovation: where the as-yet-unrealized project of free, just, and democratically controlled education for all stands as the measure against which any proposed reforms are judged. If “innovation” is to be anything more than a buzzword—or a Trojan horse for austerity measures, urban development, and workforce production—it must be rooted in such a commitment to the self-determination and flourishing of the publics that schools are meant to serve.</p>",
      "content_text": "In the spring of 1969, a group of parents, residents, and activists staged a series of protests in West Philadelphia. They were attempting to disrupt plans for a cutting-edge new high school that was to be built in their neighborhood. The demonstrations centered on the far-reaching educational innovations that the school, University City High, promised to deliver, and the implications those changes held for students and the surrounding community.\nThe new school was part of a larger initiative, the Educational System for the Seventies, or ES70. Developed by what was then the US Office of Education, a bureau within the Department of the Interior, with support from the departments of labor and defense, ES70 aimed to establish a national network of twenty “innovation schools” that could be exemplars of technology-enhanced, personalized education at the dawn of the 1970s. Schools in the ES70 network would forego conventional classrooms, replacing formal instruction with a “programmed” curriculum designed by disciplinary experts. Students could work through this curriculum at their own pace with the aid of audio-visual technologies and teaching machines, and they would be assessed on “competencies” in self-directed learning rather than with traditional grades.\nTo recruit participating districts, like Philadelphia, program leaders presented ES70 as a way for school systems both to raise their profile as national leaders in modernized education, and to foster connections with industry—particularly companies associated with math, science, and technology. But for residents in West Philadelphia, the plans for University City High were a diversion—a way for white district leaders to dress up their persistent disregard for the demands of local Black education activists with an ostensibly benevolent investment in the community and its children. \nResidents objected that the novel educational tools advanced by the ES70 school were unmoored from the educational reforms for which people in West Philadelphia had long been fighting—community control, increased funding, African American history courses. The ES70 program would direct focus and resources away from these demands. The protests and their aftermath were the culmination of a broader struggle in the city over the nature of “innovative” reform in a school system riven with competing visions for public education.\nToday, “innovation” continues to circulate in popular discourse as a self-evident rationale for disrupting schools and school systems. Experimental programs like the XQ Super Schools Project, founded by Laurene Powell Jobs, and AltSchool, launched by ex-Google executive Max Ventilla, position themselves as dramatic shifts in the history of schooling. They promise to supplant the supposedly antiquated rituals of conventional classrooms, which are often portrayed as factory-like preparations for an industrial economy of the past, with technology-driven personalized learning. \nThe story of University City High makes it clear that such programs are not a break from the past. They are outgrowths of a longer history of postwar reform efforts that have leveraged educational “innovation” to launder private interests as public goods, and to bolster national political-economic competition. To counter such initiatives, it’s crucial to center the alternate visions of reform that emerge from the people impacted by such efforts, like those who protested the ES70 initiative in West Philadelphia. Doing so points to an affirmative project for educational innovation—one that takes, as its starting point, a commitment to the material concerns and collective desires of the communities that public schools are meant to serve.\nSet Up to Fail\nLong before University City High was announced, or the ES70 program was inaugurated, parents and activists in West Philadelphia were advocating for transformation in their local schools. Residents in the working-poor African American neighborhood were attuned to the incongruities between their own classrooms and those in whiter, wealthier parts of the city. Facilities were crumbling and overcrowded; academic opportunities were sparse; and the curriculum did not reflect the racial and linguistic diversity of students and their families. \nOrganizing and agitation against these imbalances was common. In 1949, irate mothers stormed the office of the district business manager, demanding increased funding and smaller class sizes. Throughout the next two decades, Black-led organizations like Citizens for Progress staged protests and sit-ins for community control over local education and for nearby universities to invest in surrounding neighborhood schools. In the 1960s, the city’s NAACP chapter threatened legal action against the district, citing segregation in West Philadelphia’s predominantly Black schools as a violation of Brown v. Board of Education. The force of these cumulative pressures led school board president and former city mayor Richardson Dilworth in 1967 to hire a new superintendent, Mark Shedd, to address the community’s concerns. In his first month on the job, more than 3,500 students organized a mass walkout, marching to the district office and calling for African American history courses and culturally representative school hiring and dress code policies.\nIt was into this environment that the ES70 program was introduced. In an embattled school district with a new superintendent, the initiative had the appeal of addressing multiple problems simultaneously. A generous grant attached to the program would fund a new school building in West Philadelphia, which could ease overcrowding in other schools. The “personalized” lesson structure meant that fewer teachers were needed to run the school, freeing up money for the technological investments—teaching machines, audio-visual equipment, film strips—necessary for the ES70 model to operate. These resources, along with a math and science curriculum created by disciplinary experts from the ES70 project and the University of Pennsylvania, would also extend academic opportunities to the community. On its surface, ES70 appeared to be a win for everyone.\nLocal businesses also saw an opportunity in the ES70 program. The West Philadelphia Corporation (WPC), a coalition of industry and university leaders, had long been committed to redeveloping the neighborhood into a hub for scientific innovation modeled on the Stanford Research Park. The new ES70 school appeared to be the missing link in this plan. If the building site could overlay the residential blocks that separated the two major universities in the area—the University of Pennsylvania and Drexel Institute of Technology—then the school would effectively bridge the campuses. This would demarcate “University City” as an up-and-coming neighborhood distinct from the rest of West Philadelphia. Even more, ES70’s emphasis on science, math, and personalized learning would lure professors and industry leaders to the area so their children could attend the school. Fortuitously for the WPC, its Executive Director Leo Molinaro was named to the ES70 planning committee. Not only did the school’s site selection follow the WPC’s blueprint, but its name—University City High—reflected the organization’s larger efforts to rebrand the neighborhood.\nOver time, these competing visions of education reform—of residents, administrators, and business leaders—clashed, flaring up most visibly at a series of public forums between 1968 and 1970. Titled “Educational Innovations in University City,” these gatherings featured Shedd and Molinaro sharing details about the ES70 program and responding to public concerns. Parents and activists packed into these forums to protest the “innovations” the district and WPC were prioritizing, and the effects these would have on the neighborhood. Longtime residents, who had seen their neighbors displaced during previous WPC “redevelopment” efforts, called out the racist and classist implications of the University City High project. Others expressed outrage at the material concerns overlooked in the ES70 reforms. As one teacher said, “Hunger isn’t new. Torn pants aren’t new. They aren’t innovative. Therefore, there are no funds for that kind of problem.” Even those who saw some potential in the ES70 model voiced concerns that their children, thrust into a new, self-directed learning environment with limited preparation and teacher support, were being set up to fail. \nThis was borne out when the school opened in 1971. While some students managed to adapt to the ES70 model, the personalized curriculum failed to engage students as it promised. In the absence of formal instruction or classrooms, students opted to use their unstructured time in other ways. They abandoned their assignments and, instead, gathered in common areas where there was little supervision. After several fights broke out, local newspapers reported that University City High was in chaos. Within two months, administrators abandoned the ES70 model altogether, returning to a more traditional classroom and curricular structure.\nInnovation and Its Aftermaths\nOn the surface, the ES70 program in Philadelphia was a failure. One could view it as a breakdown in implementation—that its core innovations, while sound, were undercut by reformers’ inability to build consensus with parents and residents. Others might blame the structure of schooling itself: that the rigid conditions of classrooms are resistant to change and, by extension, produce students who are equally inflexible in the face of transformative learning opportunities.\nBut in another sense, it wasn’t a failure at all. The ostensible goal of ES70 and similar postwar reform efforts may have been to modernize schools, but the larger aim was always to enroll K-12 education into a nascent project of national innovation. The federal spending behind such programs was committed to “personalized” learning only to the extent that it turned public schools into proving grounds where the next generation of workers in innovative sectors could be trained. In this, ES70 was a success.\nEven before University City High opened, ES70’s director had already submitted a final report for the overarching project to the US Office of Education, celebrating ES70’s achievements in closing the loop between public education and scientific research and development. While individual initiatives may have faltered, as University City High did, the program was nevertheless effective at systematizing “innovation” as a model for, and aspiration of, educational policymaking. The report recommended continued investment in basic and applied research on educational innovation—an agenda that persists to the present.\nIn Philadelphia, Superintendent Shedd followed up the district’s involvement with ES70 by inaugurating an Office of Innovative Programs, which pursued more than seventy experimental initiatives in its first five years. Most of these, like ES70, were short-lived, but they contributed to a significant discursive shift. “Innovation” became the dominant strategy for school reform; and being “innovative” became more important than any particular outcome of such experiments. This, too, has proven resilient: Philadelphia continues to operate an Innovation Network of nine public schools, many dedicated to technology-enhanced personalized learning.\nIn 2021, the building for the newest of these schools was completed on the grounds where University City High once stood—a palimpsest, etched into a West Philadelphia remade by the aftermath of educational innovation. The neighborhood is no longer residential. It is now home to the University City Science Center, the largest urban research park in the US. University City High’s development in 1970 allowed the WPC to secure adjacent land for the project. While the WPC is now defunct, the reverberations of its urban renewal agenda live on in the gentrified academic-industrial economy of modern University City.\nIn all, more than 2,600 residents, most working-poor and African American, were displaced by the construction of University City High and the adjoining research park. Their stories are inextricably linked to the city’s lineage of educational “innovation.” But so too are the transformations that might have been—the counter visions of innovation that exist alongside, and in opposition to, those that enlist public goods, like schools, in the service of private and national political-economic interests. \nHow might West Philadelphia and its schools be different, today, if innovations fifty years ago had centered the material concerns of its residents: community control, equitable resourcing, small class sizes, racially and linguistically diverse teachers, and culturally sustaining instruction? What even more radical possibilities were preempted by the mode of “innovation” that gripped the district instead?\nThe legacies of struggle in West Philadelphia point to an alternate frame for educational innovation: where the as-yet-unrealized project of free, just, and democratically controlled education for all stands as the measure against which any proposed reforms are judged. If “innovation” is to be anything more than a buzzword—or a Trojan horse for austerity measures, urban development, and workforce production—it must be rooted in such a commitment to the self-determination and flourishing of the publics that schools are meant to serve.",
      "date_published": "2021-10-20T15:52:44.000Z",
      "date_modified": "2021-10-20T15:52:44.000Z",
      "_plugin": {
        "pageFilename": "177284714bddba9a2caa7e2bfc7f25db233785798dc278fe130df8ab2a24db51.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/wealth-creators",
      "url": "https://logicmag.io/kids/wealth-creators",
      "title": "Wealth Creators",
      "summary": "An inquiry into intergenerational wealth in Silicon Valley.",
      "content_html": "<p><i>Ex nihilo</i> is one of those concepts that makes you immediately suspicious. When someone claims to have made something out of nothing, there is almost always an inconvenient history that they intend to eclipse. The fantasy that before us there was nothing has a great deal of ideological power. The creator <i>ex nihilo</i> gets to claim some faint emanation of divine power—the wealth creator and the job creator are treated as distant cousins to the capital-C Creator. </p>\n<p>The same is true for the idea of <i>terra nullius</i>. When tech came to a stretch of Northern California along the San Francisco Bay, it reframed the world it found as a bunch of apricot groves, a rail line, and not much else. This kind of pioneering story abounds in Silicon Valley. It’s not just the architecture, which seems to pretend that nothing was there before whatever spaceship of an office park landed in a given lot. Rather, it’s the environmentalist facade of an industry whose dirty beginnings—above all, in the known carcinogen, trichloroethylene, long used to clean semiconductors—have dotted Santa Clara County with a record number of Superfund sites. It’s the way, looking at the names of the wealthiest people in the Valley, you get the sense of wealth that’s been created by this generation rather than inherited from previous ones. Of course, the Zuckerberg-Chan dynasty may one day amuse the Bay Area’s society columnists with their coke-fueled antics at the annual Cotillion Debutante ball. Maybe X AE A-XII Musk will one day run for governor of California like so many scions before him who were born on third base and think they hit a triple. </p>\n<p>But for now, this wealth feels new. And the newness is part of its allure, its legitimacy. Stories abound about how Silicon Valley’s newly rich don’t know how to spend their money, or how they spend it on absurd things. There is something reassuring about that framing, suggesting as it does that these protagonists are new to wealth and privilege, that wealth is foreign to them. </p>\n<p>Years ago, I became fascinated with the question of how “new” the money invested and made in Silicon Valley really is. It has fascinated me in part because it is on some level an unanswerable question: how do you decide whether money is really “new”? Even asking the question, asking where money came from, teases out some inconvenient continuities, and a different understanding of how this industry and the place it has made its home came to be. </p>\n<h1><b>Supertankers of privilege</b></h1>\n<p>Silicon Valley is good at persuading people to accept its self-perception as fact—a useful tactic, since a lot rides on that perception. In 2014, <i>Forbes</i> ran an analysis showing that “the wealthiest people in the country are increasingly self-made, leaving behind an era when dynasties inherited and concentrated wealth.” The leading indicator, they pointed out, was tech, where “more than 94 percent of the tech billionaires created their fortunes themselves.” (The numbers were much lower for sectors such as manufacturing.)</p>\n<p>How did <i>Forbes</i> determine tech wasn’t dynastic? The authors ranked Silicon Valley’s super-rich on a 1-10 scale. A “1” on their scale denoted “inherited fortune but not working to increase it”; a “4” meant “inherited fortune and increased it in a meaningful way”; a “7,” “self-made who got a head start from wealthy parents and moneyed background”; and an “8” was self-made but “came from a middle- or upper-middle-class background.” To rank a “10,” you basically had to be left in a basket on a river. </p>\n<p>The results of the analysis aren’t particularly surprising. It turns out tech is mostly, by these calculations, “8s.” After all, that’s what the methodology was basically created to deliver. Anyone involved in tech in the last forty years who wound up as a billionaire likely grew their fortune significantly. You’d have to be an idiot, or actively trying, not to. But even beyond that, the methodology is profoundly telling. There is the unspoken assumption that growing one’s wealth was somehow the opposite of being dynastic. There is also the idea that money only grows due to some immense effort—in fact, their one example of a “1,” Laurene Powell Jobs, is evidence of how hard it is to <i>avoid</i> growing your wealth once it’s reached a certain level of absurdity. And the suggestion that anyone “6” and above “truly made it on their own” is staggering. When a certain “billionaire” ex-president ranks in the middle of your scale, the off-ness of the scale seems to be the point. </p>\n<p>The most interesting questions about wealth transmission in America, however, happen within the “8s”—that is, among the twenty million millionaires as opposed to the 600 ro so billionaires in the US. <i>Forbes</i> set up their method around the idea that dynastic wealth and wealth multiplying from one generation to the next are mutually exclusive, as though taking an eighty million dollar fortune and turning it into a billion-dollar fortune is somehow the opposite of the dynastic transmission of capital. There’s one kind of story about capitalism being told when you highlight how Meg Whitman, former CEO of eBay and Hewlett Packard (and, um, Quibi), is a self-made billionaire who ran for governor of California as just “Meg.” And another when you think about the fact that she comes from two Boston Brahmin families, and one of her sons bears the almost comically dynastic name Griffith Rutherford Harsh V. (“Griff,” as he’s known, is the direct descendant of a revolutionary war general, so if anything the “V” is lowballing it.) </p>\n<p>Rather than a story of disruption and discontinuity, the story of Silicon Valley can be told as one of family legacies. Rather than upjumped kids in hoodies upsetting the staid operations of capital, it’s wealth doing what it always does—attracting more wealth. Think of the way Aaron Sorkin chooses to frame Mark Zuckerberg’s rise in <i>The Social Network</i>: here Mark Zuckerberg in a sloppy hoodie, there the Winklevoss twins—“men of Harvard,” constantly in blazers, and, as portrayed by a duplicated Armie Hammer, radiating inherited privilege from every pore. That doesn’t seem exactly untrue to life. Born in the Hamptons and raised in Greenwich, Connecticut, the Winklevoss twins surely led a life of privilege before coming to Harvard. What’s perhaps more remarkable is Sorkin’s insistence that slovenly, mousy Mark Zuckerberg, who was raised in Westchester County, and attended Phillips Exeter Academy, is somehow not just less cool than them, but socioeconomically distinct. What Sorkin insists on framing as Old Money versus The New Economy, in actuality, was more like two supertankers of privilege colliding (or, as <i>Forbes</i> would call them, “8s”).</p>\n<p>The idea that industry creates wealth out of nothing is one that US capitalism compulsively projects onto whatever segment of the economy is particularly new and shiny. Part of this idea is the notion that new elites disrupt older systems of wealth and privilege. The deck gets reshuffled, old systems of privilege get upended. The promise contained in such an idea seems deeply connected to American notions of equality. If wealth, power, and legitimacy comes from upending the old order, if fortunes are remade with each generation in different fields, the thinking goes, then there is something deeply anti-dynastic and possibly even egalitarian about wealth generation in this country. </p>\n<h1><b>From The Summit to Sand Hill Road</b></h1>\n<p>When you’re dealing with the San Francisco Bay Area, the question “where does the money come from?” is the obvious but perhaps less interesting one. San Francisco made its wealth in gold, San José in silver—or in supplying those trying to get rich off gold or silver. Generations of ranchers made vast fortunes on giant <i>estancias</i> carved from the land of the many peoples and nations now collectively known as the Muwekma Ohlone, and then from the territorial loot of the Mexican-American War. San Francisco was, and still is, a banking town—and with the advent of highways, the groves and fields up and down the Peninsula became subdivisions where home values skyrocketed. The Department of Defense invested in the region, funding whatever technology might help defeat the Soviets. When Silicon Valley started making unimaginable amounts of money, in other words, it did so in a place already awash in cash. The more interesting question is: where did that money go? </p>\n<p>If you tell the story of Silicon Valley as the story of children, grandchildren, or great-grandchildren, it becomes a story of money changing shape: shipping wealth becoming real estate holdings, becoming office parks, becoming bitcoin. When you tell the story this way, it’s less about mansions overlooking the Mission or the Presidio, but rather of The Summit atop tony Russian Hill. </p>\n<p>There are open and literal connections between the old guard and the new. Dede Wilsey, for example, a fixture of the SF social scene, was old-money dynastic to the point that she frequently claimed that the 1980s soap opera <i>Falcon Crest</i> was modeled on her clan. Her son Trevor Traina is a serial founder, whose successes (do you remember CompareNet?) mostly occurred during the first boom. Walter Haas III, the latest scion of a billionaire dynasty that goes back to the founding of Levi Strauss, is himself a founder. </p>\n<p>There are also emerging dynasties that bring together different corners of the Silicon Valley cosmos. Laura Arrillaga-Andreessen, for instance, is the daughter of John Arrillaga, Silicon Valley’s biggest commercial landlord and a Stanford mega-donor; she is married to Marc Andreessen, creator of Netscape and partner in the VC fund Andreessen Horowitz. Beyond such matches made on Sand Hill Road, there is the role family wealth has played in Silicon Valley’s preferred funding model, where family money is all over, and yet at the same time quite difficult to detect.</p>\n<p>From the outside, Silicon Valley can seem a rather mysterious engine for value generation. At the center of that mystery is so-called “venture capital.” Even within the venture capital pipeline there are more and less public segments, and wherever the mystery is most mysterious, the pipeline at its most opaque, there seems to be a pretty good chance, in the end, that the black box contains nothing but family money. </p>\n<p>When the former US Ambassador to NATO, General William Henry Draper Jr., founded Draper, Gaither &amp; Anderson in 1959, it was the first venture capital firm on the West Coast. Draper modeled the fund on the outfits that invested family money for the Vanderbilts, the Whitneys, the Carnegies, and other industrialists out east. Draper, Gaither &amp; Anderson’s initial investors included the Rockefeller family and the Hellmans, founders of San Francisco–headquartered Wells Fargo Bank. Stanford’s then-provost Frederick Terman convinced DG&amp;A to set up shop at 851 Welch Road, immediately abutting the university’s campus. The historian Leslie Berlin has pointed to the clear marching orders DG&amp;A was receiving from the Rockefellers: no real estate please; rather, the point was to connect Rockefeller cash with high tech.</p>\n<p>With time, the Drapers turned venture investing into a dynastic concern of their own. William Henry Draper Jr.’s son William Henry Draper III cofounded Sutter Hill Ventures, a legendary private equity firm based in Palo Alto. Draper’s grandson Tim Draper, before becoming famous for constantly proposing to split the Golden State into a number of smaller states that would allow Californians to shop around for their ideal California, founded Draper Fisher Jurvetson, which was an early investor in Baidu, Tesla, and, more controversially, Theranos. Tim’s daughter Jesse, who starred in several Nickelodeon shows, also runs her own venture fund, Halogen Ventures, which invests in companies founded by women. </p>\n<h1><b>The Friends and Family Round</b></h1>\n<p>Dynasties like the Drapers may not be the norm in Silicon Valley, but they’re not uncommon either. Family money shapes Silicon Valley companies, even if it does so in ways that are less readily apparent than the big bets of famous investors. That’s partly because family money gets in before anyone gets famous. VCs advise aspiring startup founders to raise money with a “friends and family” round even before turning to angel investors. “Friends and family” is entirely private, it’s decidedly small-bore, and it leaves very few traces unless someone sues (and there’s an entire cottage industry in Silicon Valley making sure that no one does). Absent a Theranos-sized fuckup, there’s usually no way to know if a founder’s parents, who both happened to work for Goldman Sachs, invested a critical $200K to help Junior get his business off the ground.</p>\n<p>When it comes to angel investors and venture capital funds, while much of their money comes from endowments, pension funds, insurance companies, and the like, one major source is “family offices.” That is a euphemism for investment funds run for one or sometimes a handful of immensely wealthy families. As the historian Tom Nicholas points out in <i>VC: An American History</i>, the structure of modern venture capital investment grew out of the need to formalize family offices in the 1920s. According to an April 2021 <i>Financial Times</i> report, there are over 7,000 family offices worldwide (a 40 percent rise from 2017 to 2019), managing about six trillion dollars in assets. The trend line has been pointing up ever since the financial crisis of 2008. And, as <i>Crunchbase</i> reported in 2018, family offices seem to be increasingly keen on investing in startups directly: pivoting, as it were, from contributing to VC funds to behaving like VCs in their own right. A 2020 report by Silicon Valley Bank suggests that over 90 percent of family offices prefer to get involved in the early stages of venture investing (meaning Seed or Series A). </p>\n<p>In Silicon Valley, many family offices were founded to manage the fabulous wealth of the tech billionaires themselves (for instance the Omidyar Network, which manages investments on behalf of the family of eBay founder Pierre Omidyar)—so relatively recent money. But some money is positively ancient. The Rockefellers’ family office, Venrock, was a crucial early investor in both Intel and Apple Computers. The Bechtel family, having made a fortune in construction going all the way back to the Western Pacific Railroad, incorporated as Bechtel in San Francisco in 1889. The family is as old money as they come in San Francisco—Bohemian Club, generations of Stanford alumni, the works. (I am—fun fact—writing this essay sitting across from a building on the Stanford campus that bears the Bechtel family name.) Their family office is called The Fremont Group, which was once run by former US Secretary of State and longtime SF high society fixture George P. Shultz. Through Trinity Ventures, founded in 1986, the Bechtels also invested directly in companies like Extreme Networks, Blue Nile, and mommy-supplier extraordinaire Zulily. </p>\n<p>One partner at a venture capital fund told me that, in his experience, VCs turn to family offices when first starting out. Big as family funds can be, the inflow of capital represented by, say, a pension fund or a university endowment is both much bigger and much more reliable. Family offices generally do not get access to what a big university endowment gets access to. The only way family offices get to play in a hot new fund is to have invested in the firm’s funds back when it was just starting out. That means that on the whole family money comes into play early in the process of fund formation.</p>\n<p>Between the “friends and family” round, the family office’s role in fund formation, and their preference for early-stage investment, the family is Silicon Valley’s ultimate incubator. Combine that with the fact that friends and family rounds tend to be extremely informal, and that family offices are barely regulated by the FDIC and SEC, and you notice that the system is perfectly set up to clothe family wealth in the trappings of an open market. </p>\n<p>The only time you get even a slight glimpse is when things go seriously wrong: when companies collapse, when people go to jail, when very wealthy people sue each other. When Theranos collapsed, it became pretty clear that wealthy families—from the Waltons, to the DeVos family, to, yes, the Drapers—had been Theranos’s main backers. Other Theranos investors, like George Shultz, while not mega-rich themselves, were fixtures of the family office world. In general, it seems that very little of the billions in valuations that evaporated had come to the biotech-startup in the way most startups make their money—one reason why Elizabeth Holmes was able to get away with her deceptions for so long. </p>\n<h1><b>Disembodied and Reconstituted</b></h1>\n<p>If family money is everywhere in Silicon Valley, albeit almost undetectably so, there’s one place where anyone making money in the Valley looks to pass it on to the next generation and to the generations after that: real estate. The federal estate tax exemption is $11.7 million as of 2021, and just owning two or three buildings in the right zip codes in the Bay Area means you leave just a trace in the federal ledgers when you die. IRS agents thus have a box seat for the way Silicon Valley moves its dynastic project forward. </p>\n<p>The thing is, they’re not seeing tech wealth show up in estate tax filings quite yet. As one agent told me, in most of the cases the Bay Area offices handle, “wealth is made through buying real estate, or indeed by inheritance. Some may dabble in high tech investments, but only after making money another way.” </p>\n<p>Some of this has to do with the fact that most techies are still young. But some of it probably has to do with the fact that the wealth that migrates from one generation to the next isn’t usually in stocks anyway. Where the IRS is seeing tech show up is in gift tax enforcement, which is handled by the same office. Techies, the IRS agent says, “are young and wealthy and hearing from the lawyers in the area about how to start gifting” their money. That means the fabulously valued stocks likely change shape into something else—among other things, real estate. </p>\n<p>If anything, real estate has probably outperformed tech since tech moved in. Silicon Valley as a collection of companies has experienced boom and bust, but as a physical location the stretch of the San Francisco Peninsula between Burlingame and San José seems to have known only one endless boom. That boom has been extremely narrowly distributed: buying some Tesla stock is not attainable for most, but still a hell of a lot more attainable than owning property in Mountain View. Real estate is still the greatest repository of dynastic wealth—and the greatest source of intergenerational immiseration. </p>\n<p>Even before a single semiconductor company moved in, the Valley made some families very rich and ensured that others would be deprived of their spin of the wheel. As the historian Stephen Pitti has noted, as Santa Clara County developed, the powers that be were concerned to attract more residents to the area, where the mining economy had largely given way to an overwhelmingly agriculture-based economy. They were concerned that not enough white people would stay in the area, and that too many Asians and Latinos might. As a result, small farming tracts were readily made available to white Americans and immigrants from Europe (Italians, Spaniards, Portuguese), while Mexican Americans were kept “as a naturally mobile, low-wage labor force.” </p>\n<p>With each subsequent generation, those small parcels had a way of generating ever more massive amounts of wealth. The well-documented explosion in home values in the area is almost entirely due to an explosion in the value of land. The inequality fostered by the nearly feudal land distribution promoted in the County has given rise to the escalating differences between the area’s rich and poor. </p>\n<p>Almost every campus up and down the Valley has a story like the new Apple spaceship: the Glendenning Farm, slowly sold off to developers in the middle of the last century, until Hewlett Packard plopped down its headquarters (long called the “apricot division”), eventually selling it to Apple. Some of the local landowners seem to have gotten stiffed by the bargain, but the rapid development also created massive wealth for some. Richard Peery and John Arrillaga bought up massive tracts of land and became two of the largest commercial landlords in the Valley. Justin Jacobs Jr. plopped down the cheap, interchangeable concrete tilt-up buildings, which still make up a majority of the low-flung Silicon Valley office parks. </p>\n<p>Most centrally, the area once occupied by the large estate maintained by the railroad barons Leland and Jane Stanford transformed itself into Stanford University, an investment behemoth and still Silicon Valley’s largest landowner. On the surface, this transformation seems perhaps the most unusual in the Valley, but it might be the most representative. Stanford University represents a frustrated dynastic project: named after Leland and Jane’s son, Leland Jr., who died a year before the university was founded, it is home to his gravesite and is dedicated to his memory. Disembodied and reconstituted as a tax-exempt entity, indivisible by the vagaries of family squabbles and immune to the decadence that might have befallen actual generations of Stanfords, Leland Stanford Jr. has dominated the area more effectively than any dynasty made of flesh and blood could have. </p>\n<p>And that seems to make unfortunate Leland Stanford Jr. something of a patron saint for the entire area, where wealth has enormous inertia and nevertheless constantly changes shape. There is an old comedy bit where Chris Rock distinguishes between being rich and being wealthy. “Rich is some shit you can lose with a crazy summer and a drug habit,” he jokes. “You can’t get rid of wealth.” Through all its transformations—from precious metals to land to superconductors to photo-sharing apps—Silicon Valley seems determined to prove that last part right.</p>",
      "content_text": "Ex nihilo is one of those concepts that makes you immediately suspicious. When someone claims to have made something out of nothing, there is almost always an inconvenient history that they intend to eclipse. The fantasy that before us there was nothing has a great deal of ideological power. The creator ex nihilo gets to claim some faint emanation of divine power—the wealth creator and the job creator are treated as distant cousins to the capital-C Creator. \nThe same is true for the idea of terra nullius. When tech came to a stretch of Northern California along the San Francisco Bay, it reframed the world it found as a bunch of apricot groves, a rail line, and not much else. This kind of pioneering story abounds in Silicon Valley. It’s not just the architecture, which seems to pretend that nothing was there before whatever spaceship of an office park landed in a given lot. Rather, it’s the environmentalist facade of an industry whose dirty beginnings—above all, in the known carcinogen, trichloroethylene, long used to clean semiconductors—have dotted Santa Clara County with a record number of Superfund sites. It’s the way, looking at the names of the wealthiest people in the Valley, you get the sense of wealth that’s been created by this generation rather than inherited from previous ones. Of course, the Zuckerberg-Chan dynasty may one day amuse the Bay Area’s society columnists with their coke-fueled antics at the annual Cotillion Debutante ball. Maybe X AE A-XII Musk will one day run for governor of California like so many scions before him who were born on third base and think they hit a triple. \nBut for now, this wealth feels new. And the newness is part of its allure, its legitimacy. Stories abound about how Silicon Valley’s newly rich don’t know how to spend their money, or how they spend it on absurd things. There is something reassuring about that framing, suggesting as it does that these protagonists are new to wealth and privilege, that wealth is foreign to them. \nYears ago, I became fascinated with the question of how “new” the money invested and made in Silicon Valley really is. It has fascinated me in part because it is on some level an unanswerable question: how do you decide whether money is really “new”? Even asking the question, asking where money came from, teases out some inconvenient continuities, and a different understanding of how this industry and the place it has made its home came to be. \nSupertankers of privilege\nSilicon Valley is good at persuading people to accept its self-perception as fact—a useful tactic, since a lot rides on that perception. In 2014, Forbes ran an analysis showing that “the wealthiest people in the country are increasingly self-made, leaving behind an era when dynasties inherited and concentrated wealth.” The leading indicator, they pointed out, was tech, where “more than 94 percent of the tech billionaires created their fortunes themselves.” (The numbers were much lower for sectors such as manufacturing.)\nHow did Forbes determine tech wasn’t dynastic? The authors ranked Silicon Valley’s super-rich on a 1-10 scale. A “1” on their scale denoted “inherited fortune but not working to increase it”; a “4” meant “inherited fortune and increased it in a meaningful way”; a “7,” “self-made who got a head start from wealthy parents and moneyed background”; and an “8” was self-made but “came from a middle- or upper-middle-class background.” To rank a “10,” you basically had to be left in a basket on a river. \nThe results of the analysis aren’t particularly surprising. It turns out tech is mostly, by these calculations, “8s.” After all, that’s what the methodology was basically created to deliver. Anyone involved in tech in the last forty years who wound up as a billionaire likely grew their fortune significantly. You’d have to be an idiot, or actively trying, not to. But even beyond that, the methodology is profoundly telling. There is the unspoken assumption that growing one’s wealth was somehow the opposite of being dynastic. There is also the idea that money only grows due to some immense effort—in fact, their one example of a “1,” Laurene Powell Jobs, is evidence of how hard it is to avoid growing your wealth once it’s reached a certain level of absurdity. And the suggestion that anyone “6” and above “truly made it on their own” is staggering. When a certain “billionaire” ex-president ranks in the middle of your scale, the off-ness of the scale seems to be the point. \nThe most interesting questions about wealth transmission in America, however, happen within the “8s”—that is, among the twenty million millionaires as opposed to the 600 ro so billionaires in the US. Forbes set up their method around the idea that dynastic wealth and wealth multiplying from one generation to the next are mutually exclusive, as though taking an eighty million dollar fortune and turning it into a billion-dollar fortune is somehow the opposite of the dynastic transmission of capital. There’s one kind of story about capitalism being told when you highlight how Meg Whitman, former CEO of eBay and Hewlett Packard (and, um, Quibi), is a self-made billionaire who ran for governor of California as just “Meg.” And another when you think about the fact that she comes from two Boston Brahmin families, and one of her sons bears the almost comically dynastic name Griffith Rutherford Harsh V. (“Griff,” as he’s known, is the direct descendant of a revolutionary war general, so if anything the “V” is lowballing it.) \nRather than a story of disruption and discontinuity, the story of Silicon Valley can be told as one of family legacies. Rather than upjumped kids in hoodies upsetting the staid operations of capital, it’s wealth doing what it always does—attracting more wealth. Think of the way Aaron Sorkin chooses to frame Mark Zuckerberg’s rise in The Social Network: here Mark Zuckerberg in a sloppy hoodie, there the Winklevoss twins—“men of Harvard,” constantly in blazers, and, as portrayed by a duplicated Armie Hammer, radiating inherited privilege from every pore. That doesn’t seem exactly untrue to life. Born in the Hamptons and raised in Greenwich, Connecticut, the Winklevoss twins surely led a life of privilege before coming to Harvard. What’s perhaps more remarkable is Sorkin’s insistence that slovenly, mousy Mark Zuckerberg, who was raised in Westchester County, and attended Phillips Exeter Academy, is somehow not just less cool than them, but socioeconomically distinct. What Sorkin insists on framing as Old Money versus The New Economy, in actuality, was more like two supertankers of privilege colliding (or, as Forbes would call them, “8s”).\nThe idea that industry creates wealth out of nothing is one that US capitalism compulsively projects onto whatever segment of the economy is particularly new and shiny. Part of this idea is the notion that new elites disrupt older systems of wealth and privilege. The deck gets reshuffled, old systems of privilege get upended. The promise contained in such an idea seems deeply connected to American notions of equality. If wealth, power, and legitimacy comes from upending the old order, if fortunes are remade with each generation in different fields, the thinking goes, then there is something deeply anti-dynastic and possibly even egalitarian about wealth generation in this country. \nFrom The Summit to Sand Hill Road\nWhen you’re dealing with the San Francisco Bay Area, the question “where does the money come from?” is the obvious but perhaps less interesting one. San Francisco made its wealth in gold, San José in silver—or in supplying those trying to get rich off gold or silver. Generations of ranchers made vast fortunes on giant estancias carved from the land of the many peoples and nations now collectively known as the Muwekma Ohlone, and then from the territorial loot of the Mexican-American War. San Francisco was, and still is, a banking town—and with the advent of highways, the groves and fields up and down the Peninsula became subdivisions where home values skyrocketed. The Department of Defense invested in the region, funding whatever technology might help defeat the Soviets. When Silicon Valley started making unimaginable amounts of money, in other words, it did so in a place already awash in cash. The more interesting question is: where did that money go? \nIf you tell the story of Silicon Valley as the story of children, grandchildren, or great-grandchildren, it becomes a story of money changing shape: shipping wealth becoming real estate holdings, becoming office parks, becoming bitcoin. When you tell the story this way, it’s less about mansions overlooking the Mission or the Presidio, but rather of The Summit atop tony Russian Hill. \nThere are open and literal connections between the old guard and the new. Dede Wilsey, for example, a fixture of the SF social scene, was old-money dynastic to the point that she frequently claimed that the 1980s soap opera Falcon Crest was modeled on her clan. Her son Trevor Traina is a serial founder, whose successes (do you remember CompareNet?) mostly occurred during the first boom. Walter Haas III, the latest scion of a billionaire dynasty that goes back to the founding of Levi Strauss, is himself a founder. \nThere are also emerging dynasties that bring together different corners of the Silicon Valley cosmos. Laura Arrillaga-Andreessen, for instance, is the daughter of John Arrillaga, Silicon Valley’s biggest commercial landlord and a Stanford mega-donor; she is married to Marc Andreessen, creator of Netscape and partner in the VC fund Andreessen Horowitz. Beyond such matches made on Sand Hill Road, there is the role family wealth has played in Silicon Valley’s preferred funding model, where family money is all over, and yet at the same time quite difficult to detect.\nFrom the outside, Silicon Valley can seem a rather mysterious engine for value generation. At the center of that mystery is so-called “venture capital.” Even within the venture capital pipeline there are more and less public segments, and wherever the mystery is most mysterious, the pipeline at its most opaque, there seems to be a pretty good chance, in the end, that the black box contains nothing but family money. \nWhen the former US Ambassador to NATO, General William Henry Draper Jr., founded Draper, Gaither & Anderson in 1959, it was the first venture capital firm on the West Coast. Draper modeled the fund on the outfits that invested family money for the Vanderbilts, the Whitneys, the Carnegies, and other industrialists out east. Draper, Gaither & Anderson’s initial investors included the Rockefeller family and the Hellmans, founders of San Francisco–headquartered Wells Fargo Bank. Stanford’s then-provost Frederick Terman convinced DG&A to set up shop at 851 Welch Road, immediately abutting the university’s campus. The historian Leslie Berlin has pointed to the clear marching orders DG&A was receiving from the Rockefellers: no real estate please; rather, the point was to connect Rockefeller cash with high tech.\nWith time, the Drapers turned venture investing into a dynastic concern of their own. William Henry Draper Jr.’s son William Henry Draper III cofounded Sutter Hill Ventures, a legendary private equity firm based in Palo Alto. Draper’s grandson Tim Draper, before becoming famous for constantly proposing to split the Golden State into a number of smaller states that would allow Californians to shop around for their ideal California, founded Draper Fisher Jurvetson, which was an early investor in Baidu, Tesla, and, more controversially, Theranos. Tim’s daughter Jesse, who starred in several Nickelodeon shows, also runs her own venture fund, Halogen Ventures, which invests in companies founded by women. \nThe Friends and Family Round\nDynasties like the Drapers may not be the norm in Silicon Valley, but they’re not uncommon either. Family money shapes Silicon Valley companies, even if it does so in ways that are less readily apparent than the big bets of famous investors. That’s partly because family money gets in before anyone gets famous. VCs advise aspiring startup founders to raise money with a “friends and family” round even before turning to angel investors. “Friends and family” is entirely private, it’s decidedly small-bore, and it leaves very few traces unless someone sues (and there’s an entire cottage industry in Silicon Valley making sure that no one does). Absent a Theranos-sized fuckup, there’s usually no way to know if a founder’s parents, who both happened to work for Goldman Sachs, invested a critical $200K to help Junior get his business off the ground.\nWhen it comes to angel investors and venture capital funds, while much of their money comes from endowments, pension funds, insurance companies, and the like, one major source is “family offices.” That is a euphemism for investment funds run for one or sometimes a handful of immensely wealthy families. As the historian Tom Nicholas points out in VC: An American History, the structure of modern venture capital investment grew out of the need to formalize family offices in the 1920s. According to an April 2021 Financial Times report, there are over 7,000 family offices worldwide (a 40 percent rise from 2017 to 2019), managing about six trillion dollars in assets. The trend line has been pointing up ever since the financial crisis of 2008. And, as Crunchbase reported in 2018, family offices seem to be increasingly keen on investing in startups directly: pivoting, as it were, from contributing to VC funds to behaving like VCs in their own right. A 2020 report by Silicon Valley Bank suggests that over 90 percent of family offices prefer to get involved in the early stages of venture investing (meaning Seed or Series A). \nIn Silicon Valley, many family offices were founded to manage the fabulous wealth of the tech billionaires themselves (for instance the Omidyar Network, which manages investments on behalf of the family of eBay founder Pierre Omidyar)—so relatively recent money. But some money is positively ancient. The Rockefellers’ family office, Venrock, was a crucial early investor in both Intel and Apple Computers. The Bechtel family, having made a fortune in construction going all the way back to the Western Pacific Railroad, incorporated as Bechtel in San Francisco in 1889. The family is as old money as they come in San Francisco—Bohemian Club, generations of Stanford alumni, the works. (I am—fun fact—writing this essay sitting across from a building on the Stanford campus that bears the Bechtel family name.) Their family office is called The Fremont Group, which was once run by former US Secretary of State and longtime SF high society fixture George P. Shultz. Through Trinity Ventures, founded in 1986, the Bechtels also invested directly in companies like Extreme Networks, Blue Nile, and mommy-supplier extraordinaire Zulily. \nOne partner at a venture capital fund told me that, in his experience, VCs turn to family offices when first starting out. Big as family funds can be, the inflow of capital represented by, say, a pension fund or a university endowment is both much bigger and much more reliable. Family offices generally do not get access to what a big university endowment gets access to. The only way family offices get to play in a hot new fund is to have invested in the firm’s funds back when it was just starting out. That means that on the whole family money comes into play early in the process of fund formation.\nBetween the “friends and family” round, the family office’s role in fund formation, and their preference for early-stage investment, the family is Silicon Valley’s ultimate incubator. Combine that with the fact that friends and family rounds tend to be extremely informal, and that family offices are barely regulated by the FDIC and SEC, and you notice that the system is perfectly set up to clothe family wealth in the trappings of an open market. \nThe only time you get even a slight glimpse is when things go seriously wrong: when companies collapse, when people go to jail, when very wealthy people sue each other. When Theranos collapsed, it became pretty clear that wealthy families—from the Waltons, to the DeVos family, to, yes, the Drapers—had been Theranos’s main backers. Other Theranos investors, like George Shultz, while not mega-rich themselves, were fixtures of the family office world. In general, it seems that very little of the billions in valuations that evaporated had come to the biotech-startup in the way most startups make their money—one reason why Elizabeth Holmes was able to get away with her deceptions for so long. \nDisembodied and Reconstituted\nIf family money is everywhere in Silicon Valley, albeit almost undetectably so, there’s one place where anyone making money in the Valley looks to pass it on to the next generation and to the generations after that: real estate. The federal estate tax exemption is $11.7 million as of 2021, and just owning two or three buildings in the right zip codes in the Bay Area means you leave just a trace in the federal ledgers when you die. IRS agents thus have a box seat for the way Silicon Valley moves its dynastic project forward. \nThe thing is, they’re not seeing tech wealth show up in estate tax filings quite yet. As one agent told me, in most of the cases the Bay Area offices handle, “wealth is made through buying real estate, or indeed by inheritance. Some may dabble in high tech investments, but only after making money another way.” \nSome of this has to do with the fact that most techies are still young. But some of it probably has to do with the fact that the wealth that migrates from one generation to the next isn’t usually in stocks anyway. Where the IRS is seeing tech show up is in gift tax enforcement, which is handled by the same office. Techies, the IRS agent says, “are young and wealthy and hearing from the lawyers in the area about how to start gifting” their money. That means the fabulously valued stocks likely change shape into something else—among other things, real estate. \nIf anything, real estate has probably outperformed tech since tech moved in. Silicon Valley as a collection of companies has experienced boom and bust, but as a physical location the stretch of the San Francisco Peninsula between Burlingame and San José seems to have known only one endless boom. That boom has been extremely narrowly distributed: buying some Tesla stock is not attainable for most, but still a hell of a lot more attainable than owning property in Mountain View. Real estate is still the greatest repository of dynastic wealth—and the greatest source of intergenerational immiseration. \nEven before a single semiconductor company moved in, the Valley made some families very rich and ensured that others would be deprived of their spin of the wheel. As the historian Stephen Pitti has noted, as Santa Clara County developed, the powers that be were concerned to attract more residents to the area, where the mining economy had largely given way to an overwhelmingly agriculture-based economy. They were concerned that not enough white people would stay in the area, and that too many Asians and Latinos might. As a result, small farming tracts were readily made available to white Americans and immigrants from Europe (Italians, Spaniards, Portuguese), while Mexican Americans were kept “as a naturally mobile, low-wage labor force.” \nWith each subsequent generation, those small parcels had a way of generating ever more massive amounts of wealth. The well-documented explosion in home values in the area is almost entirely due to an explosion in the value of land. The inequality fostered by the nearly feudal land distribution promoted in the County has given rise to the escalating differences between the area’s rich and poor. \nAlmost every campus up and down the Valley has a story like the new Apple spaceship: the Glendenning Farm, slowly sold off to developers in the middle of the last century, until Hewlett Packard plopped down its headquarters (long called the “apricot division”), eventually selling it to Apple. Some of the local landowners seem to have gotten stiffed by the bargain, but the rapid development also created massive wealth for some. Richard Peery and John Arrillaga bought up massive tracts of land and became two of the largest commercial landlords in the Valley. Justin Jacobs Jr. plopped down the cheap, interchangeable concrete tilt-up buildings, which still make up a majority of the low-flung Silicon Valley office parks. \nMost centrally, the area once occupied by the large estate maintained by the railroad barons Leland and Jane Stanford transformed itself into Stanford University, an investment behemoth and still Silicon Valley’s largest landowner. On the surface, this transformation seems perhaps the most unusual in the Valley, but it might be the most representative. Stanford University represents a frustrated dynastic project: named after Leland and Jane’s son, Leland Jr., who died a year before the university was founded, it is home to his gravesite and is dedicated to his memory. Disembodied and reconstituted as a tax-exempt entity, indivisible by the vagaries of family squabbles and immune to the decadence that might have befallen actual generations of Stanfords, Leland Stanford Jr. has dominated the area more effectively than any dynasty made of flesh and blood could have. \nAnd that seems to make unfortunate Leland Stanford Jr. something of a patron saint for the entire area, where wealth has enormous inertia and nevertheless constantly changes shape. There is an old comedy bit where Chris Rock distinguishes between being rich and being wealthy. “Rich is some shit you can lose with a crazy summer and a drug habit,” he jokes. “You can’t get rid of wealth.” Through all its transformations—from precious metals to land to superconductors to photo-sharing apps—Silicon Valley seems determined to prove that last part right.",
      "date_published": "2021-10-12T14:14:59.000Z",
      "date_modified": "2021-10-12T14:14:59.000Z",
      "_plugin": {
        "pageFilename": "de24cac7b3d639091555eba48167a8837c9e0db60794bdcce79a459ae055d58f.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/socialist-cyborgs",
      "url": "https://logicmag.io/kids/socialist-cyborgs",
      "title": "Socialist Cyborgs",
      "summary": "When Bulgaria tried to save communism with the kids.",
      "content_html": "<p>In the spring of 1989, a virus began attacking computers in Europe, the United States, and Asia. During every sixteenth run of an infected executable file, the virus overwrote a random sector of a machine’s hard disk and manifested the phrase “Eddie lives… somewhere in time” on the monitor. A signature declared the virus’ origin: “This program was written in the city of Sofia (C) 1988–89 Dark Avenger.” </p>\n<p>Dark Avenger was the most prolific of a number of hackers that emerged in Bulgaria in the late 1980s and 1990s. In December 1990, <i>The New York Times</i> reported that the Eastern Bloc nation had become a major infection vector in the new information economy. The late John McAfee told the newspaper, “I would say that 10 percent of the sixty calls we receive each week are for Bulgarian viruses.” By another estimate, around ninety out of the 300 then extant viruses for IBM machines originated from the country. In 1997, <i>Wired</i> called Bulgaria “the heart of darkness.” </p>\n<p>How could a small socialist country become ground zero for so many digital epidemics? The conventional narrative of Eastern European communism is one of technologically backward states that failed to enter the information age, locked behind an impenetrable Iron Curtain that prevented both people and ideas from circulating. In Bulgaria, however, the electronic industry’s success was considered a key component of achieving the state’s ideological and economic dreams. The Bulgarian Communist Party hoped that the computer would usher in a communist utopia. Automation would streamline planning through a nationwide information network, and man would be free from menial tasks. More pressingly, the party was betting that computers could revive an economy that had once been the second fastest-growing in the world, but was floundering by the 1980s.</p>\n<p>This vision was partially fulfilled: by the mid-1980s, socialist Bulgaria was producing up to 47 percent of all computer hardware within the Eastern Bloc, from Berlin to Vladivostok. But the country still suffered from negligible growth rates and low worker productivity, in part due to the party’s inability to implement the technology its factories were producing. State-produced hardware, computers, and numerically-controlled machines often languished unused due to a shortage of necessary software. </p>\n<p>As this problem played out over the course of the 1980s, the party vested its hopes in a mass education effort to transform what turned out to be the last children of socialism into the first electronic generation. These kids would be trained to create the software that would allow the party to automate all it dreamed of automating—from chemical production to managing pension databases. Beginning in 1983, Bulgarian children as young as twelve were enrolled in a state-run program of technical tinkering. High schools and universities were transformed into laboratories of the future and factories for the regime. While learning BASIC, Bulgarian children were to advance themselves as intellectual laborers and truly creative citizens of a newly scientific socialist world, in order to become the future governors of much more complex production and social processes.</p>\n<p>In reality, however, the 1980s generation of Bulgarian children found themselves becoming cogs in an economy that continued to suffer shortages, bottlenecks, and scarcity—all of which contributed to the collapse of the communist regime in 1989. When that happened, the technological skills and entrepreneurial desires the state had cultivated in its children were rechanneled into viruses and the first software enterprises of democratic Bulgaria. </p>\n<p>Hackers like Dark Avenger were thus the most notorious product of a failed political and cultural experiment with a long afterlife. The death of the party’s dream pushed much of the 1980s generation into an ideology that was fiercely opposed to socialism, but still wildly utopian. Many of these kids eventually emigrated to Silicon Valley and other hubs in the global information economy, bringing with them a strongly capitalist version of the communist’s dream: liberation of the human spirit through technology.</p>\n<h1><b>Tinker and Spy</b></h1>\n<p>Karl Marx once quipped that under communism man would be a fisherman in the morning and an artist in the afternoon. By the 1960s, the Bulgarian Communist Party believed that automation had brought Marx’s vision to the cusp of realization. Thousands of engineers were trained in the country’s universities, and cybernetics became a watchword for the party’s economic programs. Computers would streamline information flows, provide objective information on the economy, and allow planners in Sofia to accurately predict the future. The Politburo trumpeted that “science would be a productive force.”</p>\n<p>Just a generation before, that idea of Bulgaria’s future had seemed unthinkable. Back in 1944, when the party assumed power as Stalin’s Red Army rolled over the Danube, this small Balkan state was largely an agricultural producer. In the nascent field of international development, Bulgaria was considered an example of the region’s “trap,” which could only be escaped through large-scale investment. That is precisely what the Soviets brought, in the guise of breakneck Stalinist industrialization. Throughout the 1950s, the country assumed the Soviet economic model: central planning, smokestack industries, and a growing industrial proletariat squeezed into the cities. </p>\n<p>By the 1960s, however, Bulgaria’s extensive growth period was tapering off, and the country was suffering a debt crisis. On the advice of Bulgarian engineers trained in western Europe, the party turned to electronics as the good of the future. As the party’s leader, Todor Zhivkov, put it, “We couldn’t industrialize with tomatoes and eggs.” Heavy state investment was combined with Japanese licensing and a prodigious espionage program to create the Bulgarian computer industry. By the 1970s, dozens of Bulgarian factories and institutes were churning out CPUs, mini-computers, and peripherals, such as ES-1020 mainframes and IZOT hard drives. Most of this technology was licensed or reverse-engineered after the Bulgarian intelligence services had procured it in the West; from its inception, the nation’s hardware industry was based on spying and tinkering, rather than true domestic innovation. The golden goose was the hard disk, which Bulgaria almost monopolized in the Eastern Bloc.</p>\n<p>The 1980s were marked by continual heavy investment in robotics and personal computing, bringing the automation age into the office and onto the factory floor. Imperfect as it was, Bulgarian automation did take hold to some extent—around 200,000 workers in a country of eight million worked in the electronics sector, the second largest industrial workforce in the country. Its IBM 360/370-copies, Winchester hard drives, and an Apple II clone known as the Pravetz, found their way into socialist enterprises throughout the Global South. Bulgarian computers flew on the Soviet space station Mir, were used for nuclear research in India, and equipped Mozambique’s nascent statistical authority. Though often slowly, and in a piecemeal fashion, automation entered car production processes and cement factories, monitored milk levels in collective farms, and increasingly suffused social and government services. </p>\n<p>Unfortunately, Bulgarian products often fared badly on the global capitalist market due to their sometimes shoddy quality. Rather than looking at its economic principles such as central planning as a potential source of the problem, the party focused on the “subjective factor.” In their view, it was the Bulgarian worker rather than the system that was to blame—shirking responsibilities, pilfering the petty change, and sleeping on the job. Only the computer and robot would solve this problem, by eliminating the human strategies of survival in the shortage economy of socialism, where personal links and the grey market were key to procuring scarce goods. These were the peculiar conditions within which the next, truly computerized generation, would have to grow up.</p>\n<h1><b>The Man-Machine-Environment</b></h1>\n<p>The organization that prepared most Bulgarian children to be the model communists of the future was the Dimitrov Communist Youth Union (DKMS). In 1984, the DKMS started publishing <i>Computer for You</i>, a monthly magazine for the new generation. The magazine’s first editorial told these kids that “we will aim to offer you knowledge, experience and creativity from the interesting world of ‘her majesty’ ELECTRONISATION.” </p>\n<p>Her majesty was indeed marching through children’s lives. In 1979, the party had directed twenty-seven schools across the country to implement experiments in computer education. But it was the personal computing revolution that opened the Bulgarian school to electronics. In 1983, the Sofia High School of Electronics received its first fully equipped classroom of eighteen Bulgarian PCs, and informatics became part of the school curriculum. </p>\n<p>Within a year, there were over 300 PCs in Bulgarian schools, and the numbers continued growing. Education software was used in language training, mathematics, and science lessons, alongside BASIC classes. Eleventh grade was reconstructed to include units such as “an introduction to cybernetics” and “production automation.” <i>Computer for You</i> contained architects’ plans for new classrooms that treated students like cyborgs—“integration into the school environment is effective only if it ensures optimal functioning of the Man-Machine-Environment system,” a cybernetics engineer told the magazine. </p>\n<p>If the economy was going to be composed of man-machine systems, schools would be, too. New educational methods were developed under the auspices of mathematician Blagovest Sendov, who had participated in the creation of Vitosha, the first Bulgarian computer, in the early 1960s. In an article for the magazine, Sendov called the computer “a fantastical object” and deemed it the new age’s defining metaphor. Bulgarian socialism, he said, would be defined by the “mind to be molded—on the computer model.” The new society was one of informational glut, and kids had to learn to “continue learning” throughout life—to sift through information, synthesize it, and see the connections between different areas of human endeavor. Learning the language of computers—what Sendov called “the second literacy”—was to become the crux of every school’s curriculum.</p>\n<p>Children were also enticed into the new dream through a network of computer clubs operated by the DKMS. The first appeared in 1984 in the capital of Sofia; by 1987, there were over 530 of them throughout the country, from the largest cities to many villages. They contained over 4,000 PCs, as well as small, domestically produced robots, which students could program to perform various tasks, such as moving small loads between two tables. Annual nationwide “Informatics Olympiads” were held throughout the country, and Bulgarian computer clubs also popped up in the USSR, Cuba, North Korea, Ethiopia, and Vietnam. The DKMS estimated that over 600,000 students and young workers used the computer clubs every year.</p>\n<p>By 1985, the first student-run enterprise in computing was already helping to solve the country’s economic problems. In the course of just a few months, Avantgarde, a collective of high school and university students from Sofia and the city of Plovdiv, had created sixty games and twenty educational programs for classrooms and the computer club network. They also cooperated with state factories, creating specialized data processing packages for the economy: graphic editors for design studios, electronic databases for enterprise personnel record-keeping, troubleshooting programs, and more. The young engineer that oversaw Avantgarde noted that, by 1986, there were software enterprises in many provincial cities, while over fifty economic entities in the state economy were interested in either ordering or co-developing software packages. In the typically staid language of the time, he saw all this as “linking more closely with the ideological preparation… of the young population, in the spirit of the realities that determine the technological transition of socialist Bulgaria into the 21st century.” And as <i>Computer for You </i>more rhapsodically put it, “The intellectual revolution is in the hands of today’s students.”</p>\n<h1><b>Viral Load</b></h1>\n<p>Ultimately, Marx’s vision of hunting in the morning and debating in the afternoon never arrived for socialist Bulgaria. Eastern Europe was swept up in the grand changes of 1989, and the Bulgarian Communist Party initiated a palace coup the day after the Berlin Wall fell, removing Todor Zhivkov from power and starting down the road to democratic elections. Yet the country’s intellectual revolution had nevertheless occurred: the cyborgification of Bulgarian youth had succeeded, on both a technical and a cultural level.</p>\n<p>Two years before the fall of communism, in an effort to stave off the collapse of the economy, the party had begun introducing modest economic reforms. This included limited forms of private enterprise, and Bulgarian youth formed some of the country’s first legal private companies. Many children found it easy to make this transition to market capitalism—as <i>Computer for You </i>pointed out, young programmers in particular were already operating in the conditions of freedom that the state was now proclaiming. Much of the software being used by major firms had come out of those children’s brains. The state’s airline, Balkan Airways, used the Syntez program from Burgas-based software firm Busoft, where a tenth grader awed journalists by pulling up flight schedules and reservation systems in Bulgarian and English. Young developers had automated hotel reservation, office correspondence, and wage databases, and demonstrated their inventions at the Plovdiv international exposition in 1985, which was themed “the creations of young inventors.”</p>\n<p>As the Bulgarian economy faltered at the end of the decade, young Bulgarian programmers lost their job prospects along with much of their creative freedom. In this crisis was born the other face of socialist Bulgaria’s computer revolution—the virus. The first mention of “computer viruses” in <i>Computer for You</i> came in April 1988; in effect, the magazine let young programming enthusiasts know what a virus was, and that it could be copied, improved, and spread. Because most Bulgarian computers were shared by dozens of people in classrooms and computer clubs, it was easy to get hold of a virus and infect a machine inadvertently. Viruses also suited the logics of reverse-engineering and copying on which the Bulgarian computer economy was already running. Why not tinker with a digital pathogen and send it out into the world beyond Bulgaria? After all, you knew it would work virtually anywhere, because your Pravetz was compatible with an Apple!</p>\n<p>Starting in early 1989, computers as far away as the USA and Thailand were infected with Bulgarian viruses. Some were minor irritants, such as the “Yankee Doodle” virus, which simply played the eponymous melody on your computer. Other viruses were what Bulgaria’s first anti-virus expert, Vesselin Bontchev, called “technopathic,” with one causing over one million dollars in losses to an unidentified East Coast company. </p>\n<p>During socialism, young people with hippie haircuts or punk fashion had often been persecuted by the Bulgarian police. But the regime’s software industry had nevertheless allowed and even encouraged self-expression, and this was reflected in the almost libertine spirit of Bulgaria’s virus culture. To gain access to the Virus eXchange, a dial-in bulletin board system set up by a university student in November 1988, you had to provide one new virus to a growing collection of over 300; the site proclaimed itself “a place for free exchange of viruses and a place where everything is permitted!” This ethos would shape the last socialist generation’s political commitments, too.</p>\n<h1><b>The Long Drive West</b></h1>\n<p>In his powerful trilogy, <i>The Information Age</i>, Spanish sociologist Manuel Castells argued that the USSR and the socialist world system failed in part because they never fully made the jump to a post-industrial, post-Fordist, and “informational” organization of the economy—based not on the rustbelt industries of manufacturing, but on the shiny offices of the flexible service sector. In Bulgaria, the economy continued to be dominated by smokestack enterprises and the nascent computer sector was expected to subsidize other, failing industries. </p>\n<p>But the failure of the techno-socialist utopia which created Bulgaria’s first generation of coders and founders continues to inform the ideas of Bulgarian tech workers. Those who moved to tech companies in the West left the socialist elements of the party’s political project behind, but retained its techno-utopian ideals. That utopianism found a new ideological home in the libertarian culture of Silicon Valley. Momchil Kyurkchiev, the founder of the Silicon Valley firm Leanplum, which makes a mobile marketing platform, recently told a Bulgarian television station that he sees important similarities between the US today and his childhood in early 1990s Bulgaria: if you don’t struggle, you don’t succeed. It is daring entrepreneurship, he added, that separates the winners from the losers. Indeed, the “drive West” of Bulgarian computer programmers, as the onetime scientific secretary of the Institute of Technical Cybernetics in Sofia called it when I interviewed him, has not produced many critiques of the West. If anything, it seems that Bulgarians’ professional success in Silicon Valley has confirmed many in the belief that they had the right acumen, but were born into the wrong social system.</p>\n<p>Today, Bulgaria has among the European Union’s poorest economies, but the country nevertheless boasts a robust software industry. The post-1989 generations continue to flock to the sector as a guarantor of relatively high wages. According to Eurostat, the European Union’s directorate for statistical information, in 2018 Bulgaria was third in the EU in terms of information and communication technology’s share of gross domestic product. There has even been one high-profile, home-grown software success story: in 2014, the Sofia-based firm Telerik, which creates tools for web development, was sold to a US company in a deal worth $262 million. Svetozar Georgiev, one of the company’s four founders, recalled in an interview with ZDNet that he first taught himself to program on a Pravetz-16 that his father brought home in the late 1980s. </p>\n<p>Notably, many of the programmers who stayed in Bulgaria and now work in its software sector vote for center-right parties that promise fewer social services and more competition in all spheres of governance and economic life. According to these parties, the solutions to the country’s major problems—widespread corruption and a bloated bureaucracy that drive Bulgaria to the bottom of every index, from economic growth to media freedom—are technological. Bozhidar Bozhanov, one of the chief candidates for Democratic Bulgaria, a centrist political alliance, is an IT entrepreneur who posits that only forms of electronic governance and digital tools of citizen-state interaction can lessen the bureaucracy, corruption, and opaqueness of Bulgarian politics. Their “six month accelerated program of digitalization” calls for everything from electronic signatures for all citizens and electronic registers of all businesses that have received Covid relief funds, to telemedicine, distance learning, and “electronic justice” which aims to lessen the obstacles to registering complaints and dealing with the opaque judiciary. Anything that stands in the way of this “electronic governance” is to be removed, branded a holdover from the bygone era of yesteryear. In their view, Bulgarian democracy needs transparency, and only electronic tools are able to produce it. This call holds at its heart the party’s aim to downsize the state administration, laying off state employees who much of the public see as corrupt and inefficient. Digitalization’s march can only be achieved through human unemployment.</p>\n<p>By the same token, the health of the IT sector is the prism through which parties’ policies are being judged. The country’s effectively regressive flat tax on income and profits, introduced in the late 2000s, is considered one of the pillars of the current IT renaissance. As the journalist Daniel Vasilev put it before the country’s March 2021 elections, any call for progressive taxation would be “deadly,” because it would cause investors, especially those in the computer sector, to flee Bulgaria. State investment in the sector is also discouraged by those on the center-right; the only thing the state should do, in their view, is remove regulations facing entrepreneurs. The labor code must also be reformed, they claim, because it is currently preventing a flexible market, by which they really mean the introduction of zero-hour contracts and precarious gig work. </p>\n<p>Of course, the belief that all the problems of a corrupt Bulgaria can be solved through the perfect tools is not that different to the Bulgarian Communist Party’s old dream that central planning through electronic brains would create communism. In both cases, the state is to be stripped back to a minimum. Perhaps today’s technological and political entrepreneurs, like their socialist predecessors, may find out that a new generation raised in conditions of financial crashes, pandemics, and political deadlock may draw different ideological conclusions to what the new status quo intends.</p>\n<p>\n\n\n</p>",
      "content_text": "In the spring of 1989, a virus began attacking computers in Europe, the United States, and Asia. During every sixteenth run of an infected executable file, the virus overwrote a random sector of a machine’s hard disk and manifested the phrase “Eddie lives… somewhere in time” on the monitor. A signature declared the virus’ origin: “This program was written in the city of Sofia (C) 1988–89 Dark Avenger.” \nDark Avenger was the most prolific of a number of hackers that emerged in Bulgaria in the late 1980s and 1990s. In December 1990, The New York Times reported that the Eastern Bloc nation had become a major infection vector in the new information economy. The late John McAfee told the newspaper, “I would say that 10 percent of the sixty calls we receive each week are for Bulgarian viruses.” By another estimate, around ninety out of the 300 then extant viruses for IBM machines originated from the country. In 1997, Wired called Bulgaria “the heart of darkness.” \nHow could a small socialist country become ground zero for so many digital epidemics? The conventional narrative of Eastern European communism is one of technologically backward states that failed to enter the information age, locked behind an impenetrable Iron Curtain that prevented both people and ideas from circulating. In Bulgaria, however, the electronic industry’s success was considered a key component of achieving the state’s ideological and economic dreams. The Bulgarian Communist Party hoped that the computer would usher in a communist utopia. Automation would streamline planning through a nationwide information network, and man would be free from menial tasks. More pressingly, the party was betting that computers could revive an economy that had once been the second fastest-growing in the world, but was floundering by the 1980s.\nThis vision was partially fulfilled: by the mid-1980s, socialist Bulgaria was producing up to 47 percent of all computer hardware within the Eastern Bloc, from Berlin to Vladivostok. But the country still suffered from negligible growth rates and low worker productivity, in part due to the party’s inability to implement the technology its factories were producing. State-produced hardware, computers, and numerically-controlled machines often languished unused due to a shortage of necessary software. \nAs this problem played out over the course of the 1980s, the party vested its hopes in a mass education effort to transform what turned out to be the last children of socialism into the first electronic generation. These kids would be trained to create the software that would allow the party to automate all it dreamed of automating—from chemical production to managing pension databases. Beginning in 1983, Bulgarian children as young as twelve were enrolled in a state-run program of technical tinkering. High schools and universities were transformed into laboratories of the future and factories for the regime. While learning BASIC, Bulgarian children were to advance themselves as intellectual laborers and truly creative citizens of a newly scientific socialist world, in order to become the future governors of much more complex production and social processes.\nIn reality, however, the 1980s generation of Bulgarian children found themselves becoming cogs in an economy that continued to suffer shortages, bottlenecks, and scarcity—all of which contributed to the collapse of the communist regime in 1989. When that happened, the technological skills and entrepreneurial desires the state had cultivated in its children were rechanneled into viruses and the first software enterprises of democratic Bulgaria. \nHackers like Dark Avenger were thus the most notorious product of a failed political and cultural experiment with a long afterlife. The death of the party’s dream pushed much of the 1980s generation into an ideology that was fiercely opposed to socialism, but still wildly utopian. Many of these kids eventually emigrated to Silicon Valley and other hubs in the global information economy, bringing with them a strongly capitalist version of the communist’s dream: liberation of the human spirit through technology.\nTinker and Spy\nKarl Marx once quipped that under communism man would be a fisherman in the morning and an artist in the afternoon. By the 1960s, the Bulgarian Communist Party believed that automation had brought Marx’s vision to the cusp of realization. Thousands of engineers were trained in the country’s universities, and cybernetics became a watchword for the party’s economic programs. Computers would streamline information flows, provide objective information on the economy, and allow planners in Sofia to accurately predict the future. The Politburo trumpeted that “science would be a productive force.”\nJust a generation before, that idea of Bulgaria’s future had seemed unthinkable. Back in 1944, when the party assumed power as Stalin’s Red Army rolled over the Danube, this small Balkan state was largely an agricultural producer. In the nascent field of international development, Bulgaria was considered an example of the region’s “trap,” which could only be escaped through large-scale investment. That is precisely what the Soviets brought, in the guise of breakneck Stalinist industrialization. Throughout the 1950s, the country assumed the Soviet economic model: central planning, smokestack industries, and a growing industrial proletariat squeezed into the cities. \nBy the 1960s, however, Bulgaria’s extensive growth period was tapering off, and the country was suffering a debt crisis. On the advice of Bulgarian engineers trained in western Europe, the party turned to electronics as the good of the future. As the party’s leader, Todor Zhivkov, put it, “We couldn’t industrialize with tomatoes and eggs.” Heavy state investment was combined with Japanese licensing and a prodigious espionage program to create the Bulgarian computer industry. By the 1970s, dozens of Bulgarian factories and institutes were churning out CPUs, mini-computers, and peripherals, such as ES-1020 mainframes and IZOT hard drives. Most of this technology was licensed or reverse-engineered after the Bulgarian intelligence services had procured it in the West; from its inception, the nation’s hardware industry was based on spying and tinkering, rather than true domestic innovation. The golden goose was the hard disk, which Bulgaria almost monopolized in the Eastern Bloc.\nThe 1980s were marked by continual heavy investment in robotics and personal computing, bringing the automation age into the office and onto the factory floor. Imperfect as it was, Bulgarian automation did take hold to some extent—around 200,000 workers in a country of eight million worked in the electronics sector, the second largest industrial workforce in the country. Its IBM 360/370-copies, Winchester hard drives, and an Apple II clone known as the Pravetz, found their way into socialist enterprises throughout the Global South. Bulgarian computers flew on the Soviet space station Mir, were used for nuclear research in India, and equipped Mozambique’s nascent statistical authority. Though often slowly, and in a piecemeal fashion, automation entered car production processes and cement factories, monitored milk levels in collective farms, and increasingly suffused social and government services. \nUnfortunately, Bulgarian products often fared badly on the global capitalist market due to their sometimes shoddy quality. Rather than looking at its economic principles such as central planning as a potential source of the problem, the party focused on the “subjective factor.” In their view, it was the Bulgarian worker rather than the system that was to blame—shirking responsibilities, pilfering the petty change, and sleeping on the job. Only the computer and robot would solve this problem, by eliminating the human strategies of survival in the shortage economy of socialism, where personal links and the grey market were key to procuring scarce goods. These were the peculiar conditions within which the next, truly computerized generation, would have to grow up.\nThe Man-Machine-Environment\nThe organization that prepared most Bulgarian children to be the model communists of the future was the Dimitrov Communist Youth Union (DKMS). In 1984, the DKMS started publishing Computer for You, a monthly magazine for the new generation. The magazine’s first editorial told these kids that “we will aim to offer you knowledge, experience and creativity from the interesting world of ‘her majesty’ ELECTRONISATION.” \nHer majesty was indeed marching through children’s lives. In 1979, the party had directed twenty-seven schools across the country to implement experiments in computer education. But it was the personal computing revolution that opened the Bulgarian school to electronics. In 1983, the Sofia High School of Electronics received its first fully equipped classroom of eighteen Bulgarian PCs, and informatics became part of the school curriculum. \nWithin a year, there were over 300 PCs in Bulgarian schools, and the numbers continued growing. Education software was used in language training, mathematics, and science lessons, alongside BASIC classes. Eleventh grade was reconstructed to include units such as “an introduction to cybernetics” and “production automation.” Computer for You contained architects’ plans for new classrooms that treated students like cyborgs—“integration into the school environment is effective only if it ensures optimal functioning of the Man-Machine-Environment system,” a cybernetics engineer told the magazine. \nIf the economy was going to be composed of man-machine systems, schools would be, too. New educational methods were developed under the auspices of mathematician Blagovest Sendov, who had participated in the creation of Vitosha, the first Bulgarian computer, in the early 1960s. In an article for the magazine, Sendov called the computer “a fantastical object” and deemed it the new age’s defining metaphor. Bulgarian socialism, he said, would be defined by the “mind to be molded—on the computer model.” The new society was one of informational glut, and kids had to learn to “continue learning” throughout life—to sift through information, synthesize it, and see the connections between different areas of human endeavor. Learning the language of computers—what Sendov called “the second literacy”—was to become the crux of every school’s curriculum.\nChildren were also enticed into the new dream through a network of computer clubs operated by the DKMS. The first appeared in 1984 in the capital of Sofia; by 1987, there were over 530 of them throughout the country, from the largest cities to many villages. They contained over 4,000 PCs, as well as small, domestically produced robots, which students could program to perform various tasks, such as moving small loads between two tables. Annual nationwide “Informatics Olympiads” were held throughout the country, and Bulgarian computer clubs also popped up in the USSR, Cuba, North Korea, Ethiopia, and Vietnam. The DKMS estimated that over 600,000 students and young workers used the computer clubs every year.\nBy 1985, the first student-run enterprise in computing was already helping to solve the country’s economic problems. In the course of just a few months, Avantgarde, a collective of high school and university students from Sofia and the city of Plovdiv, had created sixty games and twenty educational programs for classrooms and the computer club network. They also cooperated with state factories, creating specialized data processing packages for the economy: graphic editors for design studios, electronic databases for enterprise personnel record-keeping, troubleshooting programs, and more. The young engineer that oversaw Avantgarde noted that, by 1986, there were software enterprises in many provincial cities, while over fifty economic entities in the state economy were interested in either ordering or co-developing software packages. In the typically staid language of the time, he saw all this as “linking more closely with the ideological preparation… of the young population, in the spirit of the realities that determine the technological transition of socialist Bulgaria into the 21st century.” And as Computer for You more rhapsodically put it, “The intellectual revolution is in the hands of today’s students.”\nViral Load\nUltimately, Marx’s vision of hunting in the morning and debating in the afternoon never arrived for socialist Bulgaria. Eastern Europe was swept up in the grand changes of 1989, and the Bulgarian Communist Party initiated a palace coup the day after the Berlin Wall fell, removing Todor Zhivkov from power and starting down the road to democratic elections. Yet the country’s intellectual revolution had nevertheless occurred: the cyborgification of Bulgarian youth had succeeded, on both a technical and a cultural level.\nTwo years before the fall of communism, in an effort to stave off the collapse of the economy, the party had begun introducing modest economic reforms. This included limited forms of private enterprise, and Bulgarian youth formed some of the country’s first legal private companies. Many children found it easy to make this transition to market capitalism—as Computer for You pointed out, young programmers in particular were already operating in the conditions of freedom that the state was now proclaiming. Much of the software being used by major firms had come out of those children’s brains. The state’s airline, Balkan Airways, used the Syntez program from Burgas-based software firm Busoft, where a tenth grader awed journalists by pulling up flight schedules and reservation systems in Bulgarian and English. Young developers had automated hotel reservation, office correspondence, and wage databases, and demonstrated their inventions at the Plovdiv international exposition in 1985, which was themed “the creations of young inventors.”\nAs the Bulgarian economy faltered at the end of the decade, young Bulgarian programmers lost their job prospects along with much of their creative freedom. In this crisis was born the other face of socialist Bulgaria’s computer revolution—the virus. The first mention of “computer viruses” in Computer for You came in April 1988; in effect, the magazine let young programming enthusiasts know what a virus was, and that it could be copied, improved, and spread. Because most Bulgarian computers were shared by dozens of people in classrooms and computer clubs, it was easy to get hold of a virus and infect a machine inadvertently. Viruses also suited the logics of reverse-engineering and copying on which the Bulgarian computer economy was already running. Why not tinker with a digital pathogen and send it out into the world beyond Bulgaria? After all, you knew it would work virtually anywhere, because your Pravetz was compatible with an Apple!\nStarting in early 1989, computers as far away as the USA and Thailand were infected with Bulgarian viruses. Some were minor irritants, such as the “Yankee Doodle” virus, which simply played the eponymous melody on your computer. Other viruses were what Bulgaria’s first anti-virus expert, Vesselin Bontchev, called “technopathic,” with one causing over one million dollars in losses to an unidentified East Coast company. \nDuring socialism, young people with hippie haircuts or punk fashion had often been persecuted by the Bulgarian police. But the regime’s software industry had nevertheless allowed and even encouraged self-expression, and this was reflected in the almost libertine spirit of Bulgaria’s virus culture. To gain access to the Virus eXchange, a dial-in bulletin board system set up by a university student in November 1988, you had to provide one new virus to a growing collection of over 300; the site proclaimed itself “a place for free exchange of viruses and a place where everything is permitted!” This ethos would shape the last socialist generation’s political commitments, too.\nThe Long Drive West\nIn his powerful trilogy, The Information Age, Spanish sociologist Manuel Castells argued that the USSR and the socialist world system failed in part because they never fully made the jump to a post-industrial, post-Fordist, and “informational” organization of the economy—based not on the rustbelt industries of manufacturing, but on the shiny offices of the flexible service sector. In Bulgaria, the economy continued to be dominated by smokestack enterprises and the nascent computer sector was expected to subsidize other, failing industries. \nBut the failure of the techno-socialist utopia which created Bulgaria’s first generation of coders and founders continues to inform the ideas of Bulgarian tech workers. Those who moved to tech companies in the West left the socialist elements of the party’s political project behind, but retained its techno-utopian ideals. That utopianism found a new ideological home in the libertarian culture of Silicon Valley. Momchil Kyurkchiev, the founder of the Silicon Valley firm Leanplum, which makes a mobile marketing platform, recently told a Bulgarian television station that he sees important similarities between the US today and his childhood in early 1990s Bulgaria: if you don’t struggle, you don’t succeed. It is daring entrepreneurship, he added, that separates the winners from the losers. Indeed, the “drive West” of Bulgarian computer programmers, as the onetime scientific secretary of the Institute of Technical Cybernetics in Sofia called it when I interviewed him, has not produced many critiques of the West. If anything, it seems that Bulgarians’ professional success in Silicon Valley has confirmed many in the belief that they had the right acumen, but were born into the wrong social system.\nToday, Bulgaria has among the European Union’s poorest economies, but the country nevertheless boasts a robust software industry. The post-1989 generations continue to flock to the sector as a guarantor of relatively high wages. According to Eurostat, the European Union’s directorate for statistical information, in 2018 Bulgaria was third in the EU in terms of information and communication technology’s share of gross domestic product. There has even been one high-profile, home-grown software success story: in 2014, the Sofia-based firm Telerik, which creates tools for web development, was sold to a US company in a deal worth $262 million. Svetozar Georgiev, one of the company’s four founders, recalled in an interview with ZDNet that he first taught himself to program on a Pravetz-16 that his father brought home in the late 1980s. \nNotably, many of the programmers who stayed in Bulgaria and now work in its software sector vote for center-right parties that promise fewer social services and more competition in all spheres of governance and economic life. According to these parties, the solutions to the country’s major problems—widespread corruption and a bloated bureaucracy that drive Bulgaria to the bottom of every index, from economic growth to media freedom—are technological. Bozhidar Bozhanov, one of the chief candidates for Democratic Bulgaria, a centrist political alliance, is an IT entrepreneur who posits that only forms of electronic governance and digital tools of citizen-state interaction can lessen the bureaucracy, corruption, and opaqueness of Bulgarian politics. Their “six month accelerated program of digitalization” calls for everything from electronic signatures for all citizens and electronic registers of all businesses that have received Covid relief funds, to telemedicine, distance learning, and “electronic justice” which aims to lessen the obstacles to registering complaints and dealing with the opaque judiciary. Anything that stands in the way of this “electronic governance” is to be removed, branded a holdover from the bygone era of yesteryear. In their view, Bulgarian democracy needs transparency, and only electronic tools are able to produce it. This call holds at its heart the party’s aim to downsize the state administration, laying off state employees who much of the public see as corrupt and inefficient. Digitalization’s march can only be achieved through human unemployment.\nBy the same token, the health of the IT sector is the prism through which parties’ policies are being judged. The country’s effectively regressive flat tax on income and profits, introduced in the late 2000s, is considered one of the pillars of the current IT renaissance. As the journalist Daniel Vasilev put it before the country’s March 2021 elections, any call for progressive taxation would be “deadly,” because it would cause investors, especially those in the computer sector, to flee Bulgaria. State investment in the sector is also discouraged by those on the center-right; the only thing the state should do, in their view, is remove regulations facing entrepreneurs. The labor code must also be reformed, they claim, because it is currently preventing a flexible market, by which they really mean the introduction of zero-hour contracts and precarious gig work. \nOf course, the belief that all the problems of a corrupt Bulgaria can be solved through the perfect tools is not that different to the Bulgarian Communist Party’s old dream that central planning through electronic brains would create communism. In both cases, the state is to be stripped back to a minimum. Perhaps today’s technological and political entrepreneurs, like their socialist predecessors, may find out that a new generation raised in conditions of financial crashes, pandemics, and political deadlock may draw different ideological conclusions to what the new status quo intends.\n\n\n\n",
      "date_published": "2021-09-17T14:46:30.000Z",
      "date_modified": "2021-09-17T14:46:30.000Z",
      "_plugin": {
        "pageFilename": "6db44368dbe99c01e1731d834b8384959ea8059832d0be1cd888019e013c1081.html"
      }
    },
    {
      "id": "https://logicmag.io/kids/system-update",
      "url": "https://logicmag.io/kids/system-update",
      "title": "System Update",
      "summary": "We promise we’ll do better next time.",
      "content_html": "<p><b>1/</b></p>\n<p>We are, in many ways, badly made. A foal walks within hours. On YouTube, you can watch scores of baby turtles hatch and scrabble right down to the surf. It takes us a quarter century before our minds work properly. They say having kids is like letting your heart walk outside your body. The whole thing seems improbable, how much care a human being needs to survive, but cognitive psychologists say this is the secret of our species. The brain plasticity that makes us so needy also makes us creative, and capable of the kind of play that can make our worlds change. </p>\n<p>Remind us of this the next time we are trying desperately to finish an editorial note before the kids wake up and start screaming. </p>\n<p>Kids can be hard to see clearly. <i>What are you having</i>? Walking around pregnant is a great way to test the line between oppressiveness and good will, which is sometimes nonexistent—the stranger who immediately, excitedly asks about the gender of your fetus, as if you could know. Kids precipitate intense hope and fear and nostalgia, mix up the past and the future completely, which is why we project so much not only onto “our” kids (who are not our property; if anything, most days, the opposite seems true) but onto childhood as such. </p>\n<p>Like everything, all this had to be invented. Medieval Christian theology regarded babies not as angels, but demons. In paintings, even the baby Jesus looks like an old man. The heroes of epics, up to at least Dante’s <i>Commedia</i>, were not young, but middle-aged. Scholars have shown that for childhood to become what it is now—among other things, a protected site and a source of sentiment—a lot of things had to happen, and of course they did not happen for everyone. Some people are never allowed childhoods: to the cops, a twelve-year-old playing with a toy looks like a killer. Other people never have to grow up: to venture capitalists and the business press, the forty-something CEO who messes up just needs more time to grow. There may be little that feels more obvious than the imperative to protect the innocence of children. Yet innocence as a category is anything but. </p>\n<p><b>2/</b></p>\n<p>This issue of the magazine tries to move beyond commonplaces, while also analyzing what those commonplaces are about, in the first place. Our authors examine the relationship between youth and technology. Relationships, plural, we should say. Because, as the cliché goes, it’s <i>complicated</i>. One of the first myths to dispel is that only one kind of connection is at stake. The singular reflects the idea that kids are a blank slate: naturals, “digital natives,” the ones whom large scale innovations should target, whether it’s the One Laptop Per Child initiative or Google Classroom. </p>\n<p>Some pieces investigate the persistence of history that an emphasis on the youthfulness of technologies and technologists obscures. One writer points out that, although the money in Silicon Valley is often presented as new, much of it is in fact inherited. Indeed, tech’s dynasties raise the question of whether “new” money even exists, if wealth is ever created <i>ex nihilo</i> or only, like a face that travels through generations, changes shape, updates. Another writer looks at algorithms developed to manage the dispossession of Indigenous people in the nineteenth century, and how this same technocratic regime of laws and logics are now used to apportion shrinking water supplies in the climate-apocalyptic West. It can be unsettling to recognize the continuities of systems of oppression, how often our tools have simply been <i>updated to remain the same</i>. </p>\n<p>But sometimes, more disruptive updates slip through, the kind that repurpose the system. The purpose of a system is what it does, cybernetic theorist Stafford Beer reminds us. When the state trains you in STEM for a communist utopia that never arrives, it turns out you can use those skills to hack the planet. It turns out, if you want to get a glimpse into the torture chambers of the War on Terror, you can set the geolocation on your Tinder app to 19.9031 N, 75.0967 W: Guantánamo, Cuba. Some of the young guards may turn out to be like you: bored, lonely, in love, ambitious, uncertain, hoping for a change. They won’t stay long. This does not make their role warehousing those whose own youth has disappeared into the blacksite less horrifying; it makes it more.</p>\n<p>Other contributions in this issue look at various attempts to protect young people from technology. These include parents and teachers, but sometimes also the kids themselves. Sometimes the kids long for less technical times, when the world felt more open for self-discovery, when you had to go cruising, instead of having the TikTok recommendation algorithm tell you you were gay. The tech industry tends to claim the mantle of youth in order to pretend it has no history and to bolster its ownership claims over the future. In this issue, we speak with recent college graduates who have gone into tech and have come to doubt these narratives, but who still want to use the power that the industry lets pass into young hands for good. Notwithstanding the lucrative business of defining and branding distinct generations, we find that one feature of youth today is that there are far too many kinds of kids to generalize about.</p>\n<p><b>3/</b></p>\n<p>As we close this issue, schools across the United States are starting back up in person. For many kids, the pandemic turned schooltime into screentime. Other kids stopped going to school at all. At night, after we finally get our own kids to sleep, we open our <i>New York Times</i> push notifications. They are frightening. In August, the American Academy of Pediatrics announced that nearly one in five new Covid-19 cases were children. A number of them have developed “long Covid.” Former star athletes are sleeping all day. Former star students cannot focus. It is hard to know how good the data is. It feels impossible to know what to do. </p>\n<p>They say children are the revenge of grandparents: in them, we come back to haunt ourselves. If we didn’t sleep, they don’t. If we whined all the time, they do. Kids are where we see the past return. But they also carry our hopes for the future. They make us feel that certain things can change, that maybe we can do better next time. The pandemic has made abundantly clear that we are all interconnected spatially. Kids help us see how interconnected we are temporally. <i>Now now now now</i> is their favorite saying, second only to <i>Again</i>! They are reminders of our shared vulnerability, of how each generation makes the next. We promise we’ll do better next time. Next time, we’ll get it right.</p>",
      "content_text": "1/\nWe are, in many ways, badly made. A foal walks within hours. On YouTube, you can watch scores of baby turtles hatch and scrabble right down to the surf. It takes us a quarter century before our minds work properly. They say having kids is like letting your heart walk outside your body. The whole thing seems improbable, how much care a human being needs to survive, but cognitive psychologists say this is the secret of our species. The brain plasticity that makes us so needy also makes us creative, and capable of the kind of play that can make our worlds change. \nRemind us of this the next time we are trying desperately to finish an editorial note before the kids wake up and start screaming. \nKids can be hard to see clearly. What are you having? Walking around pregnant is a great way to test the line between oppressiveness and good will, which is sometimes nonexistent—the stranger who immediately, excitedly asks about the gender of your fetus, as if you could know. Kids precipitate intense hope and fear and nostalgia, mix up the past and the future completely, which is why we project so much not only onto “our” kids (who are not our property; if anything, most days, the opposite seems true) but onto childhood as such. \nLike everything, all this had to be invented. Medieval Christian theology regarded babies not as angels, but demons. In paintings, even the baby Jesus looks like an old man. The heroes of epics, up to at least Dante’s Commedia, were not young, but middle-aged. Scholars have shown that for childhood to become what it is now—among other things, a protected site and a source of sentiment—a lot of things had to happen, and of course they did not happen for everyone. Some people are never allowed childhoods: to the cops, a twelve-year-old playing with a toy looks like a killer. Other people never have to grow up: to venture capitalists and the business press, the forty-something CEO who messes up just needs more time to grow. There may be little that feels more obvious than the imperative to protect the innocence of children. Yet innocence as a category is anything but. \n2/\nThis issue of the magazine tries to move beyond commonplaces, while also analyzing what those commonplaces are about, in the first place. Our authors examine the relationship between youth and technology. Relationships, plural, we should say. Because, as the cliché goes, it’s complicated. One of the first myths to dispel is that only one kind of connection is at stake. The singular reflects the idea that kids are a blank slate: naturals, “digital natives,” the ones whom large scale innovations should target, whether it’s the One Laptop Per Child initiative or Google Classroom. \nSome pieces investigate the persistence of history that an emphasis on the youthfulness of technologies and technologists obscures. One writer points out that, although the money in Silicon Valley is often presented as new, much of it is in fact inherited. Indeed, tech’s dynasties raise the question of whether “new” money even exists, if wealth is ever created ex nihilo or only, like a face that travels through generations, changes shape, updates. Another writer looks at algorithms developed to manage the dispossession of Indigenous people in the nineteenth century, and how this same technocratic regime of laws and logics are now used to apportion shrinking water supplies in the climate-apocalyptic West. It can be unsettling to recognize the continuities of systems of oppression, how often our tools have simply been updated to remain the same. \nBut sometimes, more disruptive updates slip through, the kind that repurpose the system. The purpose of a system is what it does, cybernetic theorist Stafford Beer reminds us. When the state trains you in STEM for a communist utopia that never arrives, it turns out you can use those skills to hack the planet. It turns out, if you want to get a glimpse into the torture chambers of the War on Terror, you can set the geolocation on your Tinder app to 19.9031 N, 75.0967 W: Guantánamo, Cuba. Some of the young guards may turn out to be like you: bored, lonely, in love, ambitious, uncertain, hoping for a change. They won’t stay long. This does not make their role warehousing those whose own youth has disappeared into the blacksite less horrifying; it makes it more.\nOther contributions in this issue look at various attempts to protect young people from technology. These include parents and teachers, but sometimes also the kids themselves. Sometimes the kids long for less technical times, when the world felt more open for self-discovery, when you had to go cruising, instead of having the TikTok recommendation algorithm tell you you were gay. The tech industry tends to claim the mantle of youth in order to pretend it has no history and to bolster its ownership claims over the future. In this issue, we speak with recent college graduates who have gone into tech and have come to doubt these narratives, but who still want to use the power that the industry lets pass into young hands for good. Notwithstanding the lucrative business of defining and branding distinct generations, we find that one feature of youth today is that there are far too many kinds of kids to generalize about.\n3/\nAs we close this issue, schools across the United States are starting back up in person. For many kids, the pandemic turned schooltime into screentime. Other kids stopped going to school at all. At night, after we finally get our own kids to sleep, we open our New York Times push notifications. They are frightening. In August, the American Academy of Pediatrics announced that nearly one in five new Covid-19 cases were children. A number of them have developed “long Covid.” Former star athletes are sleeping all day. Former star students cannot focus. It is hard to know how good the data is. It feels impossible to know what to do. \nThey say children are the revenge of grandparents: in them, we come back to haunt ourselves. If we didn’t sleep, they don’t. If we whined all the time, they do. Kids are where we see the past return. But they also carry our hopes for the future. They make us feel that certain things can change, that maybe we can do better next time. The pandemic has made abundantly clear that we are all interconnected spatially. Kids help us see how interconnected we are temporally. Now now now now is their favorite saying, second only to Again! They are reminders of our shared vulnerability, of how each generation makes the next. We promise we’ll do better next time. Next time, we’ll get it right.",
      "date_published": "2021-09-07T14:35:06.000Z",
      "date_modified": "2021-09-07T14:35:06.000Z",
      "_plugin": {
        "pageFilename": "a7013164e291a1ab0b2eee6b45567f25404859354af45b6cf8e1654f1b5f6148.html"
      }
    }
  ],
  "_plugin": {
    "rawFeed": "<rss\n    xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n    xmlns:content=\"http://purl.org/rss/1.0/modules/content/\"\n    xmlns:atom=\"http://www.w3.org/2005/Atom\"\n    xmlns:media=\"http://search.yahoo.com/mrss/\"\n    version=\"2.0\">\n  <channel>\n    <title>\n        <![CDATA[ Logic Magazine ]]>\n    </title>\n    <description>\n        <![CDATA[\n        Logic is a new magazine devoted to deepening the discourse around technology. We publish three times per year in print and digital formats.\n        ]]>\n    </description>\n    <link>https://logicmag.io</link>\n    <image>\n        <url>https://logicmag.io/images/rss-icon.jpeg</url>\n        <title>Logic Magazine</title>\n        <link>https://logicmag.io</link>\n    </image>\n    <generator>Lovingly by Hand</generator>\n    <lastBuildDate>Tue, 22 Feb 2022 19:53:14 +0000</lastBuildDate>\n    <atom:link href=\"https://logicmag.io/rss.xml\" rel=\"self\" type=\"application/rss+xml\"/>\n    <ttl>60</ttl>\n    <item>\n        <title>Organizing as Joy: An Ocean-Hill Brownsville Story, with Tranae Moran and Fabian Rogers</title>\n        <link>https://logicmag.io/beacons/organizing-as-joy-an-ocean-hill-brownsville-story-with-tranae-moran-and</link>\n        <guid>https://logicmag.io/beacons/organizing-as-joy-an-ocean-hill-brownsville-story-with-tranae-moran-and</guid>\n        <description>\n            <![CDATA[\n                <p>A conversation about dismantling surveillance the Brooklyn way.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Tranae Moran, Fabian Rogers ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;7GuNgiV2WHfp1sNkgBlxVZ&#x2F;e6dcca03d3b2469dbc1c51d5dc0483f7&#x2F;organizing-as-joy.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p><i>In the fall of 2018, the residents of Atlantic Plaza Towers, a rent-stabilized apartment complex in Brownsville, Brooklyn, received an alarming notice from their landlord stating that the key fob system to enter the building was to be replaced with facial recognition technology. More than 130 residents opposed Nelson Management Group’s plan to install the facial recognition system and mandate photographs for mailbox key replacements. Atlantic Plaza Towers resident Tranae Moran led the fight, then celebrated the successful defeat of Nelson Management’s plan by founding the Ocean Hill-Brownsville Alliance (OBA). Fabian Rogers, a former floor captain at Atlantic Towers—a volunteer position that involves helping residents in an emergency—has followed Tranae to OBA in order to continue educating their community about the dangers of biometrics and elevate the joy of the Ocean Hill-Brownsville neighborhood. Issue editor J. Khadijah Abdurahman spoke to Moran and Rogers about what they’ve learned through their organizing work, and how the anti-surveillance struggle fits into the broader fight for environmental justice, social housing, and community reinvestment.</i></p>\n<p><b>Can you start us off with the basics? What would you like readers to know about who you are and the work you’ve been engaged with since the peak of resistance against facial recognition in Atlantic Plaza Towers?</b></p>\n<p>Tranae Moran (TM): I am a community organizer and community outreach specialist, and my nine-to-five is working with the City’s Tenant Support Unit. I founded the Ocean Hill-Brownsville Alliance (OBA) after assisting the Atlantic Plaza Towers Tenants Association in pushing back against facial recognition technology. After we succeeded in preventing the installation of facial recognition technology in our apartment complex, I wanted to continue the work of educating people about biometric collecting systems and just general tenants rights. I didn’t want to take up too much space in the Tenants Association, so I started the OBA in order to push that initiative forward. So, here we are. </p>\n<p>Fabian Rogers (FR): Technically, I think Tranae usually throws the title of cofounder my way, but I’m more of a participant. I’m kind of like an assistant aide of sorts to the Ocean Hill-Brownsville Alliance. But, you know, Tranae would beg to differ, of course. Also, I was a floor captain from Atlantic Plaza Towers, but currently I work as a constituent advocate for New York State Senator Jabari Brisport’s office out here in my Senate District 25. Tranae and I have been able to change the trajectory of our careers, essentially, just from organizing, at no cost at all—just kind of pushing forward until folks finally told us we can make a profit from it. </p>\n<p>TM: I don’t want to say a profit; I would rather say make a living out of it. People from our community don’t think of civic engagement and community work as an actual career. No one thinks that just by helping the community, you can make a living doing that. So, this was a very eye-opening experience for both Fabian and I, because we found ourselves doing passion work but ended up making some real impact, and were able to use our lived experience through that to start a career in community work.</p>\n<p><b>A lot of articles feature the fight and the resistance that the Atlantic Towers community waged against the implementation of facial recognition technology. I was wondering if you could set the stage for us: What does Brownsville and Ocean Hill look like? What is your relationship to the community and how did that set the stage for this successful battle? </b></p>\n<p>TM: What does Brownsville look like? Brownsville looks like a multitude of things. It’s a very vibrant and resilient neighborhood with a legacy of activism. When the time comes, we are able to come together and make some waves. Just Atlantic Towers specifically, we are a tight-knit community. We’ve been here for generations: elderly folks, young people—it’s just a little bit of everyone. Our Tenants Association is a direct reflection of that: we have municipal workers, we have people who work for MTA, we have lawyers, we have real estate agents, we have teachers, nurses, caregivers. So it’s a very diverse group of people with expertise in different spaces, which means, if we have the right foundation, we can make a lot of positive movement.</p>\n<p>There’s a lot of focus on the negative things that happen in Brownsville. I always say to people, I don’t see a lot of this stuff that you guys say is happening here. It could just be because I am from here and I identify what many other people wouldn’t consider as joy! I know people come to Brownsville and may be a bit taken aback, but I just took a walk to go buy a new pair of headphones because the ones I purchased didn’t work out so well and I’m just like, this is such a joyful neighborhood. Yes, we have things happen, but what neighborhood doesn’t have things going on? </p>\n<p>I want to magnify the joy that is present here while giving folks the information they need in order to navigate and not be taken advantage of, because there is gentrification coming here in Brownsville and not everyone has the same access to information. OBA is stepping in to assist with the flow of information. </p>\n<p>FR: The other thing to understand is the resiliency and the persistence of Black and brown folks within this community in particular. Fighting back against the narrative that you’re a product of your environment—a lot of Ocean Hill-Brownsville-ites are more than what their environment is. At the same time, a lot of their environment is that which they can’t control. Health disparities come from the fact that Brownsville was industrialized and those remnants of industrialization play a role in environmental violence. Things that you can’t see that make it seem as though Black and brown folks are just born with respiratory issues, when it’s really the environment that we’re living in that plays a large role as opposed to our habits and things like that. </p>\n<p>When folks find out about the more invisible things like air quality being bad, or illegal projects affecting the health of Ocean Hill-Brownsville, a lot of times folks become activists and advocates for the community. People live, love, and learn in this community. I think that that’s a staple as to why the culture of Ocean Hill-Brownsville continues to persist despite gentrification and other disparities.</p>\n<p>TM: Brownsville is made up of the highest concentration of public housing buildings in New York. They are not a priority to the city, if you ask me. There is a lot of neglect happening in these neighborhoods. This neighborhood is a food desert. We don’t have markets. Fresh fruits and vegetables are not easy to find. I mean, we do have a beautiful network of community gardens and local people who contribute their time and energy to those gardens, and help to make our community a more vibrant place. But as far as the city coming in to do cleanups and things like that, we don’t see much of that happening. </p>\n<p>Are we creating community spaces for people to take up space in and do whatever it is that they want to do? That is not being done, which is why OBA is committed to creating space for joy, imagination, and vision in Brownsville. Because of the things that people have been through, a lot of them are numb and we have to wake them up first—liven them up with some joy again and de-stressing activities through art—before we can focus on fighting biometric information collecting or the things that take a bit more time for understanding. </p>\n<h1><b>Not Just Playing Candy Crush</b></h1>\n<p><b>I don’t know if this is your experience, but it’s something I definitely complain about in academic or institutional spaces, when they want to bring in “community,” the currency is “impacted people.” They want you to share a little bit of your trauma, your individual story, and then talk about “organizing”—organizing is anything that’s not writing a paper in the way that they speak. And then they’re done with you, and you can go back to whence you came from until they want to trot you back out again for the pictures and stuff. I’m not even interested in critiquing that. Rather, I want to ask, what does the conversation look like across ourselves and across neighborhood intimacies? </b></p>\n<p><b>It definitely has stood out to me how OBA has been a collective effort. It’s you leading the fight Tranae, but it’s not like you are the sole hero. Even how you conceptualize what the problem is and how you situate it into both the joyous community and the environmental factors or ecologies of various types of violences that people are subjected to. I really appreciated that. I remember reading all about OBA in 2019, and now we are about to be in 2022 and you guys haven’t just been chillin’ playing Candy Crush. What is the state of OBA organizing, not just with Covid, but over this length of time? What has been like, “Yo, I’m never doing that again,” or “This is what has been really hard,” or however you’d like to reflect on that passage of time? </b></p>\n<p>TM: We have been refocusing what OBA wants to do. At first, the main thought was that we need to get information out about biometric collecting systems. We need to inform our community about the dangers and why they need to be aware of their surroundings. That is still a major theme in OBA but this has just been a very stressful time, so we have been trying to find ways to make an impact that don’t ask for too much energy from our community. They are exerting themselves in so many different ways, with work, with kids going back to school, and just with navigating life post-vaccines becoming available. </p>\n<p>We partnered with AI For the People last summer for OBA’s first public outdoor event on Juneteenth. The community appreciated the music, food, and information about all of the invisible harms. Many people didn’t know about the topics we covered, including the fact that National Grid runs a fracked gas pipeline through Brownsville. Leaks in that pipeline can expose people to cancer-causing and radioactive gas. As Fabian just mentioned, we are already dealing with environmental issues in Brownsville. There is a large community of people who have asthma here and respiratory problems, and now things are being done that will potentially cause more harm to the health of the people in this community. </p>\n<p>FR: We’ve been trying to connect dots between different struggles going on between housing justice, environmental justice, and surveillance with Housing Organizers for People Empowerment (HOPE), AI For the People, and Brownsville Green Justice. For example, pointing out how our landlord trying to install facial recognition into our building plays into the grand scheme of housing injustice. Anti-surveillance includes pushing for social housing or housing access vouchers for homeless folks and things like that. </p>\n<p>National Grid is building a fracked gas pipeline in Brownsville. It’s one of many different corporate entities monopolizing essential utilities for all New York housing. It’s reliant on the fossil fuel industry and so they make money by building new infrastructure, not necessarily through gas flowing. This means they have to find ways to circumvent New York state law and other state laws in order to continue building infrastructure. And they end up picking Black and brown communities that don’t come off as active or as in tune with what’s going on, or seem to have a sense of wanting to push back. National Grid fails to inform the community and then the community has to be reactive, so you suddenly see a community activate and want to inform themselves, understand what’s going on, and push back against corporate BS. </p>\n<h1><b>(Re)active Situations</b></h1>\n<p><b>Do you see anti-surveillance organizing as a strategy of abolition or defunding the police? How do you situate privacy issues relative to the other issues emerging in the community? </b></p>\n<p>FR: Sometimes it’s not necessarily focusing on surveillance rights, but just looking at how we deal with corporate enterprises. How do you look at a biometrics company like StoneLock that tried to install its facial recognition system in Atlantic Towers? How do you look at the shenanigans that they pulled off and compare it to the strategies that National Grid is putting in place to try to give folks in Brownsville and Ocean Hill a hard time, in terms of trying to build new infrastructure that will then impact folks’ lives for the sake of a profit that they don’t need?</p>\n<p>In partnership with the Surveillance Technology Oversight Project, I’ve gotten tapped into different anti-surveillance groups, including the G.A.N.G.S. Coalition (Grassroots Advocates for Neighborhood Groups &amp; Solutions). They are trying to dispel the myths embedded in gang databases by reframing the issue for disenfranchised communities that are riddled with gang and community violence as a lack of opportunity, a lack of funding, a lack of resources that makes folks desperate and have to take risks in order to make a consistent living. </p>\n<p>When you dispel the idea of “folks out here just trying to create trouble” and you look deeper into it, it forces you to question the tactics that the NYPD uses in order to build a database to help with their so-called policing. With this gang database in particular, it’s a database built off of police bias. It’s not built off of fact. It’s not built off of factual information. </p>\n<p>When I think of justice, I always try to simplify it to the essential issue. What’s the essential device that allows this issue to proliferate in said communities, and how do we tap into communities to try to address quality of life issues? How do we tap into communities to be able to empower themselves to be the force to stop those pejorative relationships? If you get caught up in the monotony, you’ll lose sight of the fact that a lot of times these corporate enterprises are using the same strategies. It’s a very cookie-cutter system, but because it’s in a different sort of industry, you don’t think of it as such.</p>\n<p>For me and Tranae and other folks that were on our side in terms of surveillance and data privacy advocacy, we had to think about technology in a different way. We had to think about these issues as a housing issue. You often have to think outside of the context of what you’re put in to really be able to dissect the issue and be able to address it, and then be able to translate it to allow folks to feel as though they can be informed, they can be empowered. And then from there, they can be partners and allies, and oftentimes can be leaders.</p>\n<p>TM: We are very reactive when things happen because there are no conversations being held with our community about changes being made. That flow of information seems to not flow to us in the way that it should, which is where I want OBA to be able to step in. I want us to be a hub. A lot of these technology companies, real estate developers, and all kinds of folks who are just making their way over to Brownsville claim that they can’t find anyone to talk to. I’m just like, there’s so many community organizations doing work in Brownsville. How could you not find anyone to talk to and get insights from? So, you decided to still push forward with whatever this project was, without speaking to anyone in the community or trying to have a town hall or anything, despite the fact that we are very open to all of those things? </p>\n<p>Why aren’t these companies speaking to the community-based organizations? I want OBA to be a hub where they know they can come here and speak with community members who have expertise in different areas, so that we’re not just like, “Oh, what the heck is that? We never heard of this. What are you doing here?” Instead, it’s like, “Oh no, we had conversations with these people. We let them know that we wanted this and that to happen, and this is what we don’t want to see.” Those conversations don’t happen. It’s always a too little, too late kind of situation for us, and I want to change that. </p>\n<p>I want us to be involved in the conversations that are being had about the space that we occupy. Like, we live here. There are people here that have a brain and they have wants and needs, and they want to see different things in their community. When Fabian was speaking about gangs, how kids end up in those situations is that they want to go outside, but we don’t have green fields for them to sit in the grass and look at the sky and just ponder. We don’t have spaces like that. They come outside of their homes into all kinds of confusion. Young people have to navigate through these communities, digesting what they see and that’s how they learn. And it’s not always the greatest thing when they don’t have someone, or an organization, there to explain to them what they’re experiencing, so that they can make better and more informed decisions about how they want to navigate through the community. </p>\n<h1><b>Housing and (De)Funding The Police</b></h1>\n<p><b>As far as the gang database, who gets categorized as a gang? You mentioned that National Grid is putting poisonous gas under the ground, affecting a lot of people. Nobody is calling them a gang, right? But if you’re fifteen years old, Black, with certain colors on, you’re more likely to be identified as a gang member. </b></p>\n<p><b>Tranae, you mentioned the density of housing projects in Brownsville. People don’t seem to understand that you have a high density of projects, but you also have middle-class home ownership and residents with white-collar jobs. So, even when we talk about community, people within the community have very different relationships to the intensity of surveillance and policing. I also know from my experience, caseworkers live in Brownsville, so there’s people who sit in a lot of different places and have different relationships to policing. How are you thinking through class differences and funding relationships as you organize in Ocean Hill-Brownsville? </b></p>\n<p>TM: In Ocean Hill, there’s a larger amount of home ownership than there is down in Brownsville, which I’ve found to be one of the dividing factors. This is one of the reasons why OBA started and why we have this name—I wanted to bring the two communities together because we are separated due to the infrastructure of Brownsville and the density of the housing projects. We have the same issues, but the intensity of those issues is greater in Brownsville. Ocean Hill will probably be gentrified way faster than down in Brownsville. It’s happening at the same time, but the changes are happening a lot quicker in Ocean Hill. </p>\n<p>I’m not finding that everyone wants to defund the police here. The police have actually been very supportive of OBA, thus far, in our events and organizing outdoors. I think it’s about the people and not just police in general, because we have been met with folks not being happy about our presence outside. For example, business owners have called the police but when the police arrive, they’re actually helpful and they like what they see us doing, which is creating space for imagination and joy, and providing information on these invisible harms: facial recognition, surveillance, and fracked gas pipelines in Brooklyn. </p>\n<p>We want to focus on meeting people where they are, and not on specific topics such as defunding the police, because everyone doesn’t share that vision and we are not trying to divide the community more than it may be already. Everyone has to navigate however it works for their specific family unit. I feel like everyone has that capacity as long as they have the information to do it. </p>\n<p>We have not been accepting funding from many organizations. One, because we’re still laying down the foundations for OBA. With the climate of community organizing and community work, and these corporations wanting to put money into the community with whatever other agendas they have going on, I have been trying to be very careful about who we are accepting funding from. We have organizations like National Grid, who are doing great events in our community, but at the same time, they’re running a fracked gas pipeline in Brownsville. They were handing out hot dogs. First of all, why are you giving people hot dogs, anyway? They’re smiling and in community and giving away all these things but, at the same time, they’re being a double. They have these construction workers digging in front of your apartment building, putting all kinds of nonsense into the ground. And they are just going to leave and say, “Okay, we had a great event while you’re dealing with respiratory problems” and who knows what other kinds of health issues because of the things that they’re doing in the community. </p>\n<p>FR: An example of resistance we’ve encountered is from homeowners, because Amazon’s Ring doorbell and similar surveillance technologies are marketed to them as basic home protection. One approach that I’ve found helpful is pointing out the corporate relations between a product and possible policing. For instance, Amazon partners with and donates to police departments, and so by buying into the Ring system, you may be indirectly paying into an unnecessary police budget. Trying to build that sort of conversation helps folks understand the bigger picture as to what goes on. </p>\n<p>“Defund the police,” in particular, has always been an interesting conversation because people think, like, “Oh, we’re going to take the badges and weapons away from the police.” It’s like, no, folks just want to defund the police’s excessive budget and refund the community for how strapped it’s been for resources. I’m always a stickler for making simple phrases that can open up a bigger conversation. When folks get very defensive about something like “defund the police,” for instance, I’m like, “Well, I think you should look at it in the context that it’s only half the phrase. It’s more of ‘defund the police,’ ‘refund the community.’” We <i>all</i> make the big arguments about how strapped our community has been since the 1970s.</p>\n<p>Reaganomics and trickle-down theory started to trickle away the resources that helped working-class blue-collar communities push through by having supportive programs, trade schools, and alternatives to what’s out there. So, we should be thinking about how the police are asked to be a Swiss Army Knife when their training doesn’t allow them to be. A police officer isn’t a mental health expert. That’s just a fact, unless they had that background beforehand and then they became a police officer.</p>\n<p>Folks say “defund the police” because we’ve bolstered a couple of different economies rather than the community. If we see that the police have bolstered their pockets, maybe it’s a chance to look at how we can stop the excessive spending and start to think about how to funnel back money into the community. That’s what happened pre-Reaganomics, trickle-down theory, and things like that. That all gets lost in the chaos of folks getting caught up in a phrase like “defund the police” or “Black Lives Matter.” It’s always the monotony of getting caught up in the moment of a phrase that feels triggering, rather than unpacking the history and the impact and the side effects of systemic changes that end up de-establishing what a community can provide for itself and for others.</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Tue, 22 Feb 2022 15:04:00 +0000</pubDate>\n    </item>\n    <item>\n        <title>Beyond Dark Matter</title>\n        <link>https://logicmag.io/beacons/dark-matter</link>\n        <guid>https://logicmag.io/beacons/dark-matter</guid>\n        <description>\n            <![CDATA[\n                <p>A tween zine about time traveling and overthrowing master technologies.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Neta Bomani, Romi Ron Morrison, Sabii Borno ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;6m3BETQqqfofwWK7StqFPV&#x2F;0ee9595a20c6298a49156ee0674d916f&#x2F;web-beyond-dark-matter-spreads_Page_18.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p><b><i>Beyond Dark Matter </i></b>is a tween zine about time traveling and overthrowing master technologies featuring Gem, a young student who is always on the go, Ms. Johnson, an elder who runs the local community kitchen and Archie, a retired postal service worker and handyman who volunteers at the community kitchen.\n\nThis zine is based on <a href=\"https://netabomani.com/darkmatter/\">Dark matter objects: Technologies of capture and things that can’t be held</a>.</p>\n<p></p>\n<div style=\"position:relative;padding-top:max(60%,326px);height:0;width:100%\"><iframe sandbox=\"allow-top-navigation allow-top-navigation-by-user-activation allow-downloads allow-scripts allow-same-origin allow-popups allow-modals allow-popups-to-escape-sandbox\" allowfullscreen=\"true\" style=\"position:absolute;border:none;width:100%;height:100%;left:0;right:0;top:0;bottom:0;\" src=\"https://e.issuu.com/embed.html?d=web-spread-beyond-dark-matter&pageLayout=singlePage&u=logicmagazine\"></iframe></div>\n<p></p>\n<p></p>\n        ]]>\n        </content:encoded>\n        <pubDate>Mon, 14 Feb 2022 14:20:26 +0000</pubDate>\n    </item>\n    <item>\n        <title>Family Units</title>\n        <link>https://logicmag.io/beacons/family-units</link>\n        <guid>https://logicmag.io/beacons/family-units</guid>\n        <description>\n            <![CDATA[\n                <p>The communities behind the data annotation work that powers AI.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Julian Posada ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;1XhGn4ERQGcSNujrlzWZj2&#x2F;54234eaa38d17daa023548e00b85c1f8&#x2F;family-units.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p>Since the early months of the Covid-19 pandemic, María’s house has been run like a factory. Every day, her family of six synchronizes their routines so two people are always behind a computer. María, her husband Rodrigo, and their children, Daniela (20), Andrés (18), and Camila (13) are among the unknown number of Venezuelans who, after years of political and economic crisis exacerbated by the pandemic, now try to make a living by annotating data through crowdsourcing platforms. Using two Canaima laptops, which the Hugo Chavéz government provided a decade ago for school children, they tag images and videos, transcribe text and audio, search for information online, and send videos and pictures of themselves to developers at companies and research institutions in Europe and North America. The developers use this data to train machine learning algorithms, like the ones that do facial recognition, moderate content, and guide self-driving cars.</p>\n<p>The family’s activities all revolve around data production because this is their only source of income and, according to María, they have to “focus on the same objective to survive.” She and Rodrigo do most of the work, although she also takes care of many domestic duties. Camila, Andrés, and Daniela work part time on data annotation while attending high school and university. Only María’s youngest child, Sebastián (7) is able to focus exclusively on school. Although most crowdsourcing platforms’ terms of use state that each account must be run by a single adult, often the only hard requirement to set up an account is for someone to prove that they are at least eighteen years old by taking pictures of an identification card and their face, and praying that a third-party facial recognition verification system called Onfido detects a match.</p>\n<p>The platform the family works for pays them a few cents per task, in cryptocurrency. They are only allowed to transfer the money to their online wallet once they have made at least the equivalent of ten dollars. After working every day of the week, they usually earn around twice that much, but recently they have barely made the minimum. “Last week, we couldn’t cash in,” Maria told me. “We couldn’t even make five dollars in total.” Her family dreads the day when the tasks will stop coming, the computer breaks, or they will lose access to the internet and electricity. Ofelia, another data annotation worker, who has diabetes, depends entirely on the platform to purchase insulin. “I would die without this income,” she told me. “I would literally die.”</p>\n<p>Income from data annotation is essential to Ophelia, María’s family, and the other Venezuelans who do this work because hyperinflation has made the official monthly minimum wage in the country worth only a few dollars, which is not enough to afford staple foods to survive even a week. That has rendered most jobs paid in bolivars, the national currency, unsustainable. After years of economic mismanagement due to government corruption and its economic dependency on oil, Venezuela has a goods and services shortage and has inflation levels that are consistently among the highest in the world. This situation, combined with its existing internet infrastructure, has made the country an appealing target of crowdsourcing platforms. In the absence of a robust social safety net, workers often see these platforms as their most reliable source of income in US dollars. </p>\n<p>Before the pandemic, María and her family were migrants in neighboring Colombia for a year. María worked at a beauty salon while her husband Rodrigo worked selling coffees in the streets. The children all studied in the public education system. These were difficult but more stable times for the family. When the pandemic hit, María lost her job and, with deserted streets, Rodrigo couldn’t find many clients. With no other choice, they decided to return to Venezuela. “Here we had to look for options, and a friend recommended the platform to us,” Maria said. When the pandemic stopped in-person teaching, it meant that her three eldest children were stuck at home too, and could also perform data annotation work. In dozens of interviews with platform workers in Latin America, many of whom are or were migrants, I have heard similar stories: they were collectivizing platform labor across their household members, with teenage children doing more and more work after the onset of the pandemic. </p>\n<p>In these ways, the political and economic crisis in Venezuela, as well as the pandemic and remote schooling, have turned out to be productive for data annotation platforms, their clients, and the venture capitalists that back them. (These crises have also generated profits for companies selling information to carceral states: Onfido, the identity verification company used by electronic wallets, shares the identity and facial recognition data it collects with the United Kingdom police.) The thousands of companies and research institutions that develop artificial intelligence are using platforms to find cheap outsourced labor, especially from low-income economies, for global markets in which data and labor are sold as commodities. One of the results is a race to the bottom in which wages get lower and lower as competition between platforms—and their ability to find pools of ready labor even among people living in refugee camps—goes up.</p>\n<p>The invisibility of the workers in this process, and the myth of “one user, one account,” which permeates the technology industry, are at the center of many tech companies’ business models; in many cases, they pretend that their products are entirely automated and devoid of human intervention. In fact, the most popular data-annotation platform in the United States and India, Amazon Mechanical Turk, is named after an eighteenth-century automaton that deceived spectators by seeming to play chess autonomously while concealing a human player inside. From the clients’ perspective, workers are just users or, even worse, less than robots: “To be successful at this job, you have to think like a machine,” said one of the platform administrators to Cecilia, a worker I interviewed.</p>\n<p>Once we see through the single-user facade, we can begin to appreciate the ways in which workers and their networks have gamed data annotation platforms and collaborated to mitigate the crises they face. These survival tactics can be important resources for other workers and communities facing similar exploitation. At the same time, though, these tactics indirectly serve to prop up the neocolonial labor practices of the platforms, their clients, and venture capital. In order to challenge these larger forces, we not only need to hold companies and research institutions accountable for the value they extract from “indivisibilized” workers. More importantly, we need to support emerging community-based alternatives to data annotation platforms—alternatives built by the people actually subject to this highly extractive form of work.</p>\n<h1><b>Survival Tactics</b></h1>\n<p>In the suburbs of Valencia, in Carabobo State, data-annotation workers like Alfredo must increasingly rely on their own efforts to survive. “Our water comes from a pump,” Alfredo told me recently. “Every block of houses has a well, and every day the community designates someone to operate the pump to fill those wells.” The country’s ongoing economic and political crisis has caused the state and traditional businesses to become less present and effective in peoples’ lives; with little support from their local institutions or from employers, workers have increasingly had to rely on families and local communities for survival. Many of these communities manage water and waste disposal locally as common goods and services. These community-based services are necessary so workers can be ready for work, but not always robust or safe; for example, workers in communities that have had to resort to private waste incineration have been poisoned by smoke pollution. </p>\n<p>Community support is also critical online, where workers share resources and organize with others through social media platforms like Facebook and Discord. Originally, the data-annotation platforms themselves created internal online groups to communicate with workers; however, these groups were heavily policed by moderators from the platforms. On one occasion, Roberto, a Black Venezuelan, wondered why Onfido’s AI could not manage to match his face and ID to validate his account. The moderators responded by expelling him from the online group. “I was astonished,” he told me. “I was expelled for asking a question!” </p>\n<p>This kind of policing prompted many workers to form their own groups. Through my interviews, I found groups where workers would seek help learning how to complete tasks, complain about the platforms, and, on one occasion, organize a strike: members of a major Facebook group for data-annotation workers in Venezuela tried to convince their peers not to work for a few days, inspired by colleagues in the Philippines who, according to the organizers, successfully improved their wages by refusing to work. Despite the organizers’ efforts, most workers and their families were so dependent on the platform income that they couldn’t join the strike. </p>\n<p>Through my interviews, I also found that some workers are part of smaller, closed groups on text-based apps like Telegram. These groups have a few dozen members with fees of a few dollars per month. (It was through Rogelio, the administrator of one of these groups, that I interviewed María and her family.) These sort of online professional associations were built for workers to help each other, to generate trust, and to access currency traders, who exchange virtual dollars and cryptocurrency for bolivars. In these groups, workers share resources, like bots that alert them when tasks are available, and guides that explain how to solve tasks more efficiently. I was told that one group pooled their savings to pay a programmer in Spain to code one of these bots for them. </p>\n<p>Workers also use the groups to buy and sell accounts on the data-annotation platforms. New platform workers are not allowed by the platforms to perform many annotation tasks, and it takes a great investment of time to gain access to the best work. As a result, there is an informal market for the highest, “level 3” accounts, which are sometimes sold individually for roughly ten US dollars, or in packages of at least as many as ten.</p>\n<p>Online worker groups can also transcend the virtual—for example, when a fellow member cannot work from home and needs a place to go, or when a member tries to take advantage of another one. A worker named Rodolfo told me about a colleague who refused to pay after receiving login details for ten platform accounts. “Hopefully, the moderators have personal information of every single member, including addresses,” he told me. “They contacted the seller physically and realized that she had lost access to electricity and couldn’t complete the transaction.” Trust in his fellow workers is essential in a context where online scams are common.</p>\n<p>These forms of community support are vital to workers, but they also put the onus on workers to make the data platforms’ business models sustainable. But even then, workers are disposable: when a platform can no longer drive down wages in a particular country, they can simply look to other places and other crises.</p>\n<h1><b>Beyond the Visible</b></h1>\n<p>Since platforms are not usually physically and administratively present in the countries where workers are located, they can relocate quickly. I have conducted quantitative research on the web traffic of ninety-three crowdsourcing platforms and shown that some of those present in Venezuela are now targeting workers in Kenya. This repeats the same model used by non-data-annotation gig work apps, such as Uber, which launch in a country with incentives that make workers dependent on the platform and then remove those incentives once they create dependency. </p>\n<p>Making workers and their communities more visible may be one way to demand these platforms change their business models. But pointing out the collective exploitation at the heart of data annotation should also be used to pressure the platforms’ clients, including developers, management, and individual researchers, as well as investors, shareholders, and university administrators. In order to do this, we need more efforts to document the origins of datasets, third-party audits on AI models to assess their compliance with local and international labor standards, and assessments of the working conditions of platforms.</p>\n<p>However, as the scholar Noopur Raval argues, making workers and their communities visible is not enough. Since the economic incentives for platforms and their clients will remain, major actors in the data-annotation pipeline need to be directed to change their practices through regulation. In addition, in the place of exploitative multinational gig work platforms, companies and research institutions that require annotation need to support local initiatives from unionization to cooperative ownership of locally created platforms.</p>\n<p>In fact, there is a burgeoning ecosystem of platform companies owned and managed by workers. These companies have the potential to be more sustainable alternatives to the mainstream gig economy platforms. The Platform Cooperative Consortium lists 506 co-op projects in thirty-three countries. Many have emerged in sectors like ride-hailing and delivery, but the market for cooperative data annotation remains untapped. It is also worth mentioning that local impact sourcing companies, where data annotation occurs on-site by employed workers, could represent a more reliable alternative, in terms of data quality and labor conditions, than many platforms currently in the market. Ultimately, only solutions that recognize the communal nature of work and economic justice can have transformative effects on the lives of workers like María and her family. Inequality in platform labor is not an issue of individual workers, but networks of people who resist the paradox of a technology that innovates for some by exploiting others.</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Tue, 8 Feb 2022 13:54:22 +0000</pubDate>\n    </item>\n    <item>\n        <title>Holding to Account: Safiya Umoja Noble and Meredith Whittaker on Duties of Care and Resistance to Big Tech</title>\n        <link>https://logicmag.io/beacons/holding-to-account-safiya-umoja-noble-and-meredith-whittaker</link>\n        <guid>https://logicmag.io/beacons/holding-to-account-safiya-umoja-noble-and-meredith-whittaker</guid>\n        <description>\n            <![CDATA[\n                <p>Critique and capture in the strange space of “AI ethics.”</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Safiya Umoja Noble, Meredith Whittaker ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;DalvhJvbNz39ZdcsJfAGJ&#x2F;296f2d3902ba2e06f2bcc607c20cb3fa&#x2F;holding-to-account.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p><i>The tech industry is a monopolizing force, and one of the many things it monopolizes is the means for producing knowledge about it. In the platform era, the machinery of the internet is locked behind closed doors, creating problems for researchers. Companies like Facebook aren’t keen to share data or the other computational resources needed to develop a complete picture of how large algorithmic systems work (and whom they work for). And these companies’ endless amounts of money give them plenty of other ways to derail critical research, in particular by exercising influence over academia and the other places where knowledge about the tech industry is made, as well as by co-opting or silencing individual researchers.</i></p>\n<p><i>Given these obstacles, how can researchers both inside and outside of tech companies do the difficult work of research, critique, and resistance?</i></p>\n<p><i>To discuss this and other related questions, issue editor J. Khadijah Abdurahman talked with two leading critical scholars of technology. Dr. Safiya Umoja Noble is a MacArthur Genius Fellowship recipient and an Associate Professor of Gender Studies and African American Studies at UCLA, where she serves as the cofounder and director of the UCLA Center for Critical Internet Inquiry. She is also the author of the seminal book debunking technologies as neutral artifacts of progress, </i>Algorithms of Oppression: How Search Engines Reinforce Racism.<i> Meredith Whittaker is the Faculty Director and cofounder of the AI Now Institute, and a Minderoo Research Professor at NYU. She resigned from Google after organizing with her coworkers against the company’s efforts to build military AI and its failure to address rampant discrimination and sexual abuse. Abdurahman spoke with Noble and Whittaker about how to do critical tech research, and how to insist on transformative justice practices as we try to dismantle technologies of oppression.</i></p>\n<hr />\n<p><b><i>Beacons</i></b><b> was conceived of in the wake of Dr. Timnit Gebru’s high-profile firing from Google. Similarly, the impetus for this interview was the systematic firing of Black women from academia and industries—those who were essentially fulfilling their duties and showing up as their full selves. On one hand, there’s a question of what is to be done about institutional and corporate power—but the bright lines dictating who are the villains in a David and Goliath story let us off the hook in terms of internal cultures of accountability. Are there different ways to relate to one another and be accountable, as we respond to institutional repression? How are each of you thinking about these questions as we’re approaching the one year anniversary of Dr. Gebru’s firing?</b></p>\n<p>Safiya Umoja Noble (SN): The question about how do we hold ourselves accountable is really important. I know that there is always a series of conversations happening among people who work in the field of AI and ethics, which is a big tent of people holding competitive and often diametrically opposed ideas. You have, for example, companies like Google that consider themselves leaders in ethical AI; and then you have the women, the people of color, the LGBTQ scholars, the activists, and the journalists who for two decades have been trying to make their issues about the immorality or the politics of various types of technologies legible. </p>\n<p>That legibility has also led to an intense capture by people who are not interested in the radical reimagining of or resistance to these technologies, or in the way that these technologies are reshaping society, consolidating power in the hands of a few, and making the world more socially, politically, and economically unequal. So, it’s interesting to have this conversation on the almost anniversary of the firing of Dr. Gebru from Google. Because watching her ascent to that position of leadership and then her firing, when she named the racist technologies and environmentally consequential technologies that Google is developing, is symbolic of the nefarious intent or willful ignoring of the core issues at stake. It’s symbolic because there are in fact thousands of people who have been organizing for a long time around these issues, trying to ensure that these conversations about AI ethics still keep their kind of political importance and are not just completely defanged and depoliticized. I don’t know, Meredith. What do you think? </p>\n<p>Meredith Whittaker (MW): There are so many ways I can approach this. It’s very personal because Timnit is someone—along with Meg Mitchell and others—who stood up for me when Google pushed me out. So I’m also seeing an attack on support structures within these organizations and an attack on the people with the courage to call out bad behavior. I think Timnit’s firing was an inflection point that you captured in “On the Moral Collapse of AI Ethics,” Khadijah. When you published that piece in the wake of her firing, it laid bare the stakes and failures we’re confronting.</p>\n<p>Before Timnit’s firing, there’d been enough people who were willing to—mainly in the name of civility politics—give Google the benefit of the doubt. Then the company fired Timnit, someone who had been outspoken about the racism inside of Google <i>and</i> who had been doing research that was exposing fundamental problems with Google’s business practices. Timnit called out racism <i>and</i> her work showed that the large language models at the core of Google’s current product and profit strategy are biased, environmentally harmful, and an overall problem. It was when criticism of Google’s racist culture and criticism of its harmful business practices converged that Google retaliated, in what I saw as an almost reflexive reaction. It was clear that leadership just “had enough,” and went on to make an astonishing string of unforced errors. The corporate immune system kicked into gear: “Okay, fuck it, we’re going to make a really bad PR move, which we calculate we’re powerful enough to withstand. What we can’t withstand any longer is the tension of ‘supporting’ AI ethics on one side, and selling biased, extractive, unverified AI on the other; of doing diversity and inclusion PR on one side, and discriminating against Black women on the other.” </p>\n<p>Google’s firing of Timnit reverberated through the AI ethics space for many reasons. One, I think, is because the space is so co-opted and so unwilling to look at who pays us, at who our community is—insofar as we are a community. And suddenly, unexpectedly, the field was faced with big existential questions, which in many cases challenged people’s comfortable status quo: can we work with Google and other tech corporations? What are the limits corporate funders actually put on our research, on the research we review as part of our conference program committee roles, on the research of the corporate-employed collaborators we co-author with? Many in the space were largely avoiding these questions which, we should note, are standard in many other fields.</p>\n<p>This moment also illuminated some of the ways that the field is configured. People use the word community—the AI ethics community, or whatever—but a lot of times “community” is just a bunch of people a funder paid to fly somewhere, or a group of folks whose employers are willing to fund them to go to the same conference. The people in these “communities” may have vastly divergent politics and motivations, and these communities are certainly predominantly white, and often very exclusionary. I may be sitting next to someone who’s funded by the Koch Foundation, who believes Facebook is a net good. But we’re both narrated under this umbrella of “community,” and we’re all usually nice and civil to each other because clarifying political commitments in these circumstances has material stakes, and could get you kicked out of the “community.” To put it bluntly, as the leader of an organization, I have to go back home and I have to make sure my people have jobs and health insurance, that I have health insurance, that my family is supported. Of course, there’ll be certain things I do feel I can agitate or call out. But I also have a duty of care that I may be jeopardizing if I go too far, and I feel this tension constantly. </p>\n<p>Amy Westervelt has a really good podcast called <i>Drilled</i>, and the first season traces the history of Exxon. At one point the company was genuinely trying to support and understand climate science and climate change, trying to get ahead of it and figure out how its business model could adapt, to potentially provision other sources of non-fossil energy. This approach got traction until the company refused to adapt their business model to the science and doubled down, which initiated a slow process of Exxon pushing climate scientists out of the company, and then turning to climate denial; for example, funding anti-climate heterodox “scientists” and related misinformation campaigns. </p>\n<p>We’re in a similar phase in the AI ethics space. Initially, big companies accommodated the ethical implications of AI research, but when it challenged their culture and their business model, they started pushing us out, denigrating us and our research. This is happening right now. But as researchers weathering this transition, we haven’t had that real talk about things like, “Whose money do we take?” Or: “Why is so much so-called tech criticism funded by the companies whose tech is purportedly being criticized?” We’re in the process of a rude awakening. It’s like a limb coming back to life after being asleep—it’s painful for a lot of people. </p>\n<h1><b>Open Letters to the Apocalypse</b></h1>\n<p><b>Part of what I was thinking through when I wrote “On the Moral Collapse of AI Ethics” was—and I’m saying this as someone who has written my own open letter—what to do with this asymmetry between writing an open letter and the stakes of techno capitalism. The open letter that I spend a lot of time thinking about is the Franck Report of June 1945, which was signed by several prominent nuclear physicists who had worked on the Manhattan Project. They delivered it to the White House, saying “Maybe we should just let the Japanese come over and see our capability, and not drop the atomic bomb?” Then, as we all know, in August 1945, you have first Hiroshima and then Nagasaki.</b></p>\n<p><b>So we’re facing these tremendous stakes and also have to contend with the civility politics you both alluded to. How do we negotiate the obvious villains of centralized corporate computing capital, while also this negotiation among ourselves? Who is the resistance? How do we identify what that means? What does the coalition look like and how do we start thinking about some of those bright lines? </b></p>\n<p>SN: Well, one of the challenges is that not everybody who is working on these issues relates to themselves as community organizers, or relates to each other inside a politics of accountability, shared responsibility, protection, and support, or has committed to a process of hashing out hard conversations, strategies, and ideas about how to move forward. You see this most profoundly in the fairness, accountability, transparency efforts and movement under ACM—the Association for Computing Machinery, an international educational and scientific computing society—which has really, from its inception, marginalized the more radical political critiques of systems and has sought to pursue perfecting technology and to champion techno-solutionism. Though they might more recently be grafting on a Black feminist quote to open a paper, they’re still seeking to address the fairness questions around tech in terms of <i>better</i> algorithms or <i>better</i> AI. </p>\n<p>That’s really different from what others of us are doing, those of us who think some of these technologies should not exist—to your point, Khadijah, that we shouldn’t have the Manhattan Projects of AI today. And then when we look up and see that the whole world has been reorganized through these ubiquitous technology deployments, in every single industry and every sector that are, in essence, snake oil or have profound civil and human and sovereign rights implications. That’s actually a completely different project to be working on in the world. </p>\n<p>Part of the challenge here is that researchers have been socialized in academia to be apolitical or to think of themselves as scientists and not as people who have values imbued into the work that they’re doing. That is also part of the problem that we’re trying to contend with around the making of these technologies that are also allegedly neutral and just tools. This is part of the reason why we need feminists and why we need people who are committed and connected to social movements around the world to contextualize our work and to make sense of what it’s working in service of. That’s really important. </p>\n<p>MW: AI is an umbrella marketing term. It’s not a term of art that describes a specific technique. Companies apply the name AI to data-centric approaches generally, and you never quite know what you’re buying if you’re licensing an “AI” system. </p>\n<p>The AI boom of the last decade was not the result of a major scientific innovation in algorithmic techniques. It was a recognition that with massive amounts of data and computing power, you can make old techniques do things they couldn’t do before. The ascent of AI was predicated on concentrated tech company power and resources which had, as their driving force, the surveillance business model. </p>\n<p>One thing we rarely discuss is how AI research and development’s dependence on corporate resources worked—and continues to work—to shape and in some cases co-opt knowledge production. In other words, to “do AI” as defined in the current “bigger is better” paradigm, you increasingly need resources that are controlled by these handful of companies. You need access to really expensive cloud compute, you need access to data that is hard and sometimes impossible to get. You can’t just go to the data market and buy it—you often need to get access from the data’s creators or collectors, who are often the tech companies. It’s fair to say that academic computer science disciplines underwent a kind of soft-capture, in which as a condition of doing “cutting edge” AI research, over the last decade they became increasingly dependent on corporate resources, and corporate largesse. </p>\n<p>This dynamic led to practices like dual affiliation, where professors work at a tech company but have a professorial title and produce research under their university affiliation. It’s led to tech companies moving whole corporate labs into the middle of universities—like Amazon’s machine vision lab at Caltech. We have a structural imbrication between a massive, consolidated industry and knowledge production about what that industry does. And this compromised entanglement has bled into the fairness and ethics space, in many cases without anyone commenting on it. There are many forces working against our recognition of how captured the technical disciplines are at this time, and how easy it is for them to extend this capture into fairness, ethics, and other disciplinary pursuits focused on the consequences and politics of tech. </p>\n<p>To pick one example, Amazon is underwriting half of the National Science Foundation’s Fairness in Artificial Intelligence grants. And while a few people called this out, the fields concerned went on to apply for this funding, and uncritically applauded colleagues who received it. Whole labs are reliant on Amazon, Google, Facebook, Microsoft funding, and if you raise questions about it you’re endangering your ability to support your postdocs, your ability to obtain future funding, your standing with your dean. Or, you’re endangering your colleagues in these same ways. Dissecting the particularities of what it means to be able to do research on AI and related technologies, and how dependent this work often is on corporate resources, is a project that I think can help develop a clearer political-economic read of tech and the tech industry overall, and reveal the capital interests that are propelling research and knowledge production into tech and its implications. </p>\n<p>SN: This is a critical area especially during the time of Covid-19, when we saw how fragile so many of our public institutions are. We really feel that at a place like UCLA, where teaching assistants aren’t paid adequately, it’s extremely expensive to get an undergraduate degree, and the pressures to deliver public education are intense. Many, many systems are broken, and it is very painful to work under those kinds of broken systems. </p>\n<p>Meredith, I recognize this tech sector political economy you’re describing. They are capturing not only scholars but policymakers who, in essence, use public money to subsidize the entire industry, both through the research efforts at the National Science Foundation and also by making it impossible for democratic public institutions to flourish, because they don’t pay their fair share. They offshore their profits, and they don’t reinvest them back into communities where they do business in extremely exploitative ways. They just expect the public to underwrite it through tax refunds. How in the world can companies like Apple get tax refunds except through pure corruption? As we struggle in our communities with and in our institutions, we have to identify why those conditions are present. We have to recognize who has monopolized all of the resources and we have to examine the narrative about what’s happening with those resources.</p>\n<p><b>I want to ask you about social media and “cancel culture.” In July 2020, </b><b><i>Harper’s</i></b><b> published “A Letter on Justice and Open Debate,” signed by a number of prominent people, including Noam Chomsky and J.K. Rowling. The letter criticized “an intolerant climate” on the Left, and in particular, “an intolerance of opposing views, a vogue for public shaming and ostracism, and the tendency to dissolve complex policy issues in a blinding moral certainty.” The following month, in August 2020, </b><b><i>The Atlantic</i></b><b> published a piece by Anne Applebaum called “The New Puritans,” that used Nathaniel Hawthorne’s </b><b><i>The Scarlet Letter</i></b><b> to criticize social media “mob justice.” The irony of invoking the white woman’s public humiliation for being pregnant out of wedlock is that the book was published more than a decade before the Civil War. Black and Indigenous peoples’ ongoing bondage and claims to liberation are as unnamed in the book as they are in today’s epistles of moral panic.</b></p>\n<p><b>But how do we negotiate this issue? Is calling people out on Twitter our only mode of addressing power dynamics in the AI ethics space? How can we put forward a vision that is constructive and not just reactive, even though our operational capacity is so low, even though we’re all exhausted, grieving, and torn into so many different directions? What is our vision for transformative justice in the context of knowledge production?</b></p>\n<p>MW: Look, I have a lot to say here. First, I think there’s a visibility bias: people see when calls for accountability and redress spill into the public. They rarely see the agonizing work of trying to hold harmful people and institutions accountable behind the scenes. Work that’s too often not only unrewarded, but actively punished. Like many people, I have engaged in a number of accountability processes that didn’t end with Twitter callouts and are not visible to the public. In my experience, Twitter is always a last resort. There are failures upon failures upon failures within these institutions and with the way power moves within them, all of which happen before someone is going to take to Twitter or call on social media as a witness. Timnit taking to Twitter didn’t save her job. </p>\n<p>Buried in the moral panic around “cancel culture” is a burning question about how you hold power to account when you’re in an institution that will punish you for doing so. What do you do when your wellbeing and duties of care dictate that you confront and curtail harmful behavior, but you know that any such attempt risks your livelihood and institutional and professional standing? Institutions protect power. Universities don’t want to touch a star professor who’s bringing in press and grants; tech companies have every incentive to coddle the person architecting the algorithm that is going to make them a shit ton of money. These corporations and corporate universities are structured to protect flows of capital and, by extension, to protect the people who enable them. There are infrastructures in place—including HR and most Title IX offices—to make sure that those who enable the interests of capital are elevated and to make sure that it’s as painful as possible for the people who might report anything. </p>\n<p>This is the backdrop against which we’re trying to figure out how we, as people within these environments, protect ourselves and each other. In my view, the answer to this question doesn’t start with building a better HR, or hiring a diversity consultant. It’s rooted in solidarity, mutual care, and in a willingness to understand ourselves as committed to our own and others’ wellbeing over our commitments to institutional standing or professional identity. </p>\n<p>That’s also a question of how we can be accountable ourselves. Especially as people who have institutional power, and who may experience favorable treatment from the same people who harm those with less power. In other words, the more power we have the less we can rely on our experience of people and institutions as an accurate barometer, because there’s every incentive to act the sycophant. This means we need to actually listen to, elevate, believe, and act on the accounts of those with less power, especially Black people and historically marginalized people for whom institutional abuse is compounded. And we need to be willing to put their safety and wellbeing above our institutional and professional standing. This is very hard, but in my view it’s the floor. If you can’t do it, then you shouldn’t be in a position of leadership. </p>\n<p>SN: I relate so much to all the things you’re saying. I think we’re in a long struggle around creating systems of mutual care, aid, and support, and that is very difficult. Most of the environments that we’re trying to build those systems within, like academia, are hostile to trying to get work done and get people supported properly. Having said that, we have to keep building these networked communities. We have to be agile and we have to think about how we’re going to create more space for others to do their work. </p>\n<p>In my own experience and my own career, I have felt at many times completely unsupported. I have felt like if I could just expand the circle at some point in my career so that more people could be supported, that would be something. The question is, to what degree can we institutionalize that so that all of the possibilities don’t hinge on one person in one space or place, but that we remake entire systems? We want those systems to last and not rely on any one particular person. That’s difficult work and we need to be sharing ideas about how to do that. </p>\n<p>But the problems that we’re working on are very big problems in the world and in our communities. I think about abolitionist traditions: you know, how did a handful of people change the world? Millions of Americans got up every day and made pancakes and went to work while people were being human-trafficked right in front of them and enslaved, beaten, lynched, and harmed on the regular. How did abolitionists, in the face of those conditions, abolish the transatlantic slave trade or change the laws around the enslavement of African peoples? How did others resist the expansion into First Nations and Indigenous peoples’ lands? There weren’t millions of people working on these issues. It was, relative to the population, a very small number of people who worked on those things. </p>\n<p>I guess I feel heartened by the fact that if enough people can be coordinated, a lot of change can happen. That is why we have to study history and study social movements to figure out how they did it and how to make it last. Especially for those of us right now living through the rollback of the Civil Rights Movement, we know that those changes can also be precarious. We have to figure out how to make them last. </p>\n<h1><b>On Some Global Tech Resistance</b></h1>\n<p><b>Academia is coming for our lives, so much of our time is swallowed up into institutional administrative overhead, and also we’re facing major stakes that are global. It’s so difficult to even stay on top of our own “domain expertise,” so how do we facilitate transnational solidarity? How do we think about this work as global? What are the points of connections you identify around intellectually, and politically, in your own work? What kind of infrastructure represents the next steps that could be taken to bolster this kind of transnational research?</b></p>\n<p>SN: We have to keep our diasporic commitments intact while we’re doing our work. And of course, we sit here in the heart of the American technology empire. We have a responsibility where we are in this location to press on these companies and on governments to ease exploitation around the world. Many of us understand these questions because we come from internal colonies of the United States, which is one of the ways that sociologists have talked about Black people’s experience in the Americas. Our work is connected materially to other people’s lives around the world. </p>\n<p>We have to be in community. We have to be in conversation. And we also have to recognize what our piece of the puzzle is ours to work on. While it is true, yes, we’re just individual people, together we’re a lot of people and we can shift the zeitgeist and make the immorality of what the tech sector is doing—through all its supply chains around the world—more legible. It’s our responsibility to do that as best we can. </p>\n<p>MW: Yeah, I agree. I’m a white lady raised in LA. I had to educate myself on so much that I didn’t understand, and that process is humbling and ongoing. </p>\n<p>My voice doesn’t need to be the center of every conversation. But, okay, if I have a little power and a little standing maybe I can move capital, maybe I can ask people what they need and see what I can do to get it to them, to support and nurture their expertise and organizing and approaches, which may be completely unfamiliar to me, and may not need any advice or insight from me. I’m thinking of the ACM Conference on Fairness, Accountability, and Transparency (FAccT). Briefly, it’s a computer-science focused conference exploring fairness in algorithms. Over the years, we have seen increasing calls to examine algorithmic and other technologies in the context of racial capitalism and structural inequality, accompanied by warnings about the insufficiency of narrow FAccT-style technical approaches to the problems of algorithms and tech. So, what was the response? From many people, it wasn’t a re-evaluation of the field, but instead a move to absorb. Like, “Oh, well, how about we bolt an Audre Lorde quote to this computational social science paper.” This response continues to place computer science at the center, with racial justice as seasoning. Even though there are, of course, Black feminist conferences that could use some funding, and that have been deep in these topics for decades before FAccT. So my question is, why is the instinct always to absorb into the core instead of diffuse the resources to those already doing the work? </p>\n<p><b>I mean, I fuck with that. We need allyship in the form of funneling actual, material support out of these Western institutions.</b></p>\n        ]]>\n        </content:encoded>\n        <pubDate>Tue, 1 Feb 2022 14:59:42 +0000</pubDate>\n    </item>\n    <item>\n        <title>The Oversight Bloc</title>\n        <link>https://logicmag.io/beacons/the-oversight-bloc</link>\n        <guid>https://logicmag.io/beacons/the-oversight-bloc</guid>\n        <description>\n            <![CDATA[\n                <p>An investigation into how tech workers and community organizers fought the San Diego surveillance state.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Lilly Irani, Khalid Alexander ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;3Cgr0uaLMzIBOPyNb2rlCY&#x2F;e291ef435e7343c88eeae418e078a2cd&#x2F;oversight-bloc.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p>In July 2019, one of us, Khalid Alexander, received a tip from a fellow San Diego community organizer. “You should be paying attention to the city’s new streetlights.” The message continued, “Apparently, they have cameras attached to them.” Alexander lived in one of the many predominantly Black and brown neighborhoods in San Diego that was under constant police surveillance, including by “gang suppression units” that watch, harass, and document residents. He feared that streetlights with cameras on them could supercharge these efforts.</p>\n<p>Two weeks later, Alexander showed up at a public library for a forum about the streetlights program (which the city named the Smart Streetlights Program). The only other people at the meeting were the presenters: a police captain, a city staffer, and an executive from General Electric (GE), the company that produced the new streetlights. Their presentation began with an infomercial for the technology, a city-wide network of thousands of LED streetlights mounted with cameras that recorded video around-the-clock. The footage was uploaded to the cloud, where city agencies could use software to count cars, pedestrians, and who knows what else. According to the police captain, the smart streetlights were already being used to solve crimes.</p>\n<p>Alexander left the presentation shocked and concerned. Five years earlier, police had rounded up thirty-three Black and brown men from San Diego and charged them with fifty years to life in prison for gang crimes simply because they were included in a police surveillance database called CalGang. The Smart Streetlights would make this kind of state violence more likely—other networked surveillance programs in cities such as Chicago and Los Angeles had led to similar raids—and yet none of the city’s larger civil rights organizations seemed to be visibly fighting the project. The community was going to have to organize resistance to the streetlights itself.</p>\n<p>Alexander’s first call was to the Tech Workers Coalition (TWC). Much of the technology incorporated into the new streetlights was foreign to him, and he wanted to better understand how it might be used. He also reached out to activists from communities he knew were likely to be targeted by the surveillance—homeless advocates, immigration rights organizers, police abolitionists—and invited them to the next streetlights community forum. At that meeting, held a month later, Alexander and his fellow activists managed to pack the house.</p>\n<p>This was the beginning of a two-year grassroots campaign to rein in the Smart Streetlights Program. By connecting surveillance to a wider set of issues than policing alone, the organizers were able to create a coalition wide enough to win. A lynchpin of their success was not only building a traditional coalition of community organizations from around the city, but also bringing in new allies: workers from the companies and research institutions building these technologies. The methods might be a model for other struggles against surveillance and carceral technologies in cities around the country.</p>\n<h1><b>The New Bacon</b></h1>\n<p>The infomercial Alexander was shown at the first community forum boasted that the data produced by the Smart Streetlights were “the new bacon”—they went with anything and could serve almost any purpose that agencies with access to the data could imagine. The other one of us, Lilly Irani, an organizer with TWC, listened to the presentation at the second community forum and realized that surveillance was only one part of what the streetlights could be used for.</p>\n<p>Community members at the forum immediately raised concerns about the technology’s ability to further criminalize San Diego residents. Black and brown-led organizations worried about heightened racial profiling using video streams. Refugee advocates worried that the streetlights could intensify the criminalization of Muslims by using software to analyze behavior near mosques. Homeless rights groups predicted the city would use the streetlights to more quickly find encampments to sweep. Border activists worried the streetlights could help track and deport people by being integrated with systems such as those developed for the Department of Homeland Security by Palantir.</p>\n<p>A police officer at the forum assured the crowd that the cameras did not record private property, but a computer engineer from TWC was able to force the officer to clarify that the cameras <i>did</i> record private property, which was then scrubbed from the data by a software program. What the city called the “sensors” on the streetlights also included microphones that could record people’s voices without their knowledge. The officer said the microphones were currently disabled, but admitted that they might be used for gunshot detection in the future. When a community member asked how long the streetlights were going to collect information, a city staffer replied that it was “undetermined”; the officer tried to reassure the crowd that “the answer is probably never.”</p>\n<p>Activists recognized that what the city and law enforcement said it was doing (and planning to do) with the program was beside the point. San Diego has long been an innovator in police surveillance networks. The county’s Automated Regional Justice Information System, which shares surveillance data between more than sixty-five law enforcement agencies, has been in place since the 1980s. More recently, the county had provided facial recognition devices to law enforcement agencies across the southwestern border region until the state passed a moratorium on such devices and the Electronic Freedom Foundation sued to have the moratorium enforced. For years, the San Diego Police Department shared data from its automated license plate readers with Border Patrol to help the federal agency track, detain, and deport migrants, until the practice was exposed by journalists. When it came to the streetlights, the hard part was already done: more than three thousand units were installed across the city. Expanding what that hardware could help officials do would only be a few software updates away. As the officer admitted, the sensors weren’t even covered by civil codes the way similar technologies, such as automatic license plate readers, were.</p>\n<p>And it wasn’t only city and law enforcement agencies that might deploy the technology. All of the data generated by the streetlights would be made publicly available, albeit in an ostensibly anonymized form. A city staffer at the forum explained that this would allow “civic entrepreneurs” to use the data to build businesses to improve the city, including an app to help people find parking downtown. Irani knew this was code for gentrification—the city would give or even sell data harvested from the public, without its consent, to tech companies that would use the data to reshape the city in ways that favored wealthier white communities and pushed Black, brown, and poor people out of San Diego. Irani and Alexander later discovered through a public records request that the city had used Federal Community Development Block Grants, meant for projects that benefit low-income neighborhoods, to fund the streetlights.</p>\n<p>This range of concerns about how the technology might be used in the future became the basis for the grassroots campaign. Within a month, thirty community and activist groups had joined together in what became the Transparent and Responsible Use of Surveillance Technology San Diego (TRUST SD) Coalition. It grew quickly, in part, because people recognized that the Smart Streetlights surveillance infrastructure spanned the city and could bring anyone into the law enforcement dragnet. The campaign also relied on the working relationships that Alexander had built over years of organizing with different communities.</p>\n<p>Tech workers, too, were an essential part of the coalition. They joined because they did not want to build tools of state violence and oppression. In many public contests over technology, experts from industry and the state dominate conversations by wielding technical knowledge that communities cannot counter. In this coalition, however, the technical expertise of tech workers allowed organizers to counter official claims about what the Smart Streetlights technology could or couldn’t do, and helped them understand how the surveillance applications they feared could in fact be built on top of the existing network. The alliance with tech workers neutralized the city’s advantage.</p>\n<h1><b>Organizing the Lab Rats</b></h1>\n<p>The coalition decided to focus on three goals. Articulating these was crucial to keeping the various political and ideological factions within the coalition from splintering over other issues. First, it called for an immediate moratorium on streetlight acquisition, installation, and operation. This would end the immediate threats that the streetlights posed while organizers lobbied for more radical changes to public policy.</p>\n<p>Those changes to public policy were the coalition’s second goal. Organizers sought public participation in the creation of legally enforceable policies over all surveillance technologies used by the city, not just the streetlights. A wide range of technologies beyond the streetlights—known and unknown—made up the surveillance dragnet of San Diego. Worse, surveillance tech could come to the city through donations to the Police Officer Association or through free trials like those offered by facial recognition company Clearview AI. This meant that the City Council did not always have to approve the technologies and the public had no way to see what was in use, unless someone peppered city departments with scattershot public records requests. Council members had not even discussed the Smart Streetlights Program publicly before they signed off on it; that was two years before communities realized a mass surveillance technology was even on the table. Communities needed a legal infrastructure that would alert them to surveillance technologies before they were approved. Rather than playing whack-a-mole to stop individual technologies, the coalition sought transparency, oversight, and City Council authority over <i>all</i> city surveillance technology, existing and future.</p>\n<p>Finally, the coalition demanded public records showing how the streetlights had already been used and accessed. As organizers studied these records, they discovered that the city had considered monetizing the data and had even explored providing a livestream to the police. These discoveries informed the coalition’s activism and provided fodder for breaking news stories that added momentum to the campaign.</p>\n<p>Because the mayor had championed the program, organizers would need a veto-proof majority of council members to support the moratorium and the policy changes we were fighting for. So the campaign worked to build public pressure on the city council through press conferences, newspaper opinion pieces, public events, and direct lobbying. Organizers broadened their discussion of the issue beyond criminalization to larger concerns about the dangerous power of big tech to engage liberal and conservative elected officials in different ways. In one opinion piece, they argued that San Diego residents had been turned into “lab rats for innovation.”</p>\n<p>The Mayor’s Office and city officials tried to dismiss the campaign as a small handful of activists with hidden agendas. They also attempted to frame it as ignorant of the technical dimensions of the streetlight program. In November 2019, a tech worker who had experience working on artificial intelligence contracts read the contract the city had signed with GE, and discovered that the city had signed over to the company ownership of the data produced by the streetlights. The data were stored on GE’s servers, and the city merely accessed them through a subscription, which meant the city lacked final say over what the company could do with the data. An anonymous city staffer responded by calling the coalition’s findings “insane lies,” but ultimately the city could not undermine the credibility of tech workers who had built or worked closely on smart cities hardware, artificial intelligence models, and similar technologies.</p>\n<p>Over the following months, members of the coalition lobbied city council members and found them increasingly at odds with the mayor and the city attorney over the scope and legal framework of the Streetlights Program. In order to channel that frustration into a tactical win, organizers followed a two-pronged approach. First, they expanded their attempts to put public pressure on these elected officials. They held town halls, screenings of the film <i>The Feeling of Being Watched</i>—about government surveillance of Muslim communities in Chicago—and workshops at which we taught community members and activists about the technology and brought them into the organizing efforts. They also did direct outreach to community leaders and journalists.</p>\n<p>The second prong was to write a “surveillance technology transparency and oversight” ordinance. The coalition would hand the draft legislation over to a champion on the city council, who could then present it as a “common sense” solution they could claim as a legislative victory. Organizers adapted their ordinance from ones already in place in Oakland and Seattle. It required city departments to create use policies and impact reports to gain Council approval for any new technology with surveillance capabilities. It emphasized oversight over all such technologies, not just those used by the police. The LED streetlights, after all, had been acquired in the name of energy savings and innovation, obscuring the technology’s connections to law enforcement. The ordinance also created a Privacy Advisory Board to support the City Council with recommendations on specific technology acquisition proposals. Board seats were reserved for representatives from “equity-focused organizations” serving communities impacted by surveillance, as well as information technology and civil liberties experts; anyone with financial ties to companies selling surveillance technologies was disqualified. </p>\n<p>Organizers wrote the ordinance to appeal to a wide range of constituencies. Fiscal conservatives liked it because they wanted to reduce government spending. (The streetlight program, budgeted at $30 million over a decade, was already seeing cost overruns.) Liberals who believed in deliberative process appreciated that the ordinance created an independent body to advise the city council and included civil rights oversight. More radical organizing communities recognized that they needed the ordinance in order to find out about new technologies if they were to have any chance of organizing against them.</p>\n<p>The coalition was lucky to find a champion on the Council who was willing to take the ordinance through committees and do the behind-the-scenes work to get it passed. The Councilmember, formerly a civil rights attorney at the ACLU, also had close relationships with people in the coalition. Meanwhile, organizers kept pressure on the city to shut down the streetlights and adopt the ordinance by organizing people to show up at council meetings and the mayor’s office, and led telephone and email campaigns ahead of crucial votes.</p>\n<p>The coalition also seized upon Covid-related budget cuts to defund the streetlights. Mid-pandemic, Irani assembled a dystopian hackathon with coalition-aligned students to prototype creepy examples of what the streetlight technology could already do. Irani thought the demos would help persuade the Council of potential harms, but the most important outcome turned out to be the discovery that the streetlights didn’t deliver the promised data for city planning. The coalition alerted an investigative journalist, who broke the story in April 2020. By May, the city was proposing Covid budget cuts. The mayor had put library hours on the chopping block but saved the streetlights. The coalition worked with the progressive Community Budget Alliance to mobilize residents to email and call council members and demand they defund the streetlights. San Diego Climate Action also joined the effort, since the lights, operated under the Sustainability Department budget, had redirected funds to a broken, greenwashing surveillance system. In the end, the Council refused to fund the system. </p>\n<h1><b>Tools for Struggle</b></h1>\n<p>In May 2020, the mayor made a last ditch attempt to hand over control of the surveillance system to the police and fund it using an obscure budget pool that City Council didn’t control. The coalition was able to show through old legal memos that this funding strategy was likely illegal and held a press conference to make the point. The mayor fought organizers for months, but finally, in September, he surprised everyone by announcing that the Smart Streetlight sensors and networks would be turned off until an ordinance was created to oversee the surveillance technologies run by the city. </p>\n<p>In November 2020, a year after the campaign began, the Council unanimously approved the oversight ordinance. The ordinance makes visible technologies that usually operate out of public view, mounted on light poles and cop cars, or running in the circuits and servers of hardware, software, and data brokerages. It slows down technology acquisition and gives communities time to learn and organize resistance. It puts community members with negative experiences of surveillance in a role where they can build knowledge about technologies and educate others. Though some argue that such ordinances create legitimacy for surveillance technologies, they also create a mechanism for people to organize refusal where there currently is none. </p>\n<p>But ordinances like these are not a panacea. They are tools for struggle and refusal, but do not guarantee resistance to surveillance. Without vigilant organizing, including alliances with technologists and elected officials, even community advisory boards may rubber stamp policies and legitimize surveillance technologies. This struggle also shows how cities do not control the technology of companies they contract with. As the coalition in San Diego worked to get the ordinance passed, it put the fear in city council members by explaining how the NYPD lost control of its data to Palantir. Then, the same thing happened to San Diego. With defunding, the city lost access to the streetlights’ surveillance feed. But the cameras continue to record. GE sold off the streetlight network to another company, which sold it to a Florida-based firm called Ubicquia. Ubicquia refuses to stop recording even though the city can no longer access the data. But even this did not stop the police from removing the camera and harddrive in one case to access and share the video. </p>\n<p>Paradoxically, it was the process of organizing for the ordinance that strengthened the coalition’s political capacity to challenge emerging surveillance technologies. By political capacity, we mean relationships among community members who trust one another, can teach each other, and can work together; we mean the time that people can spend researching, calling into council, occupying the mayor’s office, strategizing, and running educational forums. More people means more time spent doing these things, and more relationships with people who will get involved in the movement. </p>\n<p>In advocating for the ordinance, Irani and Alexander talked to a wide range of people, from anti-racism activists to former soldiers. Each person had different reasons to fear surveillance. People who showed up out of fear of big tech or privacy violations also learned about the criminalization of marginalized San Diegans. Anti-criminalization activists learned a lot about technology and its potential role in further entrenching the carceral state. Many of the people engaged by the coalition took their first steps from awareness to action. But the coalition’s work to resist and refuse mass surveillance doesn’t end with the ordinance. It begins in earnest once the ordinance is in place.</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Tue, 25 Jan 2022 15:06:23 +0000</pubDate>\n    </item>\n    <item>\n        <title>(dis)Info Studies: André Brock, Jr. on Why People Do What They Do on the Internet</title>\n        <link>https://logicmag.io/beacons/dis-info-studies-andre-brock-jr</link>\n        <guid>https://logicmag.io/beacons/dis-info-studies-andre-brock-jr</guid>\n        <description>\n            <![CDATA[\n                <p>A conversation about the unholy trinity of whiteness, modernity, and capitalism.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ André Brock, Jr. ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;5M89ssCTXGEbxf3J4jGCyA&#x2F;a6103a504d21ea4d51a89bd16d1ef31c&#x2F;dis-info-studies.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p>The Black internet has a long history. It has multiple points of origin, as Charlton McIlwain has documented—from Afronet, a BBS network for Black users, to NetNoir, an AOL-based portal “devoted to Afrocentric material,” both of which launched in the mid-1990s. Today, the Black internet has entered the platform era, distributing its riches across Twitter and Instagram and YouTube.</p>\n<p>What would it mean to take the Black internet seriously? What would it mean to see Black digital practices (in all their diversity) not in pathological terms—as hailing from the wrong side of a “digital divide”—but as creative, joyful, affirming? What if the Black internet offers a standpoint from which the rest of the internet can be seen, and critiqued, more clearly?</p>\n<p>These are some of the questions that guide the work of André Brock, Jr., associate professor of Black Digital Studies at Georgia Institute of Technology and the author of <i>Distributed Blackness: African American Cybercultures</i>. In his work, Brock uses a methodology that he calls “critical technocultural discourse analysis” (CTDA). “It decenters the Western deficit perspective on minority technology use to instead prioritize the epistemological standpoint of underrepresented groups of technology users,” he writes, with the aim of conducting “a holistic analysis of an information technology artifact and its practices.” In other words, CTDA asks, why do people do what they do on the internet—especially when “people” are not just white, cis, heteronormative men? Central to CTDA is the idea of the “libidinal economy,” which originates with Freud, was further developed by the French philosopher Jean-François Lyotard, and has more recently been taken up by Fred Moten, Frank B. Wilderson III, and other Black thinkers. A libidinal-economic approach emphasizes the role of emotional and psychological intensities in driving anti-Blackness, rather than the more rationalist models of human behavior derived from political-economic approaches. Issue editor J. Khadijah Abdurahman sat down with Brock to trace the history of disinformation from Reconstruction to the present, and to discuss “the unholy trinity of whiteness, modernity, and capitalism.”</p>\n<hr />\n<p><b>How do you see the state of mis/disinformation research? What do you think is missing from the conversation? </b></p>\n<p>Disinformation is only perceived as bad when it serves to disrupt the interests of whiteness and white power. White power sounds strong, but it fits. During Reconstruction, the country found all sorts of creative ways to keep black folk from the polls, up to and including murder. That wasn’t a problem. Du Bois documented this extensively in <i>Black Reconstruction</i>, but misinformation against non-whites is typically a footnote in history texts and media reports as it serves the telos of American democracy.</p>\n<p>Similarly, when disinformation campaigns began to surface in the mid-2000s around Gamergate—or troll farms attacking Black Lives Matter activists—that wasn’t considered worthy of research. We still don’t have great academic research on Crystal Johnson and Blacktivist—two large internet troll farm campaigns that were trying to convince Black folk not to vote. What we do have, however, is a plethora of highly funded research incorporating both quantitative and computational evidence of how disinformation has affected white voters. </p>\n<p>For example, reporting on the 2016 presidential election first framed voters as having economic anxiety. They weren’t white—they were <i>economically anxious</i>. Then folk began to find out that economics wasn’t necessarily the cause they were rallying around. They were rallying around xenophobia, anti-intellectualism, and anti-big government. All those are things that white folk are concerned about. Misinformation research is largely conducted by white folk, and their concerns reify this anxiety about the disruptive power of social media and mass media against the interests of white folk. </p>\n<p><b>The object of inquiry of disinformation research has largely been whiteness and white anxiety. Maybe that reflects the classism of disinformation researchers, who are probably mostly trust-fund babies or the partners of people who work in Big Tech. They’re concerned with these “rabble-rousing” and “ignorant” white folks. The emphasis on QAnon is fascinating to me: it’s taken such a god-like center stage in much of the disinformation research. </b></p>\n<p><b>Reporting on Black vaccine hesitancy has focused on the Tuskegee experiment. Leaving aside the fact that Tuskegee was the complete inverse of what we’re seeing with the Covid-19 vaccine—in that it was an experiment where treatment for syphilis was </b><b><i>withheld</i></b><b>, or that the racial disparities in Covid-19 vaccination rates primarily reflects availability and access, not hesitancy—the reporting has omitted how many of the pandemic conspiracy theories circulating in Black communities are tied to anti-Semitic conspiracy theories. </b></p>\n<p><b>Do you remember that right in the beginning of the shelter-in-place orders, Nick Cannon came out repeating anti-Semitic shit from Farrakhan about the caucusoids descending from the mountains? Then Viacom suspended his show. Busta Rhymes came out and said something that was anti-vax in August 2021, echoing conspiracy theories from Milton William Cooper’s </b><b><i>Behold a Pale Horse</i></b><b>. The way that book in particular has had a chokehold on the Black entertainment industry is well known in our community. Yet it’s nowhere to be found in this academic discourse of rationality, universality, and mis/disinformation. </b></p>\n<p>Disinformation technologizes and scrubs movements of their xenophobic and racist antecedents to say they represent strictly an information misbehavior. Not a cultural misbehavior. That’s part of the problem. If you scrub racism and xenophobia from disinformation campaigns, what you have is what they would like to say: an attempt to overthrow a government through illegitimate means. But what if you add back in the racism? The better antecedent for QAnon is the John Birch Society, but that’s seen as too explicitly racist. </p>\n<p>Black folk have contended with internal disinformation forever. Busta is part of the the Five-Percent Nation, which has had a deep hold on New York rap forever, in terms of coercing patriarchal gender roles and influencing Black relationships to the state. But that was just Black folk being crazy, right? </p>\n<p>If you add back in the racism, it adds an entirely powerful libidinal element, in the sense that QAnoners are not overthrowing the government because it was <i>working for white people</i>, they’re overthrowing the government because <i>they felt that it was working too hard to entitle Black and brown folk</i>. Working too hard to give them things to which these white folk feel they don’t deserve. It’s an entitlement culture: we don’t want to give them things. We want them to learn how to work for it. That’s been an anti-Black statement since the 1860s. As soon as we got free, they were like, “Oh, well, these n***** don’t work. They’re lazy. We had to beat them in order to get them to work.” </p>\n<p>That libidinal economy of the digital seeks to continually restrict information transfer and exchange as an instrumental mode. And by that I mean, it’s strictly the message that’s being communicated, not any of the things which animate that message. So, for the libidinal economy of the <i>digital</i>, we look at <i>productive</i>. We look at <i>efficient</i>. We look at <i>time and space-spanning</i>, right? We look at collapsing traditional order in order to impose modern order. We look at “just in time” manufacturing, which now we understand is a huge problem because corporations sought to “reduce inefficiencies” like merchandise sitting in warehouses or eliminating jobs to demonstrate productivity to Wall Street. As a result we have empty shelves, halted production, and inflation now, but also higher levels of inequality and stress in the decades leading up to this moment.</p>\n<h1><b>Believing in Digital Divides</b></h1>\n<p><b>I want to just scroll back to the other question about disinformation for a second. There’s this obsession with how </b><b><i>other</i></b><b> people behave and what </b><b><i>their</i></b><b> beliefs are. This white, cis, heteronormative, middle-class idea that spaces are not “diverse enough” demonstrates to me how homogenous academic and media spaces are. </b></p>\n<p><b>I used to do a lot of restaurant work. You’d be working in the back of the house with this dude who’s forty-five from Bangladesh, somebody else who is undocumented from Russia, a seventeen-year-old washing dishes who only speaks Spanish, and then you’re serving these white customers. So, really, it’s the class of people being served who has a more insular view of the world, not the people in the back of the house—yet that’s the class we’re getting research from. The disinformation discourse is very abstracted away from the conditions, beliefs, and societies it seeks to describe. </b></p>\n<p><b>When I think about disinformation campaigns, I also think about the digital divide, one of the biggest trends in pathologizing Black people’s relationship to technology. Where’s the space to turn ethnography backwards, </b><b><i>onto</i></b><b> a field that has gotten a lot wrong?</b></p>\n<p>The digital divide stuff has shifted to “information communication technology for development,” or ICT4D. They’re looking at Africa, India, Pakistan, and other places, and saying, “They don’t have the same type of networks we have in the West. So, of course, they’re struggling to access the resources that we take for granted.” It’s just as problematic as it was when they were looking at Black folk here in the States because, like you said, it never turns the gaze around to ask what created these conditions. How and why do these conditions continue to persist? Instead, let’s be liberal and only look at the ways people will either resist or are hailed by these particular technological systems in a way that disadvantages them. </p>\n<p><b>As the president of the </b><b><i>Distributed Blackness: African American Cybercultures</i></b><b> stan club, the two main contributions of your book are, in my view, Critical Technocultural Discourse Analysis (CTDA) as a process through which to understand these technologies, and the importance of the libidinal economy. This largely seems to have gone unaccepted within the dominant research discourse. Is that your experience, or do you feel like people are engaging with your approach? </b></p>\n<p><i>[Ed.: The idea of “libidinal economy” originates with Freud, was further developed by the French philosopher Jean-François Lyotard, and more recently has been taken up by Frank B. Wilderson III, Fred Moten, and other Black thinkers. It emphasizes that emotional intensities, such as desire or antiblackness, drive “rational self interest” or political-economic modes of thinking.] </i></p>\n<p>The libidinal approach is still too new. I don’t have the impact on social science research yet because I’m still talking about Black people. That’s my mistake. I didn’t try to claim white people are bad. That wasn’t my concern. My concern was to say, “Look at how <i>joyous</i> Black people are,” which is a very different thing. </p>\n<p>I have to give a talk to Microsoft in a month and they’re like, “Well, can you present your book in a way that makes it palatable to white people?” Nah, I can’t. And it’s not going to happen because you need to learn about me as opposed to learning what I do to resist you, which are two totally different things.</p>\n<p>Data science and information science have long been and will continue to be resistant to theories like libidinal economy, but also to theories like critical race theory, because they are resistant to things which are not <i>of them</i>. They think about things which they can reach out and fix, like ethics. Or reach out and bring in, like the digital divide stuff. But they don’t ever want to engage with the question of how they benefit from certain structures, or how to fix the problems they’ve created. They don’t want to do that.</p>\n<p>So the libidinal economy has a ways to go. I’m really enthused by the uptake that it’s gotten among critical academics like yourself. Somebody said to me in my DMs the other day that it gives you a framework for understanding exactly what was going on, because we didn’t have words for it before. But white folks will always say racism is not in their heart—which is their own libidinal economy, right? They’ll never be encouraged to take it up, because to do so requires that they interrogate themselves and that’s not going to happen. </p>\n<p><b>Do you think Twitter is an accurate gauge for the Discourse™️? Do you have a sense of what readings are driving the adherence to rationalism? </b></p>\n<p>Twitter really is a space where people who don’t read books want to argue with people who write books. That’s tech too, right? I had these students coming through my classes at Georgia Tech who said, “We don’t read this kind of thing. They just tell us to make stuff. They train us how to make it. They’re not asking us to think about it.”</p>\n<p>Those are the people that Georgia Tech sends into Google, Amazon, Microsoft, and Netflix. The people who are trained not to think about things. Lewis Mumford talked about this not on a racial basis, but on a technical basis. He called it “techno-rationalism,” and he said no manufacturer wants a person who has a tendency to engage in anthropomorphic, quasi-rational thinking about the industry that we inhabit. They don’t want anybody to personalize it, because why would you personalize something that’s based on extraction?</p>\n<p>The only emotion that they valorize is the one where you don’t have a reaction to your extraction. That’s the way we train STEM graduates, and engineers specifically. Then they hear ethics and they’re like, “Oh yeah, I took a course on ethics.” Well, how many courses did you take in your program? Seventeen? I mean, of course you took an ethics class. How do you put critical race theory on top of that? How do you put the libidinal economy on top of that? The whole curriculum is designed not to introduce them to things about the world, much less critical texts. But that’s whiteness. It’s what Charles Mills calls “an epistemology of ignorance.” If they are born not to know, they don’t ever have to interrogate the conditions which led them to their success, because all they have to do is bask in the profit and the privilege. Oh, and enforce the denial of those profits and privileges to people who don’t look like them. </p>\n<p><b>To put it another way, part of my question about libidinal economy is: what is the why of rationality?</b></p>\n<p>Let me ask you a different question. Why has Marxism been taken up so strongly by information science and technology people, but not critical race theory? </p>\n<p><b>I know your resistance to political economy and I understand it to a degree. I don’t know if I read enough information science or things that are self-identified in that category to speak confidently about it. But, I’ll say, Ruha Benjamin put together her collection </b><b><i>Captivating Technology: Race, Carceral Technoscience, and Liberatory Imagination in Everyday Life </i></b><b>with scholars who are arguably taking up Black Marxism and the Black radical tradition, including R. Joshua Scannell and Andrea Miller, in a way that I find productive. I wouldn’t claim it’s critical race theory per se, but they’re definitely thinking with scholars like Katherine McKittrick and Sylvia Wynter when they’re writing about drones, for example. The end goal is not to be like, “Aaah, apocalypse coming, all the Black people gon’ die because drones is coming.” </b></p>\n<p><b>There is an evacuated critical race theory where people will cite Crenshaw, Lorde, and the Combahee River Collective—in that order—and have read none of them, understand none of them, and they’re just referencing in order to #decolonize for corporate diversity—</b></p>\n<p>—to just check off the boxes. </p>\n<h1><b>The Unholy Trinity</b></h1>\n<p><b>To me, there’s a connection between the epistemology of ignorance, philistinism or the refusal to read, whiteness, and techno-rationalism because, like you said, there are seventeen courses. There’s one week of ethics, sure—but those seventeen courses were about race too, in their refusal to address it as an explicit object, right?</b></p>\n<p>And not race broadly speaking, but white supremacy as a desire to control the nonwhite world and the natural world. I’ve been reading some good stuff recently, McKittrick specifically, and she writes about whiteness’ desire to control the world in hierarchical ways—to categorize it so that it can be placed in a hierarchy. That’s much more modernity than it is whiteness. But they’re hard to separate. You have the holy trinity, or the unholy trinity, of whiteness, modernity, and capitalism. Modernity wants to take us away from our folkways and traditions and make us more efficient and, as such, it extracts us from humans to numbers. Capitalism is like, “<i>Word</i>, because if we extract these people from their humanity, we can then exploit them for profit.” And then whiteness is like, “<i>Say, word</i>, because I was ready to extract these n***** anyway!”</p>\n<p>So, they all work together in concert and it’s really hard to untangle them. Which is the point of the libidinal economy for me, because it goes past modernity’s desire for numerical extraction and capital’s desire for labor. The strongest political economy critiques address capitalism’s desire to exploit humanity, the world, and its resources for profit. The libidinal economy goes past that to say, “Hey, there’s something about whiteness here.” There’s something <i>specifically</i> about anti-Blackness, because we could talk about China and Africa, right? China is not white. They don’t think of themselves as white. They do think of themselves as a sovereign in the world order and are intent on imposing their way of thinking about the world on the world. So, you see them making loans to African nations where they retain property rights over the properties they develop. And the African nations basically just get to host it. They get a little change from which they can skim off, you know, to make their families rich. But China <i>owns</i> all of that and, by extension, they are exploiting and extracting from the natural resources of the continent, for their own game. Is that anti-Black? Absolutely. Is that white? </p>\n<p><b>Well, it’s Han nationalist. I mean, the Uyghurs aren’t the only ones who aren’t Han. </b></p>\n<p>Right, the Uyghurs are not the only ones who aren’t Han. The entire country is made up of multiple ethnic minorities, but it’s strange how the Muslim ones get singled out for that. </p>\n<p><b>Well, also, I would like to abolish the word ethnicity.</b></p>\n<p>Noooo… [whimpers]</p>\n<p><b>No, the term ethnicity must die. You don’t understand, for us sitting in relationship to Ethiopia, they say ethnicity with a hard R. What really is an ethnic group? No, so I’m telling you straight up, Amhara supremacists, they’ll be like, “All those ethnic, ethno-nationalists, all this tribalism…” This is how they refer to Black Indigenous land claims because they want this universal category of Black that is defined by state-based nationalism, in a way that circumvents their own complicity in a system that produces benefit for them at the expense of the vast majority of people, in the wake of the slavery and colonization that happen in Ethiopia. And so, what is an ethnicity? Because the claims that you can make as an ethnic group are very different from the claims that you make as a nation. The former hails a kind of parochialism that I think is different. </b></p>\n<p>The reason why I want to hold on to ethnicity partially is that’s where I got my definition of race from for <i>Distributed Blackness</i>. I fell in love with the sociological explanation of ethnicity. In relationship to Quebec, Everett Cherrington Hughes said ethnicity is <i>not</i> a pattern of traits or behaviors that you can assign to a particular group. Instead, it’s what both the in-group and the outgroup agree that the in-group says does, believes, and behaves. So, it’s a discursive definition and, from there, I feel like it’s important we get the understanding that no ethnicity exists in isolation. It’s always in response to cultural, environmental, geographic, and political factors around them. </p>\n<p>So, China is really trying to do the political work of saying there are no ethnicities here, “We’re all one China.” But we can look back at the Freedmen here in Oklahoma who are fighting to be considered part of the Cherokee ethnic group because they got that oil money, and the Cherokee are like, “No, we’re going to go to science and say, ‘You’re not genetically Cherokee, you can’t get this money.’” But the Freedmen are like, “We were raised with you. We have children with you. We have ancestors with you. Therefore, we are part of this culture.” And that difference to me—between race and ethnicity—<i>that</i> is the really tricky thing. It’s always slippery, right? But it’s a boundary that I think makes sense in our world of signifying and meaning. </p>\n<p><b>I would say the same exact thing in my explanation of why the term ethnicity must die. The thing is, the work “ethnicity” does in America is perhaps different than in other parts of the world. The most contention is around the category of Hispanic, when they have you fill out demographic forms around race and the options presented are Hispanic or Black—what the fuck is Hispanic? Who agreed to even be from Spain? </b></p>\n<h1><b>What to do about Logic (and Kevin)?</b></h1>\n<p><b>Shout out to </b><b><i>Logic</i></b><b>. I’m appreciative that they let me hijack this shit, right? But I’ve definitely been thinking about what it means to hijack </b><b><i>Logic</i></b><b>, because “logic” has been so central to the dominant critique of mis/disinformation—that these ignorant, economically anxious white actors are illogical. They’re not pledging allegiance to science and are undermining the Enlightenment rationality that we fought for, that our forefathers fought for—though maybe they shouldn’t have committed genocide against Indigenous people and enslave the Blacks along the way. But they say, “We recognize that, we make an acknowledgment of past harm,” and now let’s focus on logic. So, how do we intervene in the context of this way of thinking about logic, enlightenment, and rationality? </b></p>\n<p>The best thing we can do is establish the validity of alternative epistemological standpoints. What I mean when I say that is that every culture approaches their version of reality differently. Whether it’s geographic, whether it’s genetic, whether it’s environmental, whether it’s political—they all approach it differently. And for the last five or six hundred years, we’ve been forced to endure a world that is structured by a white disavowal of their own embodied consciousness, disdain for women, and anti-Black racism. Those three things are the pillars of what whiteness is, so rationality is a disavowal of not just feelings but also a disavowal of the role that women have in the decision-making process, because women under rationality are considered hysterical. </p>\n<p>If you take women out of the decision-making process, you basically get the thoughts of white men. Under whiteness, white men are valued for their ability to resist their dark desires, their empathy, and their care, because they’re making “unemotional” decisions about how to apportion resources. That comes <i>directly</i> back into the data science that we’re arguing with and about, because, to them, the most elegant code is the code that is beautiful in its simplicity and its aesthetic minimalism. The most elegant code also does things to social situations that seem as if they are situations devoid of emotional resonance. </p>\n<p>So we could talk about social welfare algorithms where people are now being asked to fill out entire questionnaires about what type of toothpaste they use, because their answer to that question will be put into a database and used to calculate that they are not deserving of welfare benefits because they have too good a taste in toothpaste. How dare you have sensitive teeth? You don’t deserve Sensodyne, you better go get you some Arm &amp; Hammer toothpaste for a dollar! So it’s this continual asceticism, this denial of the pleasures, or even the denial of the experience of the visceral, of the libidinal. That is one of the core functions of whiteness. </p>\n<p>One of the most interesting trends during the early stages of the pandemic was that African countries were not experiencing Covid-19 at the same rates as white Western nations. And it turns out that it was because these folk, since they had lived with chronic deadly diseases for centuries, had built up protocols for infection control strategies. And there are other examples where people are doing fantastic things for themselves, of themselves, by themselves that are not beholden to a Western paradigm. </p>\n<p>But, to go back to an American context, how are we supposed to gain control over these information resources in order to institute a different epistemological standpoint? Because one of the other things that whiteness is good at is <i>denying</i> access to those resources, so that we can achieve—I hate the word sovereignty—some sort of valence of being part of this nation.</p>\n<p>One of the slickest things that I’ve seen over the last thirty years is how good conservative movements are at taking terms like woke and critical race theory, stripping them of all meaning, and then getting them used against us. That interpretive flexibility, I would argue, is whiteness’s greatest resource. And it works well for the libidinal economy of information because the digital itself is flexible. It can promote pieces of information in a way that strips them of their context and makes it seem like they’re universal, when, in actuality, they’re very particular. So whiteness and information technology work well hand-in-hand. Maybe by design. What would a Wakandan information technology look like? </p>\n<p><b>Could you talk a little about what you mean when you say that </b><b><i>Distributed Blackness </i></b><b>proposes a Morrisonian approach to technology? </b></p>\n<p>That’s Ruha Benjamin’s fault. Ruha interviewed me, and at the end of the conversation, she said, “This is a <i>Morrisonian</i> approach to information technology.” I was like, “What you mean? That’s too big. I can’t take that.” She’s like, “No, if you think about <i>Playing in the Dark</i>, where Morrison spends a lot of time in the first couple of chapters talking about ‘American Africanism,’ or a white identity premised on a negative, inverse relationship with Blackness. You’re making that same conversation—not about literature, but about technology.” </p>\n<p>What I’m trying to do is establish what Black people have always done. We have always had to watch the other carefully in order to not get eaten by the other or destroyed by the other. We have to know their ways. We have to know how they work and, in the process, from that outside perspective, what we do is we build a Black inquiry on an analysis of <i>invention</i>—because what’s more invented than whiteness? They made themselves up out of English, German, Italian, Dutch, Norwegian. They made themselves into this category called white—that’s an invention like a mothafucka’, right? But in the process of doing so, they had to center that invention against a Black body in order to make it legible. </p>\n<p>Charles Mills says Blackness is illumination. Y’all been telling us that we need to illuminate what Blackness is for y’all. But Blackness actually illuminates what modernity is. And that’s where I sit. I use my epistemological standpoint, my positionality in and of the world, to critique the world that brought me into being—that’s Morrison. If you think about <i>Sula</i>, if you think about <i>The Bluest Eye</i>, those are all positions, those are all texts interrogating the world from a particular standpoint that has already been destroyed or attempted to be destroyed. </p>\n<p>That shit is powerful to me. It’s not a position of abjectness. I’m not saying, “Oh, I’m on the other side of the digital divide and I’m trying to cross that bridge.” No, I peeped that bridge and it doesn’t take me anywhere that’s really necessary for me to go. And let me tell you how fucked up it was, what you did while you was tearing down the ecosystem and destroying the land, and destroying the people who owned that land before you, in order to make this bridge happen so that you could be more efficient and not have to go all the way around to the ford to ship your goods. </p>\n<p>So a Morrisonian approach—an American Africanism—is shorthand for basically saying, from this standpoint, from where you stand on the margins of white society, but in your fullness as a Black person (because Blackness is human, regardless of what Afro-pessimists say), what critiques have you made or can you make about whiteness and the world that whiteness has created? A shit-ton, a lot, right? And they’re critiques that white folk are not capable of making because this is their utopia. For all that they complain about it, this is the world that they wanted, the world that they got. </p>\n<p>Man, that look on your face. I’d pay money for that. </p>\n<p><b>So, where we at? Where do we locate this Black sense of place when we know that information science is already so dominated by whiteness? Where do we just stand still and where do we act? We got McKittrick writing </b><b><i>Dear Science and Other Stories</i></b><b>, Ruha Benjamin’s multiple books, and Simone Browne’s </b><b><i>Dark Matters</i></b><b>. But, on the whole, where is the Black study folk at? </b></p>\n<p>Black studies has not concerned itself with science in any real way. Black studies is more focused on the interpretation of texts, film, video, music, and the like. They have not focused on science at all. You have some historians who have done amazing work, but in general Black studies don’t care. </p>\n<p>What McKittrick does that’s really valuable is she talks passionately about how we understand ourselves not grounded in the ways the world told us we should be, but how we understand ourselves as what Black people do. She said Black knowing is feeling, and I was like, “You motherfucking right,” because there’s something about that embodied cognition. When the world is inflicted upon your body, then you listen to what your body says when it’s trying to tell you about the world. </p>\n<p>We lack the means of control or even dominance in these tech industries. The best we can do is get an interest convergence with well-meaning white people (WMWPs) and liberal folk to at least trouble their understandings of what the world they’re creating is—whether that’s Black feminist epistemology, whether that’s intersectionality, whether that’s critical race theory, any of those things, right? If we can get them to understand that the harms that they visit upon us are also inadvertently visited upon their children and their grandparents, then we’ll get some action. The problem is we created industries full of white men who don’t care about their momma. Have you seen the movie <i>We Need to Talk About Kevin? </i></p>\n<p><b>Yes.</b></p>\n<p>That’s the type of industry we’ve created right now. “I wonder what this bow and arrow will do? Oh, I’m sorry, Dad, I didn’t mean to kill them with it.” </p>\n<p>We’ve got three white men fighting to get higher into the low Earth orbit—not even in fucking space, just far enough from the planet so they can float. And their aims are celebrated by the mainstream press because they’re visions of a future where they can escape Blackness. As opposed to dealing with the harms that they’ve created with just-in-time manufacturing and two-day shipping and this surveillance culture that they have fostered under the guise of friendship and community. They don’t want to address those harms because those harms have made them a <i>shit ton of money.</i> </p>\n<p>Facebook is a good example. My students always grimace when I say the best way to understand Facebook is that it was a creation of a horny nineteen-year-old with more computing skills than social skills, and this was a way he could get to meet, in the abstract, the women he wanted to be with. Because that’s what Facebook was. It was a network that he built where people would submit pictures of themselves and he could select them at his leisure without them knowing that he was looking at them. Once you start from that understanding, Facebook’s extraction of personal data and sales to advertisers makes a lot more sense. It never has been about community. You can see how poorly they understand community with the way they moderate and run Facebook groups. It always has been about the extraction of something to satisfy the libidinal, whether it’s voyeurism or simply wanting to profit off of others.</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Tue, 18 Jan 2022 15:57:51 +0000</pubDate>\n    </item>\n    <item>\n        <title>Technologies of Black Freedoms: Calling On Black Studies Scholars, with SA Smythe</title>\n        <link>https://logicmag.io/beacons/technologies-of-black-freedoms-calling-on-black-studies-scholars-with-sa</link>\n        <guid>https://logicmag.io/beacons/technologies-of-black-freedoms-calling-on-black-studies-scholars-with-sa</guid>\n        <description>\n            <![CDATA[\n                <p>Refusing to see like a state.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ SA Smythe ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;2rcLO0Hd82IV05sG3NnfsA&#x2F;73cb02a3958b18d8f8827ce52ad30614&#x2F;Technologies_of_Black_Freedoms.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p><i>There’s been an increasing recognition of how racial regimes are mediated by digital technologies, particularly through things like computational policing practices that target communities of color and automated hiring platforms that exacerbate employment discrimination. But so far, the discourse about “algorithmic bias” largely treats race as an aftermath of technology, as a downstream effect. Further, it treats race as a problem—race is the way you add up the bad things that technology does to people. Race is a way to measure harm. </i></p>\n<p><i>Both premises need to be challenged. Racial regimes aren’t downstream of technology—they’re present from the very start. They centrally shape the design, development, and deployment of the computational systems that govern our lives. And the obsession with calculating race as a function of harmful impact institutionalizes Black people as objects of suffering without agency or political subjectivity that extends beyond advocating for social remedy. </i></p>\n<p><i>To overcome the limitations of the algorithmic bias discourse, we need to ask a completely different set of questions about technology, drawing on the traditions of black thought and black freedom-dreaming. To help formulate these questions, and begin to sketch some possible answers, issue editor J. Khadijah Abdurahman talked with SA Smythe, an assistant professor in the Gender Studies and African American Studies departments at UCLA. Smythe is a poet, translator, and scholar of black European literary and cultural studies and Black trans poetics, and is deeply invested in the coalitional project of black life, black study, and relishing nonbinary experiences across the diaspora. Abdurahman talked to Smythe about abolition organizing on Turtle Island, statecraft as reproduced in humanitarian technologies, and orienting toward “otherwise possibility.”</i></p>\n<p><i></i></p>\n<p><b>The joke I always make is that techno-capitalism puts people who have never taken the humanities in charge of humanity. In that vein, the driving motivation behind </b><i>Beacons</i><b> is thinking about how we “call in” Black studies and abolitionist organizers into this technology discourse. Even as I say that, I want to be careful to not reify technology as the property of white, cisgender male tech bros straight outta Silicon Valley because we are all already using, interacting, and modifying techniques and technologies all the time, right? </b></p>\n<p>This time that we are asymmetrically experiencing has been intense and overwhelming due to the convergence of so-called “crises,” which are of course interrelated. So, I’m really grateful to be taking up those questions in this format. I’ve felt insecure about how to jump in and have a conversation about “tech” even though it’s so pervasive and is foundational to much of our relationship to modern life/modernity. How do we think about technologies as various techniques, tools, or modalities for collective liberation or for black freedoms? How do we get humanists and humanities adjacent folks—especially people who engage in various black radical traditions and Black feminist practices—to think more urgently about Technology in the capital T sense? I’m not quite sure, but the invitation is key. Of course, as we’ve talked about this ongoing invitation, with scholars like Simone Browne, Katherine McKittrick, Safiya Noble, and Ruha Benjamin, plus many of the other folks in this issue who have been working against “algorithms of oppression,” data, and technologies of liberation through a Black feminist lens for some time—you’ve reminded me to answer and amplify this call.</p>\n<p>I’m thinking about the movement and solidarity work that I joined in the wake of the ongoing Covid-19 pandemic and global Black rebellions in the summer of 2020. For the Cops Off Campus Coalition organizing both regionally and locally across Turtle Island, 95 percent of our convening, strategizing, and public campaigning was unthinkable without Zoom, Google Hangouts, or Skype, and apps like Cryptee, Google Docs, Canva, and Lucidchart, inviting one another to amplify our campaigns and build shared demands across different time zones to mobilize people and share resources. This was of course true for the Black Abolition Futures political education group and political organizing spaces in Europe that I was able to re-enter while physically in the US. It’s challenging, trying to think about what we need to imagine liberation tools and technologies beyond our current capacities, particularly when we’re in movement work or, like you, directly confronting these questions of technology on a day to day basis, and considering what otherwise can materially mean and how to bring that to bear in our present. </p>\n<p>When we’re inundated with technologies perceived to be “our only hope” à la <i>Star Wars</i>, where that’s the last chance that we’ve got to get ourselves free; that’s where I think we need to take a second to pause and double down on an acknowledgment: that this is precisely the time where we must mobilize for something else beyond our current capacities. This is when I orient towards the replenishable resource of <i>otherwise possibility</i>, a framing I first came across in the work of Ashon Crawley. Anyone telling you that new technological expansion is our last chance, that there’s no other way, or that this is the easiest path if you want to do the work that you’ve set out to do, I think we all need to reflect and think about our intentions, aspirations, and who among us is really out of time. What options do we have access to or must create?</p>\n<h1><b>Smaller Scales and The Digital Sea</b></h1>\n<p><b>What stands out to me is the idea of </b><b><i>thinkability</i></b><b>. Mariame Kaba says this a lot in reference to abolition. You know, that organizers worked for a very, very long time. And you know, organizers, including incarcerated people and people who were formerly incarcerated, right? Because sometimes there’s a weird binary—the organizer becomes the one who is separate from incarcerated people. But they work to make the idea of abolition </b><b><i>thinkable</i></b><b>, something that people, in a decentralized way, practice in their own lives and in their own scholarship. </b></p>\n<p><b>When we’re thinking about tech, the idea that you need to be a Black Girl who Codes or have mastered JavaScript and HTML in order to enter into the conversation is hegemonic. On top of that, the kind of digital environments you mentioned relying on in your organization work for Cops Off Campus are so default, that it is very hard to even think about what a different wave would look like. </b></p>\n<p>Exactly this. And I’m thinking about scale—digital, corporeal, and geopolitical scale all entwined together. While holding the need for global political revolution and exchange, I wonder if we might make the scales smaller and have the kind of impact on the ground that might lead toward a shift in digital space. So to put it more concretely: What’s really great about certain kinds of mutual aid is that I can send money to someone right now in Senegal or in Tahiti. It’ll get there roughly at the same time. But I wonder what this means in terms of rapid gentrification and displacement and dispossession of Black, brown, and indigenous peoples. I’m wondering about the capacity for a digital that is the people’s right, belonging to the people on a smaller scale, and without western attachments to property. </p>\n<p>What would that look like—if that’s even a useful way to start thinking about it—so that it’s not governed or even governable by a large scale, monolithic, usually evil enterprise? On a smaller scale, say you live in apartment 5B and you need a babysitter, one of your kids has an ear infection. You have to run out and go take care of them real quick. You can’t bring the other kids with you because that will be too hard to manage alone. Is someone available in the building right now to babysit? It would be cool to think from smaller scale mutual interdependence that abolitionists talk a lot about, that doesn’t look like TaskRabbit, that doesn’t feed into the gig economy which provides care as service for compensation independent of human, communal investment and accountability. </p>\n<p>One instance that comes to mind is the Watch the Med Alarm Phone project, a self-organized hotline for refugees in distress in the Mediterranean Sea. For example, if you arrive at the Port of Tripoli in Libya and join a voyage attempting to cross the Mediterranean into Europe but the boat capsizes or something goes wrong, you could call the hotline which would then point rescue operations to your relative location and come to your aid. </p>\n<p>On the one hand, this is a project on a relatively small scale, which is unfortunate in this case because it should be the work of governments whose borders are leading to catastrophe. As Harsha Walia says, the border is the crisis. But you know, government neglect is what it is. There are no real mechanisms then, digital or otherwise, that are consistent and hold the community of those rendered refugees or asylum seekers making that treacherous journey. </p>\n<p>The ephemera of the large-scale digital space has made it such that, at the end of the task, of the act, there is nothing, you fall off of the cliff from support after the GoFundMe gets circulated. The lives are anonymized and lost in these spaces while we do the (to be clear, very necessary) work of redistributing wealth to the oppressed, away from the Global North, etc. So, I’m wondering what would happen if the digital realm (which feels to me really large and nebulous, like a sea in its own right) can come down to a smaller scale such that we can collectively navigate our way through. Or does that seem idealistic in a non-useful way, because someone will need to administer it and technology is not value neutral in terms of how it produces and exacerbates material asymmetry? </p>\n<p><b>I’m just pausing to think, because I’m like, “both and neither.” Both in the sense that yes, I think that we do need to find better relationships to administer mutual aid or social support through digital infrastructures. I’m not a nihilist or saying, “Cash App is corrupt,” therefore die slow. I think that it is what it is and we have to help our people. I’ve also been in situations, in my own life, where I needed people to help me. I’m not going to be so dogmatic to the point that I’m saying, “Now you are complicit with capitalism because you have a wage and you’re going to send it to me on this commercial app.” But, I guess the “neither” part is recognizing how these apps are infrastructure and are controlling us as populations. I mean, it’s not so linear like that. I think about the algorithmic flagging of fraudulent transactions resulting in any money being sent to Palestinians on these platforms being suspended and frozen without recourse.</b></p>\n<p><b>We are in a situation where we must have mutual aid. We must send money back home. We must send money to Texas when the state has failed to take care of people. But in that must, we’re relying on these apps or these infrastructures that were designed not in service of us. Not to produce that livability, right? So how do we think about whether there is something qualitatively new manifesting in these technologies? What is new about predictive policing? Before the prediction, policing was still bad, still needed to be abolished, right? Is it just automating that same practice or is something different happening? I think about Virginia Eubanks’ comparison between the 20th century brick-and-mortar poorhouse and the present day digital poorhouse that is using algorithms. She emphasizes how the former geographically co-located Eastern European immigrants and Black Americans together—which some argue laid the ground for the Poor People’s Movement—as compared to the algorithmic sorting of the digital poorhouse which preempts that kind of cross racial solidarity or physical proximity. I feel like the way political subjectivities are formed in relationship to a state’s (often concealed) control of people’s movement through space is a theme of your work on Blackness and migration. Are there connections that you’re making in thinking about these examples?</b></p>\n<p>That’s really helpful. I love examples since I really appreciate having something to hold on to. Your question about this distinction makes me think of Cedric Robinson’s concept of racial regimes—that which does not want to be revealed, but by the very nature of its revelation, speaks the truth about the mutability of racial representations as historically uncertain. This is why the system of racial capitalism and the flourishing of white supremacy is specifically one of the things that pretends it does not exist, that there is no hand there building on pre-existing cultural forms with new technologies that emerge to retrench those processes. In this way, “new” technology hides the original intent and how those aims differentially structure our realities.</p>\n<p>Last month, when Facebook apps all went down—a possible distraction from the testimony of the company’s whistleblower Frances Haugen before the US Senate—I felt this regime acutely. I was trying to help support planning and get information about my grandfather’s funeral in Jamaica, and I couldn’t reach any of my relatives in the Caribbean and across the diaspora, who all use WhatsApp as the primary mode of communication. For a lot of my family, like millions across the Global South, staying in touch internationally is far too expensive over landlines, and VoIP services like WhatsApp have filled this need. During the temporary crash, I couldn’t figure out how to send money to them. I couldn’t figure out where they were physically so that I could then try to find out which cousin or which uncle or family friend or local pastor had a landline that I could attempt to reach. At that moment, I realized WhatsApp, owned by Facebook, was completely determining my ability to connect with my family, to grieve and support and organize my community in real time, with material consequences.</p>\n<p>That’s just one personal example among millions, not even just in this particular incident, but consistently and recklessly when we think of, for example, Black trans sex workers being suppressed by the algorithms of most mainstream platforms. While OnlyFans began to ramp up this same suppression that Instagram did, taking down photos that have Cash App links on them, pop stars on the same apps, wearing similar amounts of clothing, are being promoted widely on all of our screens.</p>\n<h1><b>Fourteen Ninety-Two</b></h1>\n<p><b>My impression is that black study hasn’t taken up technology as a primary site of analysis. Do you see an opportunity for scholars like yourself to intervene in the discourse of techno-capitalism and liberation? </b></p>\n<p>Black studies folks who are not already invested in thinking through technology as an instrument of capitalism should get on board because, as I mentioned, we’re already thinking about things like racial regimes, hidden infrastructures, and what they do to our material conditions and the ability to survive, thrive, and resist. Bedour Alagraa’s work becomes really key to my thinking on this and so many other things when she talks about catastrophe, the “changing same<i>,” </i>and the retrenchment of shared articulations of our dispossession. </p>\n<p>First of all, we need to acknowledge that, right? Acknowledge that fact—that this is a different era, but it is an extension from the deadly worldmaking event of 1492 into what we’re perceiving as our present day. And so there are all of these different kinds of work that Black studies scholars are doing to think about the revelations of the coercive organization of our daily lives, conceiving of how we can even begin to think about resisting, about liberation, about freedom dreaming. I’m convinced it’s really important and the intersections are increasingly being laid bare during this phase of neoliberal late stage capitalism. </p>\n<p>What I’m trying to hold onto is precisely the ephemeral understanding that “now is not working.” What we’re knowing as “the now”—the conditions of Western oriented or ontologically Western Space-Time—is not working. And actually, we’ve been in the same moment since 1492. So one of the ways it’s not working is that we think it’s 2021 and that has consistent material implications. On the internet people are like, “It’s 2021. We shouldn’t be saying this joke anymore,” or “How is this still happening and it’s 2021?” And I’m like, this is because we never left 1492. We’re playing ourselves by thinking that the clock being offered to us is actually any measure of a real shift in the time that we (and by “we” I mean black people—Africa and its diasporas) have been hailed into—and even indoctrinated within—to be making these kinds of statements. To think <i>otherwise</i> is calling for a real kind of rupture from the status quo keeping us unfree. I’m talking myself into a bit of a circle because of that “both/and” that’s required, and because I would never say, “Well, no computers for anyone and so I can’t Venmo you some money for your urgent care.” Or like, now I don’t support Facebook, and I delete all of my little apps, so I can’t message my auntie in Trelawney or uncles in the mountains in Jamaica, can’t participate in mutual aid for Black trans kin, sex workers, and migrants in communities that I’m no longer physically living near but still accountable to? We need both.</p>\n<p>Breathing into <i>otherwise possibility</i> is to me a fundamental, ontological, ahistorical rupture—in the sense of capital “H” history being a Western epistemological framework. It is a total divestment from the current world order. That means that the way that we can organize ourselves (or we even dream about organizing ourselves) in relation to one another is actionable and realizable; not fixed, but possible and dynamic. </p>\n<p>I don’t think that enough of us are entertaining the possibility, because of a false binary where it’s like, “Well, I need to survive.” And I’m thinking that part of this survival is <i>orienting to this otherwise</i>—it’s not seeing your survival as just the next meal or where’s the next paycheck. That gets really hard to narrate without sounding like you’re just swimming in privilege, completely oblivious to the material conditions of people who <i>need</i> to know where the next check is coming from or how they can get together for that next meal. </p>\n<p>I find myself sort of trapped by my own seductions, by my own desires for us to collectively orient ourselves to a thing without sounding like I’m oblivious and not aware of what people need—to be, to <i>literally exist</i>. But also understanding that the current order and the current perceptions of an allegedly discrete and separate catastrophe or of some kind of linear arc toward something—as opposed to spinning the wheels, “the changing same” and a deep retrenchment or acceleration of accumulation by dispossession and being asymmetrically displaced—is not it.</p>\n<h1><b>Moving Beyond The State</b></h1>\n<p><b>I keep bringing up how algorithms are hegemonic, bringing to scale the movement of people through space and producing new kinds of divisions through classifying and sorting people. Because predictive policing is not just about expanding forms of community surveillance, it’s also a labor management tool. We see in welfare, automated decision systems are producing and managing resource scarcity, and then managing those subjectivities. Sometimes this is enacted in a very broad and decentralized way, and sometimes in an intensely violent way that is neither unclear nor metaphorical. From any given vantage point, we cannot see everything, so we need that multiplicity of perspectives. </b></p>\n<p><b>It’s well documented that predictive policing relies on dirty data sets embedded with the historic overrepresentation of Black and houseless people, thereby redirecting the police to the same geographic sites they’ve always over-policed. What Stop LAPD Spying Coalition and Free Radicals uniquely identified in their Algorithmic Ecology project, was that PredPol was not actually classifying the Skid Row residents as high risk, which is what the traditional argument of dirty data would lead us to believe. Rather than labeling the Skid Row encampments as “hot spots,” PredPol is classifying the </b><b><i>perimeters</i></b><b> of Skid Row as high risk. In practice, this means that the moment residents tried to move past these otherwise invisible borders, they would encounter higher rates of arrest and police contact. If the LAPD announced a brick-and-mortar wall was to be built as a border around Skid Row, people would riot, right? Academic researchers who primarily rely on privacy rights to critique these technologies eschew the collective or communal harms that resonate with people who are targeted. I worry that residents of Skid Row, abolitionist organizers, and others may disengage from resisting these technologies when it’s rendered unclear how the stakes are much greater than data privacy. </b></p>\n<p><b>Even if we can understand Black Marxism from Cedric Robinson and are engaged with Bedour around not just rearticulating the same modes of catastrophe, crisis, and linear march through history, we’re still not in the refugee camp. I’m not reifying standpoint epistemology, but literally we don’t have access to everything, even at this moment where massive amounts of content is constantly being produced, right? I’m thinking about this “not knowing” alongside the United Nations High Commissioner for Refugees (UNHCR) Special Rapporteur Philip Alston’s report on Human Rights Violations in the United States in 2017. Examining the coordinated housing entry system in L.A., he emphasized that experimentation with public sector adoption of automated decision systems happens on the most marginalized sections of society before being generalized to the rest of the population. We can trace policies mandating fingerprinting for welfare recipients during the Clinton era to Simone Browne’s seminal book, </b><b><i>Dark Matters</i></b><b>, explicating the proto-biometrics of the Middle Passage in the ledgers and branding of enslaved Black peoples. </b></p>\n<p><b>So, some of these technologies have </b><b><i>been</i></b><b> the situation—and at the same time as recognizing that historic lineage or sameness, we have to recognize what’s different in these new forms of surveillance and social control as they are being enacted onto broader swaths of the population. </b></p>\n<p><b>In tech, to a degree there is a sociopolitical critical analysis, it often coalesces around bias. When you get to geopolicy, the discourse becomes very reliant on statecraft and state terminology because states </b><b><i>actually</i></b><b> have an analysis of society. They </b><b><i>actually</i></b><b> have a sense of who different actors are and, in a vacuum of political or theoretical frameworks, state actors are ascending. What stands out to me so much in your work is a rejection of state terminology, particularly as I’m thinking about my family in Oromia in the southern region of Ethiopia and observing how advocates are making moral appeals to the UN or to the US State Department. Human Rights Watch branded a recent report on Eritrean refugees in Tigray with a satellite image from Maxar Technologies. This just stood out to me so much—not that I want to hearken back to the old days of the ’83 famine where they just put starving, nameless black people on the cover—but because this bird’s eye view that renders people into polygons, if they’re even seen at all, and even then it only allows for people to be seen en masse, there is no humanity within it. What does belonging mean in that context? Similar to WhatsApp, many people will justify use of satellite imagery citing it as the sole source of gathering visual evidence during a crisis.</b></p>\n<p>Neither of us is here to defend the ivory tower, <i>but</i> this is why we need black study. And I’m using that term the way Robin D.G. Kelley points us to, as distinct from Black studies. So not Black Studies™ as a hegemonic and ethnonationalist interdisciplinary framework that was heavily funded by the government, by the State, namely through the Ford Foundation from the discipline’s institutionalization in the Sixties. But black study as the deeply invested commitment to black people, black life, black possibility, and freedom dreaming, beyond institutions and in fact under siege by them. Collectively attending to black study would have us asking a very different set of questions, and perhaps being prepared to bring about very different answers. </p>\n<p>This premise about evidence and evidencing is something that black study has taught me to challenge and expose the underlying perceptions of. What am I understanding when we talk about this bird’s eye/drone’s eye/God’s eye perspective is a view of people rendered non-people. That framing is borne from a visual technology that James Scott describes in <i>Seeing Like a State</i>. In managing how and who we’re seeing, this particular apparatus instigates us into a certain organized affect, initiates into a socially reproduced hierarchy—this is effectively what citizenship, nationalism, and patriotism do.</p>\n<p>A patriot sees a flag burning and they are moved to defend the nation, as opposed to seeing a piece of cloth that they can walk over in the street, right? And that’s because of what it means to belong to the state. You might feel it as an extension of yourself as opposed to what it is, which is the other way around. And so, I think, that thinking with black study, thinking with Black thought, would actually have us question: What does it mean when we’re seeing non-people? What does it say about us if images of the oppressed masses are disseminated, and when we encounter them we can then go, “Oh, I get it, it’s really bad there.” Technologies of seeing and the epistemologies they are informed by need to be interrogated so that when we engage in movement work and defend our communities, we are not benefitting statecraft or reproducing an asymmetrical and oppressive world order.</p>\n<p>Sometimes I feel increasingly militant about not reproducing certain images as evidence because, I mean, we’ve all seen them, right? Black people drowned at sea, black people’s bodies washed up on shore or left out in the street for hours as in the case of Michael Brown and countless others, dozens of black people on, what I guess what passes for a boat with an infrastructure than cannot safely cross the Mediterranean, whose image gets printed on the cover of <i>The Telegraph</i> with the language of “the swarm” with an action shot of black people fleeing in Haiti or in Sudan. We know what gets made to matter and how. Black study reminds us whose narratives, whose stories have weight and amplifies the work that needs to be done without trafficking in the antiblack violence of dehumanizing erasure.</p>\n<p>In the campaign leading up to Brexit, there were these massive billboards of black people crowded and stacked on a road and referred to as swarms—distinctly animal and non-human language for people fleeing conditions that Britain and other imperial formations have historically wrought. The images featured migrant crossing routes in places like Afghanistan and Libya, but they were being used in the middle of the UK so that people could see it and go, “Oh, that’s what’s happening here, they’re coming across our border, encroaching on our lands.” It was falling into the mind of the white citizen subject being like, “This is happening here,” or “It has already happened here.” Sight as a visual technology, as a mechanism, is already being used and abused in ways that need to be interrogated. </p>\n<p>What I know from black study, and what I’ve experienced in my embodiment as a Black trans person and in solidarity with disability rights activists, is that seeing is not always believing, and to interrogate the privileges of sight. What you take through a visual medium and how you privilege that sense is rarely a tool for our liberation. So what then do we rely on instead? </p>\n<p>And so for me, the kind of belonging that I hail, in relation to our collective liberation, tries to make that pivot. If not, you and I belong to this nation state because we look similar or we sound similar, because we speak the same language, because we have certain kinds of perceived proximities that the state has organized us into. Instead, we can belong to a different set of commitments wherein I don’t need to visually see your suffering to actually acknowledge it. We can actually orient toward one another and the life we want to lead, so that it’s not born through a series of documents, either visual or textual in statistics, the way that the UNHCR also does, the way throughout Europe, or the way that Frontex manages us and the International Office of Migration also enumerates. Quite simply, it’s an orientation in which we collectively understand that statistics also codify our existence and extract our humanity.</p>\n<p>I don’t need to “see” evidence of the Oromo Genocide or see dead people up and down Ethiopia to know that we need to mobilize a collective response to the violence there. I have friends from Ethiopia. I have people who are in a place, telling me something is happening, and I know that they’re committed to their and our collective freedoms. So I don’t need to know that fourty-five Ethiopians were murdered today or ten or twenty or a hundred. I actually don’t need to quantify that severe loss with numbers and not names or lives or memories if I already understand that the ongoing colonial and imperial illogics are producing a reality deeper than a mere number. We don’t need to fall into the same traps of enumeration, quantification, and extraction for us to bear witness. Yet again, there is a “both/and” there, too. I understand why there are the petitions, I understand the enumerations, I understand the visualizing of these things, but I also find it to be a trap of visibility and representation, because then we’re not belonging to each other. We’re not trying to collectively belong to a possible <i>otherwise</i>. We’re actually belonging <i>into</i> the same metrics of statecraft that are causing our harm to begin with.</p>\n<p><b>A hundred percent. I don’t know if you self-identify as a group, but what I have specifically learned from you, Zoé Samudzi, and Bedour Alagraa is thinking critically about visual documentation and the desire of the audience to see or experience this sadistic yet orgiastic enjoyment of black suffering. This desire is both dehumanizing and demands bodies, which is not the same. I also appreciate your demand to distinguish black life and black bodies versus “myself.”</b></p>\n<p><b>We’re rejecting statecraft while sitting in the west and as diaspora. So I’m also thinking about people who are incarcerated or who are living in zones with an intensity of unrelenting violence, what does it mean for them to reject technologies of statecraft? What is </b><b><i>otherwise</i></b><b> for them? Going back to that Philip Alston point, you know, humanitarian technology is a site of pervasive experimentation. On one level, I appreciate that the UN is so transparent; they actually state in their internal documents something along the lines of “Thank God, unlike the EU, we don’t have GDPR, so we can experiment on these populations and try out these new things before they get generalized to everyone else.” How do we resist being brought into the only kind of relation remaining when we only see back home through a documentation of the suffering by NGOs or other humanitarian bodies, which does not allow for a kind of belonging with refugees or those categorized as “internally displaced?” How can we learn from and be in community with them when technologies of the state have become the throughway?</b></p>\n<p>I’m thinking right now of a really dope book, Eric Stanley’s <i>Atmospheres of Violence: Structuring Antagonism and the Trans/Queer Ungovernable</i>. Eric thinks a lot with Black trans feminists, as well as with Angela Davis, about what it means to become ungovernable. </p>\n<p>When I used to do work in relation to the UK border with migrant women in detention centers, with a greater physical number of people, we could get heard and things could get done. We could mobilize to stop planes—like those small European detention flights. We could shut shit down in this very material way responding to immediate political and physical needs.</p>\n<p>Part of my reticence with technology is with the sleekness and the smoothness of a user experience across platforms, which doesn’t map onto the beautiful incoherence of human subjectivity. There’s increased regulation in how we present ourselves online. Through this, we’re becoming increasingly governable. One thing to consider is actual revolution, which Fanon and many others have taught us is not pretty, not consistent. It’s not an isolated march or rally. I mean, it’s machetes, it’s fires. It’s ongoing violent struggle meeting the violence we’ve (asymmetrically) been subjected to, that we should think about turning to <i>yesterday</i>, already. I know that because of the global structures that we’ve been slated into and the ways that we relate and the things that we would already have to be giving up, revolution across the world holds different weight. I’m trying to be careful as I’m saying things, but it is something that I think a lot about: what is required and how do we prepare?</p>\n<p>And I’m thinking about how not to just think about it, but to be about it. How do we actually mobilize in the long game while our life spans are being shortened in real time, while being heavily surveilled and coercively governed, while a lot of our communities are being dispossessed and displaced in real time, and when ecological disasters and climate catastrophe means some of us are already out of time? And, here you go, I try not to talk myself out of the very answers that I think are really what’s to come, are really hard to break open and leap out of—in that Fanonian sense—out of the current world order toward some otherwise one. </p>\n<h1><b>Registering Gender</b></h1>\n<p><b>The discussion around gender that I have been exposed to feels very bureaucratic. Particularly, I’ve been thinking about being “assigned at birth.” Do you identify with the gender that you’re assigned at birth? From my understanding, this has to do with birth certificates. Ethiopia actually has one of the lowest rates of birth registration in the world. Most people don’t even get birth registration until they get their passport if they’re going to leave the country. But it’s something like 1.2-1.3 percent of all children acquire birth registration, even among the middle class. </b></p>\n<p><b>As I went down this Google rabbit hole, I was like, “Yo, this is dope,” because when you’re talking about black methodologies, of misspokenness and the broken pieces, this is the complete opposite of digital surveillance. </b><b><i>Everything</i></b><b> is about enumerating, I mean, talk about counting—that is the fundamental ontological principle, and it’s really disturbed when people do not participate in birth registration for statistical regimes. I don’t want to romanticize these small acts of bureaucratic refusal or present them as active political commitments to abolishing the gender binary. There definitely is homophobia and transphobia in Ethiopia—I don’t even know how much those words completely translate, not just the literal sexual translation, but in the way that people conceive of gender. I don’t want to make it sound like Ethiopia is in any way a paragon of sexual freedom or gender identity inclusiveness, but at the same time, there is a way that everything is not so linear. So as this gender binary is being enacted onto people through institutions, bureaucracies, and technologies, people are refusing it in different kinds of ways. How do we make sense of that, not just in relationship to resistance, but between each other? What does it mean to think about gender when there is not that same assigning?</b></p>\n<p>Gender is nothing if not bureaucratic. Gender is nothing if not a series of accruals and assignations on a global scale. But, and, also, there’s something to really delight in, I think, in terms of a refusal that doesn’t look binary. I’ve had conversations where it’s just like, “Look at all this gender. Gender comes from the West, so let’s say ‘no’ to gender, right?” And so it’s supposed to be a rejection outright. But the queer and trans people that I know and delight in and struggle with, we can relish our gender too, as well as our relationship to it. </p>\n<p>Let’s put it this way: gender is a series of attachments, much like belonging—which is probably why this relates to your question. So technology, perhaps if I can try to make a real quick but rough analogy, not as a process or a series of mechanisms through which you manage labor, bodies, time, and all of these sorts of constructs, but actually as a way of deepening attachments. I’d like to think of “trans” when I think about transnational politics and even transdisciplinary scholarship as a moving across borders drawing from how trans theorist Eva Hayward talks about trans being a series of attachments and modes of relating as opposed to across, because grammatically, trans is supposed to be across and then cis would be on the same side. Instead of crossing a border or staying on the same side of a border, of gender, of geography, and so on, it could instead be a series of attachments to that very <i>otherwise</i> set of possibilities that we’re trying to mobilize.</p>\n<p>To go back to your concrete example with the Ethiopian birth certificates, I think it’s a super cool note to end on, right, because you actually are talking about possibility. No, of course you’re not saying, “Ethiopia is the trans friendliest place on Earth” or whatever. But by nature of these minor refusals that accumulate into a set of possibilities, then we have possibilities there, right? Like 1.2 percent is nothing to sniff at. So now if I wanted to play with my gender or what I understood or perceived to be gender, away from this kind of assignation, and I’m a trans Ethiopian or a person who is—and there are different words to talk about gender variance in different geographical contexts—then I can make some room, make something else possible for myself. And so I can use the very refusal that the masses are enacting to make room for myself. </p>\n<p>And then when I’m carving up that space, because how we identify, and how we are identified is always already relational, then I’m making room for an “us” to thrive in that refusal. Again, I think that is linked to the becoming ungovernable that Stanley talks about, the moving in the wake of interminable catastrophe that Alagraa talks about, the thinking away from sort of genocidal politics of enumeration that Samudzi talks about. These are circulating conversations that black study has made, that precisely can be situated in thinking about technology. Now we’ve moved beyond “just” tech, and also to technologies of refusal and how to make those possibilities endure. </p>\n<hr />\n<p><i>A note to the reader from SA Smythe: In response to decades of Black resistance in the US, many publishers have adopted a “house style” where “Black” is capitalized when referring to Black Americans/USians. This conversation was initially recorded and then edited, but SA Smythe spoke with us about the distinction between Black/black in terms of the larger African diaspora and the continent, and what capitalization gestures toward for/as Western grammar. When referring to Black USians explicitly, they usually capitalize the word in response to those important struggles and conventions of naming. Transnationally, the debates/struggles around that aren’t consistent, and thus Smythe considers it useful to be mindful about making those conventions hegemonic from the US, and what that means for collective, global black liberation. For this reason, global black struggles outside of the US, black study (independent from the interdiscipline of Black Studies), etc., are not capitalized in this interview. As La Marr Jurelle Bruce once tweeted: “As long as you’re writing and uttering the word ‘B/black’ with love and toward liberation, we’re good.” That’s the spirit through which this conversation was held.</i></p>\n        ]]>\n        </content:encoded>\n        <pubDate>Tue, 11 Jan 2022 15:08:14 +0000</pubDate>\n    </item>\n    <item>\n        <title>A Body of Work That Cannot Be Ignored</title>\n        <link>https://logicmag.io/beacons/a-body-of-work-that-cannot-be-ignored</link>\n        <guid>https://logicmag.io/beacons/a-body-of-work-that-cannot-be-ignored</guid>\n        <description>\n            <![CDATA[\n                <p>What does it mean to “Get Out!” in the twenty-first century? How do we build fugitive technologies?</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ J. Khadijah Abdurahman ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;13ugtp5R8o8BHsWCX8nVUJ&#x2F;64e372a32471f59f8f8850fbd0ae652a&#x2F;Screen_Shot_2021-12-06_at_10.13.13_AM.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p><b>1/</b></p>\n<p>In June 1945, a committee chaired by the physicist James Franck raised the alarm about the Manhattan Project’s development of nuclear weapons. The document they produced, known as the Franck Report, urged President Truman not to use the atomic bomb against Japan. Instead, Truman should demonstrate the bomb’s destructive power by dropping it on a desert or a barren island—or he should try to keep the bomb’s existence secret for as long as possible. Otherwise, the scientists warned, a global nuclear arms race would ensue, with catastrophic consequences for the planet.</p>\n<p>The authors of the Franck Report had worked on the Manhattan Project. But rather than siphon the scientific knowledge they had accrued in developing nuclear weapons out of the lab and into the commons in order to build a mass movement, they waited until the final hour to pen a letter, addressed to a government that would never heed their call. The scientists understood the stakes of nuclear weapons better than anyone. But in making a moral appeal to the American empire, they demonstrated a profound misunderstanding of the social and political context the technology was developed in service of. Two months after they wrote the report, atomic bombs were dropped on Hiroshima and Nagasaki.</p>\n<p>I was reminded of those physicists in December 2020, in the wake of Google’s high-profile termination of AI ethics scholar Timnit Gebru. Her firing was the final step in management’s systematic silencing of her scholarship, which came to a head over a paper she coauthored called “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” The paper offers a damning critique of the energy demands and ecological costs of the sorts of large language models that are core to Google’s business, as well as how those models reproduce white supremacy—and codify dominant languages as default while expediting the erasure of marginalized languages. Thousands of Google workers, as well as supporters throughout academia, industry, and civil society, rapidly mobilized in defense of Gebru, writing an open letter to Google executives that demanded both her reinstatement and an apology for the egregious treatment she received. </p>\n<p>Like the Franck Report before it, however, this open letter represented a grave misunderstanding of the politics of AI and was in no way commensurate with the threat we face. The technologies being developed at companies like Google present major stakes for all of humanity, just as the invention of nuclear weapons did in the previous century. They are strengthening concentrations of power, deepening existing hierarchies, and accelerating the ecological crisis. More specifically, big tech corporations are extracting labor, ideas, and branding from Black people, and then disposing of them with impunity—whether it’s scholars like Gebru or Amazon workers in Bessemer, Alabama organizing against plantation conditions. </p>\n<p>Racial capitalism’s roadmap for innovation is predicated on profound extraction. AI is central to this process. The next flashpoint over AI is inevitable—but our failure to respond adequately is not. Will we continue to write letters appealing to the conscience of corporations or the state? Or will we build a mass movement? As Audre Lorde said, we cannot dismantle the master’s house with the master’s tools. We cannot stop Google from being evil by uncritically relying on the G Suite tools it developed. We cannot uncritically champion the most popular among us, as if social capital will resolve the colonial entanglements reproduced in much of what passes for research in the field of technology studies. An atlas ain’t no Green Book, and we cannot afford to pretend otherwise. What we can do is to build a better analysis of the context of racial capitalism in which extractive technologies are developed. We can share knowledge about the ways in which such technologies can be refused or have their harms mitigated. We can forge solidarities among workers, tenants, and technologists to help them organize for different futures. We can light alternate beacons. </p>\n<p><b>2/</b></p>\n<p>Dismantling racial capitalism and displacing the carceral systems on which it relies requires an understanding of how technology produces “new modes of state surveillance and control,” Dorothy Roberts argues. Part of the challenge is that these new geographies of policing, regulation, and management are largely invisible. We experience the immediacy of our Amazon package being delivered without seeing the exploitative labor conditions decreasing the distance between order and arrival. This is not a function of insufficient effort—it’s an indication of how successful big tech corporations have been in concealing the sources of their power. In his essay in this issue, Julian Posada provides a detailed account of Venezeulans performing the tedious, low-paid labor of data labeling on which AI depends—labor that is hidden beneath Silicon Valley’s minimalist user interfaces and promises of automation. The circuits of racialized capital link us ever more closely together even as the pandemic has deepened our sense of alienation. </p>\n<p>Understanding how tech has reorganized labor, and developing a strategy to break free, is not easy. It cannot be done with the narrow technical training that produces computer science PhDs—the recent appending of ethics courses notwithstanding. It requires an interdisciplinary analysis in partnership with impacted people who are on the forefront of digital experimentation. There is no way around doing this work.</p>\n<p>In theory, Black study is the intellectual method and tradition that is best positioned to lead such an analysis. As SA Smythe clarifies in these pages, Black study does not mean Black Studies™ —“a hegemonic and ethnonationalist interdisciplinary framework that was heavily funded by the government” during its founding in the 1960s. Instead, drawing on the work of Robin D. G. Kelley, Smythe defines Black study as “the deeply invested commitment to Black people, Black life, Black possibility, and freedom dreaming.” </p>\n<p>The Bulletin of the Atomic Scientists was founded by former Manhattan Project scientists in 1945 after the atomic bombs were dropped on Hiroshima and Nagasaki. Its iconic doomsday clock is currently set at one hundred seconds to midnight. This reflects the risk posed to the world from nuclear weapons, climate change, and, notably, “disruptive technologies.” Black study would have us trouble this notion of catastrophe as a singular event or a state of exception. As Smythe explains, exclamations of “How is this still happening and it’s 2021?” show that we’ve been bamboozled and hoodwinked into thinking time has marched linearly forward towards modernity. Smythe insists that the reason we find ourselves in what scholar Bedour Alagraa calls “the changing same” is that we are in fact still in 1492, circling the drain of the ongoing catastrophe initiated by white contact with the “new world.” But this is not cause for despair—it’s an opportunity to ask better questions, like the one posed by Katherine McKittrick in “Mathematics Black Life”: “What if we... begin to count it all out differently?”</p>\n<p>This desperately needed intervention is constrained by the fragmented character of knowledge production. Within computer science and information studies, race is treated primarily as a social <i>consequence</i> of technology rather than <i>constitutive</i> of technology. In the six years since Simone Browne published <i>Dark Matters</i>, a seminal work tracing the links from the proto-biometrics of the Middle Passage to the present-day use of facial-recognition technology, important scholarship has emerged—including from Gebru, Ruha Benjamin, and Safiya Noble—but not at the urgency and scale with which new technologies are violently renegotiating the social contract. And although Black folks have had no choice but to survive the tools and techniques of social control, technology with a capital T has not been a central object of Black study. Similarly, abolitionist organizers have rightly disavowed technical solutions to the prison-industrial complex as reformist reforms, but have not often recognized how central technology is to intensifying the carceral state.</p>\n<p><b>3/</b></p>\n<p>What does it mean to <i>Get Out</i>! in the twenty-first century? How do we build fugitive technologies?</p>\n<p>This special issue of <i>Logic</i> does not seek to provide a totalizing narrative or singular solution. Rather, our goal is to “call in” thinkers and artists from different disciplines—for example, Black studies scholars who are engaged with notions of catastrophe but whose insights have not been yet been taken up by people investigating how technology produces catastrophe, or integrated into the resistance strategies of communities being harmed by new forms of digital experimentation. (The approach of this issue is many times over indebted to Bedour Alagraa’s thinking on “the interminable catastrophe.”) Similarly, how can computer scientists and engineers more effectively communicate to the public not just about the harmful effects of technology but about how these systems actually work and what interventions on the level of software or hardware offer a more liberatory future? </p>\n<p>We take the stakes we’re facing seriously while leaving room for our futures to not be overdetermined by white supremacy. As André Brock, Jr. discusses in these pages, our approach to technology does not need to be one of abjectness. “I’m not saying, ‘Oh, I’m on the other side of the digital divide and I’m trying to cross that bridge,’” says Brock. “No, I peeped that bridge and it doesn’t take me anywhere that’s really necessary for me to go.” While we may not offer one path forward, we hope to <i>get in the way</i> of techno-solutionism and corporate-funded initiatives that absorb the most radical elements of the discourse without actually supporting people to go do the most radical thing. Our hope for this issue is that it will be what Seeta Peña Gangadharan, coorganizer of Our Data Bodies, calls “a body of work that cannot be ignored.”</p>\n<p>I am grateful to the <i>Logic</i> team for letting me hijack their operation, to give us some space where <i>we be imagining</i>, even as the work punctures the myth embedded in the magazine’s name. We offer no singular way of knowing, no hope for messianic deliverance. We be needing <i>logics</i>. This issue is an outlet in which we can explore these logics and meaningfully argue with each other. In a recent interview, Keeanga-Yamahtta Taylor lamented the fact that “debates that exist in the left have no space to be deliberated upon. People get on social media to either ignore or insult each other’s political ideas and opinions,” she continued, “but I’m saying if we want to be impactful in building a mass movement, to shape and direct politics in this country, then something radically different needs to happen.”</p>\n<p>In this issue you’ll find Marxists, Wynterians, Black speculative fiction, poetry written inside a cage, a graphic story about internet shutdowns in Kashmir, abolitionists, and the unaffiliated. In this issue you’ll find many beacons because, like Neta Bomani’s tween zine insists, we need to move beyond <i>The Way</i>. As guest editor, I chose to curate love letters over a manifesto—because I know plans and leaders get captured or beheaded, but we can nourish an otherwise set of relations to each other while we strategize on getting free. </p>\n<p></p>\n<h1>Postscript by Ben Tarnoff</h1>\n<p></p>\n<p>One December morning in 2020, I DM’d Khadijah on Twitter. We’d never spoken before, but I’d just read a recent essay of hers, “<a href=\"https://upfromthecracks.medium.com/on-the-moral-collapse-of-ai-ethics-791cbc7df872\">On the Moral Collapse of AI Ethics</a>,” and loved it, and wanted her to contribute to <i>Logic</i>. She said she’d be in touch with some further thoughts.</p>\n<p>A couple weeks later, she followed up by email. What she really wanted to do wasn’t write a piece, she said, but edit a whole issue:</p>\n<blockquote><p><i>I’ve been thinking about concrete next steps to move beyond calling out the failure of the status quo to providing an alternate beacon for people who are looking for space to build and think critically, take risks and specifically room to think about currently under resourced domains ie tech/data policy in the global south, grassroots response beyond the right to refuse surveillance, bringing in agroecology, the core of Black studies (ie not just citations for bias but the epistemic and historical challenges being raised at the forefront of the field) etc.</i></p></blockquote>\n<p>The aspiration for the issue would be to create “alternate beacons”—that is, to present new ways of thinking about and living with technology, drawn in particular from Black thinkers and practitioners, with the hope of moving beyond critique (as much as we love critique) and toward imagining new worlds. It felt perfect for us. I brought the idea back to the <i>Logic</i> group, who shared my enthusiasm. Soon after, I connected Khadijah to our managing editor Alex Blasdel, and the two of them embarked on the long and labor-intensive task of making this issue.</p>\n<p>Why did <i>Logic</i> decide to undertake this collaboration? I don’t presume to speak for the magazine as a whole—<i>Logic</i> is very much a collective venture, of which I am only one part—but I think it’s because Khadijah was giving us a way to evolve, to find new pathways for our project, now in its fifth year.</p>\n<p>A lot has changed since we launched <i>Logic</i> in early 2017. One of our main motivations was our contempt for popular writing about technology. In the manifesto that led our first issue, we announced that “most tech writing is shallow and pointless.” In the intervening years, however, this statement has become less defensible. As the “techlash” has bloomed, the discourse has become immeasurably more sophisticated. There is now very good reporting about the industry and, with some exceptions, tech criticism as a whole has become less idiotic, more tethered to fact.</p>\n<p>But not everything has changed. Despite the greater sense of clarity and concern, a lawyerly liberalism continues to dominate, and domesticate, the political conversation about tech. Some years back I attended a conference in which a fairly prominent tech policy person said that the best way to solve the various problems underlined by the techlash would be to put all of the “smartest people” from industry, government, and academia into one room and have them figure it out. All that was needed was the right constellation of experts, in other words.</p>\n<p>So <i>Logic</i> still has work to do. The techlash has altered the terrain, but wherever there is power there is a court, and every court has its courtiers. The new common sense is much like the old; techno-utopianism may have fallen out of fashion, but technocracy of one kind or another is harder to eradicate. The techlash has served as a mass credentialing event for a new class of experts, as “AI ethics,” “responsible innovation,” and similar pursuits attract significant funding and visibility. Many of these experts do interesting work, and everyone needs to eat, but the overall arrangement in which they participate can’t help but reiterate the logic of technocracy.</p>\n<p>What’s missing from this arrangement is the people whose lives are being reordered by technology—or, more precisely, by a particular set of practices as structured and mediated by technology. What’s missing is a view of technology <i>from below</i>, as it is encountered and experienced by living and breathing human beings. There are both epistemological and political stakes here. The feminist philosopher Nancy Hartsock once argued that systems of domination can only be fully understood from the standpoint of those they dominate, an insight she drew from Marx (only proletarians can obtain a complete view of class society) and applied to gender (only women can obtain a complete view of patriarchy). We can extend her argument further, and say that today’s technological regimes are most accurately perceived from the standpoint of those they oppress, exploit, and exclude. And this perception is to be acquired not simply for its own sake, but rather in the service of a broader political project of liberation, as it was for Hartsock and Marx. To see technology from below is also to develop the knowledge needed to govern it from below. Every cook can govern, C. L. R James reminds us, and the internet would undoubtedly be a better place if it were governed by more cooks (and fewer lawyers).</p>\n<p>This is the spirit that animates the issue that Khadijah has curated. In these pages we see technology through the eyes of sex workers and click workers, of the incarcerated and the disabled. And while there is much injustice, there is also hope, creativity, and joy. There is the great imaginative power of the Black freedom struggle and the Black radical tradition. We are not led to any single set of conclusions and we never arrive at a final orthodoxy. Some circles on the left have long believed that orthodoxy is what makes revolutions. But revolutions are notoriously irregular affairs; their combustion derives from the diversity of their inputs, which interact in unpredictable ways. “The rise of a group of people is not a simultaneous shift of the whole mass,” W. E. B. Du Bois observed, “it is a continuous differentiation of individuals with inner strife and differences of opinion, so that individuals, groups and classes begin to appear seeking higher levels, groping for better ways, uniting with other likeminded bodies and movements.” This issue attempts to seek some of those higher levels and grope for some of those better ways, to do the right kinds of searching and struggle. <i>Logic</i> will do its best to keep lighting beacons in the years ahead.</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Mon, 13 Dec 2021 14:33:52 +0000</pubDate>\n    </item>\n    <item>\n        <title>The Immune Sequence</title>\n        <link>https://logicmag.io/kids/the-immune-sequence</link>\n        <guid>https://logicmag.io/kids/the-immune-sequence</guid>\n        <description>\n            <![CDATA[\n                <p>On the dangers of chasing childhood purity.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Hannah Zeavin ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;2MF6jtejQrCODvVAkq7WVM&#x2F;78d1d9c2fb64e9e1afa06effccfa3b88&#x2F;immune-sequence.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p>A faceless, soft doll in red or blue; a wooden rattle; a mirror; kinetic sand; a rainbow silk scarf. For many families, this particular genre of children’s toy—often sold on Etsy, via targeted ads, or through subscription kits—may arrive benignly and incidentally into a child’s repertoire of plastic dolls, metal trucks, and rubber balls. But for other parents and their families, they are part of a larger system: an elaborate pedagogy meant to steer every aspect of a child’s life—including diet, environment, and even play. In these philosophies—popularized by “alternative” schools such as Montessori, Reggio Emilia, and Waldorf—such whimsical recreation is also a tool of parental control prescribed to ward off an ultimate threat: technology. </p>\n<p>Today, “alternative” schools, which focus on “hands-on” learning and spiritual development, are largely considered niche options reserved for the very wealthy—although their reach quietly extends far beyond Silicon Valley and Park Slope. In pop culture, they may most commonly be recognized as the tech-free schools where eBay’s CTO and other Valley executives send their kids, supposedly driven by esoteric knowledge about the threat of the products their companies make. (Knowledge which, as scholar Morgan Ames has pointed out, doesn’t actually exist.) It’s more likely that these parents are anxious over a question faced by most parents today: What exactly does technology do to our children, and how do we protect them from it? </p>\n<p>Parents’ individual answers to that question fall on a spectrum. Some, in the words of child icon Elsa, simply “let it go,” allowing tech to be a much-needed parenting aid. Others champion ameliorating measures, from limiting screen time, to delaying cell phone ownership, to using parental controls on the TV. But for a subset of parents, like many of those who employ “alternative” schooling, the answer is tech refusal—banishing it altogether. And where this kind of adamancy is present, other extreme politics often lurk just out of view. Such is the case with Waldorf and its underlying philosophy, a longer history of which reveals ideological ties to fascistic thought and racial hierarchies.</p>\n<p>Although it represents one extreme, the roots of this niche pedagogy can help us understand the whole spectrum of anxiety when it comes to technology and parenting. Particularly, its history makes clear how the quietly interlocking panics surrounding the technologies of screens and vaccines connect to dangerous notions of purity; ideas that—just as wooden toys tend to appear in ordinary homes—have often made their way into the mainstream, mostly unnoticed. </p>\n<h1><b>Stagnant Souls</b></h1>\n<p>In 1919—against the backdrop of the Spanish Flu, countless political uprisings, and the aftermath of World War I—Rudolf Steiner founded the first Waldorf School, located in Stuttgart, Germany. Having grown up as the son of a railway worker, Steiner’s childhood had been shaped by the violent rise of modernity, and he was determined to save future children from the same fate. Intended as a school for the children of the workers at the Waldorf-Astoria cigarette factory, two-thirds of the students were children of factory workers; the last third were children of Steiner followers.</p>\n<p>By that time, Steiner had gained prominence as the charismatic leader of an occultist movement he called “Anthroposophy,” underpinned by an original, esoteric philosophy replete with a comprehensive theory of reincarnation, spirit worlds, and higher realms. Waldorf was Steiner’s translation of Anthroposophy into pedagogy—down to the curricula and classroom design. It was, in essence, a pedagogical laboratory for an alternative spiritual life, one imagined as free from modernity while tied intimately to its labors and afflictions. </p>\n<p>The Steiner model, or “Waldorf schooling” as it became more commonly known, in part preserved traditional education in the present to safeguard it for the future; students spent time outdoors to learn from nature and worked on handicrafts. But it also used approaches that were archaic even for the time: children were categorized into supposedly preordained temperaments based on the typology of humors (phlegmatic, melancholic, sanguine, choleric) that had fallen out of the medical canon centuries prior. </p>\n<p>A system of guided movement called “Eurythmy” also played a large role in this counter-training, not just as physical education, but as medico-spiritual intervention to care palliatively for the kids. In that first year of the school, students likely would have practiced a specific pattern from Steiner’s growing repertoire, which he taught widely to address the pandemic that raged outside: “The Immune Sequence.” By coordinating sound, dance, and intention, its practitioner was thought to become their best, truest self, and therefore physically immune.</p>\n<p>At the time, medical technologies and interventions, especially vaccines, were rapidly advancing. But Steiner believed that they made one “lose an urge for a spiritual life.” He argued that illness was not just the result of pathogenetic spread or due to microorganisms. There was an extra-material reason for illness to present in its host: karma. According to Steiner, not all souls were created equal. As with the temperaments of children, the wider outcomes of this life are already written by the actions in previous incarnations, which corresponded to the supposed “evolution”—or “devolution”—of race. </p>\n<p>Put bluntly, Steiner saw the white race as the race of the future—the highest form of being, the endpoint of reincarnation, and therefore the most naturally immune. Meanwhile, melanin showed the susceptibility, karmic impurity, and “stagnation” of a soul. These stagnated souls were, for Steiner, one way illness spread—to be faulted not just for their own static sickness, but that of society. The problem posed an endless feedback loop: society ruins the soul and ruined souls, in turn, degrade society. Care of the individual soul—via the body and the mind—was to be the cure, the solve, the salvation. </p>\n<p>Additional schools followed in Germany, The Netherlands, and England. Then, in 1928, the first Rudolph Steiner school opened in New York City as a private school, which still operates today. Of course, Steiner’s set of beliefs made Anthroposophy ripe for uptake in the emerging Nazi Party. Although the Nazis temporarily closed nearly all Waldorf schools in their control, many of Steiner’s followers—including his widow—had close ties to the Party, where the occultist-karmic philosophy was taken up, both strategically and in deeper belief: both systems of thought worked to bring the world into “harmony” and achieve “regeneration.” </p>\n<p>Today, the connections (and disconnections) between Nazism, fascism, and this spiritual science are somewhat of an academic debate. According to the historical scholarship of Peter Staudenmaier, much of Steiner’s works and literatures were “cleaned up” to delete mentions of race when translated into English. That’s mostly how the ideas are implemented today: While every Waldorf school differs slightly, Steiner’s initial approach remains largely intact—from typologies, to daily Eurythmy, to anti-vax sentiment—with mentions of race simply excluded. But Steiner’s theories of illness, race, and technology all come from the same well, no matter how obscured in or by the present. His notion of the ideal child endures: The perfect kid is one who is pure. </p>\n<h1><b>Fantasies of Purity</b></h1>\n<p>And purity, it turns out, can be marketed and purchased.</p>\n<p>There are now roughly 125 Waldorf schools nationwide and more than 3,000 internationally, according to one Waldorf executive. Where Waldorf exists as an alternative, parents who see themselves as progressive—even Left—have sought it out, some in spite of larger philosophical differences or outright disbelief. “Private schools almost by definition have to craft stories that appeal to privileged strivers anxious about their children’s futures,” Morgan Ames wrote of Waldorf schools in 2019 for the <i>Los Angeles Review of Books</i>. “Some of these stories recount how their graduates’ creative brilliance was spawned in their school’s tech-free environment. Related ones ply anti-contamination themes, and fetishize the purity of childhood.” These stories frame technology as a constant threat, presenting Waldorf schools as bubbles of safety, oases within the desert of the modern. </p>\n<p>Waldorf is not alone in the pursuit of a tech-free environment. There have been many movements and philosophies that attempt to achieve purity by cutting off access to technology, specifically media, and they don’t all bend towards fascism or even apoliticality. Tech refusal looks quite different in the context of utopian projects like the back-to-the-land movement of the ’60s and other forms of communal care focused on raising children in nature, including the MOVE Family and the international “unschooling movement” of the ’70s. In the hands of the Left, the rejection of technology can be a radical act of carving out a space of resistance within capitalism and systems of repression to imagine a deeper liberation. But, following Danya Glabau in <i>Real Life</i>, “As a metaphor, purity easily translates from necessary practices to exclusionary principles.” Where the aspiration of purity becomes dangerous is when principles entail protecting one’s individual child at the <i>expense</i> of a child next door.</p>\n<p>Steiner’s adherents, whether they are “Waldorf families” or in the Anthroposophical movement, or both, subscribe to a sense of predestined exceptionalism that Laura Portwood-Stacer argues is frequently behind the rejection of media and technology—including vaccines. Such principles can lead believers and their fellow travelers to reject “herd mentality” and compromise herd immunity in the process. While Waldorf philosophy aims to protect new life from various social ills, it has become a literal incubator of viruses that, like its greater ethos, organically seep beyond its walls—whether in the case of a Waldorf school at the epicenter of a measles outbreak in New York or now, during the Covid-19 pandemic. Estimates vary, but some suggest 60 percent of Waldorf children are unvaccinated against infectious illness for which there are routine childhood vaccines. Where states grant exceptions for religious or philosophical reasons, rates of refusal are even higher. </p>\n<p>The endurance of this resistance is disquieting precisely because of the ways that this notion of purity feeds into unbridled exceptionalism—especially as it takes new, viral forms in our present. Today, 15 to 20 percent of Americans believe in some form of the QAnon conspiracy—another system of belief that, like Anthroposophy, has ties to fascism and the occult—while vaccine rejectors claim that taking the shot is antagonistic to bodily autonomy, and even argue in some cases that it causes sterilization. In turn, some vaccine rejectors are referring to their eggs or sperm as “vaccine free”—triumphantly stating that they are the <i>only</i> key to any possible reproductive future precisely because their bodies stayed pure of medical technology. These ideologies reject the basic, collective reality of modernity and late stage capitalism, as if by doing so they might manifest a different future, one that furthers the comforting—and ultimately racist—fantasy of purity. </p>\n<p>It makes sense that Steiner’s philosophies are frequently read as <i>anti</i>-modern. But perhaps this is the other side of modernity. To buy into these teachings is to search for alternative spaces within techno-culture, turning the school into a pastoral enclave that can be carried home with children in the form of rules for families and domestic space. In cherry-picking Steiner’s philosophy to exclude these other insidious forms of purity ideology, Waldorf schools have, in the words of scholar Wendy Chun, “updated to remain the same.” </p>\n<p>During our ongoing pandemic, at a Waldorf School in Upstate New York, middle schoolers and high schoolers continued to meet regularly outdoors to practice Eurythmy. According to a blog post by the school, they decided to focus on one pattern of movement to address this latest health crisis: “The Immune Sequence.”</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Wed, 1 Dec 2021 21:59:11 +0000</pubDate>\n    </item>\n    <item>\n        <title>Zoomers Versus the National Security State</title>\n        <link>https://logicmag.io/kids/zoomers-versus-the-national-security-state</link>\n        <guid>https://logicmag.io/kids/zoomers-versus-the-national-security-state</guid>\n        <description>\n            <![CDATA[\n                <p>Finding the Guantánamo that lives online.</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Muira McCammon ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;TxY5wfuo9HPOM0hLLMjii&#x2F;ff13cd3c6cb724f7c247ad7f048a8857&#x2F;zoomers-vs-national-security-state.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p>In October 2019, an op-ed in a student newspaper at the University of North Carolina at Charlotte made an allegation that rippled across campus: it claimed that the university’s administration had quietly appointed a war criminal as the new head of campus safety and security. The man, retired army colonel John Bogdan, had spent two years running the notorious detention facilities at Guantánamo Bay.</p>\n<p>The student who wrote the op-ed didn’t have to look far to find traces of Bogdan’s record. The colonel’s LinkedIn profile noted that, between 2012 and 2014, Bogdan had been “responsible for the safe and legal custody of 166 opposing force detainees.” Those detainees were young and middle-aged Muslim men who had been extrajudicially imprisoned during the so-called War on Terror. Further internet searches revealed that while Bogdan was warden of Guantánamo Bay, he had implemented a regime of intrusive genital searches, had detainees on hunger strike intravenously force fed, and had allowed guards to use rubber bullets on hunger-striking detainees. One lawyer for detainees has written that Bogdan’s Guantánamo was characterized by “displays of power for power’s sake.” Although Bogdan’s actions likely do not constitute war crimes under international law, the UNC Charlotte Chapter of the American Association of University Professors later argued that those actions “clearly violate human decency and the spirit of the Third Geneva Convention and other protocols for the treatment of prisoners.”</p>\n<p>Almost immediately, the op-ed set off a campaign to have Bogdan fired. A group of several dozen students, consisting primarily of campus Democrats and Young Democratic Socialists of America members, began searching for more evidence of what Bogdan had done at Guantánamo. They formed a group chat on GroupMe to strategize and share articles about Bogdan’s past, and a Twitter feed to publicize their discoveries and rally support. They called themselves the Coalition to Remove John Bogdan. </p>\n<p>Members of the coalition soon found themselves clashing with the university’s administration over Bogdan’s role on campus, and struggling to convince their Zoomer-generation peers—most of whom were born after 9/11 and were children during the early years of the Iraq and Afghanistan Wars—that the man who ran the Guantánamo detention center shouldn’t be the head of campus security. At the same time, the coalition members were trying to educate themselves about what had transpired in the detention facilities. In the decade after 9/11, Guantánamo was perhaps the most potent symbol of the abuses and excesses of the US national security state, but its place in the public imagination had been receding since Barack Obama’s second term in office. “I didn’t really know anything about it,” one coalition member recently told me over Zoom.</p>\n<p>The coalition members’ understanding of the base was almost entirely mediated by digital records, “Guantánamo” Google searches, Wikipedia skims, and tidbits teachers had told them along the way. But the version of Guantánamo that public schools teach and that tends to live online is very narrowly defined: a hundred-year-old naval base on forty-five square miles of US-controlled land and sea at the southeastern tip of Cuba. Though the identities and experiences of the people detained at Guantánamo have now been reported, catalogued, and even cinematized, a political and technological veil has been cast over the past and future of most former guards. The result is a Guantánamo that is always far away: the people <i>there</i> are never coming <i>here</i>, to America. </p>\n<p>That myth has made formulating the right questions about truth, justice, and the US detention center at Guantánamo Bay incredibly hard to do. Bogdan’s presence at UNC Charlotte raised exactly those questions. He was the rare exception of someone who had emerged from behind the veil.</p>\n<h1><b>A Pinpoint on Google Maps</b></h1>\n<p>Although Bogdan had listed his Guantánamo experience on his LinkedIn profile, knowledge about most of the guards that return from Guantánamo is extraordinarily hard to come by. This is largely the result of decisions made by the Pentagon, which worked for years to ensure that most guards’ identities, decisions, and actions would not be documented in public archives.</p>\n<p>The Guantánamo that emerges online tends to be a pinpoint on Google Maps, a small strip of land through which all kinds of people—private contractors, intelligence agents, soldiers, sailors, policymakers, lawyers, journalists—pass through, disappearing in discourse once they leave the base. Google Images almost inevitably turns one’s attention to the physical detention camp, too. Searches produce a checkerboard of orange jumpsuits, snapshots of current detainees, splatters of camouflage. Over the past decade, the first page of results has evolved to include photographs of protesters in the mainland US, but even those images point back to the camp: many protesters have decided that the best way to remind civilians of Gitmo’s continued existence is to dress up like detainees. In the digital archives of major US newspaper outlets, there is a parallel pattern. Almost all the photographs accompanying stories about the detention facilities show a similar montage: hurricane fencing and barbed wire; American flags and the backs of military personnel; the small, beige-colored trailers containing men deemed too dangerous for US soil. </p>\n<p>Political discourse about Guantánamo has also centered on the prison and its detainees. If the Zoomers at UNC Charlotte had looked for Guantánamo on C-SPAN.org, they would have scrolled through decades of videos of congressional representatives, national security lawyers, lieutenants, and journalists regurgitating the same five or six questions. <i>When will Guantánamo close? Where will the detainees go? What might happen to the detention facilities if they are ever emptied of people? What is it like to see Guantánamo with your own eyes? What horrors might befall America if detainees were to be housed and tried in US federal criminal courts instead of military commissions?</i></p>\n<p>Wikipedia articles about Guantánamo echo these frames, and have become repositories of contested knowledge about the detained. Footnotes include Supreme Court cases about habeas corpus petitions, links to lengthy Pentagon reports on the detention facilities, memos written by ACLU lawyers arguing for the immediate closure of the prison, and a rich archive of investigative news articles that try to detail human rights abuses at the prison. In much of this writing, the passive voice lurks in the prose, quietly obfuscating precisely who is ordering that detainees be force-fed, who is implementing groin searches, who is <i>doing</i> the detaining.</p>\n<p>Archivists, activists, and journalists have pushed against this erasure, and initiatives such as the Guantánamo Public Memory Project have endeavored to trace the lineage of the place. Reporters from some countries whose citizens have been imprisoned at Guantánamo have tried to document who did what, when, and why, and individuals released from the detention facilities have written about their experiences. Some of the most rigorous coverage of the prison is unsurprisingly written in Arabic. But language barriers have made this knowledge relatively inaccessible to English-speaking monolinguals living in the United States.</p>\n<p>Some guards have chosen to identify themselves on Twitter and other social media platforms. One even started a gym in Philly. But most keep quiet. There is no public list, no Excel spreadsheet of former guards. Instead, there is a persistent informational void about who the individual guards were, who they harmed, what ideologies motivated them, and where they went when they left the camp. Contrary to what Google Maps might show you, Guantánamo runs on the dreams and sweat and blood and logics of people like John Bogdan—former guards and wardens who are now scattered across the United States.</p>\n<h1><b>Fact Sets</b></h1>\n<p>Once wardens and guards leave Guantánamo, they tend to go quietly into the night of civilian life. The uproar over Bogdan’s appointment at UNC Charlotte was an anomaly. Members of the Coalition to Remove John Bogdan met in the GroupMe chat and in the library late at night to imagine a campus without him. They amplified their cause by tweeting and chalking the streets. In their written statements, coalition members drew heavily on reports written by Amnesty International and other organizations that had made a concerted effort to track and trace the wrongs that Bogdan’s Guantánamo had wrought. There was plenty of documentation of what was done to detainees. Reports from Human Rights Watch noted that a federal district judge had ordered Bogdan to explain a standing order that called for the use of restraint chairs during the force-feeding of detainees. But there was little information about who apart from Bogdan had been involved in doing it. </p>\n<p>It is fair to say that the administrators of UNC Charlotte did not imagine their campus would become the site of a battle over the legacy, meaning, and future of detention facilities that are over a thousand miles away. After the coalition began drawing attention to Bogdan’s alleged crimes, the university’s chancellor issued what he called a “fact set” to defend Bogdan’s reputation and employment history. But the document also went many steps further, legitimizing Guantánamo as just one of the US military’s hundreds of bases. </p>\n<p>Bogdan fought back as well. In an interview with a local reporter, he pushed the thesis that “the mission here is not far off from the military.” He declared, “The mission of the Army is to fight and win the nation’s wars. And you do that by developing a team, and teaching and growing and building the future of the nation. That’s exactly what universities do, right?” Around the same time, university administrators instructed the social media team associated with the admissions department to block the coalition on Twitter, so that prospective students were less likely to come across their arguments against the colonel.</p>\n<p>Ultimately, the coalition couldn’t translate their understanding of Guantánamo into a campaign that resonated with most of their fellow students. In part, the Zoomers had faced the challenge of teaching themselves and their peers what the military prison was and why it mattered. More importantly, perhaps, in setting out to learn about Guantánamo, they were never going to encounter examples of other struggles like theirs. In fact, there has only been one analogous case relating directly to Gitmo: since 2009, Berkeley law students have repeatedly called for the dismissal of professor John Yoo, who gained the nickname “architect of torture” for his role in justifying harsh CIA interrogation techniques deployed at Guantánamo. The students’ Google searching had led them back in time, to a period during their childhoods when Bogdan was running Guantánamo, but it brought them no closer to a blueprint for how to hold people like Bogdan accountable in the present.</p>\n<h1><b>Tindering Gitmo</b></h1>\n<p>If Guantánamo is more than a physical detention camp, if it is also a network of people and ideologies that have successfully implemented the continuous extrajudicial detention of individuals, then how can researchers, reporters, and future generations trace its contours online, and formulate questions about what justice with regard to Guantánamo might look like?</p>\n<p>In 2015, as a master’s student in comparative literature, I emailed the Joint Task Force Guantánamo, requesting to see the prison’s library. I was informed that only reporters could go, so I began a foray into freelance journalism. To go would be to see, and to see would be to understand, I told myself. Among other things, I set out to learn how the arrival of T-Mobile cell service had changed life on the naval base. I hoped I could convince US civilians that Guantánamo was not so far away—what the Bush administration had described as “the legal equivalent of outer space” was, in fact, connected by multiple fiber optic cables to the state of Florida. </p>\n<p>As I interviewed guards stationed at the base, I discovered many of them were millennials like me. They were mostly twenty-somethings, some actually younger, many of whom scuba-dived on the weekends, acting as if warehousing Muslim men was part of their patriotic duty. At the same time, I could not shake the feeling that everything I saw in the detention facilities, where I was surveilled and accompanied by a handler most of the time, was a curated performance. To understand Gitmo, I realized, I would need to find a different way backstage. </p>\n<p>For the past five years, I have relied on different open-source intelligence methods to explore the porousness of Gitmo and to follow the people who move through it. I spent one year watching the Joint Task Force scrub its own official Twitter feed of hundreds of tweets. (They subsequently deactivated the account, and I took over the handle.) I sat quietly for years with the knowledge that geolocation-based smartphone apps were a window into a military culture that most civilians will never see, and nodded my head when people told me that fitness trackers like Strava could reveal someone’s location on a military base. I knew that Strava was just the tip of the iceberg. I didn’t need to go to Gitmo to speak with personnel there; I could just turn on my phone.</p>\n<p>I considered different platforms—Facebook, YouTube, Reddit—where current and former guards might hover. All seemed too public—except Tinder. And so, in the summer of 2017, I plugged in a little personal information about myself on the app, geolocated to Guantánamo, and began to chat with men who were stationed there. I ended up swiping right on private contractors, members of the Military Police, sailors who were just passing through the port. Meanwhile, I sat in my small apartment in Massachusetts trying to understand what precisely I was trying to understand about the detention facilities. </p>\n<p>What I began to see through Tinder is that Americans would pass through the base and eventually return stateside. My new digital strategies were leading me to reckon with the fact that guards themselves were constantly returning after their rotations to communities throughout the United States, many slipping back into civilian life. Guards came, guards went, rinse, repeat. Through swiping, I could ask these people what they saw on the ground, and I could do what I had largely been unable to do at Guantánamo—learn their names, gain records of their faces, outline their moral codes, inquire what the detention facilities represented to them. </p>\n<p>The responses I gathered included disavowals and defenses of the national security state—a diversity of perspectives absent in much of the public record. At the same time, I was trying to document the identities of former guards, though at a certain point I recognized that this alone wouldn’t cause me to reckon with the vastness of the US national security state represented by Guantánamo Bay. As the scholar A. Naomi Paik argues in her book <i>Rightlessness: Testimony and Redress in U.S. Prison Camps since World War II</i>, Gitmo is part of a longstanding and ongoing US project to create physical and legal black sites. A few truths told on Tinder couldn’t make for a global reconciliation. </p>\n<h1><b>Home Truths</b></h1>\n<p>It took the UNC Charlotte students’ campaign, which I first heard about in late 2019, for me to reckon with my own lack of imagination. I had been so intent on using social media to map the identities, ideologies, and movements of former guards that I hadn’t considered what might transpire if their identities were to be widely known. The Zoomers had first learned about Bogdan’s history through LinkedIn—and then they led a concerted effort to fire him.</p>\n<p>But when I speak to members of the Coalition to Remove John Bogdan and other former UNC Charlotte students, I always find myself circling back to the same question. After unearthing this knowledge about Bogdan, if they didn’t think he belonged on their campus, where did he belong? </p>\n<p>One UNC Charlotte alumna, who now works in the national security sector, responded, “I think what shocked me was the ease with which someone that had such a high-profile position like that was able to come back and seamlessly reenter society, and that was it. I guess I just assumed they’d go to like RAND or Deloitte or somewhere like that.” Another Coalition member, now an alumnus, said the question of where Bogdan should be removed to had been stumping him from the start. “My initial reaction was to say that John Bogdan is not fit for any sort of civilian job,” he told me. “But then, I don’t necessarily want people like John Bogdan in our police or military either.” </p>\n<p>It struck me that what the students lacked was a model for justice that goes beyond any single warden or guard. This was partly a consequence of the algorithmically curated information they encountered online, but it is also the result of a widespread refusal by American society as a whole to confront this issue. As the students leave their campus and scatter across the United States, like former guards returning from their rotations, they’ll have to decide if they, too, want to leave Gitmo behind.</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Wed, 1 Dec 2021 21:58:51 +0000</pubDate>\n    </item>\n    <item>\n        <title>Big Data Stream</title>\n        <link>https://logicmag.io/kids/big-data-stream</link>\n        <guid>https://logicmag.io/kids/big-data-stream</guid>\n        <description>\n            <![CDATA[\n                <p>Who controls the algorithms that control the Colorado River?</p>\n\n            ]]>\n        </description>\n        <dc:creator>\n            <![CDATA[ Theodora Dryer ]]>\n        </dc:creator>\n        <media:content url=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;e529ilab8frl&#x2F;2KqjBUQBBoUrmVKhoPcONU&#x2F;6ca6f58e0c78112e8f6ffeb159906c81&#x2F;big-data-stream.png?w=962&amp;h=600&amp;fm=jpg&amp;fl=progressive\" medium=\"image\"/>\n        <content:encoded>\n        <![CDATA[\n\n            <p>The Colorado River snakes southwest from fifteen thousand feet high in the Rocky Mountains, down through plains and desert to present-day Mexico and the Gulf of California, draining a vast watershed of 250,000 square miles. Indigenous peoples—the Navajo and the Hopi, the Zuni and the Ute, and dozens of other nations—have been living alongside the river and its tributaries for centuries. Beginning in the 1820s, Anglo settlers began seizing water and land in the Colorado River Basin, and by the 1870s, the Colorado River Basin region had become part of the expanding United States empire. The region was reimagined by the US state as what the American geologist John Wesley Powell called “arid earth”: “drought-stricken” lands that supposedly needed to be salvaged through settler control and technology. </p>\n<p>In the decades that followed, the newly created US Geological Survey initiated a massive program of data collection to map, chart, graph, and apportion the basin’s water, land, and people. This stream of information—from acre-feet per year of river flow to racist atlases of Indigenous peoples—fed into decisions by US agencies like the Bureau of Reclamation about who should be allowed to live in the basin and use its land and water. This was, in effect, a data analytics program that entrenched white supremacist ideology into the legal and scientific functioning of the US state.</p>\n<p>Guiding decisions about how to distribute the region’s land and water was the belief that scarce resources should be optimized to foster development and maximize profits for white settlers. This regime of resource optimization persisted into the mid-twentieth century, when it was combined with a newly dominant mode of economic analysis called Input-Output (I/O) economics and programmed into computer algorithms known as linear programming algorithms, which guided the work of deciding how to allocate the basin’s water and land.</p>\n<p>Today, those optimization algorithms, and the settler-colonial logics they derive from, control the distribution of resources on which forty million people throughout the American southwest depend. According to officials in Colorado, New Mexico, Arizona, and Utah, and other states, that water system is now collapsing in the face of what the media, in a contemporary echo of Powell’s drought-stricken arid lands thesis, has described as “megadrought” and “water starvation” exacerbated by the climate crisis. That has led to calls for further technological intervention of the same kind that has long enabled settler control. But it is clear the optimization framework—which over the past century has contributed to water shortages, toxic waste from profit-driven energy development, flooding of Native American agricultural land, and enduring campaigns of water appropriation—will not solve the water crisis.</p>\n<p>There is now an urgent need to abandon that framework and imagine better water futures. Luckily, the resources for this work already exist. In the period when settler-colonial water policy was being entrenched in digital algorithms, a group of young people from the National Indian Youth Council (NIYC) were developing critiques of the optimization regime, and articulating a different vision for the Colorado River Basin. That vision can help us support sustainability and justice-centered water policy for generations to come. </p>\n<h1><b>Computing Landscapes</b></h1>\n<p>The story of how the optimization regime took over the Colorado River Basin is a complicated one. But at its core are innovations in policy, law, and technology that enthroned profit as the guiding principle of resource distribution in the region.</p>\n<p>In the nineteenth century, two doctrines guided the US empire’s allocation of Colorado River water. The first, known as the doctrine of prior appropriation, was basically a “first come, first served” rule that privileged the first interests to lay claim to the use of a given amount of water. The second, known as the doctrine of equitable apportionment, split water between US territories. In theory, these water doctrines might have favored Native American water rights, as they did after the 1908 <i>Winters v. United States</i> Supreme Court decision, which upheld the water rights of the Fort Belknap Indian Reservation over encroaching settlers. But since then, white settlers have managed to subordinate water rights under the principle of “beneficial use,” which holds that in the case of disputes, water should be allocated to the parties that intend to use it for vaguely defined beneficial purposes. In practice, this has usually meant profits for technological developers and extractive energy industries.</p>\n<p>That evolution in the principles of water distribution policies was later operationalized in new computing technologies. Beginning earlier but expanding significantly in the 1960s, analysts in laboratories at major land-grant universities like the University of Arizona took the data collected by the US Geological Survey and other agencies and encoded it onto punch cards. Mathematicians, economists, and other technologists then used those cards as the fodder for computer programs that would optimize water distribution for profit maximization.</p>\n<p>The design of these computer programs was derived from the economic technique known as Input-Output modeling. Created in the 1920s by the economist Wassily Leontief in order to optimize the transportation of grain in Soviet Russia, I/O modeling was later used to analyze entire national economies and even to guide US bombing campaigns in the Second World War, thereby advancing US imperialism and rationalizing mass destruction on the world stage.</p>\n<p>I/O models are based on a table that looks like an Excel spreadsheet, in which columns for materials (such as oil, steel, or coal) intersect with rows for industries (such as agriculture or manufacturing). The basic idea is that an economic system can be measured as the overall ratio of resources used (input) to goods produced (output). In the Cold War period, scientists at Harvard, the Pentagon, and elsewhere developed mathematical techniques known as linear programming algorithms to determine the optimal input and output numbers for a desired objective, such as optimizing resources for military development at the lowest possible cost. </p>\n<p>After being successfully implemented in imperial bombing campaigns and New England manufacturing, I/O economics and linear programming algorithms began expanding westward in the 1950s into water management on the Colorado River, becoming the dominant mode of modeling water within a decade. Researchers and students at the land-grant universities were charged with optimizing water distribution across the region. As the basis of their analysis, they carved the diverse land into relatively homogenous virtual quadrants known as “problem settings.”</p>\n<p>For example, in proposals for the Central Utah Project, initially formalized in the 1960s, the state of Utah was represented as a square divided into a grid of eight to ten smaller squares that obliterated all distinctions about whose land, histories, and water rights the grid overlaid. Researchers then used computer programs to figure out how to distribute X acre-feet of water for Y farm plots across each problem setting, so as to maximize profits and minimize costs for the region’s large agribusinesses and other industries.</p>\n<h1><b>Youth Against the Empire</b></h1>\n<p>The optimization regime is so entrenched in water policy and technology that, even in the midst of catastrophic climate change, it is difficult to imagine other futures for the Colorado River Basin and proximate regions. But in the late 1970s, a group of Native American students did just that, fighting back against a water diversion program in New Mexico, and providing a model for activism and water management that could guide us today.</p>\n<p>The NIYC was founded in 1961 as a nationwide coalition focused on environmental justice work and an intergenerational fight against US colonialism and economic extraction. In the subsequent decades, the NIYC argued countless environmental court cases, wrote numerous policy reports, and utilized every political and scientific tool to fight against the settler policy and technologies of the US empire. </p>\n<p>One of the tools they used was the Environmental Impact Statement (EIS). These statements were created in 1969 by the National Environmental Protection Act to help guide government decisions on new development projects. In the Colorado River Basin region, developers manipulated the EIS format to justify the impacts of their projects in light of those projects’ beneficial use—in other words, to show that the profits outweighed the environmental costs. </p>\n<p>In 1976, student youth members of the NIYC of Albuquerque, New Mexico, wrote their own anti-colonial EIS for the Bureau of Indian Affairs. They recognized that the EIS was a powerful policy medium that could be repurposed for environmental justice work. They were attempting to intervene against a recent data-driven decision about the allocation of water from the San Juan River—a major tributary of the Colorado River—as part of the Navajo Indian Irrigation Project. The project was supposed to take water from the Navajo Dam and Reservoir, created in early ’60s, and use it to irrigate land in San Juan County in northwestern New Mexico. </p>\n<p>The students supported the irrigation project in principle—as a founding member of the NIYC, John Redhouse, said in another context, “we’re not anti-development, we’re just anti-exploitation”—but they were concerned that Native oversight was lacking, and that the project would thereby undermine Navajo self-governance. They focused their EIS on the New Mexico state government’s opaque decision to divert 330,000 acre-feet of water from the Navajo Dam, which they pointed out was just one among countless decisions made without robust structures of Native oversight.</p>\n<p>In their statement, the students recounted how Native American water rights had been diminished since at least the early twentieth century by the doctrine of beneficial use. They pointed to the ways that dominant data-driven decision-making processes had been used to disavow Native American claims to water, and questioned the specific hydrological data employed to make the decision in this case. They decried the influence of corporate agriculture in the decision, as well as recent changes in the Navajo Council that weakened possibilities for total self-sufficiency from US resource governance. They also provided a clear vision for Navajo self-sufficiency, which included breaking away from the domination of US agribusiness to create a system of food production and distribution organized into small family farming and local Navajo food-producing cooperatives. </p>\n<p>Perhaps most importantly, they demanded transparency and power in the decision-making process, so that they could assert their voice within the Native council, and break from US water management and the technological regime of optimization. This has become a central tenet of contemporary Indigenous Environmental Justice and Indigenous Data Sovereignty resistance movements: the right to collection, ownership, and application of all data about Indigenous peoples, their lifeways, and territories. </p>\n<h1><b>Crisis Epistemology</b></h1>\n<p>Water justice requires acknowledging historical pasts as much as imagining new futures, but optimization frameworks flatten past, present, and future into calculations of profit-driven time.</p>\n<p>Optimization algorithms are misleading in stories about water in other ways, too. In upholding extractive economic systems, they formulate water crisis as a future problem and ignore the fact that this crisis has been caused by centuries of settler and capitalist control. Scholar Kyle Whyte has named this false description of climate change as new and urgent as “crisis epistemology.” This anxiety is evident in “megadrought” media descriptions of the Colorado River that warn of impending collapse. In response, technological developers and policy makers are granted unchecked decision-making power that reaffirms optimization-led economic systems. </p>\n<p>Environmental Impact Statements continue to dominate in water development policies. Standard EIS reports utilize optimization algorithms, Monte Carlo methods, and other predictive statistical frameworks. This means that dominant water policy assessment tools are designed with the same optimization logics that they are supposed to check. Against this, the NIYC’s anti-colonial EIS is a model of environmental assessment that breaks optimization’s stranglehold on water policy, and privileges intergenerational sustainability and water rights. Their approach centers the needs of the people over the profit of technological developers. </p>\n<p>The NIYC’s environmental justice work over the past seventy years—including their 1976 intervention into the Navajo irrigation project water diversion decision—and their unparalleled expertise in water policy, water-related technological development, and agriculture, underscore the critical importance of local organizing and wider coalition building, as well as centering youth perspectives, in formulating water futures written by the people. There is already enough information in these past interventions to write justice-centered policy and support livable water futures for the Colorado River.</p>\n        ]]>\n        </content:encoded>\n        <pubDate>Mon, 22 Nov 2021 17:02:44 +0000</pubDate>\n    </item>\n    </channel>\n</rss>"
  },
  "description": "Logic is a new magazine devoted to deepening the discourse around technology. We publish three times per year in print and digital formats.",
  "home_page_url": "https://logicmag.io",
  "icon": "https://logicmag.io/images/rss-icon.jpeg",
  "_ext": {
    "date_published": "2022-02-22T15:04:00.000Z",
    "date_modified": "2022-02-22T19:53:14.000Z"
  }
}