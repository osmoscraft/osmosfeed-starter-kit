{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Logic Magazine",
  "feed_url": "https://logicmag.io/rss.xml",
  "items": [
    {
      "id": "https://logicmag.io/clouds/computing-in-crip-time",
      "url": "https://logicmag.io/clouds/computing-in-crip-time",
      "title": "Computing in Crip Time",
      "summary": "A reflection on user experience and disability.",
      "content_html": "<p>I walk slower these days. Walking used to be about where I was going <i>next</i>: moving fast and hard through space. I paid less attention to the here and now; here was <i>en route</i> to my tomorrow. My old pace matched my lifestyle—stomping through a long Bay Area commute and a calendar packed with business travel. A life filled with too much working. </p>\n<p>After my spinal cord injury, that all changed. Now, I walk slower. My engagement with the world is different. I no longer just move through space, I spend time there. I spend time here, now. I use a cane to steady myself. My cane is not only an assistive device, it is a symbolic one. My cane signals to others: the way I am interacting with this space is different, and beware, the way you will interact with me is different, too. Disability has redefined my relationship to many things. Not only with spaces, as I describe, but also with time. I now meet the world differently, with a different body, and this body moves, thinks, and acts at a different pace. This is <i>crip time</i>. </p>\n<p>“Crip time” describes the alternative relationship many disabled people experience with time. As Ellen Samuels, a disability studies scholar, puts it: “Crip time is time travel.” There are many layers to crip time—from the simple fact that many of us walk or roll through space slowly, to the altered trajectories that unfold over the course of a lifetime. Crip time forces a confrontation with the messy realities of the non-normative, all the ways that our temporal experiences fall outside our expectations. Instead of looking to the norm—the averages, patterns, and trends that fill data-dripping techspeak—crip time provokes us to wonder: What about the peculiar? What about the ad hoc, the irregular, the one-off? What about the unique messiness of the here-and-now?</p>\n<p>Because I now walk slower than before, I notice much more: uneven and poorly maintained sidewalks, worn-out or missing “six feet” social-distancing floor stickers, the monstrosity of stairs. I notice when places are not built for people like me. But I also notice everyday beauty. A slower pace allows me to see the craft tangled in the mundane. I notice the playful swooping geometry of songbirds and the peppery glitter of tree shadows as they jump across the path in front of me. I have to take breaks and let my body rest. I must care for myself in ways I never did before, in ways I was never taught to. Will I be able to find something sturdy to sit awhile and rest? What will I do if I can’t?</p>\n<h1><b>Exiting the Flow</b></h1>\n<p>Where does rest figure in our everyday experiences with technology? I work as a user experience (UX) researcher. As UX professionals, we learn about the psychology of response times and how they relate to human thresholds around human-computer interactions. A machine can move too fast for a person to comprehend, which is not ideal. There is a sweet spot, according to industry expert Jakob Nielsen, to aim for: somewhere between 0.1 and 1.0 seconds is ideal for the system to stay in line with a person’s flow of thought. Ten seconds is the outer limit that a user will wait before getting bored or frustrated in waiting for a system response.</p>\n<p>But why do we get bored or frustrated? In our cult to the gods of relentless busyness, continuous digital activity feels holy. Corporate life pressures us to act quickly. We have become accustomed to high-speed internet connectivity and vast computation processing, all of it occurring with near-simultaneity as our fingers release a tap. We scroll, and scroll, and scroll—our feeds feel endless and our clicks take us seamlessly from one task to the next. </p>\n<p>This feeling of being “in the zone” is a psychological state called <i>flow</i>, and has been a design concern since the early days of personal computing in the 1980s and 1990s. Then, the concerns were largely focused on designing workplace experiences that integrated PCs with analog-driven workflows in ways that didn’t create too much friction or <i>drag</i>, the opposite of flow. </p>\n<p>Living in crip time means that flow feels rare. Since my spinal cord injury, I no longer rally for a packed work calendar, where meetings bleed together after hours of social interactions over video teleconferencing. Now, I must be strategic. Crip time means I attend some meetings with my camera on, and some with audio only. Others I watch later as a recording. An audio-only meeting likely means I am attending the meeting while pacing, kneeling, or laying down, alternating positions to help relieve the spinal cord pressure and nerve pain that builds up over the course of the day. Watching recordings of meetings later creates lots of drag, as I move between recording files, PowerPoint decks, meeting chats, and relevant emails to make sense after the fact. </p>\n<p>But this drag can be meaningful in its own way, too. Just as my slowed-down walking means I notice more in the world around me, my crip meeting practice provides me space where I am able to notice differently. Now that I live in crip time, I am always on the hunt for the red buttons and icons of recordkeeping—digital parallels to the benches and seats I watch for now when I walk. Audio-only meetings mean that I am more comfortable physically—and thus can concentrate more freely on the meeting. I take notes and jam into the conversation when I need to. I focus on the dialogue rather than my appearance via webcam. Watching recordings after the fact, I can approach the meeting well-rested and in a comfortable setting. With the ability to hit pause, I am able to wonder, consider, jot down questions. These are all things that are difficult in the flurry of marathon meetings. </p>\n<p>It’s not that my crip meeting practice appropriates a kind of alternative productivity tool. Instead, my experiences of disability and of crip time have compelled me to wonder if “flow” is really the metric against which all our journeys of work and technology should be judged. As we enter 2022, year three of the Covid-19 pandemic, this question seems particularly acute. Those of us who are able to work from home have spent month after month booting up, logging on, checking our schedule, and loading our inbox each morning. We are expected to seamlessly enter the flow of remote work at super-highway speed, reproducing pre-pandemic levels of productivity and output, even as we continue to face a world in crisis.</p>\n<p>The lens of disability studies and the experiences of the disabled offer us a different way of thinking about our experience of time. In <i>Feminist, Queer, and Crip</i>, Alison Kafer tells us: “Crip time is flex time not just expanded but exploded; it requires reimagining our notions of what can and should happen in time, or recognizing how expectations of ‘how long things take’ are based on very particular minds and bodies… Rather than bend disabled bodies and minds to meet the clock, crip time bends the clock to meet disabled bodies and minds.” Just as I have come to learn from my own disabled body my new walking pace, the time it takes my body to finish the chores of independent living, I also learn how long it takes my body to bring an article like this together or to finish an important deliverable at work. Where before I let pressures of various sorts build up to optimize my output drive overwork, I now live in crip time. Things get done, just at a different pace. Doing is re-imagined and re-configured, a process driven by my body’s differing, situated abilities, instead of some trend, pattern, or prediction. Achievement is still possible—and I do still achieve—just on my body’s own terms. What are your body’s terms?</p>",
      "content_text": "I walk slower these days. Walking used to be about where I was going next: moving fast and hard through space. I paid less attention to the here and now; here was en route to my tomorrow. My old pace matched my lifestyle—stomping through a long Bay Area commute and a calendar packed with business travel. A life filled with too much working. \nAfter my spinal cord injury, that all changed. Now, I walk slower. My engagement with the world is different. I no longer just move through space, I spend time there. I spend time here, now. I use a cane to steady myself. My cane is not only an assistive device, it is a symbolic one. My cane signals to others: the way I am interacting with this space is different, and beware, the way you will interact with me is different, too. Disability has redefined my relationship to many things. Not only with spaces, as I describe, but also with time. I now meet the world differently, with a different body, and this body moves, thinks, and acts at a different pace. This is crip time. \n“Crip time” describes the alternative relationship many disabled people experience with time. As Ellen Samuels, a disability studies scholar, puts it: “Crip time is time travel.” There are many layers to crip time—from the simple fact that many of us walk or roll through space slowly, to the altered trajectories that unfold over the course of a lifetime. Crip time forces a confrontation with the messy realities of the non-normative, all the ways that our temporal experiences fall outside our expectations. Instead of looking to the norm—the averages, patterns, and trends that fill data-dripping techspeak—crip time provokes us to wonder: What about the peculiar? What about the ad hoc, the irregular, the one-off? What about the unique messiness of the here-and-now?\nBecause I now walk slower than before, I notice much more: uneven and poorly maintained sidewalks, worn-out or missing “six feet” social-distancing floor stickers, the monstrosity of stairs. I notice when places are not built for people like me. But I also notice everyday beauty. A slower pace allows me to see the craft tangled in the mundane. I notice the playful swooping geometry of songbirds and the peppery glitter of tree shadows as they jump across the path in front of me. I have to take breaks and let my body rest. I must care for myself in ways I never did before, in ways I was never taught to. Will I be able to find something sturdy to sit awhile and rest? What will I do if I can’t?\nExiting the Flow\nWhere does rest figure in our everyday experiences with technology? I work as a user experience (UX) researcher. As UX professionals, we learn about the psychology of response times and how they relate to human thresholds around human-computer interactions. A machine can move too fast for a person to comprehend, which is not ideal. There is a sweet spot, according to industry expert Jakob Nielsen, to aim for: somewhere between 0.1 and 1.0 seconds is ideal for the system to stay in line with a person’s flow of thought. Ten seconds is the outer limit that a user will wait before getting bored or frustrated in waiting for a system response.\nBut why do we get bored or frustrated? In our cult to the gods of relentless busyness, continuous digital activity feels holy. Corporate life pressures us to act quickly. We have become accustomed to high-speed internet connectivity and vast computation processing, all of it occurring with near-simultaneity as our fingers release a tap. We scroll, and scroll, and scroll—our feeds feel endless and our clicks take us seamlessly from one task to the next. \nThis feeling of being “in the zone” is a psychological state called flow, and has been a design concern since the early days of personal computing in the 1980s and 1990s. Then, the concerns were largely focused on designing workplace experiences that integrated PCs with analog-driven workflows in ways that didn’t create too much friction or drag, the opposite of flow. \nLiving in crip time means that flow feels rare. Since my spinal cord injury, I no longer rally for a packed work calendar, where meetings bleed together after hours of social interactions over video teleconferencing. Now, I must be strategic. Crip time means I attend some meetings with my camera on, and some with audio only. Others I watch later as a recording. An audio-only meeting likely means I am attending the meeting while pacing, kneeling, or laying down, alternating positions to help relieve the spinal cord pressure and nerve pain that builds up over the course of the day. Watching recordings of meetings later creates lots of drag, as I move between recording files, PowerPoint decks, meeting chats, and relevant emails to make sense after the fact. \nBut this drag can be meaningful in its own way, too. Just as my slowed-down walking means I notice more in the world around me, my crip meeting practice provides me space where I am able to notice differently. Now that I live in crip time, I am always on the hunt for the red buttons and icons of recordkeeping—digital parallels to the benches and seats I watch for now when I walk. Audio-only meetings mean that I am more comfortable physically—and thus can concentrate more freely on the meeting. I take notes and jam into the conversation when I need to. I focus on the dialogue rather than my appearance via webcam. Watching recordings after the fact, I can approach the meeting well-rested and in a comfortable setting. With the ability to hit pause, I am able to wonder, consider, jot down questions. These are all things that are difficult in the flurry of marathon meetings. \nIt’s not that my crip meeting practice appropriates a kind of alternative productivity tool. Instead, my experiences of disability and of crip time have compelled me to wonder if “flow” is really the metric against which all our journeys of work and technology should be judged. As we enter 2022, year three of the Covid-19 pandemic, this question seems particularly acute. Those of us who are able to work from home have spent month after month booting up, logging on, checking our schedule, and loading our inbox each morning. We are expected to seamlessly enter the flow of remote work at super-highway speed, reproducing pre-pandemic levels of productivity and output, even as we continue to face a world in crisis.\nThe lens of disability studies and the experiences of the disabled offer us a different way of thinking about our experience of time. In Feminist, Queer, and Crip, Alison Kafer tells us: “Crip time is flex time not just expanded but exploded; it requires reimagining our notions of what can and should happen in time, or recognizing how expectations of ‘how long things take’ are based on very particular minds and bodies… Rather than bend disabled bodies and minds to meet the clock, crip time bends the clock to meet disabled bodies and minds.” Just as I have come to learn from my own disabled body my new walking pace, the time it takes my body to finish the chores of independent living, I also learn how long it takes my body to bring an article like this together or to finish an important deliverable at work. Where before I let pressures of various sorts build up to optimize my output drive overwork, I now live in crip time. Things get done, just at a different pace. Doing is re-imagined and re-configured, a process driven by my body’s differing, situated abilities, instead of some trend, pattern, or prediction. Achievement is still possible—and I do still achieve—just on my body’s own terms. What are your body’s terms?",
      "date_published": "2022-06-14T22:12:28.000Z",
      "date_modified": "2022-06-14T22:12:28.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/black-boxes",
      "url": "https://logicmag.io/clouds/black-boxes",
      "title": "Black Boxes",
      "summary": "Deciphering the informational arcana of public records.",
      "content_html": "<p><b>Adapted from </b><i>Redacted</i><b> (Taller California, 2021)</b></p>\n<p>San Diego is one of the most surveilled places in the United States. Located on the border with Mexico, America’s Finest City is host to one of the largest US Navy bases and a wide array of government agencies that see technology as the key to better managing public infrastructure, tracking the movements of people, and solving crimes. Hidden behind a veil of public safety and national security, the spyware is often invisible to the public.</p>\n<p>For years, officials have been rolling out technologies that they don’t totally understand and with little to no meaningful oversight, turning San Diego into a laboratory for the rest of the country. The residents here did not consent to this development, let alone vote on it—a reality that pits the interests of public planning and law enforcement against the civil liberties and civil rights of everyone else.</p>\n<p>It’s also common to find that technological experimentation in San Diego serves the interests of private companies with something to sell. General Atomics is one of these companies. In 2020, the defense contractor decided to repurpose its Predator and Reaper drones as the benign-sounding SkyGuardian and SeaGuardian. But before General Atomics could test out one of its drones above San Diego, it needed permission from the Federal Aviation Administration (FAA). The airspace above the city is a highly restricted place, where unmanned aircraft cannot typically fly.</p>\n<p>The San Diego test flight was supposed to demonstrate that the new drone, the SkyGuardian—weighing up to 12,500 pounds, with a wingspan of seventy-nine feet—could safely travel over a dense metro area while surveilling infrastructure and the natural landscape. San Diego and its people would be props in General Atomics’ killer demo.</p>\n<p>The company described the drone as a “persistent eye in the sky.” It was an unprecedented project that had the potential to open the airways above major US cities to new forms of surveillance.</p>\n<p>How were regulators evaluating the technology? Had there been any external influence—from, say, the Pentagon or the White House—to force the project through? These were pressing questions, especially because a similar drone from US Customs and Border Protection had experienced mechanical failure and crashed in the waters outside the city in 2014.</p>\n<p>So, in late March 2020, with the test flight about to take place any day, a journalist at the nonprofit news organization Voice of San Diego requested all public records related to the test flight from the FAA, including communications with the defense contractor.</p>\n<p>Complying with the request wasn’t easy. The FAA has five divisions spread across the country. By design, the agency’s public records response is decentralized. Getting the SkyGuardian off the ground required the work of three different units, each of which needed to produce—and redact—the records in its possession. Voice of San Diego filed a lawsuit to speed up the process and, in September 2020, a judge ordered the FAA to hurry up or face penalties. The pressure was on. The agency had six weeks.</p>\n<h1><b>The Minimum Amount of Redactions</b></h1>\n<p>Two months after the original request was filed—well past FOIA’s legal deadline of twenty business days—Rick Perez got the assignment in the FAA’s air certification branch. Perez had been with the FAA since 2011, and his staff was also in the middle of processing more than sixty requests for huge volumes of records related to the certification of the Boeing 737 MAX, two of which had crashed in 2018 and 2019, killing a total of 346 people. Perez’s branch consisted of three federal employees and four contractors. The SkyGuardian was just a blip on their radar.</p>\n<p>Perez’s staff consulted with other experts in the agency, ran an initial query with keywords, and then set about reading through the more than 2,500 pages they had identified. During their line-by-line reviews, it became clear that other organizations might have a stake—and a legal claim—to withhold information about the SkyGuardian, not just the FAA.</p>\n<p>NASA, for instance, had been partnering with General Atomics on the test flight. Both organizations needed to be consulted. Both would drag their feet. And both would then turn around and make cases to the FAA in private that certain documents and communications ought to be treated as confidential. General Atomics argued that some of the information contained in the records was protected by the US Arms Export Control Act, which deals with the sale of weapons overseas. This by itself was revealing: the test flight was not just about showing local officials the ways in which they could monitor infrastructure from above. The test flight was intended as a marketing ploy for international buyers.</p>\n<p>For this reason, Perez discovered, the Department of Defense also needed to weigh in. That slowed the process down even further. In October 2020, he provided the court with an update, arguing for more time—but promised to release everything in his possession “with the minimum amount of redactions.” Here’s a taste of what he produced: </p>\n<p>Still, there were some revelations visible between the blacked-out lines. What the FAA released showed that regulators did not believe the drone could fly safely above so many people. Regulators had demanded the company use a “chase plane,” manned with a pilot who could monitor the drone in real-time for any problems. Instead of complying with the request—which might have given the international buyers doubts about the technology’s true capabilities—the company rerouted the flight path and pushed the demo into the desert.</p>\n<p>But as it turns out, different units within the FAA had similar records in their possession and redacted them in different ways. The FAA wound up producing the same emails in redacted and unredacted forms, inadvertently revealing how subjective the process really is. What to keep and what to omit appeared to be dependent on the momentary feelings and fleeting judgments of whoever was doing the redactions.</p>\n<p>The email conversations show FAA employees casting doubt on General Atomics’ claim that their technology is safe. In one email, an FAA employee notes that the company is “worried about getting an approval” and that time will run out before the permit process can be completed because, “as usual, they have diplomats from the military attending and want to demonstrate the capability.”</p>\n<p>Secrecy is the way in which government agencies reveal their mistrust of the people. The cloak is needed, you’ll often hear officials say, to keep everyone safe. But safe from what? Or better yet, from whom? Secrecy breeds its own kind of distress, encouraging a fear of the unknown that justifies new levels of authority in a slow-moving but perpetual crisis. </p>\n<p>Secrecy and surveillance are two sides of the same coin. Both stem from an attitude that the people atop our institutions know better than the rest of us how to govern and structure society. Both engender mistrust and inhibit collective action. They engender mistrust by encouraging us to outsource responsibility for safety. This inhibits collective action, not only by chilling our speech and association but by ceding authority to institutions we mostly do not participate in. </p>\n<h1><b>Do It Yourself</b></h1>\n<p><b>Why would I, of all people, want to seek a public record?</b></p>\n<p>It could be to learn about an issue that affects you or your community. It could be to find more bulletproof evidence of something you know or suspect that will help with your advocacy work. It could be an entry point into the workings of politics or profit by finding the traces left behind by the companies that interact with the government.\t</p>\n<p><b>How do I get started?</b></p>\n<p>Don’t be intimidated. We had no idea what we were doing when we got started either. No one is born with this knowledge.</p>\n<p>Explore the public records universe to get a sense of the mechanics. Public records are informational arcana produced through the rituals of politicians, functionaries, and bureaucrats. It is hard to know what to ask for if you don’t have a sense of how they organize their world and their work within it. </p>\n<p>Check online to see if the agency you’re targeting has an open data portal, then start by trawling for topics that you’re interested in. Some public agencies and cities, including Los Angeles, New York City, and San Diego, have websites that allow you to search for the records others have already requested using keywords. You can then dive into the rabbit hole of what’s already been made available. Browsing the records gives you a sense of what kinds of departments exist within those agencies, what kind of records they produce, what kinds of things other people ask for, and how they ask for them.</p>\n<p><b>What kind of records could address my question?</b></p>\n<p>Records may not be available to answer your exact question, but there may be records that give you some pieces of an answer. Possible records include email communications, presentations, memoranda of understanding, policy and procedure manuals, government filings, and contracts.</p>\n<p>It can help to speak with people who interact with the government a lot. Activists, lawyers, and policy nerds can help you brainstorm based on their experiences requesting and filing documents. Again, browsing existing open records portals can also give you ideas. There is no shame in starting your request by copying and pasting another request you find and submitting it with the tweaks that get at the specific information you want. We do this all the time. You can also check the agency’s website to get a sense of the kind of forms and records they describe working with publicly. </p>\n<p><b>Which public entity has the records I want?</b></p>\n<p>Determining this is key. After you figure out what you want to know, figure out who has it. The San Diego Police Department? The National Labor Relations Board? The Food and Drug Administration? Cities will often have a clerk who you can call and talk to—an act of bureaucratic goodwill or perhaps a legal requirement, depending on the state. Networking with others who work on the topic you’re interested in can also help. You may encounter hostility from some agencies, but remember, at least California requires that officials help you route your request to the correct departments.</p>\n<p>The entity should have a website explaining their public records procedure, often with an online form. Plan ahead, as it can take months to get the records you request—and that’s if you’re lucky. The agency may also charge you for requests beyond a certain number of pages. You’re also within your rights to request that they waive those fees.</p>\n<p>Transparency is a constant struggle. It helps to have allies. Are there organized groups—unions or community organizations, for example—that have a stake in the issue you’re trying to bring to light? They may have background knowledge about the politics behind the records you seek. They may have access to lawyers who can help you navigate local public records laws. They might want to help you make sense of the records you get because it benefits them too.</p>\n<p>Finally, if you want to know more because you want to change something about the way the world works, you’ll need to join with others to make it happen. Being frustrated and alone is a trash feeling.</p>",
      "content_text": "Adapted from Redacted (Taller California, 2021)\nSan Diego is one of the most surveilled places in the United States. Located on the border with Mexico, America’s Finest City is host to one of the largest US Navy bases and a wide array of government agencies that see technology as the key to better managing public infrastructure, tracking the movements of people, and solving crimes. Hidden behind a veil of public safety and national security, the spyware is often invisible to the public.\nFor years, officials have been rolling out technologies that they don’t totally understand and with little to no meaningful oversight, turning San Diego into a laboratory for the rest of the country. The residents here did not consent to this development, let alone vote on it—a reality that pits the interests of public planning and law enforcement against the civil liberties and civil rights of everyone else.\nIt’s also common to find that technological experimentation in San Diego serves the interests of private companies with something to sell. General Atomics is one of these companies. In 2020, the defense contractor decided to repurpose its Predator and Reaper drones as the benign-sounding SkyGuardian and SeaGuardian. But before General Atomics could test out one of its drones above San Diego, it needed permission from the Federal Aviation Administration (FAA). The airspace above the city is a highly restricted place, where unmanned aircraft cannot typically fly.\nThe San Diego test flight was supposed to demonstrate that the new drone, the SkyGuardian—weighing up to 12,500 pounds, with a wingspan of seventy-nine feet—could safely travel over a dense metro area while surveilling infrastructure and the natural landscape. San Diego and its people would be props in General Atomics’ killer demo.\nThe company described the drone as a “persistent eye in the sky.” It was an unprecedented project that had the potential to open the airways above major US cities to new forms of surveillance.\nHow were regulators evaluating the technology? Had there been any external influence—from, say, the Pentagon or the White House—to force the project through? These were pressing questions, especially because a similar drone from US Customs and Border Protection had experienced mechanical failure and crashed in the waters outside the city in 2014.\nSo, in late March 2020, with the test flight about to take place any day, a journalist at the nonprofit news organization Voice of San Diego requested all public records related to the test flight from the FAA, including communications with the defense contractor.\nComplying with the request wasn’t easy. The FAA has five divisions spread across the country. By design, the agency’s public records response is decentralized. Getting the SkyGuardian off the ground required the work of three different units, each of which needed to produce—and redact—the records in its possession. Voice of San Diego filed a lawsuit to speed up the process and, in September 2020, a judge ordered the FAA to hurry up or face penalties. The pressure was on. The agency had six weeks.\nThe Minimum Amount of Redactions\nTwo months after the original request was filed—well past FOIA’s legal deadline of twenty business days—Rick Perez got the assignment in the FAA’s air certification branch. Perez had been with the FAA since 2011, and his staff was also in the middle of processing more than sixty requests for huge volumes of records related to the certification of the Boeing 737 MAX, two of which had crashed in 2018 and 2019, killing a total of 346 people. Perez’s branch consisted of three federal employees and four contractors. The SkyGuardian was just a blip on their radar.\nPerez’s staff consulted with other experts in the agency, ran an initial query with keywords, and then set about reading through the more than 2,500 pages they had identified. During their line-by-line reviews, it became clear that other organizations might have a stake—and a legal claim—to withhold information about the SkyGuardian, not just the FAA.\nNASA, for instance, had been partnering with General Atomics on the test flight. Both organizations needed to be consulted. Both would drag their feet. And both would then turn around and make cases to the FAA in private that certain documents and communications ought to be treated as confidential. General Atomics argued that some of the information contained in the records was protected by the US Arms Export Control Act, which deals with the sale of weapons overseas. This by itself was revealing: the test flight was not just about showing local officials the ways in which they could monitor infrastructure from above. The test flight was intended as a marketing ploy for international buyers.\nFor this reason, Perez discovered, the Department of Defense also needed to weigh in. That slowed the process down even further. In October 2020, he provided the court with an update, arguing for more time—but promised to release everything in his possession “with the minimum amount of redactions.” Here’s a taste of what he produced: \nStill, there were some revelations visible between the blacked-out lines. What the FAA released showed that regulators did not believe the drone could fly safely above so many people. Regulators had demanded the company use a “chase plane,” manned with a pilot who could monitor the drone in real-time for any problems. Instead of complying with the request—which might have given the international buyers doubts about the technology’s true capabilities—the company rerouted the flight path and pushed the demo into the desert.\nBut as it turns out, different units within the FAA had similar records in their possession and redacted them in different ways. The FAA wound up producing the same emails in redacted and unredacted forms, inadvertently revealing how subjective the process really is. What to keep and what to omit appeared to be dependent on the momentary feelings and fleeting judgments of whoever was doing the redactions.\nThe email conversations show FAA employees casting doubt on General Atomics’ claim that their technology is safe. In one email, an FAA employee notes that the company is “worried about getting an approval” and that time will run out before the permit process can be completed because, “as usual, they have diplomats from the military attending and want to demonstrate the capability.”\nSecrecy is the way in which government agencies reveal their mistrust of the people. The cloak is needed, you’ll often hear officials say, to keep everyone safe. But safe from what? Or better yet, from whom? Secrecy breeds its own kind of distress, encouraging a fear of the unknown that justifies new levels of authority in a slow-moving but perpetual crisis. \nSecrecy and surveillance are two sides of the same coin. Both stem from an attitude that the people atop our institutions know better than the rest of us how to govern and structure society. Both engender mistrust and inhibit collective action. They engender mistrust by encouraging us to outsource responsibility for safety. This inhibits collective action, not only by chilling our speech and association but by ceding authority to institutions we mostly do not participate in. \nDo It Yourself\nWhy would I, of all people, want to seek a public record?\nIt could be to learn about an issue that affects you or your community. It could be to find more bulletproof evidence of something you know or suspect that will help with your advocacy work. It could be an entry point into the workings of politics or profit by finding the traces left behind by the companies that interact with the government.\t\nHow do I get started?\nDon’t be intimidated. We had no idea what we were doing when we got started either. No one is born with this knowledge.\nExplore the public records universe to get a sense of the mechanics. Public records are informational arcana produced through the rituals of politicians, functionaries, and bureaucrats. It is hard to know what to ask for if you don’t have a sense of how they organize their world and their work within it. \nCheck online to see if the agency you’re targeting has an open data portal, then start by trawling for topics that you’re interested in. Some public agencies and cities, including Los Angeles, New York City, and San Diego, have websites that allow you to search for the records others have already requested using keywords. You can then dive into the rabbit hole of what’s already been made available. Browsing the records gives you a sense of what kinds of departments exist within those agencies, what kind of records they produce, what kinds of things other people ask for, and how they ask for them.\nWhat kind of records could address my question?\nRecords may not be available to answer your exact question, but there may be records that give you some pieces of an answer. Possible records include email communications, presentations, memoranda of understanding, policy and procedure manuals, government filings, and contracts.\nIt can help to speak with people who interact with the government a lot. Activists, lawyers, and policy nerds can help you brainstorm based on their experiences requesting and filing documents. Again, browsing existing open records portals can also give you ideas. There is no shame in starting your request by copying and pasting another request you find and submitting it with the tweaks that get at the specific information you want. We do this all the time. You can also check the agency’s website to get a sense of the kind of forms and records they describe working with publicly. \nWhich public entity has the records I want?\nDetermining this is key. After you figure out what you want to know, figure out who has it. The San Diego Police Department? The National Labor Relations Board? The Food and Drug Administration? Cities will often have a clerk who you can call and talk to—an act of bureaucratic goodwill or perhaps a legal requirement, depending on the state. Networking with others who work on the topic you’re interested in can also help. You may encounter hostility from some agencies, but remember, at least California requires that officials help you route your request to the correct departments.\nThe entity should have a website explaining their public records procedure, often with an online form. Plan ahead, as it can take months to get the records you request—and that’s if you’re lucky. The agency may also charge you for requests beyond a certain number of pages. You’re also within your rights to request that they waive those fees.\nTransparency is a constant struggle. It helps to have allies. Are there organized groups—unions or community organizations, for example—that have a stake in the issue you’re trying to bring to light? They may have background knowledge about the politics behind the records you seek. They may have access to lawyers who can help you navigate local public records laws. They might want to help you make sense of the records you get because it benefits them too.\nFinally, if you want to know more because you want to change something about the way the world works, you’ll need to join with others to make it happen. Being frustrated and alone is a trash feeling.",
      "date_published": "2022-06-14T22:12:15.000Z",
      "date_modified": "2022-06-14T22:12:15.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/omnivorous-analysis",
      "url": "https://logicmag.io/clouds/omnivorous-analysis",
      "title": "Omnivorous Analysis",
      "summary": "Untangling the satellite imagery supply chain.",
      "content_html": "<p>Satellite imagery has woven itself into the fabric of the internet. We recognize these crisp, high-definition, bird’s-eye-view images most commonly from Google Earth—but we employ them in much more besides: from reporting on stuck shipping containers to getting directions to a friend’s house, to tracking forest fires in real time and scrolling through real estate listings. Given their ever-widening range of commercial, consumer, and civic uses, it won’t surprise most people to hear that the industry that produces them (also known as Earth Observation, or EO) is growing at an exponential rate, and is only expected to expand further in the coming years.</p>\n<p>Yet despite the prominence of satellite imagery in the geographical imagination of the internet, the imperatives of the industry are much less clear. The corporations that produce them are much less well known, and the military interests that back them remain as murky as ever. The highly visible commercial side of the industry is still deeply intertwined with its classified counterpart, and two companies, Maxar and Planet, have emerged to dominate the industry—supporting civilian functions with one hand, while supplying US defense needs with the other. </p>\n<p>Indeed, the ubiquity of commercial satellite imagery gives nearly anyone godlike powers of reconnaissance and surveillance not that far removed from those enjoyed by militaries and intelligence agencies—a fact that causes no small amount of anxiety within the Pentagon. The pervasiveness and power of their imagery compels us to ask: Where do they come from? And how are they being put to use?</p>\n<h1><b>Launching the Industry</b></h1>\n<p>The story of satellite imagery begins with military surveillance. The CORONA satellite program was launched in secret by the NRO (the National Reconnaissance Office, whose existence wasn’t declassified until the 1990s) in response to the USSR’s Sputnik-1 in 1958. CORONA ultimately put over 144 satellites into orbit over twelve years. Satellites were soon found to be useful for surveying purposes as well: the oil, gas, and mining industries, as well as climate researchers could make use of satellite imagery in their work. The academic, commercial, and national-security interest in satellite imagery of natural resources culminated in the launch of the Earth Resources Technology Satellite, now called Landsat 1, in 1972. Landsat remains the longest-running satellite imagery program to date.</p>\n<p>Following the end of the Cold War in 1992, private companies were permitted to enter the satellite business in the United States, kickstarting the industry that we know today. But the newfangled EO industry never drifted far from its origins in the military-industrial complex. In 1994, defense contractor Lockheed Martin was granted a license to sell commercial satellite high-resolution imagery. In 1995, the first commercial imaging satellite, OrbView-1, was launched by Orbital Sciences Corporation, in partnership with NASA. Soon afterwards, WorldView Imaging Corporation (later called DigitalGlobe) was given the first contract to build and operate a commercial satellite system. As the industry grew during the 2000s, it created new markets and many of the companies we know today. In 2004, Google acquired three geospatial companies that formed the basis for Google Maps. (One of them, Keyhole, had received funding from the CIA.) As the industry has expanded, the number of satellites orbiting the planet has grown: from one in 1958 to over 3,300 in 2020.</p>\n<p>Despite the staggering number of satellites, the business of capturing satellite imagery is dominated by a small number of major players. DigitalGlobe and Orbital Sciences (by then called GeoEye) merged in 2013; the resulting corporation, Maxar Technologies, became the largest satellite imagery company in the United States—a monopoly, in effect. Planet, founded by ex-NASA scientists in 2010, initiated a new chapter for the industry, launching small-scale micro satellites that could capture imagery of the entire planet at least once a day. The miniature satellites themselves are called “doves,” ironic given their recently renewed contract with the NRO in late 2021. Planet, which went public on the New York Stock Exchange just weeks later in 2021, has been hailed as an industry disruptor for years. Maxar and Planet have emerged as twin giants of the industry: one supplies high resolution, the other, speed. </p>\n<p>The granularity of satellite imagery can be divided into three categories: low resolution (over 60m/pixel), medium resolution (10–30m/pixel), and high resolution (30cm–5m/pixel). The precise resolution of NRO satellites remains classified but continues to occupy the highest rung, while public research satellites like Landsat 1 capture the medium to low resolution needed for climate science. Historically, commercial satellites have been restricted to selling imagery up to 50cm/pixels (lowered to 40cm in 2014, then 30cm in 2015) despite their capacity to produce much higher resolution, as is the case with Maxar’s satellites, in particular. While Planet satellites aren’t capable of capturing the same sort of resolution (they max out at 50cm/pixel), the sheer number of micro-satellites they have launched means that Planet has the largest constellation of satellites ever assembled. As of 2022, Planet’s doves can capture and transmit imagery at least once a day, and this “guaranteed collection” business model is, in part, responsible for their recent IPO. </p>\n<p>In other words, if Landsat imagery can capture a retreating glacier, Maxar can capture every crack—and Planet can capture its movement day-in, day-out. The NRO satellites? Who knows what they can do.</p>\n<h1><b>The GEOINT Singularity</b></h1>\n<p>Thanks to their size and technological advantages, Maxar and Planet have become the go-to suppliers of satellite imagery used to document everything from tornado damage to the 2021–2022 military actions in Ukraine. According to its own statements, Maxar “provides 90 percent of the foundational geospatial intelligence used by the US government,” and was initially the sole supplier of imagery to the US government. Since 2019, the NRO has subscribed to Planet’s services (a contract that was recently expanded). Meanwhile, other companies like Satellogic (which recently partnered with Palantir in early 2022) and BlackSky (contracted to the NRO and NASA) have emerged with similar capabilities.</p>\n<p>At the same time, the growth of “open source intelligence” (OSINT) and open data initiatives has enabled satellite imagery to be co-opted as both an investigative tool and public good, sometimes even used against the very states and corporations that released their imagery in the first place. Organizations like Amnesty International and Forensic Architecture have used satellite imagery to document human rights abuses, while Bellingcat has done the same for US military bases (both using Planet imagery). OpenStreetMap, an open data project, uses Maxar imagery to create a crowdsourced map of the world (often called the “Wikipedia of maps”). Such civic use of satellite imagery has shifted public access as well, as when Maxar released high-resolution imagery of Israel-Palestine in 2021—imagery that has been historically blurred and kept classified due to US government restrictions. </p>\n<p>This fact is not lost on US intelligence professionals, many of whom fear a looming “GEOINT singularity,” in which public geospatial knowledge may equal that which is known by “experts.” But even the Pentagon understands that OSINT is here to stay—and may even be a resource for the military to exploit, as a DoD strategy report from August 2021 suggests. Similarly, the National Geospatial Intelligence (NGI) agency has emphasized the role of private companies in the geospatial intelligence community, and more such government-commercial partnerships are expected to develop in the coming years. </p>\n<p>For all its pervasiveness online, the increased production of satellite imagery by companies like Maxar and Planet is not necessarily leading to an increased commercial demand to use it. From a business perspective, the thousands of satellites circling overhead are producing an excess of supply, and demand is still dominated by defense agencies. </p>\n<p>Indeed, given how much more advanced NRO satellites must be compared to the commercial industry as a whole (something we have the right to assume, given their classified status—the NRO, for instance, was able to unexpectedly donate two high-resolution telescopes of the same quality as Hubble to NASA), it’s worth asking why the government continues to acquire lower-resolution commercial imagery in the first place. The recent declassification of “Sentient,” an “omnivorous analysis tool” being developed by the NRO, points to their need for vast quantities of satellite imagery to train AI-driven imagery analyses. Could the exigencies of AI be driving the DoD’s continuing support of the industry? On the other hand, buying up imagery could also be a means of controlling the flow of information, pushing the images into the wrong (or right) hands. Could their support be a means of ensuring that satellite imagery is steered in the direction of US military interests?</p>\n<p>In either case, we may not ever know for sure—at least not in the near future. But the questions are a reminder that the commercial satellite imagery industry remains impossible to separate from the military applications from which it arose. They are a reminder that the “supply chain” of satellite imagery—the set of companies and institutions that bring the images from above the atmosphere to the apps on our phones—is not necessarily as straightforward as the notion of “surveillance capitalism” might make it seem. In the meantime, this convoluted mix of civil, military, and commercial actors will continue to fill our skies—and our screens—with satellite imagery.</p>",
      "content_text": "Satellite imagery has woven itself into the fabric of the internet. We recognize these crisp, high-definition, bird’s-eye-view images most commonly from Google Earth—but we employ them in much more besides: from reporting on stuck shipping containers to getting directions to a friend’s house, to tracking forest fires in real time and scrolling through real estate listings. Given their ever-widening range of commercial, consumer, and civic uses, it won’t surprise most people to hear that the industry that produces them (also known as Earth Observation, or EO) is growing at an exponential rate, and is only expected to expand further in the coming years.\nYet despite the prominence of satellite imagery in the geographical imagination of the internet, the imperatives of the industry are much less clear. The corporations that produce them are much less well known, and the military interests that back them remain as murky as ever. The highly visible commercial side of the industry is still deeply intertwined with its classified counterpart, and two companies, Maxar and Planet, have emerged to dominate the industry—supporting civilian functions with one hand, while supplying US defense needs with the other. \nIndeed, the ubiquity of commercial satellite imagery gives nearly anyone godlike powers of reconnaissance and surveillance not that far removed from those enjoyed by militaries and intelligence agencies—a fact that causes no small amount of anxiety within the Pentagon. The pervasiveness and power of their imagery compels us to ask: Where do they come from? And how are they being put to use?\nLaunching the Industry\nThe story of satellite imagery begins with military surveillance. The CORONA satellite program was launched in secret by the NRO (the National Reconnaissance Office, whose existence wasn’t declassified until the 1990s) in response to the USSR’s Sputnik-1 in 1958. CORONA ultimately put over 144 satellites into orbit over twelve years. Satellites were soon found to be useful for surveying purposes as well: the oil, gas, and mining industries, as well as climate researchers could make use of satellite imagery in their work. The academic, commercial, and national-security interest in satellite imagery of natural resources culminated in the launch of the Earth Resources Technology Satellite, now called Landsat 1, in 1972. Landsat remains the longest-running satellite imagery program to date.\nFollowing the end of the Cold War in 1992, private companies were permitted to enter the satellite business in the United States, kickstarting the industry that we know today. But the newfangled EO industry never drifted far from its origins in the military-industrial complex. In 1994, defense contractor Lockheed Martin was granted a license to sell commercial satellite high-resolution imagery. In 1995, the first commercial imaging satellite, OrbView-1, was launched by Orbital Sciences Corporation, in partnership with NASA. Soon afterwards, WorldView Imaging Corporation (later called DigitalGlobe) was given the first contract to build and operate a commercial satellite system. As the industry grew during the 2000s, it created new markets and many of the companies we know today. In 2004, Google acquired three geospatial companies that formed the basis for Google Maps. (One of them, Keyhole, had received funding from the CIA.) As the industry has expanded, the number of satellites orbiting the planet has grown: from one in 1958 to over 3,300 in 2020.\nDespite the staggering number of satellites, the business of capturing satellite imagery is dominated by a small number of major players. DigitalGlobe and Orbital Sciences (by then called GeoEye) merged in 2013; the resulting corporation, Maxar Technologies, became the largest satellite imagery company in the United States—a monopoly, in effect. Planet, founded by ex-NASA scientists in 2010, initiated a new chapter for the industry, launching small-scale micro satellites that could capture imagery of the entire planet at least once a day. The miniature satellites themselves are called “doves,” ironic given their recently renewed contract with the NRO in late 2021. Planet, which went public on the New York Stock Exchange just weeks later in 2021, has been hailed as an industry disruptor for years. Maxar and Planet have emerged as twin giants of the industry: one supplies high resolution, the other, speed. \nThe granularity of satellite imagery can be divided into three categories: low resolution (over 60m/pixel), medium resolution (10–30m/pixel), and high resolution (30cm–5m/pixel). The precise resolution of NRO satellites remains classified but continues to occupy the highest rung, while public research satellites like Landsat 1 capture the medium to low resolution needed for climate science. Historically, commercial satellites have been restricted to selling imagery up to 50cm/pixels (lowered to 40cm in 2014, then 30cm in 2015) despite their capacity to produce much higher resolution, as is the case with Maxar’s satellites, in particular. While Planet satellites aren’t capable of capturing the same sort of resolution (they max out at 50cm/pixel), the sheer number of micro-satellites they have launched means that Planet has the largest constellation of satellites ever assembled. As of 2022, Planet’s doves can capture and transmit imagery at least once a day, and this “guaranteed collection” business model is, in part, responsible for their recent IPO. \nIn other words, if Landsat imagery can capture a retreating glacier, Maxar can capture every crack—and Planet can capture its movement day-in, day-out. The NRO satellites? Who knows what they can do.\nThe GEOINT Singularity\nThanks to their size and technological advantages, Maxar and Planet have become the go-to suppliers of satellite imagery used to document everything from tornado damage to the 2021–2022 military actions in Ukraine. According to its own statements, Maxar “provides 90 percent of the foundational geospatial intelligence used by the US government,” and was initially the sole supplier of imagery to the US government. Since 2019, the NRO has subscribed to Planet’s services (a contract that was recently expanded). Meanwhile, other companies like Satellogic (which recently partnered with Palantir in early 2022) and BlackSky (contracted to the NRO and NASA) have emerged with similar capabilities.\nAt the same time, the growth of “open source intelligence” (OSINT) and open data initiatives has enabled satellite imagery to be co-opted as both an investigative tool and public good, sometimes even used against the very states and corporations that released their imagery in the first place. Organizations like Amnesty International and Forensic Architecture have used satellite imagery to document human rights abuses, while Bellingcat has done the same for US military bases (both using Planet imagery). OpenStreetMap, an open data project, uses Maxar imagery to create a crowdsourced map of the world (often called the “Wikipedia of maps”). Such civic use of satellite imagery has shifted public access as well, as when Maxar released high-resolution imagery of Israel-Palestine in 2021—imagery that has been historically blurred and kept classified due to US government restrictions. \nThis fact is not lost on US intelligence professionals, many of whom fear a looming “GEOINT singularity,” in which public geospatial knowledge may equal that which is known by “experts.” But even the Pentagon understands that OSINT is here to stay—and may even be a resource for the military to exploit, as a DoD strategy report from August 2021 suggests. Similarly, the National Geospatial Intelligence (NGI) agency has emphasized the role of private companies in the geospatial intelligence community, and more such government-commercial partnerships are expected to develop in the coming years. \nFor all its pervasiveness online, the increased production of satellite imagery by companies like Maxar and Planet is not necessarily leading to an increased commercial demand to use it. From a business perspective, the thousands of satellites circling overhead are producing an excess of supply, and demand is still dominated by defense agencies. \nIndeed, given how much more advanced NRO satellites must be compared to the commercial industry as a whole (something we have the right to assume, given their classified status—the NRO, for instance, was able to unexpectedly donate two high-resolution telescopes of the same quality as Hubble to NASA), it’s worth asking why the government continues to acquire lower-resolution commercial imagery in the first place. The recent declassification of “Sentient,” an “omnivorous analysis tool” being developed by the NRO, points to their need for vast quantities of satellite imagery to train AI-driven imagery analyses. Could the exigencies of AI be driving the DoD’s continuing support of the industry? On the other hand, buying up imagery could also be a means of controlling the flow of information, pushing the images into the wrong (or right) hands. Could their support be a means of ensuring that satellite imagery is steered in the direction of US military interests?\nIn either case, we may not ever know for sure—at least not in the near future. But the questions are a reminder that the commercial satellite imagery industry remains impossible to separate from the military applications from which it arose. They are a reminder that the “supply chain” of satellite imagery—the set of companies and institutions that bring the images from above the atmosphere to the apps on our phones—is not necessarily as straightforward as the notion of “surveillance capitalism” might make it seem. In the meantime, this convoluted mix of civil, military, and commercial actors will continue to fill our skies—and our screens—with satellite imagery.",
      "date_published": "2022-05-16T13:35:33.000Z",
      "date_modified": "2022-05-16T13:35:33.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/the-barn",
      "url": "https://logicmag.io/clouds/the-barn",
      "title": "The Barn",
      "summary": "A climate-fiction story about mundane apocalypses.",
      "content_html": "<p>I wonder what’s taken me so long to pop the question, and why this ritual that’s been performed countless times by so many before me bears down on me like I’m the first woman in history to put a knee to the floor and offer the ring and say the words. She’ll say yes. We talked about it. When we lay beside each other, Aluna gains the power to ease the edge around momentous things, and it’s all in how she finds the right tenor, right whisper, the right circles of pressure to trace along the dips of my neck. I’ve brought all sorts of crises to her before sleep. VR recordings of tragedy filmed that very morning, from hundreds of miles away and through the dissociative lens of a drone’s 360 degree camera. Roaming tent cities trudging across the Sahara that siphon power from abandoned solar panel farms. Ocean slums sprawling off the coasts of Italy, Spain, France, sinking as their fate is decided in boardrooms graced with AC. Sea spray is everywhere it shouldn’t be, and scatters the footage into clouds of discordant pixels—that’s when Aluna pauses our replay, blinks our retinas clear. While the bedroom is at its darkest, we shift to face each other and she tells me what she thinks comes next. Never lessening the blows, but making it all feel approachable, which is exactly how she responded when I asked if we might actually spend the rest of our lives together. And she said yes.</p>\n<p>It feels like I lost my chance. Tonight marks our first week sleeping on the shelter’s temporary foldout beds. We’d considered my SUV but it’s packed tight with all the remaining fragments of our apartment, the things that survived the flood. We gave it a shot, wedging ourselves between piles of clothing in the front seat, but Aluna couldn’t fall asleep. She didn’t complain once. She made constant shifts in her seat through the night, awkwardly reaching for my body only to be thwarted by the packed detritus of our old home.</p>\n<p>Video floats at the shelter tent’s apex above all our heads. It plays the breakdown from every angle, accompanied by live commentary. First comes a deep whine, then a spear of pressured mist breaking through Boston’s seawall. Rapid growth from needle thin spikes of water to spiderweb cracks. A network of black spread over concrete, and freeze-frame there.</p>\n<p>They’re calling it unprecedented. It’s become our country’s favorite word. A guy walks between our cots, offering each of us a refill from his chrome thermos. He looks confused yet determined, young enough to be a Harvard undergrad, coming out to volunteer and help the new climate refugees that huddle in the mandated shelters on his campus. We’re a couple blocks from where the flooding occurred and yet Cambridge is absolutely dry.</p>\n<p>“She’s sad again,” Aluna says, like I can’t hear the dog’s cries for myself. It’s an incessant whimper from a few cots down, battling the mutters of a human trying to shut their pet up. If Aluna had her way she’d know the puppy’s name, who is looking out for her, the neighbors beside them who will have to endure her cries. She peers about the tent and watches as much as she can.</p>\n<p>Since our apartment flooded, my work instruments have been reduced to a loan computer from the company. By the time Aluna and I realized what was happening, our floor swam beneath saltwater. She splayed her arms across the dining table and scooped up a swath of our electronics like a squirrel. Saving what she thought was most important to us, though in real-time, as crisis plays out, that’s so much harder to gauge. You can’t ever be sure of what’s supposed to matter. You grow up with all those educational vids about what to do, how to save yourself, and yet when evacuation sirens blare across the neighborhood all thoughts vacate. Most of us aren’t built for catastrophe.</p>\n<p>I unroll my computer, laying it on my lap. My supervisor has given me some leeway with sign-on times for work due to, well, everything—but I still feel uncomfortable catching up on team messages thirty minutes late. I never imagined that being a climate victim would be so embarrassing. Aluna and I lived in a good neighborhood, made decent money, and were much more used to watching disaster rather than being a part of it. After the seawall breach, I didn’t know what to tell my boss except that it happened, that I wouldn’t wait and burn PTO, that I’d log on as always and work admin. Not out of loyalty to the brand, but to a lifestyle I wasn’t prepared to abandon. Besides, Aluna and I need the money. We haven’t touched our savings yet and we wanna keep it that way, so the work pays for the little things that patch our days together—like walking off campus to purchase snacks from the grocery store. Aluna buys cheap things to distribute among the children here. Her way of keeping up routine as a teacher, since most local schools are temporarily closed and she wouldn’t be much help conducting class from a refugee tent regardless.</p>\n<p>My team’s been talking about the disaster all morning, filling up our text channel with questions and reports on how bad Boston’s been hit. <i>Bickering everywhere</i>, Garrett says, <i>maintenance pointing fingers at the original construction firm, mayor’s scrambling. Good thing is no fingers pointed our way yet but.. Bottom line is the wall should’ve never failed.</i></p>\n<p>Unprecedented, unprecedented.</p>\n<p>Manager claims he doesn’t have much for me to do right now. Our division at Centra isn’t taking the brunt of the heat, none of the inquiries about damaged property or when the neighborhoods might be “fixed”—as if we can cast a spell and suck the ocean back in place. It’s hard to not glance at other refugees (a word I still find so strange to use here, so near my home) who either tap away on their own devices or blink through screens on their internal retina displays. I wonder which of them are filing the next complaint to the company I work for, and if I might swallow enough pride to do so myself. We all seem the type to be ashamed of this all, how we’re good enough to own multiple devices and line the cots with sets of clothes saved from the water, and yet none of us are second-home rich. Not enough resources to avoid the tents, but just enough to feel bad using them.</p>\n<p>Admin tasks are the majority of my workload at Centra. Garrett and I are specifically in charge of benefits paperwork for the employees working under our relocation division, a reasonable job since the company keeps that section small. While Centra brands itself in all the climate net corporation tropes—commercials aglow with green fields, wind turbines swaying against sunset—the refugee relocation programs we helm are a side gig. That’s how it is with climate nets, a bit of a trend for corporations eager for a brand cleanup. Shove a random percentage of the budget to securing rent-controlled housing in northern, inland cities shielded from the typical forms of climate catastrophe, then offer up leases to a portion of the newly homeless. Great PR, makes the government happy that we do their work for them, and it provides everyone forced to live in tents a shard of hope.</p>\n<p>A couple hours into my work day, Aluna rests a small bag of potato chips on my shoulder and kisses my cheek. She’s fond of a greeting with food involved because I’d probably forget to eat otherwise. As she takes a spot on the bed next to me, Aluna glances at the computer in my lap.</p>\n<p>“You think Centra’s gonna put us up in a loft or something a little more? Maybe a whole house. They’ve got space out in Colorado or wherever for giving us some land, don’t you think? Full patio, a yard neither of us will know what to do with.”</p>\n<p>“No thinking for me, love.” I dance my fingertips across the screen. “Only typing.”</p>\n<p>Aluna grabs the bag of chips before they slide from my shoulder, opening them as she scoots closer. “Liar. You just don’t wanna tell me our spot in the queue, don’t deny it.”</p>\n<p>Wherever we’re at, it’s probably so far down we shouldn’t think about it. Company gossip has gotten more frantic as it seems that our relocation system has ground to a halt. Centra’s been skimming people off the climate net division and nobody’s left the Cambridge tents with a golden ticket. You’d know if someone got a way out, the excitement and rush they’d fail to hide, but nobody here has escaped.</p>\n<p>Something we’ve said snared the attention of the man who sleeps a cot away from us. He leans forward, locking eyes with me. His blazer hasn’t come off the whole week and it’s acquired a film of dust.</p>\n<p>“Hey, I heard ‘queue.’ Can you check my status? Is there a way you can look at that?”</p>\n<p>With a grimace, I shake my head.</p>\n<p>“Sorry, doesn’t work that way. I couldn’t show you the odds if I wanted to. There’s no access to relocation logs from my department.”</p>\n<p>“Damn. Come on, really?” He hugs himself. “If you want me to pay for it, I will. Name your price. Money’s not a problem, trust me. I’m supposed to be out of here in a few days anyway, I just want to see the queue for a plan B.”</p>\n<p>“I don’t work relocation, has nothing to do with me. Like I said, I’m sorry—I really would, but there’s nothing I can do. We all gotta wait.”</p>\n<p>“Everyone’s fucking waiting. That all we’re supposed to do now? Those guys who got flooded in Miami, too, just sitting there.” The man squats, eyes locked on the rubber mat below us, a kindergarten sky blue. “Nobody’s moving anymore. When’s the last time you heard someone get the golden ticket? Who’s being whisked away to safe cities? Because I don’t know anybody.”</p>\n<p>It’s not that he’s wrong, it’s just that I have nothing to say about it. There’s nothing I could say that would fix this. As the man leaves us with the ghost of his cologne, Aluna gives my hand a brief squeeze, a pulse.</p>\n<p>And at night, that dog starts whining more. I could turn on my night vision, but instead I lay in the dark with Aluna wedged by me, still dreaming, sharing the cot’s limited real estate. Around me are rustling blankets, murmurs. Pointless, flitting. These limp sounds rise with the dog’s whimpers, a cross-species call and response.</p>\n<p>I think I can find a relative peace again. At least one strong enough to drift back asleep, salvage some scraps of rest before the day starts. My eyes are shut against the tent’s collective discomfort. It’s the most solitude I’m capable of carving out for myself, and for the past week it has been enough. Enough against the same sighs, the coughs, the sobs that should’ve never traveled so well across this space.</p>\n<p>The dog’s whining swoops up an octave. I’ve never heard her so distressed—beyond distressed. A shimmering yelp scraping against my eardrums, forcing me upright. Aluna’s hands scramble up my forearm and feel out my skin. There’s nothing left except for the dog and that howl, a guttural pain.</p>\n<p>Then she’s done. One more bark, cut short and high. She’s left us in silence undercut by shifting blankets. Our neighbors freeze and look about for the source of disruption, as if pinpointing it all might let us drift back to sleep. As if we won’t all sink back to our cots, turn along the taut stretches of nylon, curl around our partners and ourselves to find a steady beat again, something like the mattress you lost back home under tons of seawater, something that was once warm with you and whoever shared life with you. But it won’t be enough to sleep.</p>\n<p>When the morning comes, Aluna returns to bed. I hadn’t realized she left.</p>\n<p>“She’s okay,” Aluna says, “but shaken. Someone tried to strangle her last night, right here. We think it’s one of us.”</p>\n<p>Everyone is much too awake. People glare at their neighbors, at the ceiling. In their little movements is stored all the dread that has no legitimate avenue for escape. Our urge for relief isn’t new, though it’s become painfully visible.</p>\n<p>My work chat is a repeat of yesterday, gossip about whose heads are on the chopping block. Talk of a “rapid retreat” from upper echelons that none of us know how to interpret. I can’t vent to Aluna no matter how much I’d like to, not in front of the other refugees.</p>\n<p>She drifts back and forth, out into town, buying snacks for the children and a treat for the dog. This is the first time her offers are rejected. From afar, I see parents push her away. Gentle shakes of the head, hands rising up. She’s too far for me to hear how she responds.</p>\n<p>***</p>\n<p>I suggest we leave at sunset. She doesn’t know how to take that. We’re exchanging messages over internal displays, eating the rations they’ve started handing out for lunch. Aluna would <i>wait and see</i> as she put it, staying in the shelter, till the next disaster forced us to relocate again. This is no home and yet she can barely imagine leaving it. Maybe it’s the proximity to what we lost that keeps her tethered. Cambridge’s parks, rowhouses, and stores provide a familiar urban texture, and when you drift far enough from the tents it succeeds in lulling you back to normality. It’s delusional. I work where the miracles are made, and the only thing Centra is concerned about is laying people off and minimizing damage for the PR fallout of the broken seawall—a tragedy that they refuse to claim as their responsibility, taking all distancing measures available. It will grow clearer over the coming days that there is no help on the way. Not for any of us. We have to leave the city.</p>\n<p><i>And where would we go?</i> Aluna asks. She already mentioned us hitting up friends who live near Cambridge, ones who haven’t experienced climate failure outside of the dearth of food lining the shelves. We’ve held off because that shame flares up. None of our community has the bandwidth for that type of support no matter how much we wish they could provide it. They ask us what happened, if we’re alright, how they might help, and we dodge each question enough to allow them an out. They always take it.</p>\n<p>We can’t go to them, not now. While Boston as a whole might be running relatively fine, the pockets where they’ve shoved us will soon boil over. I sigh and send Aluna a message. Even though we’re sitting across from each other, I find a way to avoid her eyes.</p>\n<p><i>There’s a spot little less than an hour out of town owned by Centra. Part of their data infrastructure, and it’s quiet. We don’t need to be there for long… Just give it time for things to settle over here, a few days at most—the SUV will hold its charge, so we won’t have any problems coming in and out. A mini-retreat?</i></p>\n<p>She doesn’t even crack a smile. Right before dinner, we get up and leave. Just like that. There’s nothing for us to bring along. All that’s left of our submerged home is in our SUV, sitting beneath platinum LED streetlights.</p>\n<p>Autopilot’s enabled for this region, though I’m quick to shut it off. The highway’s riddled with flooding issues now, and I doubt the car could keep up.</p>\n<p>As we exit the parking lot and get on the road, Aluna and I pass the low, inflated lozenges of the refugee tents, pinned to the soil with near-invisible lines of rope. Nearly biological in their aversion to clean, sharp angles, growing out of the flat campus lawns like massive fungi. Logos adorn the sides, all the entities responsible for erecting this crisis architecture. Centra’s branding appears on the tent as a circle adorned with light rays, a flat design vision of a glowing sun. In the encroaching murk, it can’t be easily defined. The sun seems to waver in the shadows, like a pinned spider flat against the outer wall.</p>\n<p>***</p>\n<p>There was once a time—probably late ’50s, early ’60s—when vehicular windshield HUDs were an inescapable trend of automotive design. Glowing, transparent skins hemmed glass borders, providing location-specific updates, weather, and navigation tips. By then, every other American had a retina display, though the AR novelty of these car HUDs was pushed as if it were cutting edge. At its core, the overlays are candy-colored, highly restricted web browsers tacked to the front of our vehicles. “Futuristic” was the word that nobody wanted to use, and yet guided every step of the design process. The HUDs exist because, as we near the end of the century, they seem like they should.</p>\n<p>The glyphs and readouts bordering my windshield begin to disappear. First it’s the weather icon, a cloud eclipsing a crescent moon, winking out. Then all the stats about the car battery. That one’s especially ironic since you’d assume the SUV’s drawing on local, in-vehicle data. Just like all the other visuals drifting away, it warns me of NO INTERNET CONNECTION before vanishing.</p>\n<p>We’ve split from I-90 onto a lone road that twists away from the city, away from the gleam of retina-enhanced billboards that outshine tent villages sprawled beneath overpasses. Density gets a lot lighter out here. Autumn foliage flanks us on either side, swimming up to high focus in the titanium pools of our headlights. It’s been almost half an hour since we passed another car.</p>\n<p>“If you don’t know where we’re going,” Aluna mutters, “you might want to turn back, Imani. GPS is about to go out.”</p>\n<p>That’s concerning. It’s one of the few visuals remaining on the windshield. I squeeze her thigh.</p>\n<p>“It’s not far love. I’ll get us there. Trust me, it’s exactly the right place for us to lay low. There’ll be better connection in the barn too, so we can keep track of how things play out in town. When it seems a bit safer we can drive back in.”</p>\n<p>“Why would the barn have good connection if it’s abandoned?”</p>\n<p>“These things never go fully dead.” I keep an eye out for our turn. “That said, though, Centra’s moved most of their servers elsewhere, further inland. They think they’re future proofing. All this one’s used for now is cold storage, backups of backups.”</p>\n<p>I’ve got no doubt it has to do with the sunk-cost fallacy. Decades ago Centra spent millions to get the server farm up and running, and they can’t bear wiping the whole thing out. Funny how risk averse these corporations get in the face of unstable environmental conditions.</p>\n<p>“Look,” I say, pointing at the growing lights on the horizon, a fluorescent wash against overcast. “That’s the suburb around the corner from it. Not much longer.”</p>\n<p>“Good ’cause we got no reception <i>at all </i>now.”</p>\n<p>Aluna’s stare hits that middle space, out of focus. She’s accessing her retinal screen and judging from the grimace, she’s not liking what she sees.</p>\n<p>“Imani? This isn’t right. No connection whatsoever, we’re completely in the dark. Is there a dampener or something?”</p>\n<p>“I’m… not sure. I don’t know why there’d be one active around here.”</p>\n<p>Rising over the canopy is a gas station sign, blaring out to the night. I can’t help slowing past, getting a closer look at the metal bars meshing the windows and door. They’ve got a drone hovering at the entrance, hardened edges and matte black finish implying combat. The few cars in the parking lot give off the same energy. Tints and acute angles. I’m half-convinced we’ll glimpse an insignia of some sort, hopefully one of a private military firm instead of a paramilitary group, like the ethnostate bands that crawl through the Pacific Northwest.</p>\n<p>The homes out here are different too. Most of us try to avoid traveling via highway, so the suburbs have become a rare occurrence in our lives. Last time I passed through was maybe a year and a half ago, and the two-story homes were adorned with the typical New England fanfare of ivy and wrought iron. A handsome weariness. Last time I came through, the internet worked. Now it’s all dark. Bars mesh over every window. It’s a stretch to call this a neighborhood, this collection of fortresses tucked away at the end of winding driveways, peeking through the forest in utter silence. If it were daytime we might even see the antennae they erected to shut down the network. All we’ve got is their absence.</p>\n<p>“We’re okay,” I say, and Aluna doesn’t respond. I turn down the side street marked with the Centra logo, and we creep down a long gravel path.</p>\n<p>***</p>\n<p>It’s called the barn because it’s a massive, ugly, hulking structure that carves up the forest with gray paneling and harsh floodlights. The electrified gate swings open once it recognizes me and allows us to approach the dead server farm. Maybe not the right word there, dead. The building’s humming with vibrations and light. While there are potholes eating their way across the asphalt, and there’s not a single other car in the area, the place is still on.</p>\n<p>Once we drive past the threshold, the car’s HUD returns in a flicker. Our connection piggybacks on Centra’s network. Aluna settles in the passenger seat.</p>\n<p>“I’m checking the news.”</p>\n<p>I park near the barn’s main entrance, two glass padlocked doors. Judging from the imagery of server farms I’ve seen back in the day, the aesthetics of these buildings refuse to change. They remain one step abstracted from a warehouse.</p>\n<p>“We don’t have to stay here for too long,” I say. “Just a night or two. Just to see if things heat up in town or if we’re good.”</p>\n<p>She nods along, but I’m not sure if it’s enough. This feels right to me, getting out, so I have to find a way to swallow the guilt. The last thing Aluna wants is to be far from the community, disengaged with helping in all those small ways. I don’t operate like that. Not to say I don’t care, but when I exchange snacks or provide some clothing, I only feel dread. I’m never doing enough. Aluna might find fulfillment in those acts, or she might hide her fear better than I do. It’s not something I’ve had the urge to figure out until now.</p>\n<p>We lean our seats back as far as they go, crushing the remains of our apartment in the back. Each readjustment brings another plastic creak.</p>\n<p>“Look,” Aluna says, and shares video of Southie. More drone footage, smooth like the camera’s on rails in the sky. The water has already started to lessen. All of our neighborhood’s detritus has mixed in the flood to make the ground invisible. Frothing, dark water, yet so low, getting lower… It feels odd to think of it this way, but the destruction feels pathetic. A quilt drifts from what was once a window. It’s matted with glass and other things, objects I can’t identify no matter how close the zoom gets. Whatever’s been abandoned wades through ruins that we want more than anything to return to.</p>\n<p>I blink away the footage and turn to face Aluna.</p>\n<p>“What do you think?”</p>\n<p>And at first, it seems she might respond as she used to when we slept in a bed together. Aluna opens her mouth and hesitates. Her hand reaches across the cup holders and up my arm, to my collarbone, and finally the dips of my neck.</p>\n<p>“I think we should learn how to be lost. It’s okay, or it’ll have to be. Know what I mean?”</p>\n<p>“Want an honest answer?”</p>\n<p>She nods. I catch her hand in my own, feel where the ring should be. I should’ve asked her already. I bought her a ring, and I don’t know where it might be buried. It could be in this car with us or tumbling down a sewer drain.</p>\n<p>“We shouldn’t be fucked over so fast, Aluna. It’s not supposed to all end so quickly. I always thought there’d be a… I don’t know, a warning? A heads up of some sort. Like, yes, the end’s coming, as it’s been since forever, but here’s a week head start. Or even a day. I don’t know how we wake up and face all of it gone, and whatever. That’s it. We keep going.”</p>\n<p>“I mean, you just said it. It’s always been coming. The warning call’s blared for decades, and we watched it every night. We just thought we’d be lucky.”</p>\n<p>We can’t live off luck. One day soon, we’ll have to find a path forward. It’s not something I can think of now. Now, all I see is Aluna, her cheekbones carved through the data center’s security floodlights. For an hour more, we stay up and watch more footage from back home. The tents are not faring well tonight—actual skirmishes popping up, people who never imagined fighting for survival forced to fend for any resources they can get a handle on. I wish a wake up call didn’t involve people getting hurt.</p>\n<p>By the time we start drifting off, we agree it’s not as bad as it could’ve been. Even from the scattered news footage, it’s clear there are people like Aluna among the tents. Lots of little things resulting in countless points of de-escalation. Though we’ll need more to recreate our homes, it’s a start. I think, next morning, we’ll head back.</p>\n<p>***</p>\n<p>I check the back while Aluna’s fast asleep. The trunk, too. Moving as quietly as possible through years and years of our shit, all of it bursting at the seams and threatening to fall across the parking lot. Every exhale is a puff of mist, and I blink to clear my eyes.</p>\n<p>Journals, clothes, random pieces of silverware, actual physical books, toothpaste, blankets—I bring one out, drape it over Aluna’s body in the passenger seat, then go back to my search.</p>\n<p>I find it wedged on the trunk floor, beneath the corner of a box. It must’ve fallen out of the case. Unmarred, a thin silver ring.</p>\n<p>After scooting back in the driver’s seat, I hover with the ring tucked in my palm. It grows warm there, in the safety of my hand. I don’t ever want to let it go until Aluna’s ready to take it. So I’ll wait till next morning, and see what she says.</p>",
      "content_text": "I wonder what’s taken me so long to pop the question, and why this ritual that’s been performed countless times by so many before me bears down on me like I’m the first woman in history to put a knee to the floor and offer the ring and say the words. She’ll say yes. We talked about it. When we lay beside each other, Aluna gains the power to ease the edge around momentous things, and it’s all in how she finds the right tenor, right whisper, the right circles of pressure to trace along the dips of my neck. I’ve brought all sorts of crises to her before sleep. VR recordings of tragedy filmed that very morning, from hundreds of miles away and through the dissociative lens of a drone’s 360 degree camera. Roaming tent cities trudging across the Sahara that siphon power from abandoned solar panel farms. Ocean slums sprawling off the coasts of Italy, Spain, France, sinking as their fate is decided in boardrooms graced with AC. Sea spray is everywhere it shouldn’t be, and scatters the footage into clouds of discordant pixels—that’s when Aluna pauses our replay, blinks our retinas clear. While the bedroom is at its darkest, we shift to face each other and she tells me what she thinks comes next. Never lessening the blows, but making it all feel approachable, which is exactly how she responded when I asked if we might actually spend the rest of our lives together. And she said yes.\nIt feels like I lost my chance. Tonight marks our first week sleeping on the shelter’s temporary foldout beds. We’d considered my SUV but it’s packed tight with all the remaining fragments of our apartment, the things that survived the flood. We gave it a shot, wedging ourselves between piles of clothing in the front seat, but Aluna couldn’t fall asleep. She didn’t complain once. She made constant shifts in her seat through the night, awkwardly reaching for my body only to be thwarted by the packed detritus of our old home.\nVideo floats at the shelter tent’s apex above all our heads. It plays the breakdown from every angle, accompanied by live commentary. First comes a deep whine, then a spear of pressured mist breaking through Boston’s seawall. Rapid growth from needle thin spikes of water to spiderweb cracks. A network of black spread over concrete, and freeze-frame there.\nThey’re calling it unprecedented. It’s become our country’s favorite word. A guy walks between our cots, offering each of us a refill from his chrome thermos. He looks confused yet determined, young enough to be a Harvard undergrad, coming out to volunteer and help the new climate refugees that huddle in the mandated shelters on his campus. We’re a couple blocks from where the flooding occurred and yet Cambridge is absolutely dry.\n“She’s sad again,” Aluna says, like I can’t hear the dog’s cries for myself. It’s an incessant whimper from a few cots down, battling the mutters of a human trying to shut their pet up. If Aluna had her way she’d know the puppy’s name, who is looking out for her, the neighbors beside them who will have to endure her cries. She peers about the tent and watches as much as she can.\nSince our apartment flooded, my work instruments have been reduced to a loan computer from the company. By the time Aluna and I realized what was happening, our floor swam beneath saltwater. She splayed her arms across the dining table and scooped up a swath of our electronics like a squirrel. Saving what she thought was most important to us, though in real-time, as crisis plays out, that’s so much harder to gauge. You can’t ever be sure of what’s supposed to matter. You grow up with all those educational vids about what to do, how to save yourself, and yet when evacuation sirens blare across the neighborhood all thoughts vacate. Most of us aren’t built for catastrophe.\nI unroll my computer, laying it on my lap. My supervisor has given me some leeway with sign-on times for work due to, well, everything—but I still feel uncomfortable catching up on team messages thirty minutes late. I never imagined that being a climate victim would be so embarrassing. Aluna and I lived in a good neighborhood, made decent money, and were much more used to watching disaster rather than being a part of it. After the seawall breach, I didn’t know what to tell my boss except that it happened, that I wouldn’t wait and burn PTO, that I’d log on as always and work admin. Not out of loyalty to the brand, but to a lifestyle I wasn’t prepared to abandon. Besides, Aluna and I need the money. We haven’t touched our savings yet and we wanna keep it that way, so the work pays for the little things that patch our days together—like walking off campus to purchase snacks from the grocery store. Aluna buys cheap things to distribute among the children here. Her way of keeping up routine as a teacher, since most local schools are temporarily closed and she wouldn’t be much help conducting class from a refugee tent regardless.\nMy team’s been talking about the disaster all morning, filling up our text channel with questions and reports on how bad Boston’s been hit. Bickering everywhere, Garrett says, maintenance pointing fingers at the original construction firm, mayor’s scrambling. Good thing is no fingers pointed our way yet but.. Bottom line is the wall should’ve never failed.\nUnprecedented, unprecedented.\nManager claims he doesn’t have much for me to do right now. Our division at Centra isn’t taking the brunt of the heat, none of the inquiries about damaged property or when the neighborhoods might be “fixed”—as if we can cast a spell and suck the ocean back in place. It’s hard to not glance at other refugees (a word I still find so strange to use here, so near my home) who either tap away on their own devices or blink through screens on their internal retina displays. I wonder which of them are filing the next complaint to the company I work for, and if I might swallow enough pride to do so myself. We all seem the type to be ashamed of this all, how we’re good enough to own multiple devices and line the cots with sets of clothes saved from the water, and yet none of us are second-home rich. Not enough resources to avoid the tents, but just enough to feel bad using them.\nAdmin tasks are the majority of my workload at Centra. Garrett and I are specifically in charge of benefits paperwork for the employees working under our relocation division, a reasonable job since the company keeps that section small. While Centra brands itself in all the climate net corporation tropes—commercials aglow with green fields, wind turbines swaying against sunset—the refugee relocation programs we helm are a side gig. That’s how it is with climate nets, a bit of a trend for corporations eager for a brand cleanup. Shove a random percentage of the budget to securing rent-controlled housing in northern, inland cities shielded from the typical forms of climate catastrophe, then offer up leases to a portion of the newly homeless. Great PR, makes the government happy that we do their work for them, and it provides everyone forced to live in tents a shard of hope.\nA couple hours into my work day, Aluna rests a small bag of potato chips on my shoulder and kisses my cheek. She’s fond of a greeting with food involved because I’d probably forget to eat otherwise. As she takes a spot on the bed next to me, Aluna glances at the computer in my lap.\n“You think Centra’s gonna put us up in a loft or something a little more? Maybe a whole house. They’ve got space out in Colorado or wherever for giving us some land, don’t you think? Full patio, a yard neither of us will know what to do with.”\n“No thinking for me, love.” I dance my fingertips across the screen. “Only typing.”\nAluna grabs the bag of chips before they slide from my shoulder, opening them as she scoots closer. “Liar. You just don’t wanna tell me our spot in the queue, don’t deny it.”\nWherever we’re at, it’s probably so far down we shouldn’t think about it. Company gossip has gotten more frantic as it seems that our relocation system has ground to a halt. Centra’s been skimming people off the climate net division and nobody’s left the Cambridge tents with a golden ticket. You’d know if someone got a way out, the excitement and rush they’d fail to hide, but nobody here has escaped.\nSomething we’ve said snared the attention of the man who sleeps a cot away from us. He leans forward, locking eyes with me. His blazer hasn’t come off the whole week and it’s acquired a film of dust.\n“Hey, I heard ‘queue.’ Can you check my status? Is there a way you can look at that?”\nWith a grimace, I shake my head.\n“Sorry, doesn’t work that way. I couldn’t show you the odds if I wanted to. There’s no access to relocation logs from my department.”\n“Damn. Come on, really?” He hugs himself. “If you want me to pay for it, I will. Name your price. Money’s not a problem, trust me. I’m supposed to be out of here in a few days anyway, I just want to see the queue for a plan B.”\n“I don’t work relocation, has nothing to do with me. Like I said, I’m sorry—I really would, but there’s nothing I can do. We all gotta wait.”\n“Everyone’s fucking waiting. That all we’re supposed to do now? Those guys who got flooded in Miami, too, just sitting there.” The man squats, eyes locked on the rubber mat below us, a kindergarten sky blue. “Nobody’s moving anymore. When’s the last time you heard someone get the golden ticket? Who’s being whisked away to safe cities? Because I don’t know anybody.”\nIt’s not that he’s wrong, it’s just that I have nothing to say about it. There’s nothing I could say that would fix this. As the man leaves us with the ghost of his cologne, Aluna gives my hand a brief squeeze, a pulse.\nAnd at night, that dog starts whining more. I could turn on my night vision, but instead I lay in the dark with Aluna wedged by me, still dreaming, sharing the cot’s limited real estate. Around me are rustling blankets, murmurs. Pointless, flitting. These limp sounds rise with the dog’s whimpers, a cross-species call and response.\nI think I can find a relative peace again. At least one strong enough to drift back asleep, salvage some scraps of rest before the day starts. My eyes are shut against the tent’s collective discomfort. It’s the most solitude I’m capable of carving out for myself, and for the past week it has been enough. Enough against the same sighs, the coughs, the sobs that should’ve never traveled so well across this space.\nThe dog’s whining swoops up an octave. I’ve never heard her so distressed—beyond distressed. A shimmering yelp scraping against my eardrums, forcing me upright. Aluna’s hands scramble up my forearm and feel out my skin. There’s nothing left except for the dog and that howl, a guttural pain.\nThen she’s done. One more bark, cut short and high. She’s left us in silence undercut by shifting blankets. Our neighbors freeze and look about for the source of disruption, as if pinpointing it all might let us drift back to sleep. As if we won’t all sink back to our cots, turn along the taut stretches of nylon, curl around our partners and ourselves to find a steady beat again, something like the mattress you lost back home under tons of seawater, something that was once warm with you and whoever shared life with you. But it won’t be enough to sleep.\nWhen the morning comes, Aluna returns to bed. I hadn’t realized she left.\n“She’s okay,” Aluna says, “but shaken. Someone tried to strangle her last night, right here. We think it’s one of us.”\nEveryone is much too awake. People glare at their neighbors, at the ceiling. In their little movements is stored all the dread that has no legitimate avenue for escape. Our urge for relief isn’t new, though it’s become painfully visible.\nMy work chat is a repeat of yesterday, gossip about whose heads are on the chopping block. Talk of a “rapid retreat” from upper echelons that none of us know how to interpret. I can’t vent to Aluna no matter how much I’d like to, not in front of the other refugees.\nShe drifts back and forth, out into town, buying snacks for the children and a treat for the dog. This is the first time her offers are rejected. From afar, I see parents push her away. Gentle shakes of the head, hands rising up. She’s too far for me to hear how she responds.\n***\nI suggest we leave at sunset. She doesn’t know how to take that. We’re exchanging messages over internal displays, eating the rations they’ve started handing out for lunch. Aluna would wait and see as she put it, staying in the shelter, till the next disaster forced us to relocate again. This is no home and yet she can barely imagine leaving it. Maybe it’s the proximity to what we lost that keeps her tethered. Cambridge’s parks, rowhouses, and stores provide a familiar urban texture, and when you drift far enough from the tents it succeeds in lulling you back to normality. It’s delusional. I work where the miracles are made, and the only thing Centra is concerned about is laying people off and minimizing damage for the PR fallout of the broken seawall—a tragedy that they refuse to claim as their responsibility, taking all distancing measures available. It will grow clearer over the coming days that there is no help on the way. Not for any of us. We have to leave the city.\nAnd where would we go? Aluna asks. She already mentioned us hitting up friends who live near Cambridge, ones who haven’t experienced climate failure outside of the dearth of food lining the shelves. We’ve held off because that shame flares up. None of our community has the bandwidth for that type of support no matter how much we wish they could provide it. They ask us what happened, if we’re alright, how they might help, and we dodge each question enough to allow them an out. They always take it.\nWe can’t go to them, not now. While Boston as a whole might be running relatively fine, the pockets where they’ve shoved us will soon boil over. I sigh and send Aluna a message. Even though we’re sitting across from each other, I find a way to avoid her eyes.\nThere’s a spot little less than an hour out of town owned by Centra. Part of their data infrastructure, and it’s quiet. We don’t need to be there for long… Just give it time for things to settle over here, a few days at most—the SUV will hold its charge, so we won’t have any problems coming in and out. A mini-retreat?\nShe doesn’t even crack a smile. Right before dinner, we get up and leave. Just like that. There’s nothing for us to bring along. All that’s left of our submerged home is in our SUV, sitting beneath platinum LED streetlights.\nAutopilot’s enabled for this region, though I’m quick to shut it off. The highway’s riddled with flooding issues now, and I doubt the car could keep up.\nAs we exit the parking lot and get on the road, Aluna and I pass the low, inflated lozenges of the refugee tents, pinned to the soil with near-invisible lines of rope. Nearly biological in their aversion to clean, sharp angles, growing out of the flat campus lawns like massive fungi. Logos adorn the sides, all the entities responsible for erecting this crisis architecture. Centra’s branding appears on the tent as a circle adorned with light rays, a flat design vision of a glowing sun. In the encroaching murk, it can’t be easily defined. The sun seems to waver in the shadows, like a pinned spider flat against the outer wall.\n***\nThere was once a time—probably late ’50s, early ’60s—when vehicular windshield HUDs were an inescapable trend of automotive design. Glowing, transparent skins hemmed glass borders, providing location-specific updates, weather, and navigation tips. By then, every other American had a retina display, though the AR novelty of these car HUDs was pushed as if it were cutting edge. At its core, the overlays are candy-colored, highly restricted web browsers tacked to the front of our vehicles. “Futuristic” was the word that nobody wanted to use, and yet guided every step of the design process. The HUDs exist because, as we near the end of the century, they seem like they should.\nThe glyphs and readouts bordering my windshield begin to disappear. First it’s the weather icon, a cloud eclipsing a crescent moon, winking out. Then all the stats about the car battery. That one’s especially ironic since you’d assume the SUV’s drawing on local, in-vehicle data. Just like all the other visuals drifting away, it warns me of NO INTERNET CONNECTION before vanishing.\nWe’ve split from I-90 onto a lone road that twists away from the city, away from the gleam of retina-enhanced billboards that outshine tent villages sprawled beneath overpasses. Density gets a lot lighter out here. Autumn foliage flanks us on either side, swimming up to high focus in the titanium pools of our headlights. It’s been almost half an hour since we passed another car.\n“If you don’t know where we’re going,” Aluna mutters, “you might want to turn back, Imani. GPS is about to go out.”\nThat’s concerning. It’s one of the few visuals remaining on the windshield. I squeeze her thigh.\n“It’s not far love. I’ll get us there. Trust me, it’s exactly the right place for us to lay low. There’ll be better connection in the barn too, so we can keep track of how things play out in town. When it seems a bit safer we can drive back in.”\n“Why would the barn have good connection if it’s abandoned?”\n“These things never go fully dead.” I keep an eye out for our turn. “That said, though, Centra’s moved most of their servers elsewhere, further inland. They think they’re future proofing. All this one’s used for now is cold storage, backups of backups.”\nI’ve got no doubt it has to do with the sunk-cost fallacy. Decades ago Centra spent millions to get the server farm up and running, and they can’t bear wiping the whole thing out. Funny how risk averse these corporations get in the face of unstable environmental conditions.\n“Look,” I say, pointing at the growing lights on the horizon, a fluorescent wash against overcast. “That’s the suburb around the corner from it. Not much longer.”\n“Good ’cause we got no reception at all now.”\nAluna’s stare hits that middle space, out of focus. She’s accessing her retinal screen and judging from the grimace, she’s not liking what she sees.\n“Imani? This isn’t right. No connection whatsoever, we’re completely in the dark. Is there a dampener or something?”\n“I’m… not sure. I don’t know why there’d be one active around here.”\nRising over the canopy is a gas station sign, blaring out to the night. I can’t help slowing past, getting a closer look at the metal bars meshing the windows and door. They’ve got a drone hovering at the entrance, hardened edges and matte black finish implying combat. The few cars in the parking lot give off the same energy. Tints and acute angles. I’m half-convinced we’ll glimpse an insignia of some sort, hopefully one of a private military firm instead of a paramilitary group, like the ethnostate bands that crawl through the Pacific Northwest.\nThe homes out here are different too. Most of us try to avoid traveling via highway, so the suburbs have become a rare occurrence in our lives. Last time I passed through was maybe a year and a half ago, and the two-story homes were adorned with the typical New England fanfare of ivy and wrought iron. A handsome weariness. Last time I came through, the internet worked. Now it’s all dark. Bars mesh over every window. It’s a stretch to call this a neighborhood, this collection of fortresses tucked away at the end of winding driveways, peeking through the forest in utter silence. If it were daytime we might even see the antennae they erected to shut down the network. All we’ve got is their absence.\n“We’re okay,” I say, and Aluna doesn’t respond. I turn down the side street marked with the Centra logo, and we creep down a long gravel path.\n***\nIt’s called the barn because it’s a massive, ugly, hulking structure that carves up the forest with gray paneling and harsh floodlights. The electrified gate swings open once it recognizes me and allows us to approach the dead server farm. Maybe not the right word there, dead. The building’s humming with vibrations and light. While there are potholes eating their way across the asphalt, and there’s not a single other car in the area, the place is still on.\nOnce we drive past the threshold, the car’s HUD returns in a flicker. Our connection piggybacks on Centra’s network. Aluna settles in the passenger seat.\n“I’m checking the news.”\nI park near the barn’s main entrance, two glass padlocked doors. Judging from the imagery of server farms I’ve seen back in the day, the aesthetics of these buildings refuse to change. They remain one step abstracted from a warehouse.\n“We don’t have to stay here for too long,” I say. “Just a night or two. Just to see if things heat up in town or if we’re good.”\nShe nods along, but I’m not sure if it’s enough. This feels right to me, getting out, so I have to find a way to swallow the guilt. The last thing Aluna wants is to be far from the community, disengaged with helping in all those small ways. I don’t operate like that. Not to say I don’t care, but when I exchange snacks or provide some clothing, I only feel dread. I’m never doing enough. Aluna might find fulfillment in those acts, or she might hide her fear better than I do. It’s not something I’ve had the urge to figure out until now.\nWe lean our seats back as far as they go, crushing the remains of our apartment in the back. Each readjustment brings another plastic creak.\n“Look,” Aluna says, and shares video of Southie. More drone footage, smooth like the camera’s on rails in the sky. The water has already started to lessen. All of our neighborhood’s detritus has mixed in the flood to make the ground invisible. Frothing, dark water, yet so low, getting lower… It feels odd to think of it this way, but the destruction feels pathetic. A quilt drifts from what was once a window. It’s matted with glass and other things, objects I can’t identify no matter how close the zoom gets. Whatever’s been abandoned wades through ruins that we want more than anything to return to.\nI blink away the footage and turn to face Aluna.\n“What do you think?”\nAnd at first, it seems she might respond as she used to when we slept in a bed together. Aluna opens her mouth and hesitates. Her hand reaches across the cup holders and up my arm, to my collarbone, and finally the dips of my neck.\n“I think we should learn how to be lost. It’s okay, or it’ll have to be. Know what I mean?”\n“Want an honest answer?”\nShe nods. I catch her hand in my own, feel where the ring should be. I should’ve asked her already. I bought her a ring, and I don’t know where it might be buried. It could be in this car with us or tumbling down a sewer drain.\n“We shouldn’t be fucked over so fast, Aluna. It’s not supposed to all end so quickly. I always thought there’d be a… I don’t know, a warning? A heads up of some sort. Like, yes, the end’s coming, as it’s been since forever, but here’s a week head start. Or even a day. I don’t know how we wake up and face all of it gone, and whatever. That’s it. We keep going.”\n“I mean, you just said it. It’s always been coming. The warning call’s blared for decades, and we watched it every night. We just thought we’d be lucky.”\nWe can’t live off luck. One day soon, we’ll have to find a path forward. It’s not something I can think of now. Now, all I see is Aluna, her cheekbones carved through the data center’s security floodlights. For an hour more, we stay up and watch more footage from back home. The tents are not faring well tonight—actual skirmishes popping up, people who never imagined fighting for survival forced to fend for any resources they can get a handle on. I wish a wake up call didn’t involve people getting hurt.\nBy the time we start drifting off, we agree it’s not as bad as it could’ve been. Even from the scattered news footage, it’s clear there are people like Aluna among the tents. Lots of little things resulting in countless points of de-escalation. Though we’ll need more to recreate our homes, it’s a start. I think, next morning, we’ll head back.\n***\nI check the back while Aluna’s fast asleep. The trunk, too. Moving as quietly as possible through years and years of our shit, all of it bursting at the seams and threatening to fall across the parking lot. Every exhale is a puff of mist, and I blink to clear my eyes.\nJournals, clothes, random pieces of silverware, actual physical books, toothpaste, blankets—I bring one out, drape it over Aluna’s body in the passenger seat, then go back to my search.\nI find it wedged on the trunk floor, beneath the corner of a box. It must’ve fallen out of the case. Unmarred, a thin silver ring.\nAfter scooting back in the driver’s seat, I hover with the ring tucked in my palm. It grows warm there, in the safety of my hand. I don’t ever want to let it go until Aluna’s ready to take it. So I’ll wait till next morning, and see what she says.",
      "date_published": "2022-05-10T22:46:29.000Z",
      "date_modified": "2022-05-10T22:46:29.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/agile-and-the-long-crisis-of-software",
      "url": "https://logicmag.io/clouds/agile-and-the-long-crisis-of-software",
      "title": "Agile and the Long Crisis of Software",
      "summary": "An investigation into everybody’s favorite way to build software.",
      "content_html": "<p>I first encountered Agile when I got a job in a library. I’d been hired to help get a new digital scholarship center off the ground and sometimes worked with the library’s software development team to build tools to support our projects. There were about six members of this team, and I noticed right away that they did things differently from the non-technical staff. At meetings, they didn’t talk about product features, but “user stories”—tiny narratives that described features—to which they assigned “story points” that measured the effort involved in completing the associated tasks. They met every morning for “standup,” a meeting literally conducted standing up, the better to enforce brevity. A whiteboard had pride of place in their workspace, and I watched the developers move Post-it notes across the board to signify their state of completion. They worked in “sprints,” two-week stretches devoted to particular tasks.</p>\n<p>At meetings with the rest of us on the library staff, the head of the development team reported on progress using software that included a dashboard indicating the state of every project. The manager could also show us a graph of the team’s “velocity,” the rate at which the developers finished their tasks, complete with historical comparisons and projections. </p>\n<p>This was Agile, I learned, a method for managing software development that had achieved enormous popularity in technical workplaces of all kinds—and, increasingly, even non-technical workplaces (including, as one TED speaker would have it, the family home). Honestly, I was impressed. In my own work, I often felt as though I was flailing around, never quite sure if I was making progress or doing anything of real value. The developers, in contrast, seemed to know exactly what they were doing. If they ran into a roadblock, it was no big deal; they just dealt with it. They expected requirements to change as they progressed, and the two-week time horizons allowed them to substitute one feature for another, or adopt a new framework, without starting all over from scratch.</p>\n<p>That’s the beauty of Agile: designed for ultimate flexibility and speed, it requires developers to break every task down into the smallest possible unit. The emphasis is on getting releases out fast and taking frequent stock, changing directions as necessary.</p>\n<p>I was intrigued; Agile was different from anything I’d experienced before. Where had it come from, and why?</p>\n<p>I began to explore the history of Agile. What I discovered was a long-running wrestling match between what managers want software development to be and what it really is, as practiced by the workers who write the code. Time and again, organizations have sought to contain software’s most troublesome tendencies—its habit of sprawling beyond timelines and measurable goals—by introducing new management styles. And for a time, it looked as though companies had found in Agile the solution to keeping developers happily on task while also working at a feverish pace. Recently, though, some signs are emerging that Agile’s power may be fading. A new moment of reckoning is in the making, one that may end up knocking Agile off its perch.</p>\n<h1><b>Turning Weirdos into Engineers</b></h1>\n<p>Software development was in crisis even before the word “software” was coined. At a 1954 conference convened by leaders in industry, government, and academia at Wayne State University in Detroit, experts warned of an imminent shortage of trained programmers. The use of the term “software” to mean application programming first appeared in print in an article by statistician John W. Tukey four years later. By the mid-1960s, at least a hundred thousand people worked as programmers in the United States, but commentators estimated an immediate demand for fifty thousand more.</p>\n<p>In the first decades of the programming profession, most experts assumed that formulating computer-readable directions would be a relatively trivial job. After all, the system analysts—the experts who specify the high-level architecture—had already done the hard intellectual work of designing the program and hardware. The job of the coder was simply to translate that design into something a computer could work with. It was a surprise, then, when it turned out that this process of translation was in fact quite intellectually demanding. </p>\n<p>The nature of these intellectual demands, along with the larger question of what kind of work software development actually is, continues to baffle managers today. In the computer’s early years, it seemed to some people that coding was, or should be, a matter of pure logic; after all, machines just do what you tell them to do. There was, self-evidently, a formally correct way to do things, and the coder’s job was simply to find it. </p>\n<p>And yet, the actual experience of programming suggested that coding was as much art as science. Some of the most advanced programming, as Clive Thompson notes in his 2019 book <i>Coders</i>, was pushed forward by long-haired weirdos who hung around university labs after hours, hackers who considered themselves as much artisans as logicians. The fact that one couldn’t physically touch a piece of software—its storage media, perhaps, but not the software itself—made software development more abstract, more mysterious than other engineering fields. Where other fields could be expected to obey the laws of physics, the ground seemed to be constantly shifting under software’s feet. Hardware was perpetually changing its parameters and capabilities. </p>\n<p>Nevertheless, the field of electronic data processing—the automation of office functions, like time cards and payroll—was growing rapidly. The hulking machines designed for the purpose, leased from IBM, quickly became the hallmark of the technologically forward-thinking operation. But they required teams of operators to design the programs, prepare the punch cards, and feed data into the system. Established managers resented the specialized expertise and professional eccentricity of the growing ranks of “computer boys.” They resented, too, that software projects seemed to defy any estimation of cost and complexity. The famed computer scientist Frederick Brooks compared software projects to werewolves: they start out with puppy-like innocence, but, more often than not, they metamorphose into “a monster of missed schedules, blown budgets, and flawed products.” You could say, then, that by the late 1960s, software development was facing three crises: a crying need for more programmers; an imperative to wrangle development into something more predictable; and, as businesses saw it, a managerial necessity to get developers to stop acting so <i>weird</i>. </p>\n<p>It was in this spirit of professionalization that industry leaders encouraged programmers to embrace the mantle of “software engineer,” a development that many historians trace to the NATO Conference on Software Engineering of 1968. Computer work was sprawling, difficult to organize, and notoriously hard to manage, the organizers pointed out. Why not, then, borrow a set of methods (and a title) from the established fields of engineering? That way, programming could become firmly a science, with all the order, influence, and established methodologies that comes with it. It would also, the organizers hoped, become easier for industry to manage: software engineers might better conform to corporate culture, following the model of engineers from other disciplines. “In the interest of efficient software manufacturing,” writes historian Nathan Ensmenger, “the black art of programming had to make way for the science of software engineering.”</p>\n<h1><b>Chasing Waterfalls</b></h1>\n<p>And it worked—sort of. The “software engineering” appellation caught on, rising in prominence alongside the institutional prestige of the people who wrote software. University departments adopted the term, encouraging students to practice sound engineering methodologies, like using mathematical proofs, as they learned to program. The techniques, claimed the computer scientist Tony Hoare, would “transform the arcane and error-prone craft of computer programming to meet the highest standards of the engineering profession.” </p>\n<p>Managers approached with gusto the task of organizing the newly intelligible software labor force, leading to a number of different organization methods. One approach, the Chief Programmer Team (CPT) framework instituted at IBM, put a single “chief programmer” at the head of a hierarchy, overseeing a cadre of specialists whose interactions he oversaw. Another popular approach placed programmers beneath many layers of administrators, who made decisions and assigned work to the programmers under them. </p>\n<p>With these new techniques came a set of ideas for managing development labor, a management philosophy that has come to be called (mostly pejoratively) the “waterfall method.” Waterfall made sense in theory: someone set a goal for a software product and broke its production up into a series of steps, each of which had to be completed and tested before moving on to the next task. In other words, developers followed a script laid out for them by management. </p>\n<p>The term “waterfall,” ironically, made its first appearance in an article indicting the method as unrealistic, but the name and the philosophy caught on nevertheless. Waterfall irresistibly matched the hierarchical corporate structure that administered it. And it appealed to managers because, as Nathan Ensmenger writes, “The essence of the software-engineering movement was control: control over complexity, control over budgets and scheduling, and, perhaps most significantly, control over a recalcitrant workforce.” This was precisely the kind of professional that waterfall development was designed to accommodate.</p>\n<p>But before long, software development was again in crisis—or crises. Part of the problem was keeping up with the need for new computer scientists. Universities in 1980 couldn’t fill the faculty positions necessary to train the huge number of students with ambitions to become software engineers. “This situation seriously threatens the ability of Computer Science departments to continue developing the skilled people needed both by our information processing industry and by an increasingly technological society,” warned the Association for Computing Machinery. </p>\n<p>The industry’s dearth of qualified developers wasn’t its only problem. Software development itself seemed to be struggling. Waterfall’s promise of tightly controlled management was a mirage. No amount of documentation, process, or procedure seemed capable of wrestling development into predictability. Software projects were big, expensive, and they seemed to be spiraling out of control—huge initiatives foundered unfinished as requirements changed and warring project teams bickered about details. Despite managers’ efforts to make software development reliable and predictable, it seemed, if anything, to have only grown more unwieldy. As the computer scientist Jeff Offutt put it, “In the 1960s, programmers built ‘tiny log cabins,’” while “in the 1980s, teams of programmers were building office buildings”—and by the 1990s, skyscrapers. Yet teams of technologists seemed unable to coordinate their work. Peter Varhol, a technology industry consultant, estimates that in the early 1990s, the average application took three years to develop, from idea to finished product. Technology was supposed to make American business smarter, faster, and more profitable, and yet the most respected corporations couldn’t seem to get their projects off the ground.</p>\n<p>The designation of “engineer,” the administrative hierarchies, the careful planning and documentation: all of this had been intended to bring order and control to the emerging field of software development. But it seemed to have backfired. Rather than clearing the way for software developers to build, waterfall gummed up the works with binders of paperwork and endless meetings. </p>\n<p>For their parts, engineers complained of feeling constrained by heavy-handed management techniques. They just wanted to build software. Why were they hamstrung by paperwork? The typical picture of corporate programming in the 1990s is of the existentially bored twenty-somethings in Douglas Coupland’s novel <i>Microserfs</i>, or the desperate developers in Mike Judge’s movie <i>Office Space</i>, whose rage lurks just below the surface.</p>\n<h1><b>Khakis and Dad Jeans</b></h1>\n<p>Enter what may be the world’s most unlikely group of rock stars: seventeen middle-aged white guys, dressed in khakis and dad jeans, all obsessed with management. The now-legendary authors of what came to be called the Agile Manifesto gathered at Utah’s Snowbird ski resort in February 2001 to hammer out a new vision for the software development process. This wasn’t their first meeting; they’d been gathering in various configurations to discuss software development for some time, though, until the 2001 meeting, they hadn’t come up with much to show for it. This time was different. Scrawled on a whiteboard was the Agile Manifesto, a set of values that, in the following years, would become nearly ubiquitous in the management of programmers, from fledgling startups to huge corporations. It’s pleasantly concise:</p>\n<blockquote><p><i>We are uncovering better ways of developing software by doing it and helping others do it.</i></p><p><i>Through this work we have come to value:</i></p><p><b><i>Individuals and interactions</i></b><i> over processes and tools</i></p><p><b><i>Working software </i></b><i>over comprehensive documentation</i></p><p><b><i>Customer collaboration</i></b><i> over contract negotiation</i></p><p><b><i>Responding to change</i></b><i> over following a plan</i></p><p><i>That is, while there is value in the items on the right, we value the items on the left more.</i></p></blockquote>\n<p>The manifesto, supplemented by twelve additional principles, targeted the professional frustrations that engineers described. Waterfall assumed that a software application’s requirements would be stable, and that slowdowns and logjams were the result of deviating from management’s careful plan. Agile tossed out these high-level roadmaps, emphasizing instead the need to make decisions on the fly. This way, software developers themselves could change their approach as requirements or technology changed. They could focus on building software, rather than on paperwork and documentation. And they could eliminate the need for endless meetings. </p>\n<p>It’s an interesting document. Given the shortage of qualified developers, technology professionals might have been expected to demand concessions of more immediate material benefit—say, a union, or ownership of their intellectual property. Instead, they demanded a workplace configuration that would allow them to do better, more efficient work. Indeed, as writer Michael Eby points out, this revolt against management is distinct from some preceding expressions of workplace discontent: rather than demand material improvements, tech workers created “a new ‘spirit,’ based on cultures, principles, assumptions, hierarchies, and ethics that absorbed the complaints of the artistic critique.” That is, the manifesto directly attacked the bureaucracy, infantilization, and sense of futility that developers deplored. Developers weren’t demanding better pay; they were demanding to be treated as different people.</p>\n<h1><b>Organizational Anarchists</b></h1>\n<p>It seems likely that changes in opinions about the nature of software development didn’t take place in 2001 exactly, but in the decade leading up to the authorship of the Agile Manifesto. Consensus was growing—among developers, but also among managers—that software development couldn’t be made to fit the flow-charts and worksheets in which analysts had placed so much hope. Software, as the historian Stuart Shapiro wrote in 1997, is complex in a particularly complex way: the problems are “fuzzy, variable, and multifaceted, and thus rarely proved amenable to any one approach; instead, they demanded hybrid and adaptive solutions.” Not, then, forms and timecards. Moreover, as the workforce of programmers grew by leaps and bounds in the 1990s, companies hired, of necessity, people without formal computer science training. These younger workers likely had less invested in the drive of the 1970s and 1980s to turn software development into a science. The manifesto wasn’t really a shot across the bow: it was more of a punctuation mark, emphasizing years of discontent with prevailing models of corporate management.</p>\n<p>Nevertheless, while Agile had a devoted following, its mandate—the removal of top-down planning and administrative hierarchy—was a risk. It meant management ceding control, at least to some extent, to developers themselves. And most large companies weren’t willing to do that, at least not until the 2010s. Between 2012 and 2015, though, according to the Agile consultancy Planview, more than 50 percent of practicing development teams characterized themselves as “Agile.” </p>\n<p>Doubtless, some of this popularity had to do with the growth of high-speed internet connections, which drastically altered the way software got released. Before, it wasn’t unusual for software to be updated once a year, or at even longer intervals. The fact that updates had to be distributed on physical media like CD-ROMs and floppy disks limited the speed of new releases. But high-speed internet made it possible to push out fixes and features as often as a company wanted, even multiple times a day. Agile made a lot of sense in this environment.</p>\n<p>Facebook’s famous former motto, “Move fast and break things,” captured the spirit of the new era well. It was an era that rewarded audacity, in software development as much as in CEOs. Venture capital firms, on the hunt for “unicorns,” poured record amounts into the technology sector during the 2010s, and they wanted to see results quickly. Competing with startups required the ability to change on a dime, to release constantly, and to develop at breakneck speed. The risk calculus shifted: it now seemed dangerous to stick with waterfall, when Agile promised so much speed.</p>\n<p>Equally, it seems, what it meant to be a software developer had changed. In the 1970s and 1980s, experts held up the systems-minded, logic-loving scientist as the ideal software worker. But over the years, this ideal had failed to take root. The programmers of the 1990s read <i>Wired</i>, not <i>Datamation</i>. If their characteristics can be intuited from the Agile Manifesto, they were intently committed to the highest standards, working quickly and confidently because managers “trust them to get the job done.” They refused to do things just because they’ve always been done that way, turning their minds to “continuous attention to technical excellence.” They weren’t thrown by fluid, fast-moving requirements; instead, they embraced them as an opportunity to “harness change for the customer’s competitive advantage.” </p>\n<p>The image of the free-thinking nonconformist fits the philosophy of Agile. The manifesto’s authors may have looked like textbook engineers, in button-downs with cell-phone holsters, but “a bigger group of organizational anarchists would be hard to find,” according to Jim Highsmith, one of their number. Particularly in the early days, there was a lot of talk about the challenge Agile posed to the traditional management paradigm. Agile’s proponents were proud of this nonconformity: the framework “scares the bejeebers out of traditionalists,” wrote Highsmith in 2001. “Agile was openly, militantly, anti-management in the beginning,” writes the software developer and consultant Al Tenhundfeld. “For example, Ken Schwaber [a manifesto author] was vocal and explicit about his goal to get rid of all project managers.” </p>\n<p>Anti-management, maybe, but not anti-corporate, not really. It’s tempting to see the archetypal Agile developer as a revival of the long-haired countercultural weirdo who lurked around the punch card machines of the late 1960s. But the two personas differ in important respects. The eccentrics of computing’s early years wanted to program for the sheer thrill of putting this new technology to work. The coder of Agile’s imagination is committed, above all, to <i>the project</i>. He hates administrative intrusion because it gets in the way of his greatest aspiration, which is to do his job at the highest level of professional performance. Like the developers in Aaron Sorkin’s <i>The Social Network</i>, he wants most of all to be in “the zone”: headphones on, distractions eliminated, in a state of pure communion with his labor.</p>\n<h1><b>Management’s Revenge</b></h1>\n<p>Back at my library job, I kept an eye on the developers, admiring their teamwork and pragmatism. As time went by, though, I couldn’t help but notice some cracks in the team’s veneer. Despite the velocity chart and the disciplined feature-tracking, the developers didn’t seem to be making all that much progress. They were all working hard, that was clear, but there was a fatal flaw: no one really knew what the project was ultimately supposed to look like, or exactly what purpose it was supposed to serve. The team members could develop features, but it wasn’t clear what all these features were being tacked on to. Maybe that problem came from my workplace’s own dysfunction, which was considerable. Still, I began to wonder whether the Agile methodology had some limitations.</p>\n<p>And, in fact, anyone with any proximity to software development has likely heard rumblings about Agile. For all the promise of the manifesto, one starts to get the sense when talking to people who work in technology that laboring under Agile may not be the liberatory experience it’s billed as. Indeed, software development is in crisis again—but, this time, it’s an Agile crisis. On the web, everyone from regular developers to some of the original manifesto authors is raising concerns about Agile practices. They talk about the “Agile-industrial complex,” the network of consultants, speakers, and coaches who charge large fees to fine-tune Agile processes. And almost everyone complains that Agile has taken a wrong turn: somewhere in the last two decades, Agile has veered from the original manifesto’s vision, becoming something more restrictive, taxing, and stressful than it was meant to be. </p>\n<p>Part of the issue is Agile’s flexibility. Jan Wischweh, a freelance developer, calls this the “no true Scotsman” problem. Any Agile practice someone doesn’t like is not Agile at all, it inevitably turns out. The construction of the manifesto makes this almost inescapable: because the manifesto doesn’t prescribe any specific activities, one must gauge the spirit of the methods in place, which all depends on the person experiencing them. Because it insists on its status as a “mindset,” not a methodology, Agile seems destined to take on some of the characteristics of any organization that adopts it. And it is remarkably immune to criticism, since it can’t be reduced to a specific set of methods. “If you do one thing wrong and it’s not working for you, people will assume it’s because you’re doing it wrong,” one product manager told me. “Not because there’s anything wrong with the framework.”</p>\n<p>Despite this flexibility in its definition, many developers have lost faith in the idea of Agile. Wischweh himself encountered a turning point while describing a standup meeting to an aunt, a lawyer. She was incredulous. The notion that a competent professional would need to justify his work every day, in tiny units, was absurd to her. Wischweh began to think about the ways in which Agile encourages developers to see themselves as cogs in a machine. They may not be buried under layers of managers, as they were in the waterfall model, but they nevertheless have internalized the business’s priorities as their own. “As developers, IT professionals, we like to think of ourselves as knowledge workers, whose work can’t be rationalized or commodified. But I think Agile tries to accomplish the exact opposite approach,” said Wischweh. </p>\n<p>Al Tenhundfeld points out that the authors of the Agile Manifesto were working developers, and that the manifesto’s initial uptake was among self-organizing teams of coders. Now, however, plenty of people specialize in helping to implement Agile, and Agile conferences notoriously tend to be dominated by managers, not developers. The ubiquity of Agile means that it is just as likely to be imposed from above as demanded from below. And Agile project managers, who are generally embedded in the team as the “product owner,” find themselves pulled in two directions: what’s best for the developers on the one hand, and what they’ve promised to deliver to management on the other. </p>\n<p>Even as the team is pulled in multiple directions, it’s asked to move projects forward at an ever-accelerating pace. “Sprinting,” after all, is fast by definition. And indeed, the prospect of burnout loomed large for many of the tech workers I spoke to. “You’re trying to define what’s reasonable in that period of time,” said technical writer Sarah Moir. “And then run to the finish line and then do it again. And then on to that finish line, and on and on. That can be kind of exhausting if you’re committing 100 percent of your capacity.”</p>\n<p>Moreover, daily standups, billed as lightweight, low key check-ins, have become, for some workers, exercises in surveillance. Particularly when work is decomposed into small parts, workers feel an obligation to enumerate every task they’ve accomplished. There’s also pressure for every worker to justify their worth; they are, after all, employees, who need to be perceived as earning their salaries. </p>\n<p>“Story points”—the abstraction that teams use to measure the effort involved in particular development tasks—have also lost some of their allure. They began as a way to give engineers some control over the amount and substance of their work. And yet, in practice, they often serve as a way to assess engineers’ performance. “Once you’ve put something in a digital tool, the amount of oversight that people want goes up, right?” said Yvonne Lam, a software engineer based in Seattle.</p>\n<p>The problem isn’t just with surveillance, but with the way the points calcify into a timeline. John Burns, an engineer at a platform company, recalled a former workplace that simply multiplied story points by a common coefficient, in order to get a rough estimate of how long a project would take. Despite the points’ avowed status as an informal, internal measure, managers used them as a planning device. </p>\n<h1><b>The Next Crisis</b></h1>\n<p>Underlying these complaints is a deeper skepticism about the freedom that Agile promises. Agile’s values celebrate developers’ ingenuity and idiosyncratic ways of working. But there are distinct limits to the kinds of creativity workers feel authorized to exercise under Agile, particularly because problems tend to be broken down into such small pieces. “It is clear that Agile dissolves many of the more visible features of hierarchical managerial control,” writes Michael Eby. “But it does so only to recontain them in subtle and nuanced ways.” Yvonne Lam notes that autonomy under Agile has distinct parameters. “People say you have the autonomy to decide how you’re going to do the work. And it’s like, yeah, but sometimes what you want is the autonomy to say, this is the wrong work.” There are so many choices to be made in the course of any software development project—about languages, frameworks, structure—that it’s possible to lose sight of the fact that developers often don’t get to weigh in on the bigger questions. </p>\n<p>And, in the last few years, those bigger questions have taken on greater importance and urgency. We’ve seen numerous examples of tech workers organizing to change the direction of their companies’ business strategies: Google developers agitating to kill an AI contract with the Department of Defense, game developers agitating to end sexual harassment. These demands go beyond Agile’s remit, since they aim not to create conditions for workers to do a better job, but to change the nature of that job altogether. </p>\n<p>It’s also worth considering how Agile might have played a role in creating a work culture that is increasingly revealed to be toxic for women, people of color, and members of gender minority groups. It’s an inescapable fact that the authors of the Agile Manifesto were a very specific group of people: white men who, whatever their varying experiences, have probably not spent much time in workplaces where they composed the minority. The working group has since acknowledged the deficit in the team’s diversity and vowed to incorporate a larger set of voices in the Agile Alliance, a nonprofit associated with the manifesto. </p>\n<p>But when you survey a list of Agile-affiliated methodologies, alarm bells might go off if you’re the kind of person who’s faced discrimination or harassment at work. Many people testify to the utility of “pair programming,” for example, but the practice—in which two developers code together, each taking turns looking over the other’s shoulder—assumes that the two coders are comfortable with each other. Similarly, the warts-and-all breakdown of Agile “retrospectives” seems healthy, but I’ve watched them descend into a structureless series of accusations; everything depends on who’s leading the team. And Coraline Ada Ehmke, former community safety manager at GitHub, has described how fellow developers used the code review—ideally a low-stakes way for developers to check each other’s work—as an instrument of harassment. We’ve long known that eliminating bureaucracy, hierarchy, and documentation feels great, until you’re the person who needs rules for protection.</p>\n<p>Could Agile even have played a role in some of the more infamous failures of the tech industry? The thought occurred to me as I watched Frances Haugen, the former Facebook manager turned whistleblower, testifying before Congress in October 2021. If a company sets a goal of boosting user engagement, Agile is designed to get developers working single-mindedly toward that goal—not arguing with managers about whether, for example, it’s a good idea to show people content that inflames their prejudices. Such ethical arguments are incompatible with Agile’s avowed dedication to keeping developers working feverishly on <i>the project</i>, whatever it might be.</p>\n<p>This issue becomes especially pressing when one considers that contemporary software is likely to involve things like machine learning, large datasets, or artificial intelligence—technologies that have shown themselves to be potentially destructive, particularly for minoritized people. The digital theorist Ian Bogost argues that this move-fast-and-break-things approach is precisely why software developers should stop calling themselves “engineers”: engineering, he points out, is a set of disciplines with codes of ethics and recognized commitments to civil society. Agile promises no such loyalty, except to the product under construction.</p>\n<p>Agile is good at compartmentalizing features, neatly packaging them into sprints and deliverables. Really, that’s a tendency of software engineering at large—modularity, or “information hiding,” is a critical way for humans to manage systems that are too complex for any one person to grasp. But by turning features into “user stories” on a whiteboard, Agile has the potential to create what Yvonne Lam calls a “chain of deniability”: an assembly line in which no one, at any point, takes full responsibility for what the team has created. </p>\n<p>The Agile Manifesto paints an alluring picture of workplace democracy. The problem is, it’s almost always implemented in workplaces devoted to the bottom line, not to workers’ well-being. Sometimes those priorities align; the manifesto makes a strong case that businesses’ products can be strengthened by worker autonomy. But they’re just as likely to conflict, as when a project manager is caught between a promise to a client and the developers’ own priorities. </p>\n<p>“There’s a desire to use process as a way to manage ambiguity you can’t control,” said Mark Matienzo, a software engineer for an academic institution. “Especially in places where you’re seen as being somewhat powerless, whether that’s to the whims of upper management or administration. So you may not be able to influence the strategic direction of a project at a high level, but Agile allows that certain conception of developer free will.” The product manager I spoke to put it more bluntly: “Agile tricks people into thinking they have ownership over their work, but from a labor perspective, they literally do not have ownership, unless they have, like, significant stock options or whatever.” </p>\n<p>Software development has never fit neatly into the timelines and metrics to which companies aspire. The sheer complexity of a modern application makes its development sometimes feel as much alchemical as logical. Computers may have emerged as military equipment, but completely subordinating programming work to the priorities of capital has been surprisingly difficult. When software engineering failed to discipline the unwieldiness of development, businesses turned to Agile, which married the autonomy that developers demanded with a single-minded focus on an organization’s goals. That autonomy is limited, however, as developers are increasingly pointing out. When applied in a corporate context, the methods and values that Agile esteems are invariably oriented to the imperatives of the corporation. No matter how flexible the workplace or how casual the meetings, the bottom line has to be the organization’s profits.</p>\n<p>There’s another angle on Agile, though. Some people I talked to pointed out that Agile has the potential to foster solidarity among workers. If teams truly self-organize, share concerns, and speak openly, perhaps Agile could actually lend itself to worker organization. Maybe management, through Agile, is producing its own gravediggers. Maybe the next crisis of software development will come from the workers themselves.</p>\n<p><i>A previous version of this article incorrectly identified Al Tenhundfeld as a co-author of the Agile Manifesto. The present version has been corrected.</i></p>",
      "content_text": "I first encountered Agile when I got a job in a library. I’d been hired to help get a new digital scholarship center off the ground and sometimes worked with the library’s software development team to build tools to support our projects. There were about six members of this team, and I noticed right away that they did things differently from the non-technical staff. At meetings, they didn’t talk about product features, but “user stories”—tiny narratives that described features—to which they assigned “story points” that measured the effort involved in completing the associated tasks. They met every morning for “standup,” a meeting literally conducted standing up, the better to enforce brevity. A whiteboard had pride of place in their workspace, and I watched the developers move Post-it notes across the board to signify their state of completion. They worked in “sprints,” two-week stretches devoted to particular tasks.\nAt meetings with the rest of us on the library staff, the head of the development team reported on progress using software that included a dashboard indicating the state of every project. The manager could also show us a graph of the team’s “velocity,” the rate at which the developers finished their tasks, complete with historical comparisons and projections. \nThis was Agile, I learned, a method for managing software development that had achieved enormous popularity in technical workplaces of all kinds—and, increasingly, even non-technical workplaces (including, as one TED speaker would have it, the family home). Honestly, I was impressed. In my own work, I often felt as though I was flailing around, never quite sure if I was making progress or doing anything of real value. The developers, in contrast, seemed to know exactly what they were doing. If they ran into a roadblock, it was no big deal; they just dealt with it. They expected requirements to change as they progressed, and the two-week time horizons allowed them to substitute one feature for another, or adopt a new framework, without starting all over from scratch.\nThat’s the beauty of Agile: designed for ultimate flexibility and speed, it requires developers to break every task down into the smallest possible unit. The emphasis is on getting releases out fast and taking frequent stock, changing directions as necessary.\nI was intrigued; Agile was different from anything I’d experienced before. Where had it come from, and why?\nI began to explore the history of Agile. What I discovered was a long-running wrestling match between what managers want software development to be and what it really is, as practiced by the workers who write the code. Time and again, organizations have sought to contain software’s most troublesome tendencies—its habit of sprawling beyond timelines and measurable goals—by introducing new management styles. And for a time, it looked as though companies had found in Agile the solution to keeping developers happily on task while also working at a feverish pace. Recently, though, some signs are emerging that Agile’s power may be fading. A new moment of reckoning is in the making, one that may end up knocking Agile off its perch.\nTurning Weirdos into Engineers\nSoftware development was in crisis even before the word “software” was coined. At a 1954 conference convened by leaders in industry, government, and academia at Wayne State University in Detroit, experts warned of an imminent shortage of trained programmers. The use of the term “software” to mean application programming first appeared in print in an article by statistician John W. Tukey four years later. By the mid-1960s, at least a hundred thousand people worked as programmers in the United States, but commentators estimated an immediate demand for fifty thousand more.\nIn the first decades of the programming profession, most experts assumed that formulating computer-readable directions would be a relatively trivial job. After all, the system analysts—the experts who specify the high-level architecture—had already done the hard intellectual work of designing the program and hardware. The job of the coder was simply to translate that design into something a computer could work with. It was a surprise, then, when it turned out that this process of translation was in fact quite intellectually demanding. \nThe nature of these intellectual demands, along with the larger question of what kind of work software development actually is, continues to baffle managers today. In the computer’s early years, it seemed to some people that coding was, or should be, a matter of pure logic; after all, machines just do what you tell them to do. There was, self-evidently, a formally correct way to do things, and the coder’s job was simply to find it. \nAnd yet, the actual experience of programming suggested that coding was as much art as science. Some of the most advanced programming, as Clive Thompson notes in his 2019 book Coders, was pushed forward by long-haired weirdos who hung around university labs after hours, hackers who considered themselves as much artisans as logicians. The fact that one couldn’t physically touch a piece of software—its storage media, perhaps, but not the software itself—made software development more abstract, more mysterious than other engineering fields. Where other fields could be expected to obey the laws of physics, the ground seemed to be constantly shifting under software’s feet. Hardware was perpetually changing its parameters and capabilities. \nNevertheless, the field of electronic data processing—the automation of office functions, like time cards and payroll—was growing rapidly. The hulking machines designed for the purpose, leased from IBM, quickly became the hallmark of the technologically forward-thinking operation. But they required teams of operators to design the programs, prepare the punch cards, and feed data into the system. Established managers resented the specialized expertise and professional eccentricity of the growing ranks of “computer boys.” They resented, too, that software projects seemed to defy any estimation of cost and complexity. The famed computer scientist Frederick Brooks compared software projects to werewolves: they start out with puppy-like innocence, but, more often than not, they metamorphose into “a monster of missed schedules, blown budgets, and flawed products.” You could say, then, that by the late 1960s, software development was facing three crises: a crying need for more programmers; an imperative to wrangle development into something more predictable; and, as businesses saw it, a managerial necessity to get developers to stop acting so weird. \nIt was in this spirit of professionalization that industry leaders encouraged programmers to embrace the mantle of “software engineer,” a development that many historians trace to the NATO Conference on Software Engineering of 1968. Computer work was sprawling, difficult to organize, and notoriously hard to manage, the organizers pointed out. Why not, then, borrow a set of methods (and a title) from the established fields of engineering? That way, programming could become firmly a science, with all the order, influence, and established methodologies that comes with it. It would also, the organizers hoped, become easier for industry to manage: software engineers might better conform to corporate culture, following the model of engineers from other disciplines. “In the interest of efficient software manufacturing,” writes historian Nathan Ensmenger, “the black art of programming had to make way for the science of software engineering.”\nChasing Waterfalls\nAnd it worked—sort of. The “software engineering” appellation caught on, rising in prominence alongside the institutional prestige of the people who wrote software. University departments adopted the term, encouraging students to practice sound engineering methodologies, like using mathematical proofs, as they learned to program. The techniques, claimed the computer scientist Tony Hoare, would “transform the arcane and error-prone craft of computer programming to meet the highest standards of the engineering profession.” \nManagers approached with gusto the task of organizing the newly intelligible software labor force, leading to a number of different organization methods. One approach, the Chief Programmer Team (CPT) framework instituted at IBM, put a single “chief programmer” at the head of a hierarchy, overseeing a cadre of specialists whose interactions he oversaw. Another popular approach placed programmers beneath many layers of administrators, who made decisions and assigned work to the programmers under them. \nWith these new techniques came a set of ideas for managing development labor, a management philosophy that has come to be called (mostly pejoratively) the “waterfall method.” Waterfall made sense in theory: someone set a goal for a software product and broke its production up into a series of steps, each of which had to be completed and tested before moving on to the next task. In other words, developers followed a script laid out for them by management. \nThe term “waterfall,” ironically, made its first appearance in an article indicting the method as unrealistic, but the name and the philosophy caught on nevertheless. Waterfall irresistibly matched the hierarchical corporate structure that administered it. And it appealed to managers because, as Nathan Ensmenger writes, “The essence of the software-engineering movement was control: control over complexity, control over budgets and scheduling, and, perhaps most significantly, control over a recalcitrant workforce.” This was precisely the kind of professional that waterfall development was designed to accommodate.\nBut before long, software development was again in crisis—or crises. Part of the problem was keeping up with the need for new computer scientists. Universities in 1980 couldn’t fill the faculty positions necessary to train the huge number of students with ambitions to become software engineers. “This situation seriously threatens the ability of Computer Science departments to continue developing the skilled people needed both by our information processing industry and by an increasingly technological society,” warned the Association for Computing Machinery. \nThe industry’s dearth of qualified developers wasn’t its only problem. Software development itself seemed to be struggling. Waterfall’s promise of tightly controlled management was a mirage. No amount of documentation, process, or procedure seemed capable of wrestling development into predictability. Software projects were big, expensive, and they seemed to be spiraling out of control—huge initiatives foundered unfinished as requirements changed and warring project teams bickered about details. Despite managers’ efforts to make software development reliable and predictable, it seemed, if anything, to have only grown more unwieldy. As the computer scientist Jeff Offutt put it, “In the 1960s, programmers built ‘tiny log cabins,’” while “in the 1980s, teams of programmers were building office buildings”—and by the 1990s, skyscrapers. Yet teams of technologists seemed unable to coordinate their work. Peter Varhol, a technology industry consultant, estimates that in the early 1990s, the average application took three years to develop, from idea to finished product. Technology was supposed to make American business smarter, faster, and more profitable, and yet the most respected corporations couldn’t seem to get their projects off the ground.\nThe designation of “engineer,” the administrative hierarchies, the careful planning and documentation: all of this had been intended to bring order and control to the emerging field of software development. But it seemed to have backfired. Rather than clearing the way for software developers to build, waterfall gummed up the works with binders of paperwork and endless meetings. \nFor their parts, engineers complained of feeling constrained by heavy-handed management techniques. They just wanted to build software. Why were they hamstrung by paperwork? The typical picture of corporate programming in the 1990s is of the existentially bored twenty-somethings in Douglas Coupland’s novel Microserfs, or the desperate developers in Mike Judge’s movie Office Space, whose rage lurks just below the surface.\nKhakis and Dad Jeans\nEnter what may be the world’s most unlikely group of rock stars: seventeen middle-aged white guys, dressed in khakis and dad jeans, all obsessed with management. The now-legendary authors of what came to be called the Agile Manifesto gathered at Utah’s Snowbird ski resort in February 2001 to hammer out a new vision for the software development process. This wasn’t their first meeting; they’d been gathering in various configurations to discuss software development for some time, though, until the 2001 meeting, they hadn’t come up with much to show for it. This time was different. Scrawled on a whiteboard was the Agile Manifesto, a set of values that, in the following years, would become nearly ubiquitous in the management of programmers, from fledgling startups to huge corporations. It’s pleasantly concise:\nWe are uncovering better ways of developing software by doing it and helping others do it.Through this work we have come to value:Individuals and interactions over processes and toolsWorking software over comprehensive documentationCustomer collaboration over contract negotiationResponding to change over following a planThat is, while there is value in the items on the right, we value the items on the left more.\nThe manifesto, supplemented by twelve additional principles, targeted the professional frustrations that engineers described. Waterfall assumed that a software application’s requirements would be stable, and that slowdowns and logjams were the result of deviating from management’s careful plan. Agile tossed out these high-level roadmaps, emphasizing instead the need to make decisions on the fly. This way, software developers themselves could change their approach as requirements or technology changed. They could focus on building software, rather than on paperwork and documentation. And they could eliminate the need for endless meetings. \nIt’s an interesting document. Given the shortage of qualified developers, technology professionals might have been expected to demand concessions of more immediate material benefit—say, a union, or ownership of their intellectual property. Instead, they demanded a workplace configuration that would allow them to do better, more efficient work. Indeed, as writer Michael Eby points out, this revolt against management is distinct from some preceding expressions of workplace discontent: rather than demand material improvements, tech workers created “a new ‘spirit,’ based on cultures, principles, assumptions, hierarchies, and ethics that absorbed the complaints of the artistic critique.” That is, the manifesto directly attacked the bureaucracy, infantilization, and sense of futility that developers deplored. Developers weren’t demanding better pay; they were demanding to be treated as different people.\nOrganizational Anarchists\nIt seems likely that changes in opinions about the nature of software development didn’t take place in 2001 exactly, but in the decade leading up to the authorship of the Agile Manifesto. Consensus was growing—among developers, but also among managers—that software development couldn’t be made to fit the flow-charts and worksheets in which analysts had placed so much hope. Software, as the historian Stuart Shapiro wrote in 1997, is complex in a particularly complex way: the problems are “fuzzy, variable, and multifaceted, and thus rarely proved amenable to any one approach; instead, they demanded hybrid and adaptive solutions.” Not, then, forms and timecards. Moreover, as the workforce of programmers grew by leaps and bounds in the 1990s, companies hired, of necessity, people without formal computer science training. These younger workers likely had less invested in the drive of the 1970s and 1980s to turn software development into a science. The manifesto wasn’t really a shot across the bow: it was more of a punctuation mark, emphasizing years of discontent with prevailing models of corporate management.\nNevertheless, while Agile had a devoted following, its mandate—the removal of top-down planning and administrative hierarchy—was a risk. It meant management ceding control, at least to some extent, to developers themselves. And most large companies weren’t willing to do that, at least not until the 2010s. Between 2012 and 2015, though, according to the Agile consultancy Planview, more than 50 percent of practicing development teams characterized themselves as “Agile.” \nDoubtless, some of this popularity had to do with the growth of high-speed internet connections, which drastically altered the way software got released. Before, it wasn’t unusual for software to be updated once a year, or at even longer intervals. The fact that updates had to be distributed on physical media like CD-ROMs and floppy disks limited the speed of new releases. But high-speed internet made it possible to push out fixes and features as often as a company wanted, even multiple times a day. Agile made a lot of sense in this environment.\nFacebook’s famous former motto, “Move fast and break things,” captured the spirit of the new era well. It was an era that rewarded audacity, in software development as much as in CEOs. Venture capital firms, on the hunt for “unicorns,” poured record amounts into the technology sector during the 2010s, and they wanted to see results quickly. Competing with startups required the ability to change on a dime, to release constantly, and to develop at breakneck speed. The risk calculus shifted: it now seemed dangerous to stick with waterfall, when Agile promised so much speed.\nEqually, it seems, what it meant to be a software developer had changed. In the 1970s and 1980s, experts held up the systems-minded, logic-loving scientist as the ideal software worker. But over the years, this ideal had failed to take root. The programmers of the 1990s read Wired, not Datamation. If their characteristics can be intuited from the Agile Manifesto, they were intently committed to the highest standards, working quickly and confidently because managers “trust them to get the job done.” They refused to do things just because they’ve always been done that way, turning their minds to “continuous attention to technical excellence.” They weren’t thrown by fluid, fast-moving requirements; instead, they embraced them as an opportunity to “harness change for the customer’s competitive advantage.” \nThe image of the free-thinking nonconformist fits the philosophy of Agile. The manifesto’s authors may have looked like textbook engineers, in button-downs with cell-phone holsters, but “a bigger group of organizational anarchists would be hard to find,” according to Jim Highsmith, one of their number. Particularly in the early days, there was a lot of talk about the challenge Agile posed to the traditional management paradigm. Agile’s proponents were proud of this nonconformity: the framework “scares the bejeebers out of traditionalists,” wrote Highsmith in 2001. “Agile was openly, militantly, anti-management in the beginning,” writes the software developer and consultant Al Tenhundfeld. “For example, Ken Schwaber [a manifesto author] was vocal and explicit about his goal to get rid of all project managers.” \nAnti-management, maybe, but not anti-corporate, not really. It’s tempting to see the archetypal Agile developer as a revival of the long-haired countercultural weirdo who lurked around the punch card machines of the late 1960s. But the two personas differ in important respects. The eccentrics of computing’s early years wanted to program for the sheer thrill of putting this new technology to work. The coder of Agile’s imagination is committed, above all, to the project. He hates administrative intrusion because it gets in the way of his greatest aspiration, which is to do his job at the highest level of professional performance. Like the developers in Aaron Sorkin’s The Social Network, he wants most of all to be in “the zone”: headphones on, distractions eliminated, in a state of pure communion with his labor.\nManagement’s Revenge\nBack at my library job, I kept an eye on the developers, admiring their teamwork and pragmatism. As time went by, though, I couldn’t help but notice some cracks in the team’s veneer. Despite the velocity chart and the disciplined feature-tracking, the developers didn’t seem to be making all that much progress. They were all working hard, that was clear, but there was a fatal flaw: no one really knew what the project was ultimately supposed to look like, or exactly what purpose it was supposed to serve. The team members could develop features, but it wasn’t clear what all these features were being tacked on to. Maybe that problem came from my workplace’s own dysfunction, which was considerable. Still, I began to wonder whether the Agile methodology had some limitations.\nAnd, in fact, anyone with any proximity to software development has likely heard rumblings about Agile. For all the promise of the manifesto, one starts to get the sense when talking to people who work in technology that laboring under Agile may not be the liberatory experience it’s billed as. Indeed, software development is in crisis again—but, this time, it’s an Agile crisis. On the web, everyone from regular developers to some of the original manifesto authors is raising concerns about Agile practices. They talk about the “Agile-industrial complex,” the network of consultants, speakers, and coaches who charge large fees to fine-tune Agile processes. And almost everyone complains that Agile has taken a wrong turn: somewhere in the last two decades, Agile has veered from the original manifesto’s vision, becoming something more restrictive, taxing, and stressful than it was meant to be. \nPart of the issue is Agile’s flexibility. Jan Wischweh, a freelance developer, calls this the “no true Scotsman” problem. Any Agile practice someone doesn’t like is not Agile at all, it inevitably turns out. The construction of the manifesto makes this almost inescapable: because the manifesto doesn’t prescribe any specific activities, one must gauge the spirit of the methods in place, which all depends on the person experiencing them. Because it insists on its status as a “mindset,” not a methodology, Agile seems destined to take on some of the characteristics of any organization that adopts it. And it is remarkably immune to criticism, since it can’t be reduced to a specific set of methods. “If you do one thing wrong and it’s not working for you, people will assume it’s because you’re doing it wrong,” one product manager told me. “Not because there’s anything wrong with the framework.”\nDespite this flexibility in its definition, many developers have lost faith in the idea of Agile. Wischweh himself encountered a turning point while describing a standup meeting to an aunt, a lawyer. She was incredulous. The notion that a competent professional would need to justify his work every day, in tiny units, was absurd to her. Wischweh began to think about the ways in which Agile encourages developers to see themselves as cogs in a machine. They may not be buried under layers of managers, as they were in the waterfall model, but they nevertheless have internalized the business’s priorities as their own. “As developers, IT professionals, we like to think of ourselves as knowledge workers, whose work can’t be rationalized or commodified. But I think Agile tries to accomplish the exact opposite approach,” said Wischweh. \nAl Tenhundfeld points out that the authors of the Agile Manifesto were working developers, and that the manifesto’s initial uptake was among self-organizing teams of coders. Now, however, plenty of people specialize in helping to implement Agile, and Agile conferences notoriously tend to be dominated by managers, not developers. The ubiquity of Agile means that it is just as likely to be imposed from above as demanded from below. And Agile project managers, who are generally embedded in the team as the “product owner,” find themselves pulled in two directions: what’s best for the developers on the one hand, and what they’ve promised to deliver to management on the other. \nEven as the team is pulled in multiple directions, it’s asked to move projects forward at an ever-accelerating pace. “Sprinting,” after all, is fast by definition. And indeed, the prospect of burnout loomed large for many of the tech workers I spoke to. “You’re trying to define what’s reasonable in that period of time,” said technical writer Sarah Moir. “And then run to the finish line and then do it again. And then on to that finish line, and on and on. That can be kind of exhausting if you’re committing 100 percent of your capacity.”\nMoreover, daily standups, billed as lightweight, low key check-ins, have become, for some workers, exercises in surveillance. Particularly when work is decomposed into small parts, workers feel an obligation to enumerate every task they’ve accomplished. There’s also pressure for every worker to justify their worth; they are, after all, employees, who need to be perceived as earning their salaries. \n“Story points”—the abstraction that teams use to measure the effort involved in particular development tasks—have also lost some of their allure. They began as a way to give engineers some control over the amount and substance of their work. And yet, in practice, they often serve as a way to assess engineers’ performance. “Once you’ve put something in a digital tool, the amount of oversight that people want goes up, right?” said Yvonne Lam, a software engineer based in Seattle.\nThe problem isn’t just with surveillance, but with the way the points calcify into a timeline. John Burns, an engineer at a platform company, recalled a former workplace that simply multiplied story points by a common coefficient, in order to get a rough estimate of how long a project would take. Despite the points’ avowed status as an informal, internal measure, managers used them as a planning device. \nThe Next Crisis\nUnderlying these complaints is a deeper skepticism about the freedom that Agile promises. Agile’s values celebrate developers’ ingenuity and idiosyncratic ways of working. But there are distinct limits to the kinds of creativity workers feel authorized to exercise under Agile, particularly because problems tend to be broken down into such small pieces. “It is clear that Agile dissolves many of the more visible features of hierarchical managerial control,” writes Michael Eby. “But it does so only to recontain them in subtle and nuanced ways.” Yvonne Lam notes that autonomy under Agile has distinct parameters. “People say you have the autonomy to decide how you’re going to do the work. And it’s like, yeah, but sometimes what you want is the autonomy to say, this is the wrong work.” There are so many choices to be made in the course of any software development project—about languages, frameworks, structure—that it’s possible to lose sight of the fact that developers often don’t get to weigh in on the bigger questions. \nAnd, in the last few years, those bigger questions have taken on greater importance and urgency. We’ve seen numerous examples of tech workers organizing to change the direction of their companies’ business strategies: Google developers agitating to kill an AI contract with the Department of Defense, game developers agitating to end sexual harassment. These demands go beyond Agile’s remit, since they aim not to create conditions for workers to do a better job, but to change the nature of that job altogether. \nIt’s also worth considering how Agile might have played a role in creating a work culture that is increasingly revealed to be toxic for women, people of color, and members of gender minority groups. It’s an inescapable fact that the authors of the Agile Manifesto were a very specific group of people: white men who, whatever their varying experiences, have probably not spent much time in workplaces where they composed the minority. The working group has since acknowledged the deficit in the team’s diversity and vowed to incorporate a larger set of voices in the Agile Alliance, a nonprofit associated with the manifesto. \nBut when you survey a list of Agile-affiliated methodologies, alarm bells might go off if you’re the kind of person who’s faced discrimination or harassment at work. Many people testify to the utility of “pair programming,” for example, but the practice—in which two developers code together, each taking turns looking over the other’s shoulder—assumes that the two coders are comfortable with each other. Similarly, the warts-and-all breakdown of Agile “retrospectives” seems healthy, but I’ve watched them descend into a structureless series of accusations; everything depends on who’s leading the team. And Coraline Ada Ehmke, former community safety manager at GitHub, has described how fellow developers used the code review—ideally a low-stakes way for developers to check each other’s work—as an instrument of harassment. We’ve long known that eliminating bureaucracy, hierarchy, and documentation feels great, until you’re the person who needs rules for protection.\nCould Agile even have played a role in some of the more infamous failures of the tech industry? The thought occurred to me as I watched Frances Haugen, the former Facebook manager turned whistleblower, testifying before Congress in October 2021. If a company sets a goal of boosting user engagement, Agile is designed to get developers working single-mindedly toward that goal—not arguing with managers about whether, for example, it’s a good idea to show people content that inflames their prejudices. Such ethical arguments are incompatible with Agile’s avowed dedication to keeping developers working feverishly on the project, whatever it might be.\nThis issue becomes especially pressing when one considers that contemporary software is likely to involve things like machine learning, large datasets, or artificial intelligence—technologies that have shown themselves to be potentially destructive, particularly for minoritized people. The digital theorist Ian Bogost argues that this move-fast-and-break-things approach is precisely why software developers should stop calling themselves “engineers”: engineering, he points out, is a set of disciplines with codes of ethics and recognized commitments to civil society. Agile promises no such loyalty, except to the product under construction.\nAgile is good at compartmentalizing features, neatly packaging them into sprints and deliverables. Really, that’s a tendency of software engineering at large—modularity, or “information hiding,” is a critical way for humans to manage systems that are too complex for any one person to grasp. But by turning features into “user stories” on a whiteboard, Agile has the potential to create what Yvonne Lam calls a “chain of deniability”: an assembly line in which no one, at any point, takes full responsibility for what the team has created. \nThe Agile Manifesto paints an alluring picture of workplace democracy. The problem is, it’s almost always implemented in workplaces devoted to the bottom line, not to workers’ well-being. Sometimes those priorities align; the manifesto makes a strong case that businesses’ products can be strengthened by worker autonomy. But they’re just as likely to conflict, as when a project manager is caught between a promise to a client and the developers’ own priorities. \n“There’s a desire to use process as a way to manage ambiguity you can’t control,” said Mark Matienzo, a software engineer for an academic institution. “Especially in places where you’re seen as being somewhat powerless, whether that’s to the whims of upper management or administration. So you may not be able to influence the strategic direction of a project at a high level, but Agile allows that certain conception of developer free will.” The product manager I spoke to put it more bluntly: “Agile tricks people into thinking they have ownership over their work, but from a labor perspective, they literally do not have ownership, unless they have, like, significant stock options or whatever.” \nSoftware development has never fit neatly into the timelines and metrics to which companies aspire. The sheer complexity of a modern application makes its development sometimes feel as much alchemical as logical. Computers may have emerged as military equipment, but completely subordinating programming work to the priorities of capital has been surprisingly difficult. When software engineering failed to discipline the unwieldiness of development, businesses turned to Agile, which married the autonomy that developers demanded with a single-minded focus on an organization’s goals. That autonomy is limited, however, as developers are increasingly pointing out. When applied in a corporate context, the methods and values that Agile esteems are invariably oriented to the imperatives of the corporation. No matter how flexible the workplace or how casual the meetings, the bottom line has to be the organization’s profits.\nThere’s another angle on Agile, though. Some people I talked to pointed out that Agile has the potential to foster solidarity among workers. If teams truly self-organize, share concerns, and speak openly, perhaps Agile could actually lend itself to worker organization. Maybe management, through Agile, is producing its own gravediggers. Maybe the next crisis of software development will come from the workers themselves.\nA previous version of this article incorrectly identified Al Tenhundfeld as a co-author of the Agile Manifesto. The present version has been corrected.",
      "date_published": "2022-05-10T22:46:07.000Z",
      "date_modified": "2022-05-10T22:46:07.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/decarbonization-as-a-service",
      "url": "https://logicmag.io/clouds/decarbonization-as-a-service",
      "title": "Decarbonization as a Service",
      "summary": "The next frontier of platform capitalism is carbon management.",
      "content_html": "<p>Net zero has gone viral. Everyone is announcing their net-zero greenhouse gas emissions targets, from Saudi Arabia to Australia. By the final day of COP26—the annual United Nations Climate Change Conference held in Glasgow in 2021—more than 130 countries had made net-zero pledges of one kind or another, representing about 70 percent of the world’s UN-recognized nations. The private sector has also rushed in: more than 30 percent of the world’s 2,000 biggest public companies have committed to net-zero targets, including Amazon, Walmart, and ExxonMobil. </p>\n<p>A global ambition has coalesced. It’s an achievement of sorts. Limiting warming to 1.5°C requires reaching net zero by midcentury, according to the Intergovernmental Panel on Climate Change (IPCC). This doesn’t mean zero emissions; rather, it means that some remaining amount of positive emissions would be canceled out by “negative emissions”—that is, by carbon removals. Negative emissions can be generated by using ecosystems like forests, farms, and oceans to store more carbon, or by using industrial technologies like carbon capture and storage (CCS) to pull carbon from the atmosphere and store it in rock formations. When these negative emissions balance out the positive emissions—when the amount of carbon being taken <i>out</i> of the atmosphere equals the amount of carbon being put <i>into</i> the atmosphere—then net zero is reached.</p>\n<p>Under such an arrangement, countries are free to continue burning fossil fuels, so long as they offset their emissions. For this reason, many climate advocates have been critical of net zero as a goal. One common critique is that net-zero pledges won’t stop the continued extraction and combustion of fossil fuels. Further, they’re aimed at a future that’s far enough away that present-day leaders won’t be accountable for what happens. “Net zero by 2050. Blah, blah, blah,” Greta Thunberg told a summit of young organizers just prior to COP26. </p>\n<p>It’s true that net zero is woefully insufficient. We also need to be talking about immediately phasing out fossil fuel production. But net zero is still a worthwhile transitional goal, because we don’t yet have all the technologies we need at scale for true climate repair. Climate change is a problem of stocks, not flows: we need not only to stop emitting carbon by switching to renewables, but to reduce the existing levels of carbon in our atmosphere. Net zero alone won’t get us there. Still, it gives us a way to buy time while we develop and deploy the technologies required for full decarbonization.</p>\n<p>Yet net zero is harder than it looks. The difficulty isn’t just political—compelling countries and companies to make promises and abide by them—but epistemological. At the center of net zero is a knowledge problem: <i>How do we know when we’ve gotten to net zero? </i>Answering this question is surprisingly hard. </p>\n<p>There are two main challenges. First, there is immense technical complexity involved in accurately measuring both positive and negative emissions. Take positive emissions: how many are embodied in the manufacture of a car? You could measure how much carbon is produced by a single car factory, but a car has around 30,000 parts. Those parts might be sourced from suppliers around the world, each with their own carbon footprint. Further, the parts use different raw materials, and the extraction and transport of those materials carry emissions of their own. And that’s only one factory; there are some 300,000 car manufacturing facilities in the US alone.</p>\n<p>Measuring negative emissions presents headaches of its own. For example, there are emergent methods for measuring how much carbon is stored in soil that hinge on spectroscopy, satellite-based sensors, and machine learning. But knowing what’s actually going on in the soil is complex, as conditions can vary even across a single farm. Knowing what’s going on with carbon in the deep ocean, as required for some carbon removal approaches, is even more challenging. Industrial technologies like CCS that store carbon geologically may seem easier to measure than biological systems, but, even then, understanding what happens to carbon that is stored thousands of feet underground isn’t easy.</p>\n<p>Even if these difficulties are overcome, however, there is still the problem of <i>carbon deception</i>. This is the second main challenge involved in knowing when we’ve gotten to net zero: the presence of dishonest actors in the system. Think about Volkswagen rigging vehicles to cheat on emissions tests, or gas station chain owner Lev Dermen, who was found guilty of stealing $1 billion from US taxpayers through claiming tax credits for renewable biodiesel that didn’t exist. Behind the office-park facade of net zero lies a seedy hotbed of white-collar crime.</p>\n<p>The knowability of net zero can’t be taken for granted, then. All those policymakers and executives are making net-zero pledges without a clue for how to see them through. How can these pledges possibly be fulfilled? How can the knowledge problem of net zero be solved?</p>\n<p>The answer, apparently, is software. Companies large and small have begun to build “platforms” that promise to help organizations meet their net-zero promises. These platforms claim to be able to deliver “decarbonization-as-a-service” through the use of digital technologies that effectively track carbon. They are racing ahead of law and policy and performing de facto governance, creating new proprietary infrastructures for knowing and managing our planet.</p>\n<p>If this new regime fails to reliably measure and monitor carbon—and it very well may—that will be bad for the climate. If it succeeds, that may also be bad for the climate, not to mention ecosystems more broadly as well as human communities. But right now, before the new computational systems are locked in, we may have a chance to intervene and shape them for the better.</p>\n<h1><b>Initial Tree Offering</b></h1>\n<p>In 2012, Derrick Emsley cofounded Tentree, a Vancouver-based clothing company that plants ten trees for every product sold. That sounds simple enough, but managing the planting projects turned out to be a challenge. “The hardest part was monitoring and verifying the work and claims we were making,” Emsley told <i>The Hill</i>’s Saul Elbein. Confirming that the trees they paid to plant were actually planted required costly in-person trips and lots of managerial overhead—it meant “traveling there, auditing them, making sure those trees were in the ground having an impact,” according to Emsley.</p>\n<p>So Tentree started developing software to help streamline the process. That software became the basis of Veritree, a publicly available “planting management platform” unveiled in the fall of 2021. When a company that wants to offset their emissions signs up for Veritree, they get access to a user portal that lets them place orders for new tree plantings and displays metrics on their current tree holdings. These metrics are collected by the planters in the developing countries, who use custom-made “collect devices”—essentially modified smartphones designed to work in internet-limited environments—to take geotagged photographs of the trees. The trees get a unique digital token, and become digital inventory, hosted on the Cardano blockchain. Using a blockchain is supposed to reduce fraud by ensuring that trees are only counted once, so that the same forest can’t be claimed by multiple entities—a well-known problem in the world of carbon credits. </p>\n<p>Veritree is in its early days, but it hopes to become “an operating system for the restoration economy,” in Emsley’s words. An “Initial Tree Offering” was used to raise money for a “First Edition Forest,” which features trees in Madagascar, Indonesia, Nepal, Kenya, Senegal, and Haiti. The appeal for corporations hoping to make good on their net-zero pledges is obvious: they can invest in a reliable carbon offset program and obtain a real-time picture of precisely how much carbon is being offset, and share that information with the public. </p>\n<p>Veritree is far from the only platform hoping to dominate the net-zero space. A wide range of digital services is being developed by companies large and small. Established “Big Four” accounting firms like KPMG and Deloitte, as well as tech giants like Salesforce, are creating tools for Environmental, Social, and Governance (ESG) accounting that help measure the carbon footprint of firms, among other things. Some companies combine carbon measurement with a portal for purchasing offsets, such as the Atlanta-based startup Cloverly. Still others try to track negative emissions, like Veritree. Agreena, for example, is a Dutch startup that monitors changes in farmers’ fields after they switch to regenerative agriculture, and issues them e-certificates. Companies can sponsor these carbon reductions, and use Agreena’s platform to track them.</p>\n<h1><b>Atoms into Commodities</b></h1>\n<p>The creators of these new platforms believe that they can solve the knowledge problem of net zero with software. Given the proliferation of net-zero pledges, this is a profitable problem to solve. But the platforms all approach this problem in a particular way: they turn carbon into a tradable commodity. This points to a broader point: net zero, in its current configuration, is a market-based project. It requires creating a global market where offsets can be freely bought and sold. This market already exists, but it has much room to grow; Mark Carney, the former governor of the Bank of England, says it could be worth $100 billion. </p>\n<p>Creating that value, though, hinges on turning lively carbon atoms into a smooth commodity. And that task, in turn, hinges on code. The new platforms aim to improve and expand carbon markets by packaging carbon into a reliable product that can be easily bought and sold online. Their value proposition isn’t just about using digital tools to do superior carbon monitoring and accounting, but about disrupting traditional carbon markets by disintermediating them.</p>\n<p>In traditional carbon markets, supply and demand is linked by retail traders who purchase carbon credits from suppliers and bundle them into portfolios, to be sold on to brokers or end buyers. This is an inefficient system, with too many middlemen; it is also rife with fraud. The new platforms want to cut the knot by connecting buyers and sellers—that is, the producers of positive emissions with the producers of negative emissions. Think of Veritree: corporations can purchase offsets by directly sponsoring planting projects in the developing world, without having to navigate a tangle of traders and brokers.</p>\n<p>The platforms don’t just want to revolutionize existing carbon markets, however. They also want to create new ones. Climate Impact X is a Singapore-based carbon exchange that plans to build a “forest carbon marketplace” that uses remote sensing, artificial intelligence, and blockchain to “open participation to forests that were previously left out of the climate solution.” The idea is that a data-driven approach will lower the barriers of entry for the producers of negative emissions and enable more of them to participate. And, if given the chance, they probably will: there is a lot of money to be made. After languishing for many years, carbon offsets are trading at record highs.</p>\n<h1><b>Risk Factors</b></h1>\n<p>The rise of a decarbonization-as-a-service sector may make it easier to commodify and exchange carbon. But what if it doesn’t actually help address climate change? There is always the risk that the platforms could be algorithmically flawed—that their software isn’t accurately quantifying emissions, whether positive or negative. But there are also deeper risks, ones that can’t be mitigated by tweaks to the code because they’re inherent in a market-based system.</p>\n<p>First, ask yourself what any of these platforms want. Continued emissions; more exchange. The platform becomes a vested actor. The company is not oriented toward the phaseout of fossil fuels. Rather, it wants to maintain its own life, its own revenue stream. If you were designing a net-zero platform with the goal of working towards full decarbonization, it would be a time-limited project. But that would be incompatible with market imperatives: nobody wants to start a business with an expiration date. This is why the companies running these platforms will have an incentive to encourage a version of net zero with continued residual emissions—not a version of net zero oriented toward a future that would make them obsolete.</p>\n<p>More broadly, a market-based system cultivates a tendency toward cheapness that’s hard to square with the costs of carbon removals. Why buy a carbon offset for $50 or $100 a ton when you can buy one for $10 a ton? How is a sustainability manager at a company going to justify that to higher-ups or shareholders? Yet that $10 offset is much less likely to be trustworthy, since proper monitoring and verification costs money. Moreover, the most permanent kind of carbon removals, performed through industrial technologies like CCS (Carbon Capture and Storage), still cost hundreds of dollars per ton. Yes, some platforms will attempt to introduce boutique or premium removals. But no matter how sophisticated the platforms for carbon management become, market logic will inevitably push companies away from these more expensive and more robust offsetting techniques, and toward cheaper and less effective ones.</p>\n<p>Another issue with a market-based system is that offsets can be purchased by any market actor. But talk to any climate scientist and they’ll tell you that to reach net zero, removals should only be used to compensate for emissions from sectors that are hard to transition to renewables, like aviation or agriculture. In an open market, offsets can be bought up by anyone, including entities that have no future in a post-carbon economy such as fossil fuel companies. That’s bad, because we need to allocate removal capacity to sectors that we want to preserve and whose emissions are truly hard to abate. Platforms can make carbon markets more efficient, but they can’t perform the sorting function needed to prioritize the offsetting of particular activities and industries.</p>\n<p>A final problem with a market-based system is that it turns the platforms themselves into black boxes. As profit-seeking enterprises, they must protect their algorithms and data, as otherwise their competitors might gain an advantage. But this opacity obstructs the learning and experimentation process that’s required to combat climate change. We need a broad-based scientific effort to help figure out what works in terms of curbing emissions and removing carbon from the atmosphere. That can’t happen if all the data is locked away on proprietary platforms, hidden from view.</p>\n<p>We wouldn’t just be entrusting the platforms with data, however. We would also be entrusting them to play a major role in the governance of ecosystems, with significant social consequences. Creating negative emissions is never a neutral, purely technical process—it always involves political choices. For example, communal land title is sometimes seen as a risk to the permanence of carbon credits.  This led to the exclusion of communally held land from one carbon credits project in Cambodia, as research by Sarah Milne and Sango Mahanty has shown. As these calculative practices scale up in digital realms, the repercussions will be turbocharged. </p>\n<p>Getting to net zero matters, but how we get there is just as important. Put another way, different attempts to quantify carbon produce different kinds of social relations. Ceding unilateral control over these choices to corporate platforms—letting them decide which kinds of net-zero social relations to make—would be a significant mistake. </p>\n<h1><b>Public and Planetary</b></h1>\n<p>Software is essential for facing the challenge of climate change. We need to build a computational infrastructure for tracking carbon. The impact of humans on ecosystems has been so deep and so complex that digital monitoring and modeling are essential for ecological repair. As Benjamin Bratton writes, “planetary-scale computation” could “contribute to the comprehension, composition, and enforcement of a shared future that is more rich, diverse, and viable.” But right now, we are headed towards a world of proprietary platforms, repeating the same mistakes that we made with the development of the internet. </p>\n<p>Shouldn’t knowledge about the Earth’s carbon flows belong to communities and the commons? Shouldn’t the benefits of such data go to the people who are working to remove and sequester carbon—tending the trees, soil, seagrass meadows, and injection wells—and to society more broadly? Shouldn’t the political choices about how to quantify carbon—and, by extension, about what kind of social relations to create in pursuit of net zero—be made democratically, rather than by executives and shareholders? </p>\n<p>We need platforms that monitor our world for the sake of collective management of a shared commons—not platforms that measure our world for the sake of profiting from the data created from it, extracting value from the digital layer the same way that value is extracted from the mines, forests, and soils of our physical world. Plundering the earth and then repeating the plunder in the metaverse is dystopia squared.</p>\n<p>We could imagine platforms that are so much better: better because they actually get us to net zero <i>and</i> address other sustainability and social challenges. The public sector must be central here. It alone can bear the costs of accurate monitoring of both positive and negative emissions—costs that disincentivize companies from buying high-quality carbon offsets, no matter how many advanced digital tools for carbon management emerge. </p>\n<p>Public platforms can also help dislodge another obstacle to climate action: community resistance. We will have to build an incredible amount of new transmission lines, solar panels, wind farms, geothermal facilities, factories, mines, and more to pull off a wholesale transformation of our energy system. But when people don’t understand the contours of the problem, or don’t benefit from the solution, they will oppose such initiatives. We’ve seen already that technocratic climate projects without public input are likely to face hostility from local communities. If such communities aren’t brought into the design process, the energy transition is imperiled. </p>\n<p>Better platforms are not a panacea for this challenge, but they could help. Imagine a platform for tracking carbon that isn’t just operating quietly in the background, but is highly visible, easy-to-use, open source, and closely integrated with community planning projects. Such platforms could enable people to collaborate on roadmaps for decarbonizing their town or region. They could integrate data around carbon flows and other ecosystem attributes with real-time visualization tools, in order to anticipate different scenarios and deliberate around possible tradeoffs. The platforms could facilitate a more participatory ecology, and thus generate community buy-in for decarbonization measures.</p>\n<p>More broadly, public planetary data infrastructures would enable the inhabitants of Earth to know their world. Knowledge about one’s environment should be a basic human right. Imagine a world where you could know what’s in your air, what’s in your drinking water, what species are in the forest near you and how much carbon it’s storing, or what the health of your local lake is like. You could use this information not just to gauge the environmental risks you face, but also to discover which companies are degrading the ecological systems you live in and hold them accountable.</p>\n<p>This isn’t to suggest that every piece of data needs to be public. As the Indigenous scholar Stephanie Carroll Rainie and her colleagues have explained, open data can be in tension with the rights of Indigenous peoples to govern their own data. In particular, it may cause tensions for communities that continue to experience data extraction under settler-colonial frameworks, and who are working to establish their own frameworks. When it comes to knowing net zero, the important thing is that the computational systems for monitoring emissions and carbon flows are publicly or community-owned, accessible to community members, and democratically governed. What this actually looks like on local, regional, and planetary scales needs to be established through participatory processes that will require time and trust.</p>\n<h1><b>Across the Binaries</b></h1>\n<p>How do we get there? The answer is not fancy. It involves assembling a coalition for public ecological data infrastructures, drawn from several existing communities. There’s the long-standing open source software movement that could participate. There’s also the open data movement in science, and the movement for Indigenous data sovereignty. Environmentalist NGOs are tracking data about emissions, from larger projects like the Environmental Defense Fund’s methane-tracking satellites to databases like the Carbon Disclosure Project. There are a number of people across these fields who might join a movement for open and public planetary data. So why doesn’t this movement exist in a more mainstream way, or even as a common demand at climate protests? </p>\n<p>One challenge is the fact that this is an anticipatory mobilization. We’re not mobilizing against something that’s already happened, we’re acting defensively based upon trends that are just beginning to emerge. Proprietary carbon management platforms are still in their infancy; their full impact might not be felt for many years. </p>\n<p>Then there’s the cultural divide between the worlds of climate activism and tech activism. Organizations concerned with climate change may be inclined to see the digital as outside their core mission; after all, many people became involved in this space because they loved being outside, not because they wanted to think about algorithms. Moreover, such people may be actively opposed to technological interventions, or understandably dismiss net zero as a narrow, technocratic goal. Meanwhile, people with expertise in algorithmic justice issues might not be tracking developments in the environmental sphere. Their attention is likely devoted to a multitude of other concerns.</p>\n<p>But each of these communities has critical things to contribute. Climate activists can help us avoid the trap of “platform determinism”—that is, the risk of fetishizing the platforms as mythically powerful actors, instead of centering the choices made by the humans who design the platforms. Such activists also bring expertise in movement building: they know how to put pressure on investors and companies, and how to form relationships with policymakers. On the other hand, those who are working on the politics of data, whether from socialist, decolonial, or Indigenous perspectives, have valuable experience in identifying the problems with data appropriation, access, and use, as well as in creating just data frameworks. And technologists can put their knowledge of quantification and design to work building platforms that are genuinely usable and inspiring. </p>\n<p>The knowledge problem of net zero is difficult but not insurmountable. Solving it the right way will require a group effort. We must build data infrastructures that embody multiple ways of knowing and understanding our world, and that help us advance both ecological and social ends, before corporations conquer this space for themselves.</p>",
      "content_text": "Net zero has gone viral. Everyone is announcing their net-zero greenhouse gas emissions targets, from Saudi Arabia to Australia. By the final day of COP26—the annual United Nations Climate Change Conference held in Glasgow in 2021—more than 130 countries had made net-zero pledges of one kind or another, representing about 70 percent of the world’s UN-recognized nations. The private sector has also rushed in: more than 30 percent of the world’s 2,000 biggest public companies have committed to net-zero targets, including Amazon, Walmart, and ExxonMobil. \nA global ambition has coalesced. It’s an achievement of sorts. Limiting warming to 1.5°C requires reaching net zero by midcentury, according to the Intergovernmental Panel on Climate Change (IPCC). This doesn’t mean zero emissions; rather, it means that some remaining amount of positive emissions would be canceled out by “negative emissions”—that is, by carbon removals. Negative emissions can be generated by using ecosystems like forests, farms, and oceans to store more carbon, or by using industrial technologies like carbon capture and storage (CCS) to pull carbon from the atmosphere and store it in rock formations. When these negative emissions balance out the positive emissions—when the amount of carbon being taken out of the atmosphere equals the amount of carbon being put into the atmosphere—then net zero is reached.\nUnder such an arrangement, countries are free to continue burning fossil fuels, so long as they offset their emissions. For this reason, many climate advocates have been critical of net zero as a goal. One common critique is that net-zero pledges won’t stop the continued extraction and combustion of fossil fuels. Further, they’re aimed at a future that’s far enough away that present-day leaders won’t be accountable for what happens. “Net zero by 2050. Blah, blah, blah,” Greta Thunberg told a summit of young organizers just prior to COP26. \nIt’s true that net zero is woefully insufficient. We also need to be talking about immediately phasing out fossil fuel production. But net zero is still a worthwhile transitional goal, because we don’t yet have all the technologies we need at scale for true climate repair. Climate change is a problem of stocks, not flows: we need not only to stop emitting carbon by switching to renewables, but to reduce the existing levels of carbon in our atmosphere. Net zero alone won’t get us there. Still, it gives us a way to buy time while we develop and deploy the technologies required for full decarbonization.\nYet net zero is harder than it looks. The difficulty isn’t just political—compelling countries and companies to make promises and abide by them—but epistemological. At the center of net zero is a knowledge problem: How do we know when we’ve gotten to net zero? Answering this question is surprisingly hard. \nThere are two main challenges. First, there is immense technical complexity involved in accurately measuring both positive and negative emissions. Take positive emissions: how many are embodied in the manufacture of a car? You could measure how much carbon is produced by a single car factory, but a car has around 30,000 parts. Those parts might be sourced from suppliers around the world, each with their own carbon footprint. Further, the parts use different raw materials, and the extraction and transport of those materials carry emissions of their own. And that’s only one factory; there are some 300,000 car manufacturing facilities in the US alone.\nMeasuring negative emissions presents headaches of its own. For example, there are emergent methods for measuring how much carbon is stored in soil that hinge on spectroscopy, satellite-based sensors, and machine learning. But knowing what’s actually going on in the soil is complex, as conditions can vary even across a single farm. Knowing what’s going on with carbon in the deep ocean, as required for some carbon removal approaches, is even more challenging. Industrial technologies like CCS that store carbon geologically may seem easier to measure than biological systems, but, even then, understanding what happens to carbon that is stored thousands of feet underground isn’t easy.\nEven if these difficulties are overcome, however, there is still the problem of carbon deception. This is the second main challenge involved in knowing when we’ve gotten to net zero: the presence of dishonest actors in the system. Think about Volkswagen rigging vehicles to cheat on emissions tests, or gas station chain owner Lev Dermen, who was found guilty of stealing $1 billion from US taxpayers through claiming tax credits for renewable biodiesel that didn’t exist. Behind the office-park facade of net zero lies a seedy hotbed of white-collar crime.\nThe knowability of net zero can’t be taken for granted, then. All those policymakers and executives are making net-zero pledges without a clue for how to see them through. How can these pledges possibly be fulfilled? How can the knowledge problem of net zero be solved?\nThe answer, apparently, is software. Companies large and small have begun to build “platforms” that promise to help organizations meet their net-zero promises. These platforms claim to be able to deliver “decarbonization-as-a-service” through the use of digital technologies that effectively track carbon. They are racing ahead of law and policy and performing de facto governance, creating new proprietary infrastructures for knowing and managing our planet.\nIf this new regime fails to reliably measure and monitor carbon—and it very well may—that will be bad for the climate. If it succeeds, that may also be bad for the climate, not to mention ecosystems more broadly as well as human communities. But right now, before the new computational systems are locked in, we may have a chance to intervene and shape them for the better.\nInitial Tree Offering\nIn 2012, Derrick Emsley cofounded Tentree, a Vancouver-based clothing company that plants ten trees for every product sold. That sounds simple enough, but managing the planting projects turned out to be a challenge. “The hardest part was monitoring and verifying the work and claims we were making,” Emsley told The Hill’s Saul Elbein. Confirming that the trees they paid to plant were actually planted required costly in-person trips and lots of managerial overhead—it meant “traveling there, auditing them, making sure those trees were in the ground having an impact,” according to Emsley.\nSo Tentree started developing software to help streamline the process. That software became the basis of Veritree, a publicly available “planting management platform” unveiled in the fall of 2021. When a company that wants to offset their emissions signs up for Veritree, they get access to a user portal that lets them place orders for new tree plantings and displays metrics on their current tree holdings. These metrics are collected by the planters in the developing countries, who use custom-made “collect devices”—essentially modified smartphones designed to work in internet-limited environments—to take geotagged photographs of the trees. The trees get a unique digital token, and become digital inventory, hosted on the Cardano blockchain. Using a blockchain is supposed to reduce fraud by ensuring that trees are only counted once, so that the same forest can’t be claimed by multiple entities—a well-known problem in the world of carbon credits. \nVeritree is in its early days, but it hopes to become “an operating system for the restoration economy,” in Emsley’s words. An “Initial Tree Offering” was used to raise money for a “First Edition Forest,” which features trees in Madagascar, Indonesia, Nepal, Kenya, Senegal, and Haiti. The appeal for corporations hoping to make good on their net-zero pledges is obvious: they can invest in a reliable carbon offset program and obtain a real-time picture of precisely how much carbon is being offset, and share that information with the public. \nVeritree is far from the only platform hoping to dominate the net-zero space. A wide range of digital services is being developed by companies large and small. Established “Big Four” accounting firms like KPMG and Deloitte, as well as tech giants like Salesforce, are creating tools for Environmental, Social, and Governance (ESG) accounting that help measure the carbon footprint of firms, among other things. Some companies combine carbon measurement with a portal for purchasing offsets, such as the Atlanta-based startup Cloverly. Still others try to track negative emissions, like Veritree. Agreena, for example, is a Dutch startup that monitors changes in farmers’ fields after they switch to regenerative agriculture, and issues them e-certificates. Companies can sponsor these carbon reductions, and use Agreena’s platform to track them.\nAtoms into Commodities\nThe creators of these new platforms believe that they can solve the knowledge problem of net zero with software. Given the proliferation of net-zero pledges, this is a profitable problem to solve. But the platforms all approach this problem in a particular way: they turn carbon into a tradable commodity. This points to a broader point: net zero, in its current configuration, is a market-based project. It requires creating a global market where offsets can be freely bought and sold. This market already exists, but it has much room to grow; Mark Carney, the former governor of the Bank of England, says it could be worth $100 billion. \nCreating that value, though, hinges on turning lively carbon atoms into a smooth commodity. And that task, in turn, hinges on code. The new platforms aim to improve and expand carbon markets by packaging carbon into a reliable product that can be easily bought and sold online. Their value proposition isn’t just about using digital tools to do superior carbon monitoring and accounting, but about disrupting traditional carbon markets by disintermediating them.\nIn traditional carbon markets, supply and demand is linked by retail traders who purchase carbon credits from suppliers and bundle them into portfolios, to be sold on to brokers or end buyers. This is an inefficient system, with too many middlemen; it is also rife with fraud. The new platforms want to cut the knot by connecting buyers and sellers—that is, the producers of positive emissions with the producers of negative emissions. Think of Veritree: corporations can purchase offsets by directly sponsoring planting projects in the developing world, without having to navigate a tangle of traders and brokers.\nThe platforms don’t just want to revolutionize existing carbon markets, however. They also want to create new ones. Climate Impact X is a Singapore-based carbon exchange that plans to build a “forest carbon marketplace” that uses remote sensing, artificial intelligence, and blockchain to “open participation to forests that were previously left out of the climate solution.” The idea is that a data-driven approach will lower the barriers of entry for the producers of negative emissions and enable more of them to participate. And, if given the chance, they probably will: there is a lot of money to be made. After languishing for many years, carbon offsets are trading at record highs.\nRisk Factors\nThe rise of a decarbonization-as-a-service sector may make it easier to commodify and exchange carbon. But what if it doesn’t actually help address climate change? There is always the risk that the platforms could be algorithmically flawed—that their software isn’t accurately quantifying emissions, whether positive or negative. But there are also deeper risks, ones that can’t be mitigated by tweaks to the code because they’re inherent in a market-based system.\nFirst, ask yourself what any of these platforms want. Continued emissions; more exchange. The platform becomes a vested actor. The company is not oriented toward the phaseout of fossil fuels. Rather, it wants to maintain its own life, its own revenue stream. If you were designing a net-zero platform with the goal of working towards full decarbonization, it would be a time-limited project. But that would be incompatible with market imperatives: nobody wants to start a business with an expiration date. This is why the companies running these platforms will have an incentive to encourage a version of net zero with continued residual emissions—not a version of net zero oriented toward a future that would make them obsolete.\nMore broadly, a market-based system cultivates a tendency toward cheapness that’s hard to square with the costs of carbon removals. Why buy a carbon offset for $50 or $100 a ton when you can buy one for $10 a ton? How is a sustainability manager at a company going to justify that to higher-ups or shareholders? Yet that $10 offset is much less likely to be trustworthy, since proper monitoring and verification costs money. Moreover, the most permanent kind of carbon removals, performed through industrial technologies like CCS (Carbon Capture and Storage), still cost hundreds of dollars per ton. Yes, some platforms will attempt to introduce boutique or premium removals. But no matter how sophisticated the platforms for carbon management become, market logic will inevitably push companies away from these more expensive and more robust offsetting techniques, and toward cheaper and less effective ones.\nAnother issue with a market-based system is that offsets can be purchased by any market actor. But talk to any climate scientist and they’ll tell you that to reach net zero, removals should only be used to compensate for emissions from sectors that are hard to transition to renewables, like aviation or agriculture. In an open market, offsets can be bought up by anyone, including entities that have no future in a post-carbon economy such as fossil fuel companies. That’s bad, because we need to allocate removal capacity to sectors that we want to preserve and whose emissions are truly hard to abate. Platforms can make carbon markets more efficient, but they can’t perform the sorting function needed to prioritize the offsetting of particular activities and industries.\nA final problem with a market-based system is that it turns the platforms themselves into black boxes. As profit-seeking enterprises, they must protect their algorithms and data, as otherwise their competitors might gain an advantage. But this opacity obstructs the learning and experimentation process that’s required to combat climate change. We need a broad-based scientific effort to help figure out what works in terms of curbing emissions and removing carbon from the atmosphere. That can’t happen if all the data is locked away on proprietary platforms, hidden from view.\nWe wouldn’t just be entrusting the platforms with data, however. We would also be entrusting them to play a major role in the governance of ecosystems, with significant social consequences. Creating negative emissions is never a neutral, purely technical process—it always involves political choices. For example, communal land title is sometimes seen as a risk to the permanence of carbon credits.  This led to the exclusion of communally held land from one carbon credits project in Cambodia, as research by Sarah Milne and Sango Mahanty has shown. As these calculative practices scale up in digital realms, the repercussions will be turbocharged. \nGetting to net zero matters, but how we get there is just as important. Put another way, different attempts to quantify carbon produce different kinds of social relations. Ceding unilateral control over these choices to corporate platforms—letting them decide which kinds of net-zero social relations to make—would be a significant mistake. \nPublic and Planetary\nSoftware is essential for facing the challenge of climate change. We need to build a computational infrastructure for tracking carbon. The impact of humans on ecosystems has been so deep and so complex that digital monitoring and modeling are essential for ecological repair. As Benjamin Bratton writes, “planetary-scale computation” could “contribute to the comprehension, composition, and enforcement of a shared future that is more rich, diverse, and viable.” But right now, we are headed towards a world of proprietary platforms, repeating the same mistakes that we made with the development of the internet. \nShouldn’t knowledge about the Earth’s carbon flows belong to communities and the commons? Shouldn’t the benefits of such data go to the people who are working to remove and sequester carbon—tending the trees, soil, seagrass meadows, and injection wells—and to society more broadly? Shouldn’t the political choices about how to quantify carbon—and, by extension, about what kind of social relations to create in pursuit of net zero—be made democratically, rather than by executives and shareholders? \nWe need platforms that monitor our world for the sake of collective management of a shared commons—not platforms that measure our world for the sake of profiting from the data created from it, extracting value from the digital layer the same way that value is extracted from the mines, forests, and soils of our physical world. Plundering the earth and then repeating the plunder in the metaverse is dystopia squared.\nWe could imagine platforms that are so much better: better because they actually get us to net zero and address other sustainability and social challenges. The public sector must be central here. It alone can bear the costs of accurate monitoring of both positive and negative emissions—costs that disincentivize companies from buying high-quality carbon offsets, no matter how many advanced digital tools for carbon management emerge. \nPublic platforms can also help dislodge another obstacle to climate action: community resistance. We will have to build an incredible amount of new transmission lines, solar panels, wind farms, geothermal facilities, factories, mines, and more to pull off a wholesale transformation of our energy system. But when people don’t understand the contours of the problem, or don’t benefit from the solution, they will oppose such initiatives. We’ve seen already that technocratic climate projects without public input are likely to face hostility from local communities. If such communities aren’t brought into the design process, the energy transition is imperiled. \nBetter platforms are not a panacea for this challenge, but they could help. Imagine a platform for tracking carbon that isn’t just operating quietly in the background, but is highly visible, easy-to-use, open source, and closely integrated with community planning projects. Such platforms could enable people to collaborate on roadmaps for decarbonizing their town or region. They could integrate data around carbon flows and other ecosystem attributes with real-time visualization tools, in order to anticipate different scenarios and deliberate around possible tradeoffs. The platforms could facilitate a more participatory ecology, and thus generate community buy-in for decarbonization measures.\nMore broadly, public planetary data infrastructures would enable the inhabitants of Earth to know their world. Knowledge about one’s environment should be a basic human right. Imagine a world where you could know what’s in your air, what’s in your drinking water, what species are in the forest near you and how much carbon it’s storing, or what the health of your local lake is like. You could use this information not just to gauge the environmental risks you face, but also to discover which companies are degrading the ecological systems you live in and hold them accountable.\nThis isn’t to suggest that every piece of data needs to be public. As the Indigenous scholar Stephanie Carroll Rainie and her colleagues have explained, open data can be in tension with the rights of Indigenous peoples to govern their own data. In particular, it may cause tensions for communities that continue to experience data extraction under settler-colonial frameworks, and who are working to establish their own frameworks. When it comes to knowing net zero, the important thing is that the computational systems for monitoring emissions and carbon flows are publicly or community-owned, accessible to community members, and democratically governed. What this actually looks like on local, regional, and planetary scales needs to be established through participatory processes that will require time and trust.\nAcross the Binaries\nHow do we get there? The answer is not fancy. It involves assembling a coalition for public ecological data infrastructures, drawn from several existing communities. There’s the long-standing open source software movement that could participate. There’s also the open data movement in science, and the movement for Indigenous data sovereignty. Environmentalist NGOs are tracking data about emissions, from larger projects like the Environmental Defense Fund’s methane-tracking satellites to databases like the Carbon Disclosure Project. There are a number of people across these fields who might join a movement for open and public planetary data. So why doesn’t this movement exist in a more mainstream way, or even as a common demand at climate protests? \nOne challenge is the fact that this is an anticipatory mobilization. We’re not mobilizing against something that’s already happened, we’re acting defensively based upon trends that are just beginning to emerge. Proprietary carbon management platforms are still in their infancy; their full impact might not be felt for many years. \nThen there’s the cultural divide between the worlds of climate activism and tech activism. Organizations concerned with climate change may be inclined to see the digital as outside their core mission; after all, many people became involved in this space because they loved being outside, not because they wanted to think about algorithms. Moreover, such people may be actively opposed to technological interventions, or understandably dismiss net zero as a narrow, technocratic goal. Meanwhile, people with expertise in algorithmic justice issues might not be tracking developments in the environmental sphere. Their attention is likely devoted to a multitude of other concerns.\nBut each of these communities has critical things to contribute. Climate activists can help us avoid the trap of “platform determinism”—that is, the risk of fetishizing the platforms as mythically powerful actors, instead of centering the choices made by the humans who design the platforms. Such activists also bring expertise in movement building: they know how to put pressure on investors and companies, and how to form relationships with policymakers. On the other hand, those who are working on the politics of data, whether from socialist, decolonial, or Indigenous perspectives, have valuable experience in identifying the problems with data appropriation, access, and use, as well as in creating just data frameworks. And technologists can put their knowledge of quantification and design to work building platforms that are genuinely usable and inspiring. \nThe knowledge problem of net zero is difficult but not insurmountable. Solving it the right way will require a group effort. We must build data infrastructures that embody multiple ways of knowing and understanding our world, and that help us advance both ecological and social ends, before corporations conquer this space for themselves.",
      "date_published": "2022-04-27T13:02:55.000Z",
      "date_modified": "2022-04-27T13:02:55.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/seeding-the-cloud",
      "url": "https://logicmag.io/clouds/seeding-the-cloud",
      "title": "Seeding the Cloud",
      "summary": "A reflection on the rise of the cloud from somebody who experienced it firsthand.",
      "content_html": "<p>My first encounter with cloud computing was in the early 2010s. It took the form of a problem—a crisis, even—that needed solving. By crisis I don’t mean a serious issue such as climate change, but rather the kind of business problem that’s treated as an existential threat, prompting late nights and “all hands on deck” emails from management.</p>\n<p>In this case, it was a problem caused by a system that couldn’t keep up with demand. I worked for a company that I’ll call Libros, which ran a book-ordering website. The website was powered by servers located on-premises—that is, within our data center. A data center is a kind of specialized warehouse used to house computers known as servers. These computers are called servers because, unlike your personal computer, they are used to serve many people simultaneously. When you use a web application such as a banking website, there are servers in data centers behind the scenes. In a data center, you’ll also find the data storage, networking, and other equipment that together form computational systems. </p>\n<p>Early in my career, I spent many hours in places like this. They’re kept very cold—think of the bone-deep chill of a February day—to prevent the equipment, which generates heat (lots of heat), from burning out. They’re also easy places to get injured. Although it was years ago, I can still vividly remember cutting my fingers (sometimes very badly) on the rails used to hold servers in place. No matter how many servers you successfully installed, there’d always be a few which were difficult to place, requiring careful work with hard metal and plastic in small spaces, a perfect recipe for cuts and pinches. It was an occupational hazard for many of us in those days, and we considered it a badge of honor.</p>\n<p>Our data center worked, but the servers it hosted could become slow or unresponsive if there was too much customer demand. (“Too much” is a relative term: the amount of work a server can do is based on factors like the amount of memory and processing capacity it has—just like your laptop but on a bigger scale.) That was the source of the crisis at Libros: every year, as the popularity of our website grew, the system became more strained. Customers complained about slow response times, lost orders, and other annoyances. Upset customers meant lost revenue, which made our executives angry, who in turn made our managers demand solutions. </p>\n<p>The trouble was that solving the problem required installing new servers. And new servers required money the company was unwilling to spend—a few million, not a trivial investment. So there we were, my colleagues and I, facing pressure to fix a problem but not provided with the tools to do it. There was another challenge: even if we <i>were</i> granted the money for the new servers, additional demand might easily outrun the added capacity, placing us back at square one. That is, by the time my colleagues and I finished installing the new servers—shivering and slicing our hands open in the data center—so many more users might be trying to access our website that the new infrastructure wouldn’t make much difference. Think of building a highway: if it fills up with cars right away, the traffic is just as bad as before.</p>\n<p>What to do? The way we solved this problem was by turning to cloud computing, a new offering at the time—so new, in fact, that most techies and managers were unaware of it and, outside of early enthusiasts, those who were familiar with it harbored deep suspicions. (“No cloud” policies were not uncommon at the time.) We had no way of knowing that the technology we used to address our specific challenges, as helpful as it was from a technical point of view, would grow over the next several years to become extraordinarily large—indeed, to become the dominant form of computing, with immense consequences for the world’s political economy and for how the power of computation would be used and abused. What few people realize today is that, in those early days, the move to the cloud mostly wasn’t a top-down decision. It was typically brought into shops quietly, surreptitiously or against management objections, by the engineers themselves, simply because it made their jobs a little easier. We let the behemoth in through the backdoor. </p>\n<h1><b>Fee Fi Fo Fum</b></h1>\n<p>As our team at Libros sweated, one of my colleagues, always on the lookout for new tech industry trends, tentatively suggested a relatively new service from Amazon called Elastic Beanstalk. In those days, before Amazon’s rise into ubiquity, our first question was: <i>Amazon? The bookseller? </i>Naturally, the second question was: <i>What the hell is an elastic beanstalk?</i> We knew what the words “elastic” and “beanstalk” meant separately, but together it seemed like a nonsensical word sandwich.</p>\n<p>“Hear me out,” my colleague said. “This is a web-based service we can use to host our customer portal—it can automatically expand and contract with growing or shrinking demand, solving our availability and response problems.” </p>\n<p>Let’s pause here to consider the impact this news had on me and my coworkers. A major problem might just disappear, <i>poof</i>, because of a computational service we could use like water or electricity. In the same way we don’t run our own power or water treatment plants—rather, <i>consuming</i> these resources as a utility—Amazon was offering a utility model of computing. It had first begun doing so in 2006, through a new division called Amazon Web Services (AWS). Rather than running our website from our own data center, we could let AWS do it from theirs. And AWS would be able to increase capacity in response to rising customer demand much faster than we could. </p>\n<p>Sure, there’d be real software development and networking effort required to get things started. But the promise of using something that was a commodity, rather than bespoke, was enticing. This was the appeal behind the new paradigm of cloud computing that was then emerging: we could rent access to data center resources like processor power, storage, and databases as needed.</p>\n<p>We listened to that colleague and directed our plans, like a conference of nerd generals, to putting Amazon’s Elastic Beanstalk to use. There was, however, a significant hurdle: management did not trust the cloud. </p>\n<h1><b>Behind the Boss’s Back</b></h1>\n<p>Today, when the cloud is dominant, it’s difficult to understand just how hostile many managers were to the technology. There were a couple main issues. The first was that Amazon, the company that first offered cloud infrastructure services, was known more for book delivery than anything having to do with enterprise computing. The second, larger obstacle was the fear of a loss of control. Capitalist enterprises crave control and predictability—the ability to forecast spending, profits, and the behavior of workers. With on-premises computing, even an executive who didn’t know the difference between a SCSI disk drive and a microwave dinner (only a slight exaggeration) could walk into a company data center and survey the physical reality of all those tens of millions spent—the chill in the air, the blinking lights, the techies busy teching the tech. It was all there. Giving that up was a very hard sell for management in the beginning.</p>\n<p>So my colleagues and I had to be stealthy. We diagrammed how to build an elastic web service—that is, a service that can expand and contract with customer demand—using Amazon’s cloud. We worked with the networking team to devise a strategy for redirecting user requests from the stressed, on-premises system to the cloud service. And we created a fallback plan, just in case our gamble didn’t pay off. </p>\n<p>The late-night tests when demand was usually low were promising; the redirect and fallback methods behaved to plan. But the only way to really know whether the new service would work was to put it online during crush time. We (metaphorically) pulled a lever and prayed to the gods that it would all come together.</p>\n<p>The customer rush began and the system responded as we’d hoped, automatically adding more capacity as demand grew and removing capacity as demand shrank. Management was pleased. For the first time in years, there were zero customer complaints and many smoothly executed sales. Eventually, after some time had passed, we let the cloud cat out of the bag. Surprise! We solved the problem by going behind everyone’s back and using new technology. At first, management was dubious. But it’s difficult to argue with success—and this particular success took pressure off middle managers, who for years had faced uncomfortable conversations with the C-suite because of crunch season complaints. The old saying that “it’s better to ask for forgiveness than permission” applied, because everyone came out looking good.</p>\n<p>Of course, cloud computing also meant the professional lives of people like me would be utterly transformed. It’s difficult to overstate the effect on those of us who had built our careers working with what in the industry is known as bare metal—those of us who had been able to touch, and engineer into complex systems, the machines that run the software we use. For some, the rise of the cloud was seen as a threat—an unwelcome change that might eliminate their job, a not unreasonable concern, particularly for workers whose jobs were focused on tasks such as server maintenance and systems and database administration. But for many others, myself included, it was seen as a relief. When I thought of the lost weekends, the ruined dates, the late nights caused by server failures, I didn’t miss the old way of working at all. Because of elasticity, we no longer had to intervene when systems were stressed. Because of hosted platform databases (instead of databases running on our own servers) we could focus on using the database, rather than constantly worrying about whether a system would work as needed. </p>\n<p>What I didn’t realize at the time was that alongside this new capability came the accumulation of a new form of techno-political power. I didn’t realize that the increasing concentration of data center capacity by a few US-based tech firms (primarily Amazon, Microsoft, and Google) would help intensify algorithmic harms and inaugurate a new era of monopoly. While trying to solve an immediate problem, my colleagues and I inadvertently helped this behemoth grow, welcoming the services it provided, failing to foresee the future we were making possible.</p>\n<h1><b>Points of Failure</b></h1>\n<p>What kind of world has the cloud helped create? Cloud data centers, which have grown so large that they now operate at what’s called hyperscale, enable cloud providers like Amazon and their customers to run the types of computationally demanding systems that only a very few companies could have hoped to assemble in the past. These systems have greatly enlarged the command and control capabilities of firms large and small. For example, without the cloud, Amazon would not be able to monitor their drivers or automate aspects of management in their warehouses. Moreover, the recent growth in machine learning startups—some offering dubious and harmful services such as facial recognition to determine hiring decisions—can be directly linked to the growth of the cloud. Hyperscale-level cloud computing makes it possible for these VC-funded companies to build complex software without needing to invest in expensive data center equipment and real estate.</p>\n<p>Using the Marxist theory of base and superstructure, we can view the cloud’s data centers as an element of the <i>mode of production</i>—the combination of tools, machinery, technical expertise, and labor that propels capitalist activity. Computation is an industrial process. Data centers are created by bringing together computers (servers) and associated equipment that are manufactured using the extraction of minerals, the forging of metals, and shaping of hydrocarbons into plastics. The tech industry presents this hard physicality—which makes software useful—as a <i>cloud</i>, an amorphous, unlimited digital resource adding pleasure and efficiency to our lives. But there’s another way to view the cloud era: as the concentration of computational power and, therefore, real power with political consequences, into fewer and fewer hands.</p>\n<p>This concentration means that only a small handful of companies—and more critically, their executives and investors—possess the ability to determine how computing capacity should be deployed. This not only grants them a vast amount of leverage, it also creates a new mode of failure. Consider the AWS outage on December 7, 2021. This event impacted many companies, including global content providers Disney and Netflix, connected devices such as Ring cameras, and even Amazon’s internal processes that utilize their computational infrastructure (“eating their own dogfood,” as we say). Before the cloud era, each organization might have made large investments in maintaining their own data centers to host the computers, storage, and networking equipment required to offer online services. But now, the access to hyperscale capability and the possibility (if not always reality) of reducing the cost of computation have pushed most companies into the cloud, leading to consolidations that have introduced new kinds of fragility.</p>\n<p>At the dawn of the cloud era, none of this was apparent to me. Like my colleagues, I was focused on technical metrics such as speed and elasticity. What few of us realized is that we were facilitating the birth of a new form of power that rose, like Godzilla from the sea, to loom over everything. The cloud is rapidly becoming the computational infrastructure of global capitalism and the basis of immense digital empires that wield significant political power. But it was workers like me, hands on keyboards, toiling behind the scenes, who laid the foundation.</p>",
      "content_text": "My first encounter with cloud computing was in the early 2010s. It took the form of a problem—a crisis, even—that needed solving. By crisis I don’t mean a serious issue such as climate change, but rather the kind of business problem that’s treated as an existential threat, prompting late nights and “all hands on deck” emails from management.\nIn this case, it was a problem caused by a system that couldn’t keep up with demand. I worked for a company that I’ll call Libros, which ran a book-ordering website. The website was powered by servers located on-premises—that is, within our data center. A data center is a kind of specialized warehouse used to house computers known as servers. These computers are called servers because, unlike your personal computer, they are used to serve many people simultaneously. When you use a web application such as a banking website, there are servers in data centers behind the scenes. In a data center, you’ll also find the data storage, networking, and other equipment that together form computational systems. \nEarly in my career, I spent many hours in places like this. They’re kept very cold—think of the bone-deep chill of a February day—to prevent the equipment, which generates heat (lots of heat), from burning out. They’re also easy places to get injured. Although it was years ago, I can still vividly remember cutting my fingers (sometimes very badly) on the rails used to hold servers in place. No matter how many servers you successfully installed, there’d always be a few which were difficult to place, requiring careful work with hard metal and plastic in small spaces, a perfect recipe for cuts and pinches. It was an occupational hazard for many of us in those days, and we considered it a badge of honor.\nOur data center worked, but the servers it hosted could become slow or unresponsive if there was too much customer demand. (“Too much” is a relative term: the amount of work a server can do is based on factors like the amount of memory and processing capacity it has—just like your laptop but on a bigger scale.) That was the source of the crisis at Libros: every year, as the popularity of our website grew, the system became more strained. Customers complained about slow response times, lost orders, and other annoyances. Upset customers meant lost revenue, which made our executives angry, who in turn made our managers demand solutions. \nThe trouble was that solving the problem required installing new servers. And new servers required money the company was unwilling to spend—a few million, not a trivial investment. So there we were, my colleagues and I, facing pressure to fix a problem but not provided with the tools to do it. There was another challenge: even if we were granted the money for the new servers, additional demand might easily outrun the added capacity, placing us back at square one. That is, by the time my colleagues and I finished installing the new servers—shivering and slicing our hands open in the data center—so many more users might be trying to access our website that the new infrastructure wouldn’t make much difference. Think of building a highway: if it fills up with cars right away, the traffic is just as bad as before.\nWhat to do? The way we solved this problem was by turning to cloud computing, a new offering at the time—so new, in fact, that most techies and managers were unaware of it and, outside of early enthusiasts, those who were familiar with it harbored deep suspicions. (“No cloud” policies were not uncommon at the time.) We had no way of knowing that the technology we used to address our specific challenges, as helpful as it was from a technical point of view, would grow over the next several years to become extraordinarily large—indeed, to become the dominant form of computing, with immense consequences for the world’s political economy and for how the power of computation would be used and abused. What few people realize today is that, in those early days, the move to the cloud mostly wasn’t a top-down decision. It was typically brought into shops quietly, surreptitiously or against management objections, by the engineers themselves, simply because it made their jobs a little easier. We let the behemoth in through the backdoor. \nFee Fi Fo Fum\nAs our team at Libros sweated, one of my colleagues, always on the lookout for new tech industry trends, tentatively suggested a relatively new service from Amazon called Elastic Beanstalk. In those days, before Amazon’s rise into ubiquity, our first question was: Amazon? The bookseller? Naturally, the second question was: What the hell is an elastic beanstalk? We knew what the words “elastic” and “beanstalk” meant separately, but together it seemed like a nonsensical word sandwich.\n“Hear me out,” my colleague said. “This is a web-based service we can use to host our customer portal—it can automatically expand and contract with growing or shrinking demand, solving our availability and response problems.” \nLet’s pause here to consider the impact this news had on me and my coworkers. A major problem might just disappear, poof, because of a computational service we could use like water or electricity. In the same way we don’t run our own power or water treatment plants—rather, consuming these resources as a utility—Amazon was offering a utility model of computing. It had first begun doing so in 2006, through a new division called Amazon Web Services (AWS). Rather than running our website from our own data center, we could let AWS do it from theirs. And AWS would be able to increase capacity in response to rising customer demand much faster than we could. \nSure, there’d be real software development and networking effort required to get things started. But the promise of using something that was a commodity, rather than bespoke, was enticing. This was the appeal behind the new paradigm of cloud computing that was then emerging: we could rent access to data center resources like processor power, storage, and databases as needed.\nWe listened to that colleague and directed our plans, like a conference of nerd generals, to putting Amazon’s Elastic Beanstalk to use. There was, however, a significant hurdle: management did not trust the cloud. \nBehind the Boss’s Back\nToday, when the cloud is dominant, it’s difficult to understand just how hostile many managers were to the technology. There were a couple main issues. The first was that Amazon, the company that first offered cloud infrastructure services, was known more for book delivery than anything having to do with enterprise computing. The second, larger obstacle was the fear of a loss of control. Capitalist enterprises crave control and predictability—the ability to forecast spending, profits, and the behavior of workers. With on-premises computing, even an executive who didn’t know the difference between a SCSI disk drive and a microwave dinner (only a slight exaggeration) could walk into a company data center and survey the physical reality of all those tens of millions spent—the chill in the air, the blinking lights, the techies busy teching the tech. It was all there. Giving that up was a very hard sell for management in the beginning.\nSo my colleagues and I had to be stealthy. We diagrammed how to build an elastic web service—that is, a service that can expand and contract with customer demand—using Amazon’s cloud. We worked with the networking team to devise a strategy for redirecting user requests from the stressed, on-premises system to the cloud service. And we created a fallback plan, just in case our gamble didn’t pay off. \nThe late-night tests when demand was usually low were promising; the redirect and fallback methods behaved to plan. But the only way to really know whether the new service would work was to put it online during crush time. We (metaphorically) pulled a lever and prayed to the gods that it would all come together.\nThe customer rush began and the system responded as we’d hoped, automatically adding more capacity as demand grew and removing capacity as demand shrank. Management was pleased. For the first time in years, there were zero customer complaints and many smoothly executed sales. Eventually, after some time had passed, we let the cloud cat out of the bag. Surprise! We solved the problem by going behind everyone’s back and using new technology. At first, management was dubious. But it’s difficult to argue with success—and this particular success took pressure off middle managers, who for years had faced uncomfortable conversations with the C-suite because of crunch season complaints. The old saying that “it’s better to ask for forgiveness than permission” applied, because everyone came out looking good.\nOf course, cloud computing also meant the professional lives of people like me would be utterly transformed. It’s difficult to overstate the effect on those of us who had built our careers working with what in the industry is known as bare metal—those of us who had been able to touch, and engineer into complex systems, the machines that run the software we use. For some, the rise of the cloud was seen as a threat—an unwelcome change that might eliminate their job, a not unreasonable concern, particularly for workers whose jobs were focused on tasks such as server maintenance and systems and database administration. But for many others, myself included, it was seen as a relief. When I thought of the lost weekends, the ruined dates, the late nights caused by server failures, I didn’t miss the old way of working at all. Because of elasticity, we no longer had to intervene when systems were stressed. Because of hosted platform databases (instead of databases running on our own servers) we could focus on using the database, rather than constantly worrying about whether a system would work as needed. \nWhat I didn’t realize at the time was that alongside this new capability came the accumulation of a new form of techno-political power. I didn’t realize that the increasing concentration of data center capacity by a few US-based tech firms (primarily Amazon, Microsoft, and Google) would help intensify algorithmic harms and inaugurate a new era of monopoly. While trying to solve an immediate problem, my colleagues and I inadvertently helped this behemoth grow, welcoming the services it provided, failing to foresee the future we were making possible.\nPoints of Failure\nWhat kind of world has the cloud helped create? Cloud data centers, which have grown so large that they now operate at what’s called hyperscale, enable cloud providers like Amazon and their customers to run the types of computationally demanding systems that only a very few companies could have hoped to assemble in the past. These systems have greatly enlarged the command and control capabilities of firms large and small. For example, without the cloud, Amazon would not be able to monitor their drivers or automate aspects of management in their warehouses. Moreover, the recent growth in machine learning startups—some offering dubious and harmful services such as facial recognition to determine hiring decisions—can be directly linked to the growth of the cloud. Hyperscale-level cloud computing makes it possible for these VC-funded companies to build complex software without needing to invest in expensive data center equipment and real estate.\nUsing the Marxist theory of base and superstructure, we can view the cloud’s data centers as an element of the mode of production—the combination of tools, machinery, technical expertise, and labor that propels capitalist activity. Computation is an industrial process. Data centers are created by bringing together computers (servers) and associated equipment that are manufactured using the extraction of minerals, the forging of metals, and shaping of hydrocarbons into plastics. The tech industry presents this hard physicality—which makes software useful—as a cloud, an amorphous, unlimited digital resource adding pleasure and efficiency to our lives. But there’s another way to view the cloud era: as the concentration of computational power and, therefore, real power with political consequences, into fewer and fewer hands.\nThis concentration means that only a small handful of companies—and more critically, their executives and investors—possess the ability to determine how computing capacity should be deployed. This not only grants them a vast amount of leverage, it also creates a new mode of failure. Consider the AWS outage on December 7, 2021. This event impacted many companies, including global content providers Disney and Netflix, connected devices such as Ring cameras, and even Amazon’s internal processes that utilize their computational infrastructure (“eating their own dogfood,” as we say). Before the cloud era, each organization might have made large investments in maintaining their own data centers to host the computers, storage, and networking equipment required to offer online services. But now, the access to hyperscale capability and the possibility (if not always reality) of reducing the cost of computation have pushed most companies into the cloud, leading to consolidations that have introduced new kinds of fragility.\nAt the dawn of the cloud era, none of this was apparent to me. Like my colleagues, I was focused on technical metrics such as speed and elasticity. What few of us realized is that we were facilitating the birth of a new form of power that rose, like Godzilla from the sea, to loom over everything. The cloud is rapidly becoming the computational infrastructure of global capitalism and the basis of immense digital empires that wield significant political power. But it was workers like me, hands on keyboards, toiling behind the scenes, who laid the foundation.",
      "date_published": "2022-04-20T15:00:58.000Z",
      "date_modified": "2022-04-20T15:00:58.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/in-defense-of-the-irrational",
      "url": "https://logicmag.io/clouds/in-defense-of-the-irrational",
      "title": "In Defense of the Irrational",
      "summary": "A polemic against rationalization.",
      "content_html": "<p>Rationalization is a form of compression that lays a grid over our world and attempts to remake it to fit its shape. The goal of rational thought is to break down a complex and infinite reality into small pieces and reconstitute it in a logical system. In computing, rationalization is the process by which phenomena like actions, identity, and emotions are split, stripped, reduced, standardized, and otherwise converted into computable data and mapped within machines. </p>\n<p>It is a process of rationalization that allows a company like DoorDash to use computational algorithms to determine “optimal” delivery speeds, and then to discipline its workers for not matching those predetermined outcomes. To believe in the efficacy and reliability of such a system, we must first accept that DoorDash is able to measure and model an intricately layered series of complex relationships—including traffic patterns, consumer desires, worker behaviors, prices, and more—and is then able to draw actionable predictions from all that information. To accept this requires a faith that each part in the complex system is knowable, quantifiable, and fixed. This is the ideology of rationality at work.</p>\n<p>But the world is not rational! The world is, in fact, irrational! It is chaotic, expansive, interrelational, and incalculable. Machines, in particular, are far too rigid in their logic and far too limited in their capacity to meaningfully capture the world. Yet we continue to grant them ever greater power. Across the public and private sector, computer-aided systems of management premised on transactional relationships and the supposed ability to optimize outcomes are being used to guide our interactions. As DoorDash workers will be the first to tell you, these systems shape behavior, remaking the activities and phenomena they are meant to model while radiating innumerable harms—from incentivizing unsafe driving speeds to suppressing wages—as a result. </p>\n<p>To resist this reconfiguration and mitigate these harms, we must reject rationality and embrace a fundamentally irrational worldview. If rationality says the world is measurable, knowable, optimizable, and automatible, an embrace of the irrational is a rejection of that ideology. Embracing irrationality allows for multiple interpretations, contradiction, inexplicability. It empowers us to reclaim the act of meaning-making as a collaborative, social exercise as opposed to one that can be automated and forgotten. Ultimately, a program of irrationality requires that we harness the power of our machines through a form of democratic oversight that acknowledges the false promise of rational management and insists that, in the absence of certainty, we must work together to organize society. Irrationality celebrates doubt, because only if the future is unknown will it be ours to build. </p>\n<h1><b>Rational Data from an Irrational World</b></h1>\n<p>Rationalization—the process of abstraction in the service of computational reasoning—has long been a feature of the sciences, math, and philosophy. Of course, tools of theoretical inquiry are often put to practical use by those in power. Beginning in the late nineteenth and early twentieth century, labor processes were mapped out rationally to the great benefit of early industrialists. In the postwar period, cyberneticists and game theorists, many employed by the US military, theorized that they could go beyond simple numerical equations or discrete production processes and rationally describe much more complex phenomena using newly developed computing machines. </p>\n<p>Around the end of World War II, the first general-purpose electronic computers were introduced. The data being entered into these machines was numerical, it was subjected to mechanically coded mathematical formulae, and the output was a solved equation. An amazing innovation, and one that—provided the inputs were entered accurately, and the machine operations properly encoded—returned an accurate and reliable result. An increased focus on feedback soon enabled a process known as “machine learning” through neural networks—a technique that has been revived in the last decade to propel a new AI boom, driven by breakthroughs in computer vision and natural language processing.</p>\n<p>Machine learning sorts through vast amounts of chaotic data and, using adaptive algorithms, closes in on specific arrangements of information while excluding other possible interpretations. But, in order for any computation to occur, a process of rationalization must first create machine-readable datasets. Real-world phenomena must be “datafied” by sorting it into categories and assigning fixed values. </p>\n<p>Take, for example, most image recognition software. Whether the goal is identifying handwriting or enemy combatants, a training set of data made up of digital images—themselves encoded arrangements of pixels—is typically created. This initial process of digital image capture is a form of reduction and compression; think of the difference between the sunset you experience and what that same sunset looks like when it is posted to Instagram. This mathematical translation is necessary so the machines can “see,” or, more accurately, “read” the images. </p>\n<p>But for the purposes of this kind of machine learning, further rationalization must occur to make the data usable. The digital image is identified and labeled by human operators. Maybe it is a set of handwriting examples of the numeral two, or drone images from a battlefield. Either way, someone, often an underpaid crowdworker on a platform like Amazon Mechanical Turk, decides what is meaningful within the images—what the images represent—so that the algorithms have a target to aim for. </p>\n<p>The set of labeled images is fed into software tasked with finding patterns within it. First, borders are identified in the encoded arrangement of pixels. Then larger shapes are identified. An operator observes the results and adjusts parameters to guide the system towards an optimal output. Is that a 2? Is that an enemy combatant or a civilian? </p>\n<p>Once this output has been deemed acceptable, the system is fed new, unlabeled images and asked to identify them. This new data, along with feedback on the functional accuracy of its initial output—“yes, that is a 2”—is used to further fine-tune the algorithm, the optimization of which is largely automated. This basic process applies to most machine learning systems: rationalized data is fed in, and through association, feedback, and refinement, the machine “learns” to provide better results. </p>\n<p>But rational data is an unstable foundation from which to learn. Those initial stages in the machine-learning process when phenomena are translated into code, when the irrational is rationalized and the real world is datafied, demand close scrutiny. And as the phenomena we are asking the software to interpret become more complex—as these systems are tasked with going from recognizing that an image contains a face to recognizing a specific face, to recognizing the emotion on that face, to determining what actions might result from someone in a certain emotional state—the more skeptical we should be of any supposed insights that are generated. </p>\n<p>The process of translating the world into code is reductive. There is a similar reduction in the labeling of data into certain categories—there will never be sufficient categories available to represent all possibilities. In an infinitely complex and constantly shifting world, any one-to-one representation is impossible. And anything that is lost in that original training data will be invisible to machine learning systems that are built upon it. </p>\n<p>Far from being a neutral process, the creation of training data is fundamentally social and subjective. It requires human actors to determine the available categories and label the data accordingly. The attendant assumptions, biases, and distinctions made by these human actors are necessary to create “rational” data, and once encoded they define the possibilities and limitations of what machine learning systems can “learn.” </p>\n<p>To be clear, <i>all</i> forms of knowledge-making are social and subjective, not just machine learning. The difference is that other ways of making sense of the world acknowledge their own fallibility. For instance, in academia, disciplines have developed various techniques for vetting new information, such as peer review. The issues are not always resolved, but there are processes that help create meaning collectively. </p>\n<h1><b>The Irrational Program</b></h1>\n<p>The making of meaning cannot be automated because an irrational world cannot be coded rationally. Machine learning systems, with their immense computational power, can surface novel arrangements of information and offer new forms of perception. But any claims to objectivity made on behalf of these systems should be disregarded outright. </p>\n<p>Moreover, these systems are engaged in actively shaping society to fit the models they create. When the options for human activity are reduced to a set of “optimal” choices made available through a machine-generated recommendation, other courses of action—and thus other possible future outcomes—are eliminated. We cannot allow this reduction to put limitations on the world in which we live. Instead, if these systems are to be salvaged, we have a responsibility to relentlessly interrogate who and what constitutes “data,” how it is made, what patterns we seek within it, and what we do with the insights that are surfaced. These questions must be put to the widest public forums available, and the decisions about how to respond must be made democratically. Then those questions must be asked again and again. </p>\n<p>The process of rationalization, and the technology it enables, are social in origin and have a social impact once deployed. Ultimately, we must embrace their collective nature and respond collectively. This means organizing the workers at the point of rationalization and organizing the subjects of datafication to resist until their demands for input into the development of these systems is met. We make technological systems as they make us, and we can remake or unmake them. When we recognize our role in the co-creation of technological systems, and take collective control over that process, who knows what innovations may result?</p>",
      "content_text": "Rationalization is a form of compression that lays a grid over our world and attempts to remake it to fit its shape. The goal of rational thought is to break down a complex and infinite reality into small pieces and reconstitute it in a logical system. In computing, rationalization is the process by which phenomena like actions, identity, and emotions are split, stripped, reduced, standardized, and otherwise converted into computable data and mapped within machines. \nIt is a process of rationalization that allows a company like DoorDash to use computational algorithms to determine “optimal” delivery speeds, and then to discipline its workers for not matching those predetermined outcomes. To believe in the efficacy and reliability of such a system, we must first accept that DoorDash is able to measure and model an intricately layered series of complex relationships—including traffic patterns, consumer desires, worker behaviors, prices, and more—and is then able to draw actionable predictions from all that information. To accept this requires a faith that each part in the complex system is knowable, quantifiable, and fixed. This is the ideology of rationality at work.\nBut the world is not rational! The world is, in fact, irrational! It is chaotic, expansive, interrelational, and incalculable. Machines, in particular, are far too rigid in their logic and far too limited in their capacity to meaningfully capture the world. Yet we continue to grant them ever greater power. Across the public and private sector, computer-aided systems of management premised on transactional relationships and the supposed ability to optimize outcomes are being used to guide our interactions. As DoorDash workers will be the first to tell you, these systems shape behavior, remaking the activities and phenomena they are meant to model while radiating innumerable harms—from incentivizing unsafe driving speeds to suppressing wages—as a result. \nTo resist this reconfiguration and mitigate these harms, we must reject rationality and embrace a fundamentally irrational worldview. If rationality says the world is measurable, knowable, optimizable, and automatible, an embrace of the irrational is a rejection of that ideology. Embracing irrationality allows for multiple interpretations, contradiction, inexplicability. It empowers us to reclaim the act of meaning-making as a collaborative, social exercise as opposed to one that can be automated and forgotten. Ultimately, a program of irrationality requires that we harness the power of our machines through a form of democratic oversight that acknowledges the false promise of rational management and insists that, in the absence of certainty, we must work together to organize society. Irrationality celebrates doubt, because only if the future is unknown will it be ours to build. \nRational Data from an Irrational World\nRationalization—the process of abstraction in the service of computational reasoning—has long been a feature of the sciences, math, and philosophy. Of course, tools of theoretical inquiry are often put to practical use by those in power. Beginning in the late nineteenth and early twentieth century, labor processes were mapped out rationally to the great benefit of early industrialists. In the postwar period, cyberneticists and game theorists, many employed by the US military, theorized that they could go beyond simple numerical equations or discrete production processes and rationally describe much more complex phenomena using newly developed computing machines. \nAround the end of World War II, the first general-purpose electronic computers were introduced. The data being entered into these machines was numerical, it was subjected to mechanically coded mathematical formulae, and the output was a solved equation. An amazing innovation, and one that—provided the inputs were entered accurately, and the machine operations properly encoded—returned an accurate and reliable result. An increased focus on feedback soon enabled a process known as “machine learning” through neural networks—a technique that has been revived in the last decade to propel a new AI boom, driven by breakthroughs in computer vision and natural language processing.\nMachine learning sorts through vast amounts of chaotic data and, using adaptive algorithms, closes in on specific arrangements of information while excluding other possible interpretations. But, in order for any computation to occur, a process of rationalization must first create machine-readable datasets. Real-world phenomena must be “datafied” by sorting it into categories and assigning fixed values. \nTake, for example, most image recognition software. Whether the goal is identifying handwriting or enemy combatants, a training set of data made up of digital images—themselves encoded arrangements of pixels—is typically created. This initial process of digital image capture is a form of reduction and compression; think of the difference between the sunset you experience and what that same sunset looks like when it is posted to Instagram. This mathematical translation is necessary so the machines can “see,” or, more accurately, “read” the images. \nBut for the purposes of this kind of machine learning, further rationalization must occur to make the data usable. The digital image is identified and labeled by human operators. Maybe it is a set of handwriting examples of the numeral two, or drone images from a battlefield. Either way, someone, often an underpaid crowdworker on a platform like Amazon Mechanical Turk, decides what is meaningful within the images—what the images represent—so that the algorithms have a target to aim for. \nThe set of labeled images is fed into software tasked with finding patterns within it. First, borders are identified in the encoded arrangement of pixels. Then larger shapes are identified. An operator observes the results and adjusts parameters to guide the system towards an optimal output. Is that a 2? Is that an enemy combatant or a civilian? \nOnce this output has been deemed acceptable, the system is fed new, unlabeled images and asked to identify them. This new data, along with feedback on the functional accuracy of its initial output—“yes, that is a 2”—is used to further fine-tune the algorithm, the optimization of which is largely automated. This basic process applies to most machine learning systems: rationalized data is fed in, and through association, feedback, and refinement, the machine “learns” to provide better results. \nBut rational data is an unstable foundation from which to learn. Those initial stages in the machine-learning process when phenomena are translated into code, when the irrational is rationalized and the real world is datafied, demand close scrutiny. And as the phenomena we are asking the software to interpret become more complex—as these systems are tasked with going from recognizing that an image contains a face to recognizing a specific face, to recognizing the emotion on that face, to determining what actions might result from someone in a certain emotional state—the more skeptical we should be of any supposed insights that are generated. \nThe process of translating the world into code is reductive. There is a similar reduction in the labeling of data into certain categories—there will never be sufficient categories available to represent all possibilities. In an infinitely complex and constantly shifting world, any one-to-one representation is impossible. And anything that is lost in that original training data will be invisible to machine learning systems that are built upon it. \nFar from being a neutral process, the creation of training data is fundamentally social and subjective. It requires human actors to determine the available categories and label the data accordingly. The attendant assumptions, biases, and distinctions made by these human actors are necessary to create “rational” data, and once encoded they define the possibilities and limitations of what machine learning systems can “learn.” \nTo be clear, all forms of knowledge-making are social and subjective, not just machine learning. The difference is that other ways of making sense of the world acknowledge their own fallibility. For instance, in academia, disciplines have developed various techniques for vetting new information, such as peer review. The issues are not always resolved, but there are processes that help create meaning collectively. \nThe Irrational Program\nThe making of meaning cannot be automated because an irrational world cannot be coded rationally. Machine learning systems, with their immense computational power, can surface novel arrangements of information and offer new forms of perception. But any claims to objectivity made on behalf of these systems should be disregarded outright. \nMoreover, these systems are engaged in actively shaping society to fit the models they create. When the options for human activity are reduced to a set of “optimal” choices made available through a machine-generated recommendation, other courses of action—and thus other possible future outcomes—are eliminated. We cannot allow this reduction to put limitations on the world in which we live. Instead, if these systems are to be salvaged, we have a responsibility to relentlessly interrogate who and what constitutes “data,” how it is made, what patterns we seek within it, and what we do with the insights that are surfaced. These questions must be put to the widest public forums available, and the decisions about how to respond must be made democratically. Then those questions must be asked again and again. \nThe process of rationalization, and the technology it enables, are social in origin and have a social impact once deployed. Ultimately, we must embrace their collective nature and respond collectively. This means organizing the workers at the point of rationalization and organizing the subjects of datafication to resist until their demands for input into the development of these systems is met. We make technological systems as they make us, and we can remake or unmake them. When we recognize our role in the co-creation of technological systems, and take collective control over that process, who knows what innovations may result?",
      "date_published": "2022-04-14T16:17:27.000Z",
      "date_modified": "2022-04-14T16:17:27.000Z"
    },
    {
      "id": "https://logicmag.io/clouds/very-like-a-whale",
      "url": "https://logicmag.io/clouds/very-like-a-whale",
      "title": "Very Like a Whale",
      "summary": "What’s in a Cloud?",
      "content_html": "<p><b>1/</b></p>\n<p>What’s in a cloud? </p>\n<p>Writers have long used clouds as metaphors for metaphor-making. In <i>Hamlet</i>, Hamlet messes with his girlfriend’s dad, the courtier Polonius, by pointing out the different shapes he sees: </p>\n<blockquote><p><i>H: Do you see yonder cloud that’s almost in the shape of a camel?</i></p><p><i>P: By th’ mass, and ’tis like a camel indeed.</i></p><p><i>H: Methinks it is like a weasel.</i></p><p><i>P: It is backed like a weasel.</i></p><p><i>H: Or like a whale?</i></p><p><i>P: Very like a whale.</i></p></blockquote>\n<p>As always, the play is playing with perception. Can a person ever know what’s real? Is that a reasonable thing to even care about? The point is also that Polonius cannot be trusted; he is a sycophant. Hamlet will stab him dead two scenes later.</p>\n<p><b>2/</b></p>\n<p>Clouds are ambiguous. Liquid solid. Ethereal material. As Shakespeare’s Mark Antony says, their most striking images “mock our eyes with air.”</p>\n<p>The writers in this issue think about clouds of various shapes. Several address the cloud—that is, the global archipelago of warehouses that collectively coordinate the world’s computing power.  </p>\n<p>Today, the press tends to talk about the cloud in imperial terms. It is the Valhalla of Amazon, Microsoft, Google, Alibaba; it is strongman leaders demanding data sovereignty for their country of a billion plus people. But those who have worked in data centers for decades tell a different story. The cloud, they point out, came into many firms from the bottom up, at the behest of engineers, not management. Yet even those who were there on the ground floor, who worked with “bare metal” and knew what it felt like to cut your fingers on the rails that held racks of servers in place (“a badge of honor”), could not anticipate the new forms of power that the cloud would bring. </p>\n<p>The advent of the cloud did not only create the conditions for the concentration of unprecedented amounts of wealth and information in the hands of a few firms. It also changed how rank-and-file engineers worked. The so-called Agile revolution started before the cloud took off. But it gained speed with it. Like previous developments in the computing industry, Agile combined counterculture and cyberculture; it was ostensibly rebellious, but committed rebels to sprinting toward corporate goals.  </p>\n<p>Other writers in this issue take, literally, to the sky. Aloft, clouds remain difficult to assess. Even as political consensus in favor of trying to reach “net zero” grows, climate scientists will struggle to measure emissions and to compute what it would take to offset them. One trick of the cloud metaphor is to suggest that recording and computation are everywhere, and yet hazy points remain.  </p>\n<p>Obscurities remain on clear days. Taking sprawling aerial surveillance programs in their sights, other contributors argue that the obscurity of individuals and organizations who have amassed the power to see everything must be dispelled. They share strategies for gaining information about government and corporate plans. Transparency is always a struggle.</p>\n<p>Clouds are part of the weather, and another sense of weather is the Romance language one: <i>le temps</i>, <i>el tiempo</i>, <i>il tempo</i>. Time itself. This issue explores other temporalities, and the bodies they are tied to. One writer celebrates “crip time” as an alternative to “flow,” which is not about fulfilling work discipline, but rather about learning to be stuck. Another writer imagines other times altogether. This issue contains the first speculative fiction we have published.</p>\n<p><b>3/</b></p>\n<p>Throughout human history, clouds have acted as omens. Aeromancy is the art of divining the future from the sky. This issue considers possible futures, without being too predictive; the sky is a complex canvas, and its patterns shift quickly with the wind.\n\n\n</p>",
      "content_text": "1/\nWhat’s in a cloud? \nWriters have long used clouds as metaphors for metaphor-making. In Hamlet, Hamlet messes with his girlfriend’s dad, the courtier Polonius, by pointing out the different shapes he sees: \nH: Do you see yonder cloud that’s almost in the shape of a camel?P: By th’ mass, and ’tis like a camel indeed.H: Methinks it is like a weasel.P: It is backed like a weasel.H: Or like a whale?P: Very like a whale.\nAs always, the play is playing with perception. Can a person ever know what’s real? Is that a reasonable thing to even care about? The point is also that Polonius cannot be trusted; he is a sycophant. Hamlet will stab him dead two scenes later.\n2/\nClouds are ambiguous. Liquid solid. Ethereal material. As Shakespeare’s Mark Antony says, their most striking images “mock our eyes with air.”\nThe writers in this issue think about clouds of various shapes. Several address the cloud—that is, the global archipelago of warehouses that collectively coordinate the world’s computing power.  \nToday, the press tends to talk about the cloud in imperial terms. It is the Valhalla of Amazon, Microsoft, Google, Alibaba; it is strongman leaders demanding data sovereignty for their country of a billion plus people. But those who have worked in data centers for decades tell a different story. The cloud, they point out, came into many firms from the bottom up, at the behest of engineers, not management. Yet even those who were there on the ground floor, who worked with “bare metal” and knew what it felt like to cut your fingers on the rails that held racks of servers in place (“a badge of honor”), could not anticipate the new forms of power that the cloud would bring. \nThe advent of the cloud did not only create the conditions for the concentration of unprecedented amounts of wealth and information in the hands of a few firms. It also changed how rank-and-file engineers worked. The so-called Agile revolution started before the cloud took off. But it gained speed with it. Like previous developments in the computing industry, Agile combined counterculture and cyberculture; it was ostensibly rebellious, but committed rebels to sprinting toward corporate goals.  \nOther writers in this issue take, literally, to the sky. Aloft, clouds remain difficult to assess. Even as political consensus in favor of trying to reach “net zero” grows, climate scientists will struggle to measure emissions and to compute what it would take to offset them. One trick of the cloud metaphor is to suggest that recording and computation are everywhere, and yet hazy points remain.  \nObscurities remain on clear days. Taking sprawling aerial surveillance programs in their sights, other contributors argue that the obscurity of individuals and organizations who have amassed the power to see everything must be dispelled. They share strategies for gaining information about government and corporate plans. Transparency is always a struggle.\nClouds are part of the weather, and another sense of weather is the Romance language one: le temps, el tiempo, il tempo. Time itself. This issue explores other temporalities, and the bodies they are tied to. One writer celebrates “crip time” as an alternative to “flow,” which is not about fulfilling work discipline, but rather about learning to be stuck. Another writer imagines other times altogether. This issue contains the first speculative fiction we have published.\n3/\nThroughout human history, clouds have acted as omens. Aeromancy is the art of divining the future from the sky. This issue considers possible futures, without being too predictive; the sky is a complex canvas, and its patterns shift quickly with the wind.\n\n\n",
      "date_published": "2022-04-01T22:53:49.000Z",
      "date_modified": "2022-04-01T22:53:49.000Z"
    },
    {
      "id": "https://logicmag.io/beacons/ontology-of-god-and-other-poems",
      "url": "https://logicmag.io/beacons/ontology-of-god-and-other-poems",
      "title": "Ontology of God and Other Poems",
      "summary": "A series of poems clocking the commonplace and the sacred, with a foreword by Joshua Bennett.",
      "content_html": "<h1><b>Ontology of God</b></h1>\n<p>Big Mike says <i>I read that dogs</i></p>\n<p><i>don’t have a sense of time</i>       a minute </p>\n<p>is like an hour an hour like a day</p>\n<p>             a day like a minute. The continuity</p>\n<p></p>\n<p> </p>\n<p></p>\n<p>is skewed &amp; time is placed without</p>\n<p>thought into various boxes. I think </p>\n<p>what it must be like to be</p>\n<p>a dog because                 yes       I be </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>with my dogs in this massive cage</p>\n<p>             trying to exhaust every thread</p>\n<p>of thought surrounding time. Maybe</p>\n<p>that’s why we say things like <i>Oh, [name]</i>? </p>\n<p><i></i></p>\n<p> </p>\n<p><i></i></p>\n<p><i>Yeah that’s </i>my<i> dog</i> &amp; use <i>dog</i></p>\n<p>as a placeholder for when we secret</p>\n<p>the names of those involved</p>\n<p>             in the robbery stabbing         extortion. </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>              We want to shake off the slough</p>\n<p>of our numbered bodies            hieroglyphs </p>\n<p>              in our skin sluiced onto the floor. </p>\n<p>We want to live in a space </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>free of calendars &amp; clocks &amp; the minutes</p>\n<p>             we must share              but the high</p>\n<p>fruits are not ready to fall from this</p>\n<p>life. Not yet. Ciph &amp; Civ claim God </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>body &amp; who am I to tell them otherwise</p>\n<p>               when we all want to claim</p>\n<p>master                            key to lock                    silo</p>\n<p>to grain &amp; again own the con-</p>\n<p></p>\n<p> </p>\n<p></p>\n<p>tents of our own dufflebags &amp; spoken</p>\n<p>languages without restraint. Still</p>\n<p>when I call Doc he says <i>What’s good</i></p>\n<p><i>God?</i> &amp; tells me about my god-</p>\n<p></p>\n<p> </p>\n<p></p>\n<p>daughter           her mews &amp; her small body</p>\n<p>taking hold of the world around</p>\n<p>             her. When I buried my faith</p>\n<p>I didn’t dig deep                        no           I didn’t </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>&amp; from the dirt sprung forth a woman</p>\n<p>I asked her                      I said <i>What is your name?</i></p>\n<p>&amp; she just smiled past me      which left</p>\n<p>me confused. When I woke up</p>\n<p></p>\n<p> </p>\n<p></p>\n<p>            I went to commune with the poodle</p>\n<p>down the hall who quietly trotted </p>\n<p>around while her master</p>\n<p>played cards. </p>\n<p></p>\n<h1><b>Bodies of Water</b></h1>\n<p><i>There are no empty vessels when everything has proper weight.</i></p>\n<p> — James Wood </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>Sitting in the substance abuse class we talk</p>\n<p>about moderation                     the therapist</p>\n<p>                Elissa loosening the clenched jaws each man </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>has labored for years to claim as his own </p>\n<p>                          opening the floor to the stories we </p>\n<p>claim. The watch-words are <i>criminal thinking</i> </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>&amp; this is commonplace. This is everyday </p>\n<p>in the joint                       correction. That’s what this is </p>\n<p>             correction                           correction in the depart- </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>ment of closely governed boxes.                  Bodies </p>\n<p>of water are different                 no longer </p>\n<p>signified in themselves                     but              these            bursting </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>symbols                       overflowing with money &amp; </p>\n<p>drugs &amp; the women we see in photo- </p>\n<p>copied porn. They become our desires </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>transposed amongst the pasts we had assumed </p>\n<p>to be ours                       stories we lived in real-time </p>\n<p>             yet are read fast by this institution </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>as empty glasses                         vessels to be filled </p>\n<p>&amp; tossed long into whatever ocean </p>\n<p>borders the nation with the most bullets </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>&amp; the most mechanisms to keep us </p>\n<p>from loading those bullets. We are thirsty </p>\n<p>for any other ocean                 for bodies </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>of water                      not                       weighted with the remnants</p>\n<p>of these floating cages                            of correction</p>\n<p>             of anything unseen                               but still policed. </p>\n<p><b></b></p>\n<h1><b>Intro</b></h1>\n<p>I don’t know how I ended</p>\n<p>up         here       yeah actually I </p>\n<p>know. I called it              I made myself </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>a dumb prophet &amp; cuffed my own </p>\n<p>wrists like a God who creates </p>\n<p>&amp; creates         &amp; creates         too </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>many worlds to wave his hand                     or </p>\n<p>whatever he believes he’s doing </p>\n<p>             over &amp; grant the prayers </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>of his reckless children. He gets </p>\n<p>mad because he gets shown up.           He </p>\n<p>fails at the feet of his </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>creations. I know how </p>\n<p>I got here.         When I first came </p>\n<p>down    they tested my criminal- </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>ity by sitting me down </p>\n<p>in a small room                        an office </p>\n<p>           giving me a battery </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>of statements like <i>If my fam- </i></p>\n<p><i>ily gets hurt I feel the urge </i></p>\n<p><i>to retaliate </i>&amp; <i>some </i></p>\n<p><i></i></p>\n<p> </p>\n<p><i></i></p>\n<p><i>people deserve to be pun- </i></p>\n<p><i>ished</i> (that one I laughed at). I was </p>\n<p>to answer with agreement                      or </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>strong denial. I must have </p>\n<p>passed                             my report read <i>Low Prob- </i></p>\n<p><i>ability of Reoffense</i> </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>            but a sentence is a sentence </p>\n<p>            &amp; now it’s almost a decade </p>\n<p>with more to go &amp; all my files </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>in a drawer full of other </p>\n<p>men’s histories                      so many </p>\n<p>histories. Do you know </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>the stories       Do you know who </p>\n<p>I am       Do you understand </p>\n<p>what I am           Can I tell you </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>             I’ll try to sing this broken </p>\n<p>song    &amp; summon my tribe      ones </p>\n<p>who will one day carry me </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>home    &amp; damn            damn       I know </p>\n<p>it’s a moonshot but        maybe </p>\n<p>you’ll come find me before I lose </p>\n<p></p>\n<p> </p>\n<p></p>\n<p>myself in this jungle. </p>",
      "content_text": "Ontology of God\nBig Mike says I read that dogs\ndon’t have a sense of time       a minute \nis like an hour an hour like a day\n             a day like a minute. The continuity\n\n \n\nis skewed & time is placed without\nthought into various boxes. I think \nwhat it must be like to be\na dog because                 yes       I be \n\n \n\nwith my dogs in this massive cage\n             trying to exhaust every thread\nof thought surrounding time. Maybe\nthat’s why we say things like Oh, [name]? \n\n \n\nYeah that’s my dog & use dog\nas a placeholder for when we secret\nthe names of those involved\n             in the robbery stabbing         extortion. \n\n \n\n              We want to shake off the slough\nof our numbered bodies            hieroglyphs \n              in our skin sluiced onto the floor. \nWe want to live in a space \n\n \n\nfree of calendars & clocks & the minutes\n             we must share              but the high\nfruits are not ready to fall from this\nlife. Not yet. Ciph & Civ claim God \n\n \n\nbody & who am I to tell them otherwise\n               when we all want to claim\nmaster                            key to lock                    silo\nto grain & again own the con-\n\n \n\ntents of our own dufflebags & spoken\nlanguages without restraint. Still\nwhen I call Doc he says What’s good\nGod? & tells me about my god-\n\n \n\ndaughter           her mews & her small body\ntaking hold of the world around\n             her. When I buried my faith\nI didn’t dig deep                        no           I didn’t \n\n \n\n& from the dirt sprung forth a woman\nI asked her                      I said What is your name?\n& she just smiled past me      which left\nme confused. When I woke up\n\n \n\n            I went to commune with the poodle\ndown the hall who quietly trotted \naround while her master\nplayed cards. \n\nBodies of Water\nThere are no empty vessels when everything has proper weight.\n — James Wood \n\n \n\nSitting in the substance abuse class we talk\nabout moderation                     the therapist\n                Elissa loosening the clenched jaws each man \n\n \n\nhas labored for years to claim as his own \n                          opening the floor to the stories we \nclaim. The watch-words are criminal thinking \n\n \n\n& this is commonplace. This is everyday \nin the joint                       correction. That’s what this is \n             correction                           correction in the depart- \n\n \n\nment of closely governed boxes.                  Bodies \nof water are different                 no longer \nsignified in themselves                     but              these            bursting \n\n \n\nsymbols                       overflowing with money & \ndrugs & the women we see in photo- \ncopied porn. They become our desires \n\n \n\ntransposed amongst the pasts we had assumed \nto be ours                       stories we lived in real-time \n             yet are read fast by this institution \n\n \n\nas empty glasses                         vessels to be filled \n& tossed long into whatever ocean \nborders the nation with the most bullets \n\n \n\n& the most mechanisms to keep us \nfrom loading those bullets. We are thirsty \nfor any other ocean                 for bodies \n\n \n\nof water                      not                       weighted with the remnants\nof these floating cages                            of correction\n             of anything unseen                               but still policed. \n\nIntro\nI don’t know how I ended\nup         here       yeah actually I \nknow. I called it              I made myself \n\n \n\na dumb prophet & cuffed my own \nwrists like a God who creates \n& creates         & creates         too \n\n \n\nmany worlds to wave his hand                     or \nwhatever he believes he’s doing \n             over & grant the prayers \n\n \n\nof his reckless children. He gets \nmad because he gets shown up.           He \nfails at the feet of his \n\n \n\ncreations. I know how \nI got here.         When I first came \ndown    they tested my criminal- \n\n \n\nity by sitting me down \nin a small room                        an office \n           giving me a battery \n\n \n\nof statements like If my fam- \nily gets hurt I feel the urge \nto retaliate & some \n\n \n\npeople deserve to be pun- \nished (that one I laughed at). I was \nto answer with agreement                      or \n\n \n\nstrong denial. I must have \npassed                             my report read Low Prob- \nability of Reoffense \n\n \n\n            but a sentence is a sentence \n            & now it’s almost a decade \nwith more to go & all my files \n\n \n\nin a drawer full of other \nmen’s histories                      so many \nhistories. Do you know \n\n \n\nthe stories       Do you know who \nI am       Do you understand \nwhat I am           Can I tell you \n\n \n\n             I’ll try to sing this broken \nsong    & summon my tribe      ones \nwho will one day carry me \n\n \n\nhome    & damn            damn       I know \nit’s a moonshot but        maybe \nyou’ll come find me before I lose \n\n \n\nmyself in this jungle. ",
      "date_published": "2022-03-15T17:41:14.000Z",
      "date_modified": "2022-03-15T17:41:14.000Z"
    },
    {
      "id": "https://logicmag.io/beacons/dismantling-the-garden",
      "url": "https://logicmag.io/beacons/dismantling-the-garden",
      "title": "Disrupting the Garden Walls",
      "summary": "An inquiry into the technologies of speech-based societies.",
      "content_html": "<p>The first time that I borrowed someone else’s voice I was six years old. After surviving two years in care-less foster homes, I had recently moved in with a family I loved and hoped to be a part of permanently. But, I worried, would I really get to stay? At the time, with no other recognizable means to communicate, I used the trailer for the film <i>Angels in the Outfield</i> to ask my most pressing question: “Dad, when are we gonna be a family?” I knew exactly when the kid popped the question, and when I saw him turn to face his dad, I’d hit STOP on the VCR. It took a number of tries before my parents learned to hear me, but eventually they did and began reassuring me that I was there to stay.</p>\n<p>We soon began creating a number of tools to communicate with each other. Cameras became our main translators. My parents took pictures of everything: activities, places, people, foods. They used the photos to make sure I understood them and to teach me how to make choices by picking photos of what I wanted. I could escape a plate of cauliflower by bringing them a logo for KFC. Each photograph was labelled with the printed word, so I could learn sight words and begin to understand what they were saying. Still, not everything could be captured in a photo. I needed other means of communication to say “stop” when my dad tickled me and I needed to catch my breath, and a way to say “bathroom,” when I needed to pee NOW. And so we developed a basic sign language to convey essential messages. Instead of insisting I join their speaking world, my parents learned these new languages with me.</p>\n<p>When it was time to start regular kindergarten at my neighborhood school, I brought my languages with me. Before long, my classmates and I were all using photos and learning to spell with our fingers. But participating in school also required new technologies. I started using a simple voice-output device like the single-switch BIGmack and Cheap Talk 8 that allowed me to play pre-recorded messages in either my mom’s or dad’s voice to answer questions during class. Because I had learned to communicate in these ways, I was taught to read and write, first with laminated sight words and later with a seventeen dollar label maker from Staples.</p>\n<p>By the time I entered middle school in 2003, written English had become my dominant mode of communication, and I began to develop a public voice. As my language got more sophisticated, so did my devices. The Gemini—a large laptop device with a touchscreen that was a quarter of my weight—allowed me to create a countless number of expressions with any degree of sophistication. In ninth grade, I got the Dynavox, a smaller but similarly heavy equivalent to the Gemini, with a clearer mechanical voice. It had a hard drive prepopulated with thousands of phrases, but they didn’t sound like me. With one finger, I laboriously programmed in as many of my own phrases as I could. </p>\n<p>For more private conversations, I far preferred the silence of written words. I brought my labeler with me everywhere, using it to converse with friends and process trauma with my therapist. It wasn’t until the tenth grade, when I got my first laptop with text-to-speech software, that I had one lightweight device that allowed me to communicate silently or speak with a digital or recorded voice. </p>\n<p>These are only some of the different technologies and modes of communication that I have used over the past two decades to gain entry—and be heard—in speech-based society. Speech-generating computers and augmentative and alternative communication (AAC) devices, like the Gemini and Dynavox, have allowed me to contribute to discussions about my people, as well as the world around us. Because they are easy for hearing-based communities to comprehend and sophisticated enough for us to convey complicated ideas in an apparently timely and efficient manner, communication technologies have given me and other alternatively communicating people a voice to be heard by large groups of people over space and time. But those technologies have also worked to define—and confine—us through their economics, their software, and the ways in which they reinforce ableist culture and notions of how communication ought to be structured.</p>\n<p>AAC devices have been around for over seventy years, yet most nonspeaking people in the US still experience widespread segregation in school and throughout their lives. I am one of only two alternatively communicating autistics to be fully mainstreamed from kindergarten through college graduation. One of the problems is accessibility. In our society, the Gemini and the Dynavox cost $12,000 and $9,000, respectively. Even at $500, an iPad with text-to-speech software is still unattainable for many disabled adults on social security, who receive $770 per month to cover all of their living expenses. </p>\n<p>Even for the relatively small number of us who can access these technologies, we are too often left to rely on prerecorded, preordained messages—to speak only the devices’ language. In our speech-centric, hearing-privileged society, speakers are unquestioningly assumed to be able-bodied, self-reliant individuals whose vocal cords effortlessly produce spoken words and whose ears naturally decode spoken language. AAC devices have been designed to mimic this narrow “ideal.” According to research, 90 percent of what a person says in a given day is made up of repetitive, automatic phrases. AAC devices are populated only with these generic messages. </p>\n<p>This ableist design assumes speakers know best what others should say and limits the kinds of relationships nontraditional communicators can form. The technology also renders invisible how much effort and time it takes to communicate this way, and it requires nothing of the speaking, hearing world. When we choose not to use AAC devices—with their stiff, generic, confining, and inauthentic prerecorded messages—society usually stops offering us other ways to connect and instead declares us “uneducable,” “untrainable,” “asocial,” “unempathetic” and “willingly walled off from the world.”</p>\n<p>I have come to think of ableism as the cultivated garden of a speech-based society. Many assistive technologies assume the disabled are outsiders, striving to inhabit that cultivated garden. These technologies don’t change the world we live in; they just allow a few of us to climb up and over the garden wall, helping us pass or pose as independent, able-bodied, speakers. Once in the garden, we are seen as validating the status quo, further fortifying the very walls that many of us hope to dismantle with other technologies, other modes of communicating, other ways of being.</p>\n<h1><b>Hearing in Red</b></h1>\n<p>We do not have a ready word for the kind of flexible communication that I practice. Instead of calling someone who uses this kind of flexible communication a “multimodal communicator,” as I choose to do, people like me are labelled “nonspeaking.” People use the verbal/nonverbal binary to render nonspeakers unheard and therefore invisible. In a speech-centric, hearing-privileged world, we are always seen as disabled, lacking. “Success stories,” maybe; “inspirations,” perhaps—but always on others’ terms. What would it mean to build technologies that create opportunities for more multimodal communication and the dense interpersonal connections such communication offers?</p>\n<p>For the past five years, I have been working through a combination of art and activism to imagine what these other modes of communication might be. My starting points are the modes of communication that I used as a child. There was an interdependent flourishing that formed around the technologies my classmates and I used in my early school years. These technologies were more multisensory, more communal, and in a sense more democratic; in pictures, sign language, and tangible sight words, my parents, teachers, friends, and I were all learners, all teachers. Using these alternative, communal languages, others in our classroom considered “at-risk for school failure” found their own pathways to literacy: some learned to spell with their fingers, others learning English as a second language used photographs as helpful translators, and visual learners found that pictures grounded in meaning what fleeting, spoken words could not. </p>\n<p>A decade and a half later, I had another insight into multimodal communication. In 2016, I was late into my undergraduate thesis in Anthropology, before I realized I was writing an autoethnographic study that completely left out the contributions of people who prefer nonalphabetic languages and that remained largely inaccessible to the majority of nontraditional communicators, who are never taught to read. A high achiever in mainstream education from kindergarten through college, I had come to communicate almost entirely in written English. What, I wondered, might I have lost in the process? I began engaging with the visual artwork of various autistics, eventually compelled by the drawings, paintings, and sculptures of seven artists to write a poetic series. By the last poem, modes of communication had begun to blur as I proudly tell five-year-old impressionist artist Iris Grace that “I’m no longer visual exactly; nor am I verbal. When I type, my fingers speak / with an accent.”</p>\n<p>Around the same time I was finishing my thesis, production was also wrapping up on <i>Deej: Inclusion Shouldn’t be a Lottery</i>, a documentary about my life, which I co-produced and narrated. In the first four minutes of the film, I use a myriad of technologies—my laptop and Dynavox, trees, walls, backpack, other people’s bodies and voices, film, literacy, and a combination of spoken poetry and animation—to maneuver my way past communication and physical barriers at my high school. That opening sequence is something of a model for what I imagine communication might be like in a world that doesn’t privilege speech over other, more interdependent, modes of communication.</p>\n<p>The strongest example of this multimodal way of communicating are the parts of the film when my poetry and the oil-paint animations of the British artist Em Cooper converse with each other. In Cooper’s constantly flowing work, no image is static. Figures emerge briefly and then merge into the background, before re-forming into other figures; everything blurs into everything else. In a dynamic that seemed to reproduce the differences between speech-dominant cultures and more multimodal ways of connecting, other animators who were approached to work on the film took my words too literally, pairing the lines “The ear that hears the cardinal hears in red” with a cartoon cardinal and “The eye that spots the salmon sees in wet” with an animated salmon. Cooper’s brushstrokes, by contrast, were full of color, motion, and texture, occasionally offering a fleeting trace of vines, volcanoes, waves, or flags—metaphors I had used elsewhere in my writing to describe myself or challenge the world we lived in. </p>\n<p>Cooper and I never thought we were taking everyone in the audience to the same destination; instead, we offered people multiple pathways into a world in which everything is interwoven, where motion, rhythm, pattern, color, sound, and texture freely interact, offering endlessly unfolding possibilities. I recognized, however, that this was a rarefied means of communicating; not something that could always be open to me, let alone anyone else. Four years later, at the outset of the pandemic, I began to ask myself how technology might allow us to create new communities in which diverse bodies, voices, and language might come together, as they had in my collaboration with Cooper, and thrive, much like we all had in kindergarten. </p>\n<p>Cut off and segregated in my own home, I turned again to poetry and technology to create some alternative pathways: co-teaching multigenerational, global, and intersectional poetry writing courses for beginning poets, and collaborating with three fellow poets based on the artwork of the artist Malcolm Corley, who is also autistic. In both the courses and the collaboration, speakers and alternative communicators came together to make work that challenged the supremacy of speech-based culture. Traces of our entanglements live on in a chapbook,<i> Studies in Brotherly Love</i>. In the introduction, poet Claretta Holsey describes our modes of communication this way: “We crafted poems that speak to us and to our causes: awareness of performative utterances, as communication can and does happen outside of written text, outside of simple speech; embrace of Black vernacular, its rhythm and blues; recognition of the Black family as a model of resilience; respect for nature, which awes and overwhelms; respect for the body, made vulnerable by want.”</p>\n<p>Imagining that technology alone can liberate us is a bit shortsighted and, in some ways, disabling. But, if we imagine the cultivated garden of a speech-based society is the only way of being, then the communication technologies we build will continue to keep us stuck in an inclusion/exclusion binary, in which some beings are seen as disposable and others not.</p>",
      "content_text": "The first time that I borrowed someone else’s voice I was six years old. After surviving two years in care-less foster homes, I had recently moved in with a family I loved and hoped to be a part of permanently. But, I worried, would I really get to stay? At the time, with no other recognizable means to communicate, I used the trailer for the film Angels in the Outfield to ask my most pressing question: “Dad, when are we gonna be a family?” I knew exactly when the kid popped the question, and when I saw him turn to face his dad, I’d hit STOP on the VCR. It took a number of tries before my parents learned to hear me, but eventually they did and began reassuring me that I was there to stay.\nWe soon began creating a number of tools to communicate with each other. Cameras became our main translators. My parents took pictures of everything: activities, places, people, foods. They used the photos to make sure I understood them and to teach me how to make choices by picking photos of what I wanted. I could escape a plate of cauliflower by bringing them a logo for KFC. Each photograph was labelled with the printed word, so I could learn sight words and begin to understand what they were saying. Still, not everything could be captured in a photo. I needed other means of communication to say “stop” when my dad tickled me and I needed to catch my breath, and a way to say “bathroom,” when I needed to pee NOW. And so we developed a basic sign language to convey essential messages. Instead of insisting I join their speaking world, my parents learned these new languages with me.\nWhen it was time to start regular kindergarten at my neighborhood school, I brought my languages with me. Before long, my classmates and I were all using photos and learning to spell with our fingers. But participating in school also required new technologies. I started using a simple voice-output device like the single-switch BIGmack and Cheap Talk 8 that allowed me to play pre-recorded messages in either my mom’s or dad’s voice to answer questions during class. Because I had learned to communicate in these ways, I was taught to read and write, first with laminated sight words and later with a seventeen dollar label maker from Staples.\nBy the time I entered middle school in 2003, written English had become my dominant mode of communication, and I began to develop a public voice. As my language got more sophisticated, so did my devices. The Gemini—a large laptop device with a touchscreen that was a quarter of my weight—allowed me to create a countless number of expressions with any degree of sophistication. In ninth grade, I got the Dynavox, a smaller but similarly heavy equivalent to the Gemini, with a clearer mechanical voice. It had a hard drive prepopulated with thousands of phrases, but they didn’t sound like me. With one finger, I laboriously programmed in as many of my own phrases as I could. \nFor more private conversations, I far preferred the silence of written words. I brought my labeler with me everywhere, using it to converse with friends and process trauma with my therapist. It wasn’t until the tenth grade, when I got my first laptop with text-to-speech software, that I had one lightweight device that allowed me to communicate silently or speak with a digital or recorded voice. \nThese are only some of the different technologies and modes of communication that I have used over the past two decades to gain entry—and be heard—in speech-based society. Speech-generating computers and augmentative and alternative communication (AAC) devices, like the Gemini and Dynavox, have allowed me to contribute to discussions about my people, as well as the world around us. Because they are easy for hearing-based communities to comprehend and sophisticated enough for us to convey complicated ideas in an apparently timely and efficient manner, communication technologies have given me and other alternatively communicating people a voice to be heard by large groups of people over space and time. But those technologies have also worked to define—and confine—us through their economics, their software, and the ways in which they reinforce ableist culture and notions of how communication ought to be structured.\nAAC devices have been around for over seventy years, yet most nonspeaking people in the US still experience widespread segregation in school and throughout their lives. I am one of only two alternatively communicating autistics to be fully mainstreamed from kindergarten through college graduation. One of the problems is accessibility. In our society, the Gemini and the Dynavox cost $12,000 and $9,000, respectively. Even at $500, an iPad with text-to-speech software is still unattainable for many disabled adults on social security, who receive $770 per month to cover all of their living expenses. \nEven for the relatively small number of us who can access these technologies, we are too often left to rely on prerecorded, preordained messages—to speak only the devices’ language. In our speech-centric, hearing-privileged society, speakers are unquestioningly assumed to be able-bodied, self-reliant individuals whose vocal cords effortlessly produce spoken words and whose ears naturally decode spoken language. AAC devices have been designed to mimic this narrow “ideal.” According to research, 90 percent of what a person says in a given day is made up of repetitive, automatic phrases. AAC devices are populated only with these generic messages. \nThis ableist design assumes speakers know best what others should say and limits the kinds of relationships nontraditional communicators can form. The technology also renders invisible how much effort and time it takes to communicate this way, and it requires nothing of the speaking, hearing world. When we choose not to use AAC devices—with their stiff, generic, confining, and inauthentic prerecorded messages—society usually stops offering us other ways to connect and instead declares us “uneducable,” “untrainable,” “asocial,” “unempathetic” and “willingly walled off from the world.”\nI have come to think of ableism as the cultivated garden of a speech-based society. Many assistive technologies assume the disabled are outsiders, striving to inhabit that cultivated garden. These technologies don’t change the world we live in; they just allow a few of us to climb up and over the garden wall, helping us pass or pose as independent, able-bodied, speakers. Once in the garden, we are seen as validating the status quo, further fortifying the very walls that many of us hope to dismantle with other technologies, other modes of communicating, other ways of being.\nHearing in Red\nWe do not have a ready word for the kind of flexible communication that I practice. Instead of calling someone who uses this kind of flexible communication a “multimodal communicator,” as I choose to do, people like me are labelled “nonspeaking.” People use the verbal/nonverbal binary to render nonspeakers unheard and therefore invisible. In a speech-centric, hearing-privileged world, we are always seen as disabled, lacking. “Success stories,” maybe; “inspirations,” perhaps—but always on others’ terms. What would it mean to build technologies that create opportunities for more multimodal communication and the dense interpersonal connections such communication offers?\nFor the past five years, I have been working through a combination of art and activism to imagine what these other modes of communication might be. My starting points are the modes of communication that I used as a child. There was an interdependent flourishing that formed around the technologies my classmates and I used in my early school years. These technologies were more multisensory, more communal, and in a sense more democratic; in pictures, sign language, and tangible sight words, my parents, teachers, friends, and I were all learners, all teachers. Using these alternative, communal languages, others in our classroom considered “at-risk for school failure” found their own pathways to literacy: some learned to spell with their fingers, others learning English as a second language used photographs as helpful translators, and visual learners found that pictures grounded in meaning what fleeting, spoken words could not. \nA decade and a half later, I had another insight into multimodal communication. In 2016, I was late into my undergraduate thesis in Anthropology, before I realized I was writing an autoethnographic study that completely left out the contributions of people who prefer nonalphabetic languages and that remained largely inaccessible to the majority of nontraditional communicators, who are never taught to read. A high achiever in mainstream education from kindergarten through college, I had come to communicate almost entirely in written English. What, I wondered, might I have lost in the process? I began engaging with the visual artwork of various autistics, eventually compelled by the drawings, paintings, and sculptures of seven artists to write a poetic series. By the last poem, modes of communication had begun to blur as I proudly tell five-year-old impressionist artist Iris Grace that “I’m no longer visual exactly; nor am I verbal. When I type, my fingers speak / with an accent.”\nAround the same time I was finishing my thesis, production was also wrapping up on Deej: Inclusion Shouldn’t be a Lottery, a documentary about my life, which I co-produced and narrated. In the first four minutes of the film, I use a myriad of technologies—my laptop and Dynavox, trees, walls, backpack, other people’s bodies and voices, film, literacy, and a combination of spoken poetry and animation—to maneuver my way past communication and physical barriers at my high school. That opening sequence is something of a model for what I imagine communication might be like in a world that doesn’t privilege speech over other, more interdependent, modes of communication.\nThe strongest example of this multimodal way of communicating are the parts of the film when my poetry and the oil-paint animations of the British artist Em Cooper converse with each other. In Cooper’s constantly flowing work, no image is static. Figures emerge briefly and then merge into the background, before re-forming into other figures; everything blurs into everything else. In a dynamic that seemed to reproduce the differences between speech-dominant cultures and more multimodal ways of connecting, other animators who were approached to work on the film took my words too literally, pairing the lines “The ear that hears the cardinal hears in red” with a cartoon cardinal and “The eye that spots the salmon sees in wet” with an animated salmon. Cooper’s brushstrokes, by contrast, were full of color, motion, and texture, occasionally offering a fleeting trace of vines, volcanoes, waves, or flags—metaphors I had used elsewhere in my writing to describe myself or challenge the world we lived in. \nCooper and I never thought we were taking everyone in the audience to the same destination; instead, we offered people multiple pathways into a world in which everything is interwoven, where motion, rhythm, pattern, color, sound, and texture freely interact, offering endlessly unfolding possibilities. I recognized, however, that this was a rarefied means of communicating; not something that could always be open to me, let alone anyone else. Four years later, at the outset of the pandemic, I began to ask myself how technology might allow us to create new communities in which diverse bodies, voices, and language might come together, as they had in my collaboration with Cooper, and thrive, much like we all had in kindergarten. \nCut off and segregated in my own home, I turned again to poetry and technology to create some alternative pathways: co-teaching multigenerational, global, and intersectional poetry writing courses for beginning poets, and collaborating with three fellow poets based on the artwork of the artist Malcolm Corley, who is also autistic. In both the courses and the collaboration, speakers and alternative communicators came together to make work that challenged the supremacy of speech-based culture. Traces of our entanglements live on in a chapbook, Studies in Brotherly Love. In the introduction, poet Claretta Holsey describes our modes of communication this way: “We crafted poems that speak to us and to our causes: awareness of performative utterances, as communication can and does happen outside of written text, outside of simple speech; embrace of Black vernacular, its rhythm and blues; recognition of the Black family as a model of resilience; respect for nature, which awes and overwhelms; respect for the body, made vulnerable by want.”\nImagining that technology alone can liberate us is a bit shortsighted and, in some ways, disabling. But, if we imagine the cultivated garden of a speech-based society is the only way of being, then the communication technologies we build will continue to keep us stuck in an inclusion/exclusion binary, in which some beings are seen as disposable and others not.",
      "date_published": "2022-03-08T15:17:28.000Z",
      "date_modified": "2022-03-08T15:17:28.000Z"
    }
  ],
  "description": "Logic is a new magazine devoted to deepening the discourse around technology. We publish three times per year in print and digital formats.",
  "home_page_url": "https://logicmag.io",
  "icon": "https://logicmag.io/images/rss-icon.jpeg"
}